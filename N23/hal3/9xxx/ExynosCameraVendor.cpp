/*
**
** Copyright 2017, Samsung Electronics Co. LTD
**
** Licensed under the Apache License, Version 2.0 (the "License");
** you may not use this file except in compliance with the License.
** You may obtain a copy of the License at
**
**     http://www.apache.org/licenses/LICENSE-2.0
**
** Unless required by applicable law or agreed to in writing, software
** distributed under the License is distributed on an "AS IS" BASIS,
** WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
** See the License for the specific language governing permissions and
** limitations under the License.
*/

/* #define LOG_NDEBUG 0 */
#define LOG_TAG "ExynosCameraSec"
#include <log/log.h>

#include "ExynosCamera.h"
#include "fimc-is-metadata.h"
#include "ExynosGraphicBuffer.h"

#ifdef SUPPORT_REMOSAIC_CAPTURE
#include "ExynosCameraFrameReprocessingFactoryRemosaic.h"
#endif //SUPPORT_REMOSAIC_CAPTURE
#ifdef USE_DEBUG_PROPERTY
#include "ExynosCameraProperty.h"
#endif

#include "ExynosCameraResourceManager.h"

#ifdef USES_OFFLINE_CAPTURE
#include "OfflineProcessing/ExynosCameraOfflineCapture.h"
#endif

#define HAL_DATASPACE_SDR_PREVIEW (android_dataspace_t)(HAL_DATASPACE_STANDARD_BT709 | HAL_DATASPACE_TRANSFER_SMPTE_170M | HAL_DATASPACE_RANGE_FULL)

#define HAL_DATASPACE_HDR10_REC (android_dataspace_t)(HAL_DATASPACE_STANDARD_BT2020 | HAL_DATASPACE_TRANSFER_ST2084 | HAL_DATASPACE_RANGE_LIMITED)
#define HAL_DATASPACE_SDR_REC (android_dataspace_t)(HAL_DATASPACE_STANDARD_BT709 | HAL_DATASPACE_TRANSFER_SMPTE_170M | HAL_DATASPACE_RANGE_LIMITED)

using vendor::graphics::BufferUsage;
using vendor::graphics::ExynosGraphicBufferUsage;
using vendor::graphics::ExynosGraphicBufferMeta;

namespace android {

void ExynosCamera::m_vendorSpecificPreConstructor(int cameraId, int scenario)
{
    CLOGI("-IN-");

    m_vendorSpecificPreConstructorInitalize(cameraId, scenario);

    CLOGI("-OUT-");

    return;
}

void ExynosCamera::m_vendorSpecificConstructor(void)
{
    CLOGI("-IN-");

    m_thumbnailCbQ = new frame_queue_t;
    m_thumbnailCbQ->setWaitTime(1000000000);

    m_thumbnailPostCbQ = new frame_queue_t;
    m_thumbnailPostCbQ->setWaitTime(1000000000);

    m_resizeDoneQ = new frame_queue_t;
    m_resizeDoneQ->setWaitTime(1000000000);

    m_resizeYuvDoneQ = new frame_queue_t;
    m_resizeYuvDoneQ->setWaitTime(1000000000);

    m_currentMultiCaptureMode = MULTI_CAPTURE_MODE_NONE;
    m_lastMultiCaptureServiceRequest = -1;
    m_lastMultiCaptureSkipRequest = -1;
    m_lastMultiCaptureNormalRequest = -1;
    m_doneMultiCaptureRequest = -1;

    for (int i = 0; i < 2; i++) {
        m_previewDurationTime[i] = 0;
    }
    m_captureResultToggle = 0;
    m_displayPreviewToggle = 0;

    m_longExposureRemainCount = 0;
    m_stopLongExposure = false;
    m_preLongExposureTime = 0;

    for (int i = 0; i < 4; i++)
        m_burstFps_history[i] = -1;

    m_flagUseInternalyuvStall = false;
    m_flagVideoStreamPriority = false;
    m_flagUseOnePort = false;

    memset(&m_stats, 0x00, sizeof(struct camera2_stats_dm));

    m_shutterSpeed = 0;
    m_gain = 0;
    m_irLedWidth = 0;
    m_irLedDelay = 0;
    m_irLedCurrent = 0;
    m_irLedOnTime = 0;

    m_vendorSpecificConstructorInitalize();

    CLOGI("-OUT-");

    return;
}

void ExynosCamera::m_vendorSpecificPreDestructor(void)
{
    CLOGI("-IN-");

    m_vendorSpecificPreDestructorDeinitalize();

    CLOGI("-OUT-");

    return;
}

void ExynosCamera::m_vendorSpecificDestructor(void)
{
    CLOGI("-IN-");

    m_thumbnailCbThread->requestExitAndWait();

    if (m_thumbnailCbQ != NULL) {
        delete m_thumbnailCbQ;
        m_thumbnailCbQ = NULL;
    }

    if (m_thumbnailPostCbQ != NULL) {
        delete m_thumbnailPostCbQ;
        m_thumbnailPostCbQ = NULL;
    }

    if (m_resizeDoneQ != NULL) {
        delete m_resizeDoneQ;
        m_resizeDoneQ = NULL;
    }

    m_vendorSpecificDestructorDeinitalize();

    CLOGI("-OUT-");

    return;
}

void ExynosCamera::m_vendorCreateThreads(void)
{
    /* m_ThumbnailCallback Thread */
    m_thumbnailCbThread = new mainCameraThread(this, &ExynosCamera::m_thumbnailCbThreadFunc, "m_thumbnailCbThread");
    CLOGD("m_thumbnailCbThread created");

#ifdef USES_SENSOR_LISTENER
    m_sensorListenerThread = new mainCameraThread(this, &ExynosCamera::m_sensorListenerThreadFunc, "sensorListenerThread");
    CLOGD("m_sensorListenerThread created");

    m_sensorListenerUnloadThread = new mainCameraThread(this, &ExynosCamera::m_sensorListenerUnloadThreadFunc, "m_sensorListenerUnloadThread");
    CLOGD("m_sensorListenerUnloadThread created");
#endif

    return;
}

status_t ExynosCamera::m_vendorReInit(void)
{
    m_captureResultToggle = 0;
    m_displayPreviewToggle = 0;
#ifdef SUPPORT_DEPTH_MAP
    m_flagUseInternalDepthMap = false;
#endif
    m_flagUseInternalyuvStall = false;
    m_flagVideoStreamPriority = false;
    m_flagUseOnePort = false;

    return NO_ERROR;
}

status_t ExynosCamera::releaseDevice(void)
{
    status_t ret = NO_ERROR;
    CLOGD("");

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, RELEASE_DEVICE_START, 0);
    setPreviewProperty(false);

    m_setBuffersThread->requestExitAndWait();
    m_startPictureBufferThread->requestExitAndWait();
    m_framefactoryCreateThread->requestExitAndWait();
    m_dualFramefactoryCreateThread->requestExitAndWait();
    m_monitorThread->requestExit();

    if (m_getState() > EXYNOS_CAMERA_STATE_CONFIGURED) {
        flush();
    }

    if (isOfflineCaptureRunning() == false) {
        m_deinitBufferSupplierThread = new mainCameraThread(this, &ExynosCamera::m_deinitBufferSupplierThreadFunc, "deinitBufferSupplierThread");
        m_deinitBufferSupplierThread->run();
        CLOGD("Deinit Buffer Supplier Thread created");
    }

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, MONITOR_THREAD_STOP_START, 0);
    m_monitorThread->requestExitAndWait();
    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, MONITOR_THREAD_STOP_END, 0);

    m_frameMgr->stop();
    m_frameMgr->deleteAllFrame();

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, RELEASE_DEVICE_END, 0);

    release();

    return ret;
}

status_t ExynosCamera::m_constructFrameFactory(void)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    CLOGI("-IN-");

    ExynosCameraFrameFactory *factory = NULL;
#ifdef USE_DUAL_CAMERA
    bool isDualMode = m_configurations->getMode(CONFIGURATION_DUAL_MODE);
#endif

    if (m_framefactoryCreateThread->isRunning() == true)
        m_framefactoryCreateThread->join();

    if (m_dualFramefactoryCreateThread->isRunning() == true)
        m_dualFramefactoryCreateThread->join();

    /* Clean-up the previous factory queue */
    if (m_frameFactoryQ != NULL)
        m_frameFactoryQ->release();

    if (m_dualFrameFactoryQ != NULL)
        m_dualFrameFactoryQ->release();

    if (m_configurations->getMode(CONFIGURATION_VISION_MODE) == false) {
        /* Preview Frame Factory */
        for (int i = 0; i < m_camIdInfo.numOfSensors; i++) {
            if (m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i] == NULL) {
                if (i == MAIN_CAM) {
#ifdef USE_DUAL_CAMERA
                    if (isDualMode == true) {
                        factory = new ExynosCameraFrameFactoryPreviewDual(m_cameraIds[i],
                                                                          m_configurations,
                                                                          m_parameters[m_cameraIds[i]],
                                                                          &m_camIdInfo);
                    } else
#endif
                    {
                        factory = new ExynosCameraFrameFactoryPreview(m_cameraIds[i],
                                                                      m_configurations,
                                                                      m_parameters[m_cameraIds[i]],
                                                                      &m_camIdInfo);
                    }
                } else {
                    factory = new ExynosCameraFrameFactoryPreview(m_cameraIds[i],
                                                                  m_configurations,
                                                                  m_parameters[m_cameraIds[i]],
                                                                  &m_camIdInfo);
                }

                factory->setFrameCreateHandler(&ExynosCamera::m_previewFrameHandler);
                factory->setFrameManager(m_frameMgr);
                factory->setFactoryType(GET_FRAME_FACTORY_TYPE(FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i));
                m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i] = factory;

                CLOGD("FRAME_FACTORY_TYPE = %d MAX_NUM_SENSORS = %d factory = %p numOfSensors = %d i = %d",
                       FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i, MAX_NUM_SENSORS, factory, m_camIdInfo.numOfSensors, i);
            }
            if (i == MAIN_CAM
                || m_configurations->getMode(CONFIGURATION_PIP_MODE) == true) {
                m_frameFactoryQ->pushProcessQ(&m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i]);
            } else {
                m_dualFrameFactoryQ->pushProcessQ(&m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i]);
            }
        }

        /* Reprocessing Frame Factory */
        if (m_parameters[m_cameraId]->isReprocessing() == true) {
#if !defined(PIP_CAMERA_SUPPORTED)
            if (m_parameters[m_cameraId]->getNumOfMcscOutputPorts() < 5 && m_configurations->getMode(CONFIGURATION_PIP_MODE) == true) {
                CLOGW("skip create framefactory(%d) mcscOutputPort(%d) PidMode(%d)",
                       FRAME_FACTORY_TYPE_REPROCESSING , m_parameters[m_cameraId]->getNumOfMcscOutputPorts(),
                       m_configurations->getMode(CONFIGURATION_PIP_MODE));
            } else
#endif
            {
                for (int i = 0; i < m_camIdInfo.numOfSensors; i++) {
                    if (m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i] == NULL) {
                        if (i == MAIN_CAM) {
#ifdef USE_DUAL_CAMERA
                            if (isDualMode == true) {
                                factory = new ExynosCameraFrameReprocessingFactoryDual(m_cameraIds[i],
                                                                                       m_configurations,
                                                                                       m_parameters[m_cameraIds[i]],
                                                                                       &m_camIdInfo);
                            } else
#endif
                            {
                                factory = new ExynosCameraFrameReprocessingFactory(m_cameraIds[i],
                                                                                   m_configurations,
                                                                                   m_parameters[m_cameraIds[i]],
                                                                                   &m_camIdInfo);
                            }
                        } else {
                            factory = new ExynosCameraFrameReprocessingFactory(m_cameraIds[i],
                                                                               m_configurations,
                                                                               m_parameters[m_cameraIds[i]],
                                                                               &m_camIdInfo);
                        }
                        factory->setFrameCreateHandler(&ExynosCamera::m_captureFrameHandler);
                        factory->setFrameManager(m_frameMgr);
                        factory->setFactoryType(GET_FRAME_FACTORY_TYPE(FRAME_FACTORY_TYPE_REPROCESSING + i));
                        m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i] = factory;
                    } else {
                        android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):reprocessing factory is NOT NULL!!", __FUNCTION__, __LINE__);
                    }

                    if (i == MAIN_CAM
                        || m_configurations->getMode(CONFIGURATION_PIP_MODE) == true) {
                        m_frameFactoryQ->pushProcessQ(&m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i]);
                    } else {
                        m_dualFrameFactoryQ->pushProcessQ(&m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i]);
                    }
                }

#ifdef SUPPORT_REMOSAIC_CAPTURE
                if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC) &&
                    m_configurations->getMode(CONFIGURATION_SESSION_MODE) &&
                    m_configurations->getModeMultiValue(CONFIGURATION_MULTI_SESSION_MODE_VALUE, EXYNOS_SESSION_MODE_REMOSAIC))
                {
                    if (m_frameFactory[FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING] == NULL) {
#ifdef USES_COMBINE_PLUGIN
                        factory = new ExynosCameraFrameReprocessingFactory(m_cameraId, m_configurations, m_parameters[m_cameraId], &m_camIdInfo);
#else
                        factory = new ExynosCameraFrameReprocessingFactoryRemosaic(m_cameraId, m_configurations, m_parameters[m_cameraId], &m_camIdInfo);
#endif
                        factory->setFrameCreateHandler(&ExynosCamera::m_captureFrameHandler);
                        factory->setFrameManager(m_frameMgr);
                        factory->setFactoryType(FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING);
                        m_frameFactory[FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING] = factory;
                        m_frameFactoryQ->pushProcessQ(&factory);
                    }
                }
#endif //SUPPORT_REMOSAIC_CAPTURE
            }
        }
    } else {
        if (m_frameFactory[FRAME_FACTORY_TYPE_VISION] == NULL) {
            /* Vision Frame Factory */
            factory = new ExynosCameraFrameFactoryVision(m_cameraId, m_configurations, m_parameters[m_cameraId], &m_camIdInfo);
            factory->setFrameCreateHandler(&ExynosCamera::m_visionFrameHandler);
            factory->setFrameManager(m_frameMgr);
            factory->setFactoryType(FRAME_FACTORY_TYPE_VISION);
            m_frameFactory[FRAME_FACTORY_TYPE_VISION] = factory;
            m_frameFactoryQ->pushProcessQ(&factory);
        }
    }

    status_t ret = m_resourceManager->registerFrameFactory(m_frameFactory);
    if (ret != NO_ERROR) {
        CLOGE("Failed to registrer frameFactory to resourceManager");
        return ret;
    }

    CLOGI("-OUT-");

    return NO_ERROR;
}

bool ExynosCamera::m_frameFactoryStartThreadFunc(void)
{
    CLOGI("");
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;
    int32_t reprocessingBayerMode;
    uint32_t prepare = m_exynosconfig->current->pipeInfo.prepare[PIPE_3AA];
    bool startBayerThreads = false;
    bool isVisionMode = m_configurations->getMode(CONFIGURATION_VISION_MODE);
#ifdef USE_DUAL_CAMERA
    bool isDualMode = m_configurations->getMode(CONFIGURATION_DUAL_MODE);
    enum DUAL_OPERATION_MODE dualOperationMode = m_configurations->getDualOperationMode();
    enum DUAL_PREVIEW_MODE dualPreviewMode = m_configurations->getDualPreviewMode();
    bool needSensorStreamOn = true;
    int32_t slaveCamIdx;
#endif
    ExynosCameraFrameFactory *factory;
    ExynosCameraParameters *parameters;

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FACTORY_START_THREAD_START, 0);

    if (m_requestMgr->getServiceRequestCount() < 1) {
        CLOGE("There is NO available request!!! "
            "\"processCaptureRequest()\" must be called, first!!!");
        return false;
    }

    m_internalFrameCount = 1;

    if (m_shotDoneQ != NULL) {
        m_shotDoneQ->release();
    }
    m_latestRequestListLock.lock();
    m_latestRequestList.clear();
    m_latestRequestListLock.unlock();
#ifdef USE_DUAL_CAMERA
    if (isDualMode == true) {
        if (m_slaveShotDoneQ != NULL) {
            m_slaveShotDoneQ->release();
        }

        m_latestRequestListLock.lock();
        m_essentialRequestList.clear();
        m_latestRequestListLock.unlock();


        m_dualTransitionCount = 0;
        m_dualCaptureLockCount = 0;
        m_dualMultiCaptureLockflag = false;
        m_earlyTriggerRequestKey = 0;

        slaveCamIdx = m_getCurrentCamIdx(false, SUB_CAM);
    }
#endif

    for (int i = 0; i < MAX_PIPE_NUM; i++) {
        if (m_pipeFrameDoneQ[i] != NULL) {
            m_pipeFrameDoneQ[i]->release();
        }
    }

    m_releaseCaptureStreamQ();

    if (isVisionMode == false) {
#ifdef USE_DUAL_CAMERA
        if (isDualMode == true && dualOperationMode == DUAL_OPERATION_MODE_SLAVE) {
            factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + slaveCamIdx];
            parameters = m_parameters[m_camIdInfo.cameraId[slaveCamIdx]];
        } else
#endif
        {
            factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
            parameters = m_parameters[m_cameraId];
        }
    } else {
        factory = m_frameFactory[FRAME_FACTORY_TYPE_VISION];
        parameters = m_parameters[m_cameraId];
    }

    if (factory == NULL) {
        CLOGE("Can't start FrameFactory!!!! FrameFactory is NULL!! Prepare(%d), Request(%d)",
                prepare,
                m_requestMgr != NULL ? m_requestMgr->getAllRequestCount(): 0);

        return false;
    } else if (factory->isCreated() == false) {
        CLOGE("Preview FrameFactory is NOT created!");
        return false;
    } else if (factory->isRunning() == true) {
        CLOGW("Preview FrameFactory is already running.");
        return false;
    }

    /* To decide to run FLITE threads  */
    reprocessingBayerMode = parameters->getReprocessingBayerMode();
    switch (reprocessingBayerMode) {
    case REPROCESSING_BAYER_MODE_NONE :
    case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON :
    case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON :
        startBayerThreads = true;
        break;
    case REPROCESSING_BAYER_MODE_PURE_DYNAMIC :
    case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC :
        startBayerThreads = (parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);
        break;
    default :
        break;
    }

    /* Adjust Prepare Frame Count
     * If current sensor control delay is 0,
     * Prepare frame count must be reduced by #sensor control delay.
     */
    prepare = prepare + parameters->getSensorControlDelay() + 1;
    CLOGD("prepare %d", prepare);

#ifdef USE_DUAL_CAMERA
    if (isDualMode == true) {
        m_flagFinishDualFrameFactoryStartThread = false;
        m_prepareFrameCount = prepare;

        if (dualOperationMode == DUAL_OPERATION_MODE_SYNC) {
            /*
             * DualFrameFactoryStartThread Starting Timing
             *  SYNC mode  : (parallel) before starting master's initPipe
             *  other mode : (serial  ) after finishing this frameFactoryStartThread
             */
            m_dualFrameFactoryStartResult = NO_ERROR;
            m_dualFrameFactoryStartThread->run();
        }
    }
#endif

    /* Set default request flag & buffer manager */
    if (isVisionMode == false) {
        ret = m_setupPipeline(factory);
    } else {
        ret = m_setupVisionPipeline();
    }

    if (ret != NO_ERROR) {
        CLOGE("Failed to setupPipeline. ret %d", ret);
        return false;
    }

    TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_INIT_PIPES_START, 0);
    ret = factory->initPipes();
    TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_INIT_PIPES_END, 0);
    if (ret != NO_ERROR) {
        CLOGE("Failed to initPipes. ret %d", ret);
        return false;
    }

    if (isVisionMode == false) {
        ret = factory->mapBuffers();
        if (ret != NO_ERROR) {
            CLOGE("m_previewFrameFactory->mapBuffers() failed");
            return ret;
        }
    }

#ifdef USE_DUAL_CAMERA
    if (isDualMode == true) {
        /* It is for standbyHint */
        ret = factory->sensorStandby(!needSensorStreamOn, true);
        if (ret != NO_ERROR)
            CLOGE("sensorStandby(%d, true) fail! ret(%d)", !needSensorStreamOn, ret);
    }
#endif

    for (uint32_t i = 0; i < prepare; i++) {
        if (isVisionMode == false) {
            ret = m_createPreviewFrameFunc(REQ_SYNC_NONE, false /* flagFinishFactoryStart */);
        } else {
            ret = m_createVisionFrameFunc(REQ_SYNC_NONE, false /* flagFinishFactoryStart */);
        }

        if (ret != NO_ERROR) {
            CLOGE("Failed to createFrameFunc for preparing frame. prepareCount %d/%d",
                     i, prepare);
        }
    }

#ifdef USE_DUAL_CAMERA
    if (isDualMode == true) {
        /* init standby state */
        ret = factory->sensorStandby(!needSensorStreamOn);
        if (ret != NO_ERROR)
            CLOGE("sensorStandby(%d) fail! ret(%d)", !needSensorStreamOn, ret);

        factory->setNeedSensorStreamOn(needSensorStreamOn);
        parameters->setStandbyState(needSensorStreamOn ? DUAL_STANDBY_STATE_OFF : DUAL_STANDBY_STATE_ON);

        m_configurations->setDualOperationModeLockCount(0);
        m_configurations->setDualDisplayCameraId(factory->getCameraId());
        android_atomic_and(0, &m_needSlaveDynamicBayerCount);

        CLOGD("Factory NeedStreamOn(%d), dualOperationMode(%d), switching(%d), UHD(%d), scenario(%d)",
               needSensorStreamOn, dualOperationMode,
               m_configurations->getDynamicMode(DYNAMIC_DUAL_FORCE_SWITCHING),
               m_configurations->getDynamicMode(DYNAMIC_UHD_RECORDING_MODE),
               m_scenario);
    }
#endif

#ifdef USE_SLSI_PLUGIN
    /* HACK: TOTO: These codes should be moved to ExynosCameraMultiLibManager */
    for(int i = PIPE_PLUGIN_BASE ; i <= PIPE_PLUGIN_MAX; i++) {
        switch (i) {
        case PIPE_PLUGIN1:
#ifdef USES_COMBINE_PLUGIN
            {
                if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                    factory->connectPPScenario(i, PLUGIN_SCENARIO_COMBINE_PREVIEW);
                    factory->startPPScenario(i, PLUGIN_SCENARIO_COMBINE_PREVIEW);
                    sp<ExynosCameraStreamThread> plugInThread = m_previewStreamPlugInThreadMap[PIPE_PLUGIN1];
                    if (plugInThread->isRunning() == false) {
                        CLOGI("m_plugInThread(PLUGIN1) run E");
                        plugInThread->run(PRIORITY_URGENT_DISPLAY);
                        CLOGI("m_plugInThread(PLUGIN1) run X");
                    }
                }
            }
#endif
            break;
        default:
            break;
        }
    }
#endif

    /* - call preparePipes();
     * - call startPipes()
     * - call startInitialThreads()
     */
    TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_STREAM_START_START, 0);
    m_startFrameFactory(factory);
    TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_STREAM_START_END, 0);

#ifdef USE_DUAL_CAMERA
    if (isDualMode == true && dualOperationMode != DUAL_OPERATION_MODE_SYNC) {
        /*
         * When it's dual mode, we'll delay starting all kinds of reprocessingFactory factory
         * to the time when dualFrameFactoryStartThread finished. Because reprocessing instance
         * should be created after creation of preview instance.
         */
        CLOGI("m_dualFrameFactoryStartThread run E");
        m_dualFrameFactoryStartResult = NO_ERROR;
        m_dualFrameFactoryStartThread->run();
        CLOGI("m_dualFrameFactoryStartThread run X");
    } else
#endif
    {
        if (parameters->isReprocessing() == true && m_captureStreamExist == true) {
            CLOGI("m_reprocessingFrameFactoryStartThread run E");
            m_reprocessingFrameFactoryStartThread->run();
            CLOGI("m_reprocessingFrameFactoryStartThread run X");
        }
    }

    if (isVisionMode == false) {
        CLOGI("m_previewStream3AAThread run E");
        m_previewStream3AAThread->run(PRIORITY_URGENT_DISPLAY);
        CLOGI("m_previewStream3AAThread run X");

        if (parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
            CLOGI("m_previewStreamISPThread run E");
            m_previewStreamISPThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamISPThread run X");
        }

        if (parameters->getHwConnectionMode(PIPE_ISP, PIPE_MCSC) == HW_CONNECTION_MODE_M2M) {
            CLOGI("m_previewStreamMCSCThread run E");
            m_previewStreamMCSCThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamMCSCThread run X");
        }

#ifdef USE_CLAHE_PREVIEW
        if (parameters->getHwConnectionMode(PIPE_MCSC, PIPE_CLAHE) == HW_CONNECTION_MODE_M2M) {
            if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
                CLOGI("m_previewStreamCLAHEThread run E");
                m_previewStreamCLAHEThread->run(PRIORITY_URGENT_DISPLAY);
                CLOGI("m_previewStreamCLAHEThread run X");
            }
        }
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
        if (m_configurations->getSecondPortId() > -1) {
            CLOGI("m_previewStreamSWMCSCThread run E");
            m_previewStreamSWMCSCThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamSWMCSCThread run X");
        }
#endif
#ifdef USE_VRA_FD
        if (parameters->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M) {
            CLOGI("m_previewStreamVRAThread run E");
            m_previewStreamVRAThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamVRAThread run X");
        }
#endif

#ifdef USE_DUAL_CAMERA
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
#ifdef USE_DUAL_BAYER_SYNC
            CLOGI("m_previewStreamBayerSyncThread run E");
            m_previewStreamBayerSyncThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamBayerSyncThread run X");
#endif

            CLOGI("m_previewStreamSyncThread run E");
            m_previewStreamSyncThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamSyncThread run X");

            CLOGI("m_previewStreamFusionThread run E");
            m_previewStreamFusionThread->run(PRIORITY_URGENT_DISPLAY);
            CLOGI("m_previewStreamFusionThread run X");
        }
#endif
    }

    if (startBayerThreads == true) {
        CLOGI("m_previewStreamBayerThread run E");
        m_previewStreamBayerThread->run(PRIORITY_URGENT_DISPLAY);
        CLOGI("m_previewStreamBayerThread run X");
        if (factory->checkPipeThreadRunning(m_getBayerPipeId()) == false) {
            CLOGI("factory->startThread run E");
            factory->startThread(m_getBayerPipeId());
            CLOGI("factory->startThread run X");
        }
    }

    CLOGI("m_mainPreviewThread run E");
    m_mainPreviewThread->run(PRIORITY_URGENT_DISPLAY);
    CLOGI("m_mainPreviewThread run X");

    CLOGI("m_monitorThread run E");
    m_monitorThread->run(PRIORITY_DEFAULT);
    CLOGI("m_monitorThread run X");

#ifdef USES_SW_VDIS
    if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0
#ifdef USE_DUAL_CAMERA
        && (m_camIdInfo.cameraId[MAIN_CAM] == factory->getCameraId())
#endif
        ) {
        CLOGD("[VDIS][CAM%d] set bufferSupplier and outputFrameDoneQ", factory->getCameraId());
        int pipeId = PIPE_VDIS;
        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }

        if (m_previewStreamVDISThread->isRunning() == false) {
            CLOGD("run m_previewStreamVDISThread");
            m_previewStreamVDISThread->run();
        }
    }
#endif


    ret = m_transitState(EXYNOS_CAMERA_STATE_RUN);
    if (ret != NO_ERROR) {
        CLOGE("Failed to transitState into RUN. ret %d", ret);
    }

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FACTORY_START_THREAD_END, 0);

    return false;
}

#ifdef USE_DUAL_CAMERA
bool ExynosCamera::m_dualFrameFactoryStartThreadFunc(void)
{
    CLOGI("");
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;
    int32_t reprocessingBayerMode;
    uint32_t prepare = m_prepareFrameCount;
    bool startBayerThreads = false;

    bool isDualMode = m_configurations->getMode(CONFIGURATION_DUAL_MODE);
    enum DUAL_OPERATION_MODE dualOperationMode = m_configurations->getDualOperationMode();
    enum DUAL_PREVIEW_MODE dualPreviewMode = m_configurations->getDualPreviewMode();
    ExynosCameraFrameFactory *factory;
    ExynosCameraParameters *parameters;

    bool supportSensorStandby;
    bool needSensorStreamOn;
    bool standby;
    int32_t slaveCamId;
    int32_t slaveCamIdx;

    bool isReprocessingRequired = false;

    if (isDualMode == false)
        return false;

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, DUAL_FACTORY_START_THREAD_START, 0);

    slaveCamIdx = m_getCurrentCamIdx(false, SUB_CAM);
    slaveCamId = m_camIdInfo.cameraId[slaveCamIdx];

    for (int cam_idx = 0; cam_idx < m_camIdInfo.numOfSensors; cam_idx++) {
        supportSensorStandby = false;
        needSensorStreamOn = false;
        standby = true;

        if (dualOperationMode == DUAL_OPERATION_MODE_SLAVE) {
            /*
             * slave framefactory corresponding to the acive sensor is started from the m_frameFactoryStartThread.
             * master framefactory and remaining slave framefactories are handled here
             */
             if (cam_idx == MAIN_CAM) {
                factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
                parameters = m_parameters[m_camIdInfo.cameraId[MAIN_CAM]];
             } else if (cam_idx == slaveCamIdx) {
                continue;
             } else {
                 factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + cam_idx];
                 parameters = m_parameters[m_camIdInfo.cameraId[cam_idx]];
             }
        } else if (cam_idx == MAIN_CAM) {
            /* master framefactory is started from m_frameFactoryStartThread */
            continue;
        } else {
            factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + cam_idx];
            parameters = m_parameters[m_camIdInfo.cameraId[cam_idx]];
        }

        if (dualOperationMode == DUAL_OPERATION_MODE_SYNC) {
            if (cam_idx == slaveCamIdx) {
                standby = false;
                needSensorStreamOn = true;
            }
        }

        /* To decide to run FLITE threads  */
        reprocessingBayerMode = parameters->getReprocessingBayerMode();
        switch (reprocessingBayerMode) {
        case REPROCESSING_BAYER_MODE_NONE :
        case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON :
        case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON :
            startBayerThreads = true;
            break;
        case REPROCESSING_BAYER_MODE_PURE_DYNAMIC :
        case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC :
            startBayerThreads = (parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);
            break;
        default :
            break;
        }

        if (parameters->isReprocessing() == true)
            isReprocessingRequired = true; //set true if any cam needs it

        supportSensorStandby = parameters->isSupportedFunction(SUPPORTED_HW_FUNCTION_SENSOR_STANDBY);
        //TODO : Need to check: There will be a problem if multiple slave sensors are simultaneously enabled.
        if (supportSensorStandby == false)
            needSensorStreamOn = true;

        if (factory == NULL) {
            CLOGE("Can't start FrameFactory!!!! FrameFactory is NULL!! Prepare(%d), Request(%d)",
                    prepare,
                    m_requestMgr != NULL ? m_requestMgr->getAllRequestCount(): 0);

            return false;
        } else if (factory->isCreated() == false) {
            CLOGE("Preview FrameFactory is NOT created!");
            return false;
        } else if (factory->isRunning() == true) {
            CLOGW("Preview FrameFactory is already running.");
            return false;
        }

        /* Set default request flag & buffer manager */
        ret = m_setupPipeline(factory);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setupPipeline. ret %d", ret);
            return false;
        }

        TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_INIT_PIPES_START, 0);
        ret = factory->initPipes();
        TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_INIT_PIPES_END, 0);
        if (ret != NO_ERROR) {
            CLOGE("Failed to initPipes. ret %d", ret);
            return false;
        }

        ret = factory->mapBuffers();
        if (ret != NO_ERROR) {
            CLOGE("m_previewFrameFactory->mapBuffers() failed");
            return ret;
        }

        if (needSensorStreamOn == true) {
            /* It is for standbyHint */
            ret = factory->sensorStandby(!needSensorStreamOn, true);
            if (ret != NO_ERROR)
                CLOGE("sensorStandby(%d, true) fail! ret(%d)", !needSensorStreamOn, ret);

            if (standby == false) {
                /* in case of standby off */
                int requestListSize = 0;
                int tryCount = 60; /* max : 5ms * 60 = 300ms */
                ExynosCameraRequestSP_sprt_t request = NULL;
                List<ExynosCameraRequestSP_sprt_t>::iterator r;
                factory_handler_t frameCreateHandler = factory->getFrameCreateHandler();

                /* get the latest request */
                while (requestListSize <= 0 && tryCount > 0) {
                    m_latestRequestListLock.lock();
                    if (m_essentialRequestList.size() > 0) {
                        r = m_essentialRequestList.begin();
                        request = *r;
                        m_essentialRequestList.erase(r);
                    } else {
                        requestListSize = m_latestRequestList.size();
                        if (requestListSize > 0) {
                            r = m_latestRequestList.begin();
                            request = *r;
                        }
                    }
                    m_latestRequestListLock.unlock();
                    tryCount--;
                    usleep(5000);
                    CLOGW("wait for latest request..tryCount(%d)", tryCount);
                }

                for (uint32_t i = 0; i < prepare; i++) {
                    if (request != NULL) {
                        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                            (this->*frameCreateHandler)(request, factory, FRAME_TYPE_PREVIEW_DUAL_SLAVE);
                        } else {
                            m_createInternalFrameFunc(NULL, false, REQ_SYNC_NONE, FRAME_TYPE_INTERNAL_SLAVE);
                        }
                    } else {
                        m_createInternalFrameFunc(NULL, false, REQ_SYNC_NONE, FRAME_TYPE_INTERNAL_SLAVE);
                    }
                }
            } else {
                /* in case of postStandby on */
                for (uint32_t i = 0; i < prepare; i++) {
                    ret = m_createInternalFrameFunc(NULL, false, REQ_SYNC_NONE,
                            dualOperationMode == DUAL_OPERATION_MODE_SLAVE ? FRAME_TYPE_TRANSITION_SLAVE : FRAME_TYPE_TRANSITION);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to createFrameFunc for preparing frame. prepareCount %d/%d",
                                i, prepare);
                    }
                }
            }
        }

        /* init standby state */
        ret = factory->sensorStandby(!needSensorStreamOn);
        if (ret != NO_ERROR)
            CLOGE("sensorStandby(%d) fail! ret(%d)", !needSensorStreamOn, ret);

        factory->setNeedSensorStreamOn(needSensorStreamOn);
        parameters->setStandbyState(needSensorStreamOn ? DUAL_STANDBY_STATE_OFF : DUAL_STANDBY_STATE_ON);

        CLOGD("cam_idx = %d, cam_id = %d Factory NeedStreamOn(%d) dualOperationMode(%d)",
                cam_idx, m_camIdInfo.cameraId[cam_idx], needSensorStreamOn, dualOperationMode);

        if (m_slaveMainThread->isRunning() == false)
            m_slaveMainThread->run(PRIORITY_URGENT_DISPLAY);

        /* - call preparePipes();
         * - call startPipes()
         * - call startInitialThreads()
         */
        TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_STREAM_START_START, 0);
        ret = m_startFrameFactory(factory);
        if (ret != NO_ERROR) {
            m_dualFrameFactoryStartResult = NO_INIT;
        }
        TIME_LOGGER_UPDATE(m_cameraId, factory->getFactoryType(), factory->getCameraId(), CUMULATIVE_CNT, FACTORY_STREAM_START_END, 0);
        if (startBayerThreads == true) {
            if (factory->checkPipeThreadRunning(m_getBayerPipeId()) == false) {
                factory->startThread(m_getBayerPipeId());
            }
        }

#ifdef USES_SW_VDIS
        if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0
                && (m_camIdInfo.cameraId[MAIN_CAM] == factory->getCameraId())) {
            CLOGD("[VDIS][CAM%d] set bufferSupplier and outputFrameDoneQ", factory->getCameraId());
            int pipeId = PIPE_VDIS;
            ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
            if (ret != NO_ERROR) {
                CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
                continue;
            }

            if (m_previewStreamVDISThread->isRunning() == false) {
                CLOGD("run m_previewStreamVDISThread");
                m_previewStreamVDISThread->run();
            }
        }
#endif
    }

    m_frameFactoryStartThread->join();
    {
        /* OK. Im finished.. */
        Mutex::Autolock lock(m_dualOperationModeLock);
        m_flagFinishDualFrameFactoryStartThread = true;
    }

    if (isReprocessingRequired == true && m_captureStreamExist == true) {
        m_reprocessingFrameFactoryStartThread->run();
    }

    /* when slave sensor stream is failed on dual sync sensor mode, get dump of master sensor */
    if (m_dualFrameFactoryStartResult == NO_INIT) {
        if ((m_scenario == SCENARIO_DUAL_REAR_PORTRAIT || m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT)
            && dualOperationMode == DUAL_OPERATION_MODE_SYNC) {
            ExynosCameraFrameFactory *masterFactory;
            masterFactory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
            if (masterFactory != NULL && masterFactory->isCreated()) {
                masterFactory->setControl(V4L2_CID_IS_CAMERA_TYPE, IS_COLD_RESET, PIPE_3AA);
            }
        }
    }

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, DUAL_FACTORY_START_THREAD_END, 0);

    return false;
}
#endif

void ExynosCamera::m_createManagers(void)
{
    status_t ret = NO_ERROR;
    const buffer_manager_tag_t initBufTag;
    buffer_manager_tag_t bufTag;

    if (!m_streamManager) {
        m_resourceManager->initManagerResources(&m_camIdInfo, nullptr, &m_streamManager, nullptr);
        CLOGD("Stream Manager created");
    }

    if (m_bufferSupplier == NULL) {
        m_bufferSupplier = new ExynosCameraBufferSupplier(m_cameraId);
        CLOGD("Buffer Supplier created");
    }

    if (m_ionAllocator == NULL) {
        ret = m_createIonAllocator(&m_ionAllocator);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create ionAllocator. ret %d", ret);
        } else {
            CLOGD("IonAllocator is created");
        }
    }

    m_resourceManager->initBufferSupplier(m_bufferSupplier, m_ionAllocator);

}

status_t ExynosCamera::m_checkStreamInfo(void)
{
    status_t ret = NO_ERROR;
#ifdef PIP_CAMERA_SUPPORTED
    /* Check PIP Mode Limitation
     * Max number of YUV stream for each device: 1
     * Max size of YUV stream: FHD(1080p)
     * Each limitation is defined at config.h
     */
    if (m_configurations->getMode(CONFIGURATION_PIP_MODE) == true) {
        int yuvStreamCount = m_streamManager->getYuvStreamCount();
        int maxYuvW = 0, maxYuvH = 0;
        m_configurations->getSize(CONFIGURATION_MAX_YUV_SIZE, (uint32_t *)&maxYuvW, (uint32_t *)&maxYuvH);

        if (yuvStreamCount > PIP_CAMERA_MAX_YUV_STREAM
            || maxYuvH > PIP_CAMERA_MAX_YUV_HEIGHT
            || (maxYuvW * maxYuvH) > PIP_CAMERA_MAX_YUV_SIZE) {

            CLOGW("PIP mode NOT support this configuration. " \
                    "YUVStreamCount %d MaxYUVSize %dx%d",
                    yuvStreamCount, maxYuvW, maxYuvH);

            ret = BAD_VALUE;
        }
    }
#endif

    m_checkStreamInfo_vendor(ret);

    return ret;
}

void ExynosCamera::m_checkRequestStreamChanged(const char *handlerName, uint32_t currentStreamBit)
{
    uint32_t changedStreamBit = currentStreamBit;
    bool hasStream[HAL_STREAM_ID_MAX] = {false,};
    bool isSWVdis = 0;
    bool isHIFIVideo = 0;

    changedStreamBit ^= (m_prevStreamBit);

    if (changedStreamBit == 0) {
        return;
    }

    for (int id = 0; id < HAL_STREAM_ID_MAX; id++) {
        hasStream[id] = (currentStreamBit >> id) & 1;
    }

    if (!strcmp(handlerName, "Preview")) {
        CLOGD("[%s Stream] PREVIEW(%d), VIDEO(%d), CB(%d), CB_PHYSICAL(%d), ZSL_OUTPUT(%d), DEPTHMAP(%d)",
                                     handlerName,
                                     hasStream[HAL_STREAM_ID_PREVIEW],
                                     hasStream[HAL_STREAM_ID_VIDEO],
                                     hasStream[HAL_STREAM_ID_CALLBACK],
                                     hasStream[HAL_STREAM_ID_CALLBACK_PHYSICAL],
                                     hasStream[HAL_STREAM_ID_ZSL_OUTPUT],
                                     hasStream[HAL_STREAM_ID_DEPTHMAP]);

        if (hasStream[HAL_STREAM_ID_VIDEO]) {
            CLOGD("[%s Mode] SWVDIS mode(%d), HIFI_VIDEO Mode(%d)",
                                     handlerName, (int32_t)isSWVdis, (int32_t)isHIFIVideo);
        }
    } else if (!strcmp(handlerName, "Capture")) {
        CLOGD("[%s Stream] RAW(%d), ZSL_INPUT(%d), JPEG(%d), CB(%d), CB_PHYSICAL(%d), CB_STALL(%d), " \
                                     "DEPTHMAP_STALL(%d), THUMBNAIL_CB(%d)",
                                     handlerName,
                                     hasStream[HAL_STREAM_ID_RAW],
                                     hasStream[HAL_STREAM_ID_ZSL_INPUT],
                                     hasStream[HAL_STREAM_ID_JPEG],
                                     hasStream[HAL_STREAM_ID_CALLBACK],
                                     hasStream[HAL_STREAM_ID_CALLBACK_PHYSICAL],
                                     hasStream[HAL_STREAM_ID_CALLBACK_STALL],
                                     hasStream[HAL_STREAM_ID_DEPTHMAP_STALL],
                                     hasStream[HAL_STREAM_ID_THUMBNAIL_CALLBACK]);
    } else if (!strcmp(handlerName, "Vision")) {
        CLOGD("[%s Stream] VISION(%d)", handlerName, hasStream[HAL_STREAM_ID_VISION]);
    } else {
        CLOGD("Invalid Handler name");
    }

    m_prevStreamBit = currentStreamBit;
    return;
}

status_t ExynosCamera::setParameters(const CameraParameters& params)
{
    status_t ret = NO_ERROR;

    CLOGI("");

    m_configurations->setParameters(params);

    setParameters_vendor(params);

    return ret;
}

status_t ExynosCamera::m_setSetfile(void) {
    int configMode = m_configurations->getConfigMode();
    int setfile = 0;
    int setfileReprocessing = 0;
    int yuvRange = YUV_FULL_RANGE;
    int yuvRangeReprocessing = YUV_FULL_RANGE;

    switch (configMode) {
    case CONFIG_MODE::NORMAL:
    case CONFIG_MODE::HIGHSPEED_60:
        for (int i = 0; i < m_camIdInfo.numOfSensors; i++) {
            m_parameters[m_camIdInfo.cameraId[i]]->checkSetfileYuvRange();
            /* general */
            m_parameters[m_camIdInfo.cameraId[i]]->getSetfileYuvRange(false, &setfile, &yuvRange);
            /* reprocessing */
            m_parameters[m_camIdInfo.cameraId[i]]->getSetfileYuvRange(true, &setfileReprocessing, &yuvRangeReprocessing);
        }
        break;
    case CONFIG_MODE::HIGHSPEED_120:
        setfile = ISS_SUB_SCENARIO_VIDEO_HIGH_SPEED;
        setfileReprocessing = ISS_SUB_SCENARIO_VIDEO_HIGH_SPEED;
        yuvRange = YUV_LIMITED_RANGE;
        break;
    case CONFIG_MODE::HIGHSPEED_240:
    case CONFIG_MODE::HIGHSPEED_480:    /* HACK: We want new sub scenario setfile index */
        setfile = ISS_SUB_SCENARIO_FHD_240FPS;
        setfileReprocessing = ISS_SUB_SCENARIO_VIDEO_HIGH_SPEED;
        yuvRange = YUV_LIMITED_RANGE;
        break;
    default:
        CLOGE("configMode is abnormal(%d)", configMode);
        break;
    }

    CLOGI("configMode(%d), PIPMode(%d)", configMode, m_configurations->getMode(CONFIGURATION_PIP_MODE));

    /* reprocessing */
    m_parameters[m_cameraId]->setSetfileYuvRange(true, setfileReprocessing, yuvRangeReprocessing);
    /* preview */
    m_parameters[m_cameraId]->setSetfileYuvRange(false, setfile, yuvRange);

    return NO_ERROR;
}

status_t ExynosCamera::m_restartStreamInternal()
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameFactory *frameFactory = NULL;
    int count = 0;

    CLOGI("IN");

    /* Wait for factory creation */
    if (m_framefactoryCreateThread->isRunning() == true) {
        m_framefactoryCreateThread->join();
    }
    if (m_dualFramefactoryCreateThread->isRunning() == true) {
        m_dualFramefactoryCreateThread->join();
    }

    /* Wait for finishing to start pipeline */
    m_frameFactoryStartThread->join();
    m_reprocessingFrameFactoryStartThread->join();

    m_frameFactoryStartThread->requestExitAndWait();
    m_reprocessingFrameFactoryStartThread->requestExitAndWait();

    if (m_getState() != EXYNOS_CAMERA_STATE_RUN) {
        CLOGD("No need to m_restartStreamInternal");
        goto func_exit;
    }

    /* Wait for finishing pre-processing threads*/
    m_mainPreviewThread->requestExitAndWait();
    m_mainCaptureThread->requestExitAndWait();
#ifdef USE_DUAL_CAMERA
    if (m_dualFrameFactoryStartThread != NULL) {
        m_dualFrameFactoryStartThread->join();
        m_dualFrameFactoryStartThread->requestExitAndWait();
    }

    if (m_slaveMainThread != NULL) {
        m_slaveMainThread->requestExitAndWait();
    }

    if (m_dualStandbyThread != NULL) {
        m_dualStandbyThread->requestExitAndWait();
    }
#endif

    /* 1. wait for request callback done.*/
    if (m_configurations->getMode(CONFIGURATION_RESTART_FORCE_FLUSH)) {
        CLOGD("m_restartStreamInternal force flush no wait frame");
    } else {
        count = 0;
        while (true) {
            uint32_t requestCnt = 0;
            count++;

            requestCnt = m_requestMgr->getAllRequestCount();

            if (requestCnt == 0)
                break;

            CLOGD("getAllRequestCount size(%d) retry(%d)", requestCnt, count);
            usleep(50000);

            if (count == 200)
                break;
        }

        /* 2. wait for internal frame done.*/
        count = 0;
        while (true) {
            uint32_t processCount = 0;
            uint32_t captureProcessCount = 0;
            count++;
            processCount = m_getSizeFromFrameList(&m_processList, &m_processLock);
            captureProcessCount = m_getSizeFromFrameList(&m_captureProcessList, &m_captureProcessLock);

            if (processCount == 0 && captureProcessCount == 0)
                break;

            CLOGD("processCount size(%d) captureProcessCount size(%d) retry(%d)",
                 processCount, captureProcessCount, count);
            usleep(50000);

            if (count == 200)
                break;
        }
    }

#ifdef USES_SENSOR_LISTENER
    if (m_sensorListenerThread != NULL) {
        m_sensorListenerThread->join();
    }
#endif

    /* Stop pipeline */
    m_stopPipeline();

    /* Wait for finishing pre-processing threads */
    if (m_shotDoneQ != NULL) {
        m_shotDoneQ->release();
    }
#ifdef USE_DUAL_CAMERA
    if (m_slaveShotDoneQ != NULL) {
        m_slaveShotDoneQ->release();
    }
    stopThreadAndInputQ(m_createReprocessingFrameThread, 1, m_createReprocessingFrameQ);
#ifdef USE_DUAL_BAYER_SYNC
    stopThreadAndInputQ(m_selectDualSlaveBayerThread, 2, m_selectDualSlaveBayerQ, m_syncBayerFrameDoneQ);
#else
    stopThreadAndInputQ(m_selectDualSlaveBayerThread, 1, m_selectDualSlaveBayerQ);
#endif
    stopThreadAndInputQ(m_gscPreviewCbThread, 1, m_pipeFrameDoneQ[PIPE_GSC]);
#endif
    stopThreadAndInputQ(m_selectBayerThread, 1, m_selectBayerQ);

    /* Wait for finishing post-processing thread */
    stopThreadAndInputQ(m_previewStreamBayerThread, 1, m_pipeFrameDoneQ[PIPE_FLITE]);
    stopThreadAndInputQ(m_previewStream3AAThread, 1, m_pipeFrameDoneQ[PIPE_3AA]);
    stopThreadAndInputQ(m_previewStreamISPThread, 1, m_pipeFrameDoneQ[PIPE_ISP]);
    stopThreadAndInputQ(m_previewStreamMCSCThread, 1, m_pipeFrameDoneQ[PIPE_MCSC]);

#ifdef USE_CLAHE_PREVIEW
    if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
        stopThreadAndInputQ(m_previewStreamCLAHEThread, 1, m_pipeFrameDoneQ[PIPE_CLAHE]);
    }
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
    if (m_configurations->getSecondPortId() > -1) {
        stopThreadAndInputQ(m_previewStreamSWMCSCThread, 1, m_pipeFrameDoneQ[PIPE_SW_MCSC]);
    }
#endif
    /* Waiting for finishing post-capture-processing thread */
    m_captureThreadStopAndInputQ();

#ifdef SUPPORT_HW_GDC
    stopThreadAndInputQ(m_previewStreamGDCThread, 1, m_pipeFrameDoneQ[PIPE_GDC]);
    stopThreadAndInputQ(m_gdcThread, 1, m_gdcQ);
#endif
#ifdef USE_SLSI_PLUGIN
    for (int i = PIPE_PLUGIN_BASE; i <= PIPE_PLUGIN_MAX; i++) {
        sp<ExynosCameraStreamThread> plugInThread = m_previewStreamPlugInThreadMap[i];
        if (plugInThread == NULL) continue;
        stopThreadAndInputQ(plugInThread, 1, m_pipeFrameDoneQ[i]);
    }
#endif
#ifdef USES_SW_VDIS
    if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
        if (m_exCameraSolutionSWVdis != NULL) {
            m_exCameraSolutionSWVdis->flush(m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW]);
        }
    }
    stopThreadAndInputQ(m_previewStreamVDISThread, 1, m_pipeFrameDoneQ[PIPE_VDIS]);
#endif
#ifdef USES_CAMERA_EXYNOS_VPL
#ifdef USES_VPL_PRELOAD
    m_vplPreloadThread->requestExitAndWait();
#endif
    stopThreadAndInputQ(m_previewStreamNFDThread, 1, m_pipeFrameDoneQ[PIPE_NFD]);
#endif
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
#ifdef USE_DUAL_BAYER_SYNC
        stopThreadAndInputQ(m_previewStreamBayerSyncThread, 1, m_pipeFrameDoneQ[PIPE_BAYER_SYNC]);
#endif
        stopThreadAndInputQ(m_previewStreamSyncThread, 1, m_pipeFrameDoneQ[PIPE_SYNC]);

        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
            stopThreadAndInputQ(m_previewStreamFusionThread, 1, m_pipeFrameDoneQ[PIPE_FUSION]);
        }
    }
#endif
#ifdef BUFFER_DUMP
    stopThreadAndInputQ(m_dumpThread, 1, m_dumpBufferQ);
#endif

    for (int i = 0; i < CAMERA_ID_MAX; i++) {
        if (m_captureSelector[i] != NULL) {
            m_captureSelector[i]->release();
        }
    }

    if (m_configurations->getMode(CONFIGURATION_RESTART_FORCE_FLUSH)) {
        CLOGD("m_restartStreamInternal force flush clear List");

        //If there are multiple flushs, need to wait for others to be finished.
        while (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
            CLOGE("Watting last flush done...");
            usleep(1000);
        };
        m_requestMgr->flush(true);

        ret = m_clearRequestList(&m_requestPreviewWaitingList, &m_requestPreviewWaitingLock);
        if (ret < 0) {
            CLOGE("m_clearList(m_processList) failed [%d]", ret);
        }
        ret = m_clearRequestList(&m_requestCaptureWaitingList, &m_requestCaptureWaitingLock);
        if (ret < 0) {
            CLOGE("m_clearList(m_processList) failed [%d]", ret);
        }
    }

    ret = m_transitState(EXYNOS_CAMERA_STATE_FLUSH);
    if (ret != NO_ERROR) {
        CLOGE("Failed to transitState into FLUSH. ret %d", ret);
        goto func_exit;
    }

    /* reset buffer */
    ret = m_bufferSupplier->resetBuffers();
    if (ret != NO_ERROR) {
        CLOGE("Failed to resetBuffers. ret %d", ret);
    }

    /* Clear frame list, because the frame number is initialized in startFrameFactoryThread. */
    ret = m_clearList(&m_processList, &m_processLock);
    if (ret < 0) {
        CLOGE("m_clearList(m_processList) failed [%d]", ret);
    }
    ret = m_clearList(&m_captureProcessList, &m_captureProcessLock);
    if (ret < 0) {
        CLOGE("m_clearList(m_captureProcessList) failed [%d]", ret);
    }

    ret = m_transitState(EXYNOS_CAMERA_STATE_CONFIGURED);
    if (ret != NO_ERROR) {
        CLOGE("Failed to transitState into CONFIGURED. ret %d", ret);
        goto func_exit;
    }

    if (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE)) {
        if (m_configurations->getMode(CONFIGURATION_RESTART_FORCE_FLUSH)) {
            m_configurations->setMode(CONFIGURATION_RESTART_FORCE_FLUSH, false);
            m_configurations->setModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE, m_configurations->getModeValue(CONFIGURATION_RESTART_VIDEO_STABILIZATION));
        }
    }

    m_configurations->setMode(CONFIGURATION_RESTART_FORCE_FLUSH, false);

func_exit:
    CLOGI("Internal restart stream OUT");
    return ret;
}

status_t ExynosCamera::flush()
{
    int retryCount;

    /* flush lock */
    m_flushLock.lock();

    status_t ret = NO_ERROR;

    /*
     * This flag should be set before stoping all pipes,
     * because other func(like processCaptureRequest) must know call state about flush() entry level
     */

    CLOGD("IN+++");
    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FLUSH_START, 0);

#ifdef TIME_LOGGER_STREAM_PERFORMANCE_ENABLE
    TIME_LOGGER_SAVE(m_cameraId);
#endif

    if (m_getState() == EXYNOS_CAMERA_STATE_CONFIGURED) {
        CLOGD("No need to wait & flush");
        goto func_exit;
    }

    if (m_getState() != EXYNOS_CAMERA_STATE_ERROR) {
        /*
         * In the Error state, flush() can not be called by frame work.
         * But, flush() is called internally when Device close is called.
         * So, flush operation is performed, and exynos_camera_state is not changed.
         */
        ret = m_transitState(EXYNOS_CAMERA_STATE_FLUSH);
        if (ret != NO_ERROR) {
            CLOGE("Failed to transitState into FLUSH. ret %d", ret);
            goto func_exit;
        }
    }

    m_captureResultDoneCondition.signal();

#ifdef USES_SENSOR_LISTENER
    if (m_sensorListenerThread != NULL) {
        m_sensorListenerThread->join();
    }
#endif

    {
        m_configurations->setUseFastenAeStable(false);
    }

#ifdef USES_OFFLINE_CAPTURE
    m_offlineCapture->flush(m_cameraSessionId);
#endif

    /* Wait for finishing to start pipeline */
    m_frameFactoryStartThread->requestExitAndWait();
    m_reprocessingFrameFactoryStartThread->requestExitAndWait();

    for (int i = 0; i < CAMERA_ID_MAX; i++) {
        if (m_captureSelector[i] != NULL) {
            m_captureSelector[i]->wakeupQ();
            m_captureSelector[i]->cancelPicture(true);
        }
    }

    /* Wait for finishing pre-processing threads and Release pre-processing frame queues */
    stopThreadAndInputQ(m_mainPreviewThread, 1, m_shotDoneQ);
    m_mainCaptureThread->requestExitAndWait();
#ifdef USE_DUAL_CAMERA
    if (m_dualFrameFactoryStartThread != NULL) {
        CLOGI("m_dualFrameFactoryStartThread join E");
        m_dualFrameFactoryStartThread->join();
        CLOGI("m_dualFrameFactoryStartThread join X");
        m_dualFrameFactoryStartThread->requestExitAndWait();
        CLOGI("m_dualFrameFactoryStartThread ExitAndWait X");
    }

    stopThreadAndInputQ(m_slaveMainThread, 1, m_slaveShotDoneQ);
    stopThreadAndInputQ(m_dualStandbyThread, 1, m_dualStandbyTriggerQ);
    stopThreadAndInputQ(m_createReprocessingFrameThread, 1, m_createReprocessingFrameQ);
#ifdef USE_DUAL_BAYER_SYNC
    stopThreadAndInputQ(m_selectDualSlaveBayerThread, 2, m_selectDualSlaveBayerQ, m_syncBayerFrameDoneQ);
#else
    stopThreadAndInputQ(m_selectDualSlaveBayerThread, 1, m_selectDualSlaveBayerQ);
#endif
#endif
    stopThreadAndInputQ(m_selectBayerThread, 1, m_selectBayerQ);
    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FRAME_CREATE_THREAD_STOP_END, 0);

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
    ////////////////////////////////////////////////
    // about factory led calibration.
    if (m_configurations->getLedCalibrationEnable() == true) {
        ret = m_stopLedCalibration(m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW]);
        if (ret != NO_ERROR) {
            CLOGE("m_stopLedCalibration() fail");
        }
    }
    ////////////////////////////////////////////////
#endif

    /* Stop pipeline */
    m_stopPipeline();

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, LIBRARY_DEINIT_END, 0);

    /* Wait for finishing post-processing thread */
    stopThreadAndInputQ(m_previewStreamBayerThread, 1, m_pipeFrameDoneQ[PIPE_FLITE]);
    stopThreadAndInputQ(m_previewStream3AAThread, 1, m_pipeFrameDoneQ[PIPE_3AA]);
#ifdef SUPPORT_GMV
    stopThreadAndInputQ(m_previewStreamGMVThread, 1, m_pipeFrameDoneQ[PIPE_GMV]);
#endif
    stopThreadAndInputQ(m_previewStreamISPThread, 1, m_pipeFrameDoneQ[PIPE_ISP]);
    stopThreadAndInputQ(m_previewStreamMCSCThread, 1, m_pipeFrameDoneQ[PIPE_MCSC]);
#ifdef USE_VRA_FD
    stopThreadAndInputQ(m_previewStreamVRAThread, 1, m_pipeFrameDoneQ[PIPE_VRA]);
#endif
#ifdef SUPPORT_HFD
    stopThreadAndInputQ(m_previewStreamHFDThread, 1, m_pipeFrameDoneQ[PIPE_HFD]);
#endif
#ifdef USE_CLAHE_PREVIEW
    if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
        stopThreadAndInputQ(m_previewStreamCLAHEThread, 1, m_pipeFrameDoneQ[PIPE_CLAHE]);
    }
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
    if (m_configurations->getSecondPortId() > -1) {
        stopThreadAndInputQ(m_previewStreamSWMCSCThread, 1, m_pipeFrameDoneQ[PIPE_SW_MCSC]);
    }
#endif
#ifdef SUPPORT_HW_GDC
    stopThreadAndInputQ(m_previewStreamGDCThread, 1, m_pipeFrameDoneQ[PIPE_GDC]);
    stopThreadAndInputQ(m_gdcThread, 1, m_gdcQ);
#endif

    /* Waiting for finishing post-capture-processing thread */
    m_captureThreadStopAndInputQ();

#ifdef USE_SLSI_PLUGIN
    for (int i = PIPE_PLUGIN_BASE; i <= PIPE_PLUGIN_MAX; i++) {
        sp<ExynosCameraStreamThread> plugInThread = m_previewStreamPlugInThreadMap[i];
        if (plugInThread == NULL) continue;
        stopThreadAndInputQ(plugInThread, 1, m_pipeFrameDoneQ[i]);
    }
#endif
#ifdef USES_SW_VDIS
    if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
        if (m_exCameraSolutionSWVdis != NULL) {
            m_exCameraSolutionSWVdis->flush(m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW]);
        }
    }
    stopThreadAndInputQ(m_previewStreamVDISThread, 1, m_pipeFrameDoneQ[PIPE_VDIS]);
#endif
#ifdef USES_CAMERA_EXYNOS_VPL
#ifdef USES_VPL_PRELOAD
    m_vplPreloadThread->requestExitAndWait();
#endif
    stopThreadAndInputQ(m_previewStreamNFDThread, 1, m_pipeFrameDoneQ[PIPE_NFD]);
#endif
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
#ifdef USE_DUAL_BAYER_SYNC
        stopThreadAndInputQ(m_previewStreamBayerSyncThread, 1, m_pipeFrameDoneQ[PIPE_BAYER_SYNC]);
#endif
        stopThreadAndInputQ(m_previewStreamSyncThread, 1, m_pipeFrameDoneQ[PIPE_SYNC]);
        stopThreadAndInputQ(m_gscPreviewCbThread, 1, m_pipeFrameDoneQ[PIPE_GSC]);

        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
            stopThreadAndInputQ(m_previewStreamFusionThread, 1, m_pipeFrameDoneQ[PIPE_FUSION]);
        }

        m_latestRequestListLock.lock();
        m_latestRequestList.clear();
        m_essentialRequestList.clear();
        m_latestRequestListLock.unlock();
    }
#endif
#ifdef BUFFER_DUMP
    stopThreadAndInputQ(m_dumpThread, 1, m_dumpBufferQ);
#endif

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, STREAM_THREAD_STOP_END, 0);

    for (int i = 0; i < CAMERA_ID_MAX; i++) {
        if (m_captureSelector[i] != NULL) {
            m_captureSelector[i]->release();
        }
    }
    {
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, REQUEST_FLUSH_START, 0);
        m_requestMgr->flush();
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, REQUEST_FLUSH_END, 0);
    }
    ret = m_clearRequestList(&m_requestPreviewWaitingList, &m_requestPreviewWaitingLock);
    if (ret < 0) {
        CLOGE("m_clearList(m_processList) failed [%d]", ret);
    }
    ret = m_clearRequestList(&m_requestCaptureWaitingList, &m_requestCaptureWaitingLock);
    if (ret < 0) {
        CLOGE("m_clearList(m_processList) failed [%d]", ret);
    }

    if (isOfflineCaptureRunning() != true) {
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, BUFFER_RESET_START, 0);
        ret = m_bufferSupplier->resetBuffers();
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, BUFFER_RESET_END, 0);
        if (ret != NO_ERROR) {
            CLOGE("Failed to resetBuffers. ret %d", ret);
        }

        ret = m_clearList(&m_captureProcessList, &m_captureProcessLock);
        if (ret < 0) {
            CLOGE("m_clearList(m_captureProcessList) failed [%d]", ret);
        }
    }

    /* Clear frame list, because the frame number is initialized in startFrameFactoryThread. */
    ret = m_clearList(&m_processList, &m_processLock);
    if (ret < 0) {
        CLOGE("m_clearList(m_processList) failed [%d]", ret);
    }

    /*
     * do unlock/lock of flushLock to give a chance to processCaptureRequest()
     * to flush remained requests and wait maximum 33ms for finishing current
     * processCaptureRequest().
     */
    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, WAIT_PROCESS_CAPTURE_REQUEST_START, 0);
    m_flushLock.unlock();
    retryCount = 33; /* 33ms */
    while (m_flushLockWait && retryCount > 0) {
        CLOGW("wait for done current processCaptureRequest(%d)!!", retryCount);
        retryCount--;
        usleep(1000);
    }
    m_flushLock.lock();
    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, WAIT_PROCESS_CAPTURE_REQUEST_END, 0);

    if (m_getState() != EXYNOS_CAMERA_STATE_ERROR) {
        /*
         * In the Error state, flush() can not be called by frame work.
         * But, flush() is called internally when Device close is called.
         * So, flush operation is performed, and exynos_camera_state is not changed.
         */
        ret = m_transitState(EXYNOS_CAMERA_STATE_CONFIGURED);
        if (ret != NO_ERROR) {
            CLOGE("Failed to transitState into CONFIGURED. ret %d", ret);
            goto func_exit;
        }
    }

func_exit:
    setPreviewProperty(false);

    /* flush unlock */
    m_flushLock.unlock();

    CLOGD(" : OUT---");
    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FLUSH_END, 0);
    return ret;
}

status_t ExynosCamera::m_fastenAeStable(ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer fastenAeBuffer[NUM_FASTAESTABLE_BUFFERS];
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;

    if (factory == NULL) {
        CLOGE("frame factory is NULL!!");
        return BAD_VALUE;
    }

    int cameraId = factory->getCameraId();

    bufTag.pipeId[0] = PIPE_3AA;
    bufTag.managerType = BUFFER_MANAGER_FASTEN_AE_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("SKIP_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create SKIP_BUF. ret %d", ret);
        return ret;
    }

    int bufferCount = m_exynosconfig->current->bufInfo.num_fastaestable_buffer - 4;

    bufConfig.planeCount = 2;
    bufConfig.size[0] = 32 * 64 * 2;
    bufConfig.reqBufCount = bufferCount;
    bufConfig.allowedMaxBufCount = bufferCount;
    bufConfig.batchSize = 1; /* 1, fixed batch size */
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = false;
    bufConfig.reservedMemoryCount = 0;

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc SKIP_BUF. ret %d.", ret);
        goto done;
    }

    for (int i = 0; i < bufferCount; i++) {
        ret = m_bufferSupplier->getBuffer(bufTag, &fastenAeBuffer[i]);
        if (ret != NO_ERROR) {
            CLOGE("[B%d]Failed to getBuffer", fastenAeBuffer[i].index);
            goto done;
        }
    }

    m_parameters[cameraId]->setFastenAeStableOn(true);

    ret = factory->fastenAeStable(bufferCount, fastenAeBuffer);
    if (ret != NO_ERROR) {
        ret = INVALID_OPERATION;
        CLOGE("fastenAeStable fail(%d)", ret);
    }

    m_parameters[cameraId]->setFastenAeStableOn(false);

    m_checkFirstFrameLux = true;
done:
     m_bufferSupplier->deinit(bufTag);

    return ret;
}

bool ExynosCamera::m_previewStreamFunc(ExynosCameraFrameSP_sptr_t newFrame, int pipeId)
{
    status_t ret = 0;
    ExynosCameraFrameFactory *factory = NULL;
#ifdef USE_DUAL_CAMERA
    enum FRAME_FACTORY_TYPE frameFactoryType;
#endif

    if (newFrame == NULL) {
        CLOGE("frame is NULL");
        return true;
    } else if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGD("[F%d P%d]Flush is in progress.",
                newFrame->getFrameCount(),
                pipeId);
        return false;
    }

    CLOG_PERFRAME(PATH, m_cameraId, m_name, newFrame.get(), nullptr, newFrame->getRequestKey(), "pipeId(%d)", pipeId);

    if (pipeId == PIPE_3AA) {
#ifdef USE_DUAL_CAMERA
        if (newFrame->getFrameType() == FRAME_TYPE_PREVIEW_SLAVE
            || newFrame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE
            || newFrame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE
            || newFrame->getFrameType() == FRAME_TYPE_TRANSITION_SLAVE) {
            m_previewDurationTimer[1].stop();
            m_previewDurationTime[1] = (int)m_previewDurationTimer[1].durationMsecs();
            CLOGV("[F%d T%d] SLAVE frame duration time(%d)",
                    newFrame->getFrameCount(), newFrame->getFrameType(), m_previewDurationTime[1]);
            m_previewDurationTimer[1].start();
        } else
#endif
        {
            m_previewDurationTimer[0].stop();
            m_previewDurationTime[0] = (int)m_previewDurationTimer[0].durationMsecs();
            CLOGV("[F%d T%d] MASTER frame duration time(%d)",
                    newFrame->getFrameCount(), newFrame->getFrameType(), m_previewDurationTime[0]);
            m_previewDurationTimer[0].start();
        }
    }

    if (newFrame->getFrameType() == FRAME_TYPE_INTERNAL
#ifdef USE_DUAL_CAMERA
        || newFrame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE
        || newFrame->getFrameType() == FRAME_TYPE_TRANSITION
        || newFrame->getFrameType() == FRAME_TYPE_TRANSITION_SLAVE
#endif
#ifdef SUPPORT_SENSOR_MODE_CHANGE
        || newFrame->getFrameType() == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION
#endif

        ) {
#ifdef USE_DUAL_CAMERA
        if (newFrame->isSlaveFrame()) {
            frameFactoryType = newFrame->getFactoryType();
            if (frameFactoryType >= FRAME_FACTORY_TYPE_MAX) {
                CLOGW("frameFactoryType (%d) is not proper", frameFactoryType);
                frameFactoryType = GET_FRAME_FACTORY_TYPE(FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + 1); //fall back
            }
            factory = m_frameFactory[frameFactoryType];
        } else
#endif
        {
            if (m_configurations->getMode(CONFIGURATION_VISION_MODE) == true) {
                factory = m_frameFactory[FRAME_FACTORY_TYPE_VISION];
            } else {
                factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
            }
        }

        /* Handle the internal frame for each pipe */
        ret = m_handleInternalFrame(newFrame, pipeId, factory);
        if (ret < 0) {
            CLOGE("handle preview frame fail");
            return ret;
        }
    } else if (newFrame->getFrameType() == FRAME_TYPE_VISION) {
        factory = m_frameFactory[FRAME_FACTORY_TYPE_VISION];
        ret = m_handleVisionFrame(newFrame, pipeId, factory);
        if (ret < 0) {
            CLOGE("handle preview frame fail");
            return ret;
        }
    } else {
        /* TODO: M2M path is also handled by this */
#ifdef USE_DUAL_CAMERA
        if (newFrame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE
            || newFrame->getFrameType() == FRAME_TYPE_PREVIEW_SLAVE) {
            if (pipeId == PIPE_FUSION
                    ) {
                factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
            } else
            {
                frameFactoryType = newFrame->getFactoryType();
                if (frameFactoryType >= FRAME_FACTORY_TYPE_MAX) {
                    CLOGW("frameFactoryType (%d) is not proper", frameFactoryType);
                    frameFactoryType = GET_FRAME_FACTORY_TYPE(FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + 1); //fall back
                }
                factory = m_frameFactory[frameFactoryType];
            }
        } else
#endif
        {
            factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
        }

        ret = m_handlePreviewFrame(newFrame, pipeId, factory);
        if (ret < 0) {
            CLOGE("handle preview frame fail");
            return ret;
        }
    }

    return true;
}

status_t ExynosCamera::m_checkMultiCaptureMode(ExynosCameraRequestSP_sprt_t request)
{
#ifdef DEBUG_STREAM_CONFIGURATIONS
    CLOGD("DEBUG_STREAM_CONFIGURATIONS::generate request frame request(%d)", request->getKey());
#endif

    {
        m_currentMultiCaptureMode = MULTI_CAPTURE_MODE_NONE;
    }

    m_checkMultiCaptureMode_vendor_update(request);

    CLOGV("- OUT - (F:%d)", request->getKey());

    return NO_ERROR;
}

status_t ExynosCamera::m_createCaptureFrameFunc(void)
{
    status_t ret = NO_ERROR;
    ExynosCameraRequestSP_sprt_t request = NULL;
    struct camera2_shot_ext *service_shot_ext = NULL;
    FrameFactoryList previewFactoryAddrList;
    FrameFactoryList captureFactoryAddrList;
    ExynosCameraFrameFactory *factory = NULL;
    FrameFactoryListIterator factorylistIter;
    factory_handler_t frameCreateHandler;
    List<ExynosCameraRequestSP_sprt_t>::iterator r;
    frame_type_t frameType = FRAME_TYPE_PREVIEW;
    bool jpegRequest = false;
    bool stallRequest = false;

#ifdef USE_DUAL_CAMERA
    ExynosCameraFrameFactory *subFactory = NULL;
    frame_type_t subFrameType = FRAME_TYPE_PREVIEW;
#endif

    if (m_getSizeFromRequestList(&m_requestCaptureWaitingList, &m_requestCaptureWaitingLock) == 0) {
        return ret;
    }

#ifdef DEBUG_STREAM_CONFIGURATIONS
    CLOGD("DEBUG_STREAM_CONFIGURATIONS::[R] generate request frame");
#endif

    m_requestCaptureWaitingLock.lock();
    r = m_requestCaptureWaitingList.begin();
    request = *r;
    m_requestCaptureWaitingList.erase(r);
    m_requestCaptureWaitingLock.unlock();

    previewFactoryAddrList.clear();
    captureFactoryAddrList.clear();
    request->getFactoryAddrList(FRAME_FACTORY_TYPE_CAPTURE_PREVIEW, &previewFactoryAddrList);
    request->getFactoryAddrList(FRAME_FACTORY_TYPE_REPROCESSING, &captureFactoryAddrList);
    CLOGD("[R%d F%d] Create CaptureFrame of request", request->getKey(), request->getFrameCount());

    m_configurations->setModeValue(CONFIGURATION_YUV_STALL_PORT_USAGE, YUV_STALL_USAGE_DSCALED);

#ifdef DEBUG_FUSION_CAPTURE_DUMP
    captureNum++;
#endif

    if (previewFactoryAddrList.empty() == true) {
        ExynosCameraRequestSP_sprt_t serviceRequest = NULL;
        m_popServiceRequest(serviceRequest);
        serviceRequest = NULL;
    }

    /* Update the entire shot_ext structure */
    service_shot_ext = request->getServiceShot();
    if (service_shot_ext == NULL) {
        CLOGE("[R%d] Get service shot is failed", request->getKey());
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        bool flagFinishFactoryStart = false;
        if (m_getState() == EXYNOS_CAMERA_STATE_RUN)
            flagFinishFactoryStart = true;

        m_checkDualOperationMode(request, false, true, flagFinishFactoryStart);
        if (ret != NO_ERROR) {
            CLOGE("m_checkDualOperationMode fail! ret(%d)", ret);
        }
    }
#endif

    /*
     * HACK: Checked the request combination!!
     * If this device hasn't three mcsc ports, it can't support
     * YUV_STALL and JPEG request concurrently.
     */
    if (m_parameters[m_cameraId]->getNumOfMcscOutputPorts() < 5) {
        for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
            int id = request->getStreamIdwithBufferIdx(i);
            switch (id % HAL_STREAM_ID_MAX) {
                case HAL_STREAM_ID_JPEG:
                    jpegRequest = true;
                    break;
                case HAL_STREAM_ID_CALLBACK_STALL:
                case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
                    stallRequest = true;
                    break;
                default:
                    break;
            }
        }

        if (jpegRequest == true && stallRequest == true) {
            CLOG_ASSERT("this device can't support YUV_STALL and JPEG at the same time");
        }
    }

    /* Call the frame create handler fro each frame factory */
    /* Frame createion handler calling sequence is ordered in accordance with
       its frame factory type, because there are dependencies between frame
       processing routine.
     */

    for (factorylistIter = captureFactoryAddrList.begin(); factorylistIter != captureFactoryAddrList.end(); ) {
        factory = *factorylistIter;
        CLOGV("frameFactory (%p)", factory);

        switch(factory->getFactoryType()) {
            case FRAME_FACTORY_TYPE_CAPTURE_PREVIEW:
                frameType = FRAME_TYPE_PREVIEW;
                break;
            case FRAME_FACTORY_TYPE_REPROCESSING:
                frameType = FRAME_TYPE_REPROCESSING;
                break;
            case FRAME_FACTORY_TYPE_VISION:
                frameType = FRAME_TYPE_VISION;
                break;
            default:
                CLOGE("[R%d] Factory type is not available", request->getKey());
                break;
        }

#ifdef USE_DUAL_CAMERA
        if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
            enum DUAL_OPERATION_MODE dualOperationMode = m_configurations->getDualOperationMode();
            enum DUAL_OPERATION_MODE dualOperationModeReprocessing =
                m_configurations->getDualOperationModeReprocessing();
            int32_t slaveCamId;
            int32_t slaveCamIdx;

            CLOGD("dualOperationMode(%d), dualOperationModeReprocessing(%d)",
                    dualOperationMode, dualOperationModeReprocessing);

            switch(factory->getFactoryType()) {
            case FRAME_FACTORY_TYPE_CAPTURE_PREVIEW:
                slaveCamIdx = m_getCurrentCamIdx(false, SUB_CAM);
                slaveCamId = m_camIdInfo.cameraId[slaveCamIdx];
                if (dualOperationMode == DUAL_OPERATION_MODE_SYNC) {
                    subFrameType = FRAME_TYPE_PREVIEW_DUAL_SLAVE;
                    subFactory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + slaveCamIdx];
                    create_frame_info *createFrameInfo = new create_frame_info(request, subFactory, subFrameType);
                    m_createReprocessingFrameQ->pushProcessQ(&createFrameInfo);

                    frameType = FRAME_TYPE_PREVIEW_DUAL_MASTER;
                } else if (dualOperationMode == DUAL_OPERATION_MODE_SLAVE) {
                    factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + slaveCamIdx];
                    frameType = FRAME_TYPE_PREVIEW_SLAVE;
                }
                break;
            case FRAME_FACTORY_TYPE_REPROCESSING:
                slaveCamIdx = m_getCurrentCamIdx(true, SUB_CAM);
                slaveCamId = m_camIdInfo.cameraId[slaveCamIdx];
                if (dualOperationModeReprocessing == DUAL_OPERATION_MODE_SYNC) {
                    if (m_scenario == SCENARIO_DUAL_REAR_PORTRAIT || m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT) {
                        frameType = FRAME_TYPE_REPROCESSING_DUAL_MASTER;
                        create_frame_info *createFrameInfo = new create_frame_info(request, factory, frameType);
                        m_createReprocessingFrameQ->pushProcessQ(&createFrameInfo);

                        factory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + slaveCamIdx];
                        frameType = FRAME_TYPE_REPROCESSING_DUAL_SLAVE;
                    } else {
                        subFrameType = FRAME_TYPE_REPROCESSING_DUAL_SLAVE;
                        subFactory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + slaveCamIdx];
                        create_frame_info *createFrameInfo = new create_frame_info(request, subFactory, subFrameType);
                        m_createReprocessingFrameQ->pushProcessQ(&createFrameInfo);

                        frameType = FRAME_TYPE_REPROCESSING_DUAL_MASTER;
                    }
                } else if (dualOperationModeReprocessing == DUAL_OPERATION_MODE_SLAVE) {
#ifdef SUPPORT_REMOSAIC_CAPTURE
                    /* ToDo: Condiser to remosaic capture in SYNC mode */
                    if (m_configurations->getMode(CONFIGURATION_REMOSAIC_CAPTURE_MODE) == true) {
                        CLOGD("[REMOSAIC] FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION");
                        factory = m_frameFactory[FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING + slaveCamIdx];
                        frameType = FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION;
#ifdef WAIT_STANDBY_ON_EXCEPT_CURRENT_CAMERA
                        ret = m_waitDualStandbyOnForRemosaicCapture(slaveCamId);
                        if (ret != NO_ERROR) {
                            CLOGE("waitDualStanbyOnForRemosaicCapture fail! ret(%d)", ret);
                        }
#endif
                    } else
#endif
                    {
                        factory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + slaveCamIdx];
                        frameType = FRAME_TYPE_REPROCESSING_SLAVE;
                    }
                }
                break;
            default:
                CLOGE("[R%d] Factory type is not available", request->getKey());
                break;
            }
        }
#endif

#ifdef SUPPORT_REMOSAIC_CAPTURE
        if (frameType == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION) {
            CLOGD("[REMOSAIC] FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION");
            factory = m_frameFactory[FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING];

#ifdef WAIT_STANDBY_ON_EXCEPT_CURRENT_CAMERA
            ret = m_waitDualStandbyOnForRemosaicCapture(m_cameraId);
            if (ret != NO_ERROR) {
                CLOGE("waitDualStanbyOnForRemosaicCapture fail! ret(%d)", ret);
            }
#endif
        }
#endif

        frameCreateHandler = factory->getFrameCreateHandler();
        (this->*frameCreateHandler)(request, factory, frameType);

        factorylistIter++;
    }

    previewFactoryAddrList.clear();
    captureFactoryAddrList.clear();

    return ret;
}

void ExynosCamera::m_updateExposureTime(struct camera2_shot_ext *shot_ext)
{
    m_vendorUpdateExposureTime(shot_ext);
}

status_t ExynosCamera::m_createInternalFrameFunc(ExynosCameraRequestSP_sprt_t request,
                                                 bool flagFinishFactoryStart,
                                                 __unused enum Request_Sync_Type syncType,
                                                 frame_type_t frameType,
                                                 int cameraId)
{
#ifndef USE_DUAL_CAMERA
    UNUSED_VARIABLE(frameType);
#endif

    status_t ret = NO_ERROR;
    bool isNeedBayer = false;
    bool isNeedDynamicBayer = false;
    ExynosCameraFrameFactory *factory = NULL;
    ExynosCameraFrameSP_sptr_t newFrame = NULL;
    ExynosCameraBuffer buffer;
    ExynosCameraRequestSP_sprt_t newRequest = NULL;
    struct camera2_shot_ext *service_shot_ext = NULL;
    int currentCameraId = 0;
    int pipeId = -1;
    int dstPos = 0;
    uint32_t needDynamicBayerCount = 0;
    const buffer_manager_tag_t initBufTag;
    buffer_manager_tag_t bufTag;
    frame_type_t internalframeType = FRAME_TYPE_INTERNAL;
    frame_handle_components_t components;
    ExynosRect bayerCropRegion = {0, };
    enum DUAL_OPERATION_MODE dualOperationMode = DUAL_OPERATION_MODE_NONE;
    bool fallback = false;
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        // get latest dualOperationMode
        dualOperationMode = m_configurations->getDualOperationMode();
        fallback = m_configurations->isFallbackOn();
    }
#endif

#ifdef USE_DUAL_CAMERA
    if (frameType == FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
        /* This case is slave internal frame on SYNC mode */
        internalframeType = FRAME_TYPE_INTERNAL_SLAVE;
    } else if (frameType == FRAME_TYPE_INTERNAL_SLAVE) {
        internalframeType = FRAME_TYPE_INTERNAL_SLAVE;
    } else if (frameType == FRAME_TYPE_TRANSITION) {
        internalframeType = FRAME_TYPE_INTERNAL;
    } else if (frameType == FRAME_TYPE_TRANSITION_SLAVE) {
        internalframeType = FRAME_TYPE_INTERNAL_SLAVE;
    }
#endif
#ifdef SUPPORT_SENSOR_MODE_CHANGE
    if (frameType == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION) {
        internalframeType = FRAME_TYPE_INTERNAL_SENSOR_TRANSITION;
    }
#endif //SUPPORT_SENSOR_MODE_CHANGE

    m_getFrameHandleComponentsWrapper(internalframeType, &components, cameraId);
    currentCameraId = components.currentCameraId;

    if (m_configurations->getMode(CONFIGURATION_VISION_MODE) == true) {
        factory = m_frameFactory[FRAME_FACTORY_TYPE_VISION];
    } else {
        factory = components.previewFactory;
    }

    bool requestVC0 = (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);

    /* Initialize the request flags in framefactory */
    factory->setRequest(PIPE_VC0, requestVC0);
    factory->setRequest(PIPE_3AC, false);
    factory->setRequest(PIPE_3AP, false);
    factory->setRequest(PIPE_3AF, false);
    factory->setRequest(PIPE_ISP, false);
    factory->setRequest(PIPE_ISPP, false);
    factory->setRequest(PIPE_ISPC, false);
    factory->setRequest(PIPE_MCSC, false);
    factory->setRequest(PIPE_MCSC0, false);
    factory->setRequest(PIPE_MCSC1, false);
    factory->setRequest(PIPE_MCSC2, false);
    factory->setRequest(PIPE_GDC, false);
#ifdef USE_SLSI_PLUGIN
    for (int i = PIPE_PLUGIN_BASE; i <= PIPE_PLUGIN_MAX; i++)
        factory->setRequest(i, false);
#endif
    factory->setRequest(PIPE_MCSC5, false);
#ifdef USE_VRA_FD
    factory->setRequest(PIPE_VRA, false);
#endif
    factory->setRequest(PIPE_HFD, false);
#ifdef USES_CAMERA_EXYNOS_VPL
    factory->setRequest(PIPE_NFD, false);
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
    factory->setRequest(PIPE_SW_MCSC, false);
#endif
#ifdef SUPPORT_DEPTH_MAP
    factory->setRequest(PIPE_VC1, m_flagUseInternalDepthMap);
#endif
#ifdef USES_SW_VDIS
    factory->setRequest(PIPE_VDIS, false);
#endif
#ifdef SUPPORT_PD_IMAGE
    if (m_parameters[currentCameraId]->isPDImageSupported())
        factory->setRequest(PIPE_VC1, true);
#endif
#ifdef SUPPORT_ME
    factory->setRequest(PIPE_ME, false);
#endif

    factory->setRequest(m_getSensorGyroPipeId(), m_configurations->getMode(CONFIGURATION_SENSOR_GYRO_MODE));

    if (request != NULL) {
        camera3_stream_buffer_t *inputBuffer = request->getInputBuffer();
        if(inputBuffer == NULL) {
            isNeedBayer = true;
        }
    }

    m_needDynamicBayerCountLock.lock();
    needDynamicBayerCount = m_configurations->getModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT);
    if (needDynamicBayerCount > 0) {
        m_configurations->setModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT, needDynamicBayerCount - 1);
        m_needDynamicBayerCountLock.unlock();
        CLOGD("needDynamicBayerCount %d", needDynamicBayerCount);
        isNeedBayer = true;
        isNeedDynamicBayer = isNeedBayer;
    } else {
        m_needDynamicBayerCountLock.unlock();
    }

#ifdef USE_DUAL_CAMERA
    factory->setRequest(PIPE_BAYER_SYNC, false);
    factory->setRequest(PIPE_SYNC, false);
    factory->setRequest(PIPE_FUSION, false);

    if (!(frameType == FRAME_TYPE_TRANSITION ||
                frameType == FRAME_TYPE_TRANSITION_SLAVE))
#endif
    {
        switch (m_parameters[m_cameraId]->getReprocessingBayerMode()) {
        case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON :
            factory->setRequest(PIPE_VC0, true);
            break;
        case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON:
            factory->setRequest(PIPE_3AC, true);
            break;
        case REPROCESSING_BAYER_MODE_PURE_DYNAMIC :
            isNeedBayer = (isNeedBayer || requestVC0);
            isNeedDynamicBayer = isNeedBayer;
            factory->setRequest(PIPE_VC0, isNeedBayer);
            break;
        case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC :
            isNeedDynamicBayer = isNeedBayer;
            factory->setRequest(PIPE_3AC, isNeedBayer);
#ifdef USE_DUAL_CAMERA
            /* master : increase dynamic bayer count */
            if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) &&
                    (frameType == FRAME_TYPE_INTERNAL) && isNeedBayer) {
                android_atomic_inc(&m_needSlaveDynamicBayerCount);
            }
#endif
            break;
        default:
            break;
        }
    }


#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (frameType == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION) {
        CLOGD("[sensor transition period] remosaic bayer is from PIPE_VC0" \
                "And PIPE_3AP should be disabled not to pass remosaic frame to preview stream");
        factory->setRequest(PIPE_VC0, true);
        factory->setRequest(PIPE_3AC, false);
        factory->setRequest(PIPE_3AP, false);
    }
#endif

    if (m_configurations->getMode(CONFIGURATION_VISION_MODE) == true){
        factory->setRequest(PIPE_VC0, false);
    }

#ifdef DEBUG_RAWDUMP
    if (m_configurations->checkBayerDumpEnable()) {
        factory->setRequest(PIPE_VC0, true);
    }
#endif

#if defined(USE_DUAL_CAMERA) && defined(USE_DUAL_BAYER_SYNC)
    /* ToDo: consider Dual Zoom */
    if (!(frameType == FRAME_TYPE_TRANSITION ||
        frameType == FRAME_TYPE_TRANSITION_SLAVE)) {
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
            && m_configurations->getDualOperationMode() == DUAL_OPERATION_MODE_SYNC) {
            if ((factory->getRequest(PIPE_VC0) == true)
                || (factory->getRequest(PIPE_3AC) == true)) {
                factory->setRequest(PIPE_BAYER_SYNC, true);
            }
        }
    }
#endif

    if (request == NULL) {
        m_latestRequestListLock.lock();
        List<ExynosCameraRequestSP_sprt_t>::iterator r;
        if (m_latestRequestList.size() <= 0) {
            CLOGE("Request is NULL");
        } else {
            r = m_latestRequestList.begin();
            newRequest = *r;
        }
        m_latestRequestListLock.unlock();
    } else {
        newRequest = request;
    }

    if (newRequest != NULL) {
        service_shot_ext = newRequest->getServiceShot();
        if (service_shot_ext == NULL) {
            CLOGE("Get service shot fail, requestKey(%d)", newRequest->getKey());
            m_metadataConverter->initShotData(m_currentInternalShot[currentCameraId]);
        } else {
            *m_currentInternalShot[currentCameraId] = *service_shot_ext;
        }
    } else {
        m_metadataConverter->initShotData(m_currentInternalShot[currentCameraId]);
    }

    m_updateShotInfoLock.lock();
#ifdef SUPPORT_VENDOR_TAG_LONG_EXPOSURE_CAPTURE
    /* Do not use the LEC Parameter for internal frame */
    if (flagFinishFactoryStart == false && service_shot_ext != NULL) {
        if (service_shot_ext->shot.ctl.aa.captureIntent == AA_CAPTURE_INTENT_STILL_CAPTURE_EXPOSURE_DYNAMIC_SHOT) {
            switch (m_configurations->getModeValue(CONFIGURATION_SESSION_MODE_VALUE)) {
            case EXYNOS_SESSION_MODE_PRO:
                m_currentInternalShot[currentCameraId]->shot.ctl.aa.captureIntent =
                    m_currentPreviewShot[m_cameraId]->shot.ctl.aa.captureIntent;
                m_currentInternalShot[currentCameraId]->shot.ctl.aa.vendor_captureExposureTime =
                    m_currentPreviewShot[m_cameraId]->shot.ctl.aa.vendor_captureExposureTime;
                m_currentInternalShot[currentCameraId]->shot.ctl.aa.vendor_captureCount =
                    m_currentPreviewShot[m_cameraId]->shot.ctl.aa.vendor_captureCount;

                CLOGD("captureIntent(%d), ExposureTime(%u), captureCount(%d)",
                        m_currentInternalShot[currentCameraId]->shot.ctl.aa.captureIntent,
                        m_currentInternalShot[currentCameraId]->shot.ctl.aa.vendor_captureExposureTime,
                        m_currentInternalShot[currentCameraId]->shot.ctl.aa.vendor_captureCount);
                break;
            default:
                CLOGE("modeValue(%d)", m_configurations->getModeValue(CONFIGURATION_SESSION_MODE_VALUE));
                break;
            }
        } else {
            CLOGW("captureIntent(%d)", m_currentInternalShot[currentCameraId]->shot.ctl.aa.captureIntent);
        }
    } else {
        CLOGW("flagFinishFactoryStart(%d), service_shot_ext is NULL", flagFinishFactoryStart);
    }
#endif
    m_updateLatestInfoToShot(m_currentInternalShot[currentCameraId], frameType, &components);

    /* Generate the internal frame */
    if (request != NULL) {
        /* Set framecount into request */
        m_frameCountLock.lock();
        if (request->getFrameCount() == 0
#ifdef USE_DUAL_CAMERA
                && (frameType != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
           ) {
            m_requestMgr->setFrameCount(m_internalFrameCount++, request->getKey());
        }
        m_frameCountLock.unlock();

        ret = m_generateInternalFrame(factory, &m_processList, &m_processLock, newFrame, internalframeType, request);
#ifdef USE_DUAL_CAMERA
    } else if (frameType == FRAME_TYPE_TRANSITION || frameType == FRAME_TYPE_TRANSITION_SLAVE) {
        ret = m_generateTransitionFrame(factory, &m_processList, &m_processLock, newFrame, frameType, request);
#endif

    } else {
        ret = m_generateInternalFrame(factory, &m_processList, &m_processLock, newFrame, internalframeType);
    }

    m_updateShotInfoLock.unlock();

    if (ret != NO_ERROR) {
        CLOGE("m_generateFrame failed");
        return ret;
    } else if (newFrame == NULL) {
        CLOGE("newFrame is NULL");
        return INVALID_OPERATION;
    }

    if (request != NULL) {
        for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
            int id = request->getStreamIdwithBufferIdx(i);
            switch (id % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_CALLBACK_STALL:
                newFrame->setStreamRequested(STREAM_TYPE_CAPTURE, true);
                break;
            case HAL_STREAM_ID_RAW:
                newFrame->setStreamRequested(STREAM_TYPE_RAW, true);
                break;
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_VISION:
            default:
                break;
            }
        }

        if (request->getNumOfInputBuffer() < 1) {
            newFrame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                                               ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED);
        }
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        newFrame->setDualOperationMode(dualOperationMode);
        newFrame->setFallbackOn(fallback);
    }
#endif

#ifdef DEBUG_STREAM_CONFIGURATIONS
    CLOGD("DEBUG_STREAM_CONFIGURATIONS:[F%d]generate internal frame.", newFrame->getFrameCount());
#else
    CLOGV("[F%d]generate internal frame.", newFrame->getFrameCount());
#endif

    if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGD("[F%d]Flush is in progress.", newFrame->getFrameCount());
        /* Generated frame is going to be deleted at flush() */
        return ret;
    }

    if (newFrame->getStreamRequested(STREAM_TYPE_CAPTURE) || newFrame->getStreamRequested(STREAM_TYPE_RAW))
        m_updateExposureTime(m_currentInternalShot[currentCameraId]);

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, USER_DATA, CREATE_INTERNAL_FRAME, newFrame->getFrameCount());

    {
        /* BcropRegion is calculated in m_generateFrame    */
        /* so that updatePreviewStatRoi should be set here.*/
        ExynosRect tempRect;
        components.parameters->getStatCropSize(&tempRect, &bayerCropRegion);
    }
    components.parameters->updatePreviewStatRoi(m_currentInternalShot[currentCameraId],
                                                    &bayerCropRegion);
    components.parameters->updateDisplayStatRoi(newFrame, m_currentInternalShot[currentCameraId]);

    if (flagFinishFactoryStart == false) {
        /*
         * Flash capture has 2 frame control delays. So, need flash meta copy. (#N -> #N-2)
         * And meta data copy is done in the Camera driver.
         * Therefore, Camera HAL should not copy first requset flash mode to the prepare frame.
         */
        m_currentInternalShot[currentCameraId]->shot.ctl.flash.flashMode = CAM2_FLASH_MODE_OFF;
        CLOGV("flashMode is OFF");
    }

#ifdef SUPPORT_VENDOR_TAG_FACTORY_OIS_FW_VER
    if (m_configurations->getOisTestReqired(CONFIGURATION_OIS_TEST_FW_VER)) {
        int ois_fw_ver = 0;
        ret = factory->getControl(V4L2_CID_IS_FACTORY_OIS_FW_VER, &ois_fw_ver, PIPE_3AA);
        if (ret) {
            CLOGE("[MotFactory] ois: getcontrol(CONFIGURATION_OIS_TEST_FW_VER) failed!!");
        } else {
            m_configurations->setOisTestFwVer(ois_fw_ver);
            m_configurations->setOisTestReqired(CONFIGURATION_OIS_TEST_FW_VER, false);
        }
    }
#endif
#ifdef SUPPORT_VENDOR_TAG_FACTORY_OIS_HEA
    if (m_configurations->getOisTestReqired(CONFIGURATION_OIS_TEST_HEA)) {
        uint32_t oishea[CONFIGURATION_OIS_HEA_MAX];
        struct v4l2_ext_controls extCtrls;
        memset(&extCtrls, 0x00, sizeof(extCtrls));
        struct v4l2_ext_control extCtrl;
        memset(&extCtrl, 0x00, sizeof(extCtrl));
        struct OisHeaParameters oisHeaParams;
        memset(&oisHeaParams, 0x00, sizeof(oisHeaParams));
        extCtrls.ctrl_class = V4L2_CTRL_CLASS_CAMERA;
        extCtrls.count = 1;
        extCtrls.controls = &extCtrl;
        extCtrl.id = V4L2_CID_IS_FACTORY_OIS_HEA;
        extCtrl.ptr = &oisHeaParams;

        ret = factory->setExtControl(&extCtrls, PIPE_3AA);
        if (ret) {
            CLOGE("[MotFactory] setExtControl (ois_hea) failed!! ret %d",ret);
        } else {
            oishea[0] = oisHeaParams.x_max;
            oishea[1] = oisHeaParams.x_min;
            oishea[2] = oisHeaParams.y_max;
            oishea[3] = oisHeaParams.y_min;
            CLOGD("[MotFactory] setExtControl => oishea (%d %d %d %d)",
                oishea[0], oishea[1], oishea[2], oishea[3]);
            m_configurations->setOisTestHea(oishea);
            m_configurations->setOisTestReqired(CONFIGURATION_OIS_TEST_HEA, false);
        }
    }
#endif

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
    ////////////////////////////////////////////////
    // hack
    // led calibration only get the one capture frame request (== does not get any preview req)
    // so, no chance to set this flash mode.
    // about factory led calibration.
    if (m_configurations->getLedCalibrationEnable() == true) {
        ret = m_setLedCalibration(m_currentInternalShot[currentCameraId]);
        if (ret != NO_ERROR) {
            CLOGE("m_setLedCalibration() fail");
        }
    }
    ////////////////////////////////////////////////
#endif

#ifdef SUPPORT_SENSOR_MODE_CHANGE
    if (frameType == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION) {
        struct camera2_shot_ext remosaicShot;
        memcpy(&remosaicShot, m_currentPreviewShot[currentCameraId], sizeof(struct camera2_shot_ext));
        m_updateMetaDataCaptureIntent(&remosaicShot, frameType);
        ret = newFrame->setMetaData(&remosaicShot);
    } else
#endif
    {
        ret = newFrame->setMetaData(m_currentInternalShot[currentCameraId]);
    }

    if (ret != NO_ERROR) {
        CLOGE("Failed to setMetaData with m_currentInternalShot. framecount %d ret %d",
                newFrame->getFrameCount(), ret);
        return ret;
    }

    newFrame->setNeedDynamicBayer(isNeedDynamicBayer);

    pipeId = m_getBayerPipeId();

    /* Attach VC0 buffer & push frame to VC0 */
    if (newFrame->getRequest(PIPE_VC0) == true) {
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_VC0;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
        if (newFrame->getFrameType() == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION) {
           bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
        }
#endif
        buffer.index = -2;
        dstPos = factory->getNodeType(bufTag.pipeId[0]);

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to get Internal Bayer Buffer. ret %d",
                    newFrame->getFrameCount(), ret);
        }

        if (buffer.index < 0) {
            CLOGW("[F%d B%d]Invalid bayer buffer index. Skip to pushFrame",
                    newFrame->getFrameCount(), buffer.index);
            newFrame->setRequest(bufTag.pipeId[0], false);
        } else {
            ret = newFrame->setDstBufferState(pipeId, ENTITY_BUFFER_STATE_REQUESTED, dstPos);
            if (ret != NO_ERROR) {
                CLOGE("Failed to setDstBufferState. pipeId %d(%d) pos %d",
                        pipeId, bufTag.pipeId[0], dstPos);
                newFrame->setRequest(bufTag.pipeId[0], false);
            } else {
                ret = newFrame->setDstBuffer(pipeId, buffer, dstPos);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setDstBuffer. pipeId %d(%d) pos %d",
                            pipeId, bufTag.pipeId[0], dstPos);
                    newFrame->setRequest(bufTag.pipeId[0], false);
                }
            }
        }
    }

#if defined(SUPPORT_DEPTH_MAP) || defined(SUPPORT_PD_IMAGE)
    if (newFrame->getRequest(PIPE_VC1) == true) {
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_VC1;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
        buffer.index = -2;
        dstPos = factory->getNodeType(bufTag.pipeId[0]);

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to get Internal Depth Buffer. ret %d",
                    newFrame->getFrameCount(), ret);
        }

        CLOGV("[F%d B%d]Use Internal Depth Buffer",
                newFrame->getFrameCount(), buffer.index);

        if (buffer.index < 0) {
            CLOGW("[F%d B%d]Invalid bayer buffer index. Skip to pushFrame",
                    newFrame->getFrameCount(), buffer.index);
            newFrame->setRequest(bufTag.pipeId[0], false);
        } else {
            ret = newFrame->setDstBufferState(pipeId, ENTITY_BUFFER_STATE_REQUESTED, dstPos);
            if (ret == NO_ERROR) {
                ret = newFrame->setDstBuffer(pipeId, buffer, dstPos);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setDstBuffer. pipeId %d(%d) pos %d",
                            pipeId, bufTag.pipeId[0], dstPos);
                    newFrame->setRequest(bufTag.pipeId[0], false);
                }
            } else {
                CLOGE("Failed to setDstBufferState. pipeId %d(%d) pos %d",
                        pipeId, bufTag.pipeId[0], dstPos);
                newFrame->setRequest(bufTag.pipeId[0], false);
            }
        }
    }
#endif

    ////////////////////////////////////////////////
    // get sensor gyro buf
    int sensorGyroPipeId = m_getSensorGyroPipeId();

    if (newFrame->getRequest(sensorGyroPipeId) == true) {
        int dstPos = factory->getNodeType(sensorGyroPipeId);

        ret = m_getBuffer(newFrame,
                          pipeId,
                          sensorGyroPipeId,
                          dstPos,
                          BUFFER_MANAGER_ION_TYPE);
        if (ret != NO_ERROR) {
            CLOGE("[F%d] m_getBuffer(newFrame, pipeId(%d), sensorGyroPipeId(%d), dstPos(%d), BUFFER_MANAGER_ION_TYPE) fail",
                newFrame->getFrameCount(), pipeId, sensorGyroPipeId, dstPos);
        }
    }

    ////////////////////////////////////////////////

#ifdef USES_SENSOR_LISTENER
    m_getSensorListenerData(&components);
#endif

    /* Attach SrcBuffer */
    ret = m_setupEntity(pipeId, newFrame);
    if (ret != NO_ERROR) {
        CLOGW("[F%d]Failed to setupEntity. pipeId %d", newFrame->getFrameCount(), pipeId);
    } else {
        factory->pushFrameToPipe(newFrame, pipeId);
    }

    return ret;
}

status_t ExynosCamera::m_handleBayerBuffer(ExynosCameraFrameSP_sptr_t frame,
                                                 ExynosCameraRequestSP_sprt_t request,
                                                 int leaderPipeId,
                                                 bool needSync)
{
    status_t ret = NO_ERROR;
    uint32_t bufferDirection = INVALID_BUFFER_DIRECTION;
    uint32_t needDynamicBayerCount = 0;
    ExynosCameraBuffer buffer;
    entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_COMPLETE;
    int dstPos = 0;
    int pipeId = leaderPipeId; // it can be changed
    frame_handle_components_t components;
#ifdef SUPPORT_DEPTH_MAP
    bool releaseDepthBuffer = true;
#endif

    if (frame == NULL) {
        CLOGE("Frame is NULL");
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);
    ExynosCameraFrameFactory *factory = components.previewFactory;
    bool flite3aaM2M = (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);
    bool flagForceHoldDynamicBayer = false;

    assert(pipeId >= 0);
    assert(pipeId < MAX_PIPE_NUM);

    switch (pipeId) {
        case PIPE_FLITE:
            dstPos = factory->getNodeType(PIPE_VC0);
            bufferDirection = DST_BUFFER_DIRECTION;

            ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getDstBuffer for PIPE_VC0. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }

            ret = frame->getDstBufferState(pipeId, &bufferState, dstPos);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to getDstBufferState for PIPE_VC0",
                    frame->getFrameCount(), bufferDirection);
            }
            break;

        case PIPE_3AA:
        case PIPE_BAYER_SYNC:
            if (components.parameters->getUsePureBayerReprocessing() == true
#ifdef SUPPORT_REMOSAIC_CAPTURE
                || (frame->getFrameType() == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION)
#endif //SUPPORT_REMOSAIC_CAPTURE
                ) {
                pipeId = flite3aaM2M ? PIPE_FLITE : PIPE_3AA;
                dstPos = factory->getNodeType(PIPE_VC0);
            } else {
                pipeId = PIPE_3AA;
                dstPos = factory->getNodeType(PIPE_3AC);
            }
            bufferDirection = DST_BUFFER_DIRECTION;

            ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getDstBuffer. pos %d. ret %d",
                        frame->getFrameCount(), buffer.index, dstPos, ret);
                goto SKIP_PUTBUFFER;
            }

            ret = frame->getDstBufferState(pipeId, &bufferState, dstPos);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to getDstBufferState. pos %d. ret %d",
                        frame->getFrameCount(), buffer.index, dstPos, ret);
                goto SKIP_PUTBUFFER;
            }

            if (leaderPipeId == PIPE_BAYER_SYNC) {
                ret = frame->getSrcBufferState(leaderPipeId, &bufferState);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to getSrcBufferState. pos %d. ret %d",
                            frame->getFrameCount(), buffer.index, dstPos, ret);
                    goto SKIP_PUTBUFFER;
                }
            }
            break;
        default:
            CLOGE("[F%d]Invalid bayer handling PipeId %d", frame->getFrameCount(), pipeId);
            return INVALID_OPERATION;
    }

    assert(buffer != NULL);

    if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
        CFLOGE(frame, "[F%d B%d]Invalid state. bufferState %d, frameState %d, pipeId %d",
                frame->getFrameCount(), buffer.index,
                bufferState, frame->getFrameState(), pipeId);

        if (frame->getStreamRequested(STREAM_TYPE_ZSL_OUTPUT) == false) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer. pipeId %d",
                        frame->getFrameCount(), buffer.index, pipeId);
                /* No operation */
            }
        }

        if (request == NULL) {
            CLOGE("[F%d] request is NULL.", frame->getFrameCount());
            ret = INVALID_OPERATION;
        } else if ((frame->getFrameType() == FRAME_TYPE_INTERNAL
#ifdef USE_DUAL_CAMERA
                    || frame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE
#endif
#ifdef SUPPORT_SENSOR_MODE_CHANGE
                    || frame->getFrameType() == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION
#endif

                    ) && m_configurations->getMode(CONFIGURATION_DYNAMIC_BAYER_MODE) == false) {
            CLOGW("[F%d B%d]Always reprocessing mode. Skip ERROR_REQUEST callback. pipeId %d",
                    frame->getFrameCount(), buffer.index, pipeId);
        } else if (frame->getNeedDynamicBayer() && frame->getStreamRequested(STREAM_TYPE_ZSL_OUTPUT) == false) {
            m_needDynamicBayerCountLock.lock();
            needDynamicBayerCount = m_configurations->getModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT);
            m_configurations->setModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT, ++needDynamicBayerCount);
            m_needDynamicBayerCountLock.unlock();
            CLOGW("[F%d B%d]Dynamic reprocessing mode. needDynamicBayerCount(%d), Skip ERROR_REQUEST callback. pipeId %d",
                    frame->getFrameCount(), buffer.index, needDynamicBayerCount, pipeId);
        } else if (frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
            == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED
#ifdef USE_DUAL_CAMERA
            // TODO: why does it give error notify to service in case of this scenario ?
            && (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == false)
#endif
            ) {
            ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d]Failed to sendNotifyError. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, ret);
            }
        }

        if (frame->getStreamRequested(STREAM_TYPE_ZSL_OUTPUT)) {
            CLOGD("[F%d B%d]Handle ZSL buffer. FLITE-3AA_%s bayerPipeId %d",
                    frame->getFrameCount(), buffer.index,
                    flite3aaM2M ? "M2M" : "OTF",
                    pipeId);

            if (request == NULL) {
                CLOGE("[F%d]request is NULL.", frame->getFrameCount());
                ret = INVALID_OPERATION;
                goto CHECK_RET_PUTBUFFER;
            }

            ret = m_sendZslStreamResult(request, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to sendZslCaptureResult. bayerPipeId %d ret %d",
                        frame->getFrameCount(), buffer.index, pipeId, ret);
                goto CHECK_RET_PUTBUFFER;
            }
        }

        goto SKIP_PUTBUFFER;
    } else if (buffer.index < 0) {
        CLOGE("[F%d B%d]Invalid bayer buffer. pipeId %d",
                frame->getFrameCount(), buffer.index, pipeId);
        ret = INVALID_OPERATION;
        goto SKIP_PUTBUFFER;
    }

    if (needSync) {
        ret = frame->setSrcBuffer(PIPE_BAYER_SYNC, buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to setSrcBuffer for bayer. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
        } else {
            m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW]->pushFrameToPipe(frame, PIPE_BAYER_SYNC);
        }

        // exit
        return ret;
    }

    if (frame->getStreamRequested(STREAM_TYPE_ZSL_OUTPUT)) {
        CLOGV("[F%d B%d]Handle ZSL buffer. FLITE-3AA_%s bayerPipeId %d",
                frame->getFrameCount(), buffer.index,
                flite3aaM2M ? "M2M" : "OTF",
                pipeId);

        if (request == NULL) {
            CLOGE("[F%d]request is NULL.", frame->getFrameCount());
            ret = INVALID_OPERATION;
            goto CHECK_RET_PUTBUFFER;
        }

        ret = m_sendZslStreamResult(request, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to sendZslCaptureResult. bayerPipeId %d ret %d",
                    frame->getFrameCount(), buffer.index, pipeId, ret);
            goto CHECK_RET_PUTBUFFER;
        }
    } else if (components.parameters->isReprocessing() == true) {
        switch (components.parameters->getReprocessingBayerMode()) {
            case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON :
            case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON :
                CLOGV("[F%d B%d]Hold internal bayer buffer for reprocessing in Always On."
                        " FLITE-3AA_%s bayerPipeId %d",
                        frame->getFrameCount(), buffer.index,
                        flite3aaM2M ? "M2M" : "OTF", pipeId);

                frame->addSelectorTag(m_captureSelector[m_cameraId]->getId(), pipeId, dstPos, (bufferDirection == SRC_BUFFER_DIRECTION));

                ret = components.captureSelector->manageFrameHoldListHAL3(frame);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to manageFrameHoldListHAL3. bufDirection %d bayerPipeId %d ret %d",
                            frame->getFrameCount(), buffer.index,
                            bufferDirection, pipeId, ret);
                }
#ifdef SUPPORT_DEPTH_MAP
                else {
                    releaseDepthBuffer = false;
                }
#endif
                break;

            case REPROCESSING_BAYER_MODE_PURE_DYNAMIC :
            case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC :
#ifdef USE_DUAL_CAMERA
                /* check the dual slave frame for dynamic capture */
                flagForceHoldDynamicBayer = (m_configurations->getMode(CONFIGURATION_DUAL_MODE) &&
                                            (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE) &&
                                            (frame->getRequest(PIPE_3AC) == true));
#endif
#ifdef SUPPORT_SENSOR_MODE_CHANGE
                flagForceHoldDynamicBayer = (flagForceHoldDynamicBayer | (frame->getFrameType() == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION));
#endif
                if (frame->getStreamRequested(STREAM_TYPE_CAPTURE)
                    || frame->getStreamRequested(STREAM_TYPE_RAW)
                    || frame->getNeedDynamicBayer() == true
                    || flagForceHoldDynamicBayer) {
                    CLOGE("[F%d B%d T%d]Hold internal bayer buffer for reprocessing in Dynamic."
                            " FLITE-3AA_%s bayerPipeId %d",
                            frame->getFrameCount(), buffer.index, frame->getFrameType(),
                            flite3aaM2M ? "M2M" : "OTF", pipeId);

                    frame->addSelectorTag(m_captureSelector[m_cameraId]->getId(), pipeId, dstPos, (bufferDirection == SRC_BUFFER_DIRECTION));

#ifdef USE_DUAL_CAMERA
                    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE)) {
                        /* use normal holding frame API, because there's no release logic in manageFrameHoldListForDynamicBayer() */
                        ret = components.captureSelector->manageFrameHoldListHAL3(frame);
                    } else
#endif
                    {
                        ret = components.captureSelector->manageFrameHoldListForDynamicBayer(frame);
                    }
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to manageFrameHoldListForDynamicBayer."
                                " bufDirection %d bayerPipeId %d ret %d",
                                frame->getFrameCount(), buffer.index,
                                bufferDirection, pipeId, ret);
                    }
#ifdef SUPPORT_DEPTH_MAP
                    else {
                        releaseDepthBuffer = false;
                    }
#endif
                } else {
                    CLOGV("[F%d B%d]Return internal bayer buffer. FLITE-3AA_%s bayerPipeId %d",
                            frame->getFrameCount(), buffer.index,
                            flite3aaM2M ? "M2M" : "OTF", pipeId);

                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret !=  NO_ERROR) {
                        CLOGE("[F%d B%d]PutBuffers failed. bufDirection %d pipeId %d ret %d",
                                frame->getFrameCount(), buffer.index,
                                bufferDirection, pipeId, ret);
                    }
                }
                break;

            default:
                CLOGE("[F%d B%d]ReprocessingMode %d is not valid.",
                        frame->getFrameCount(), buffer.index,
                        components.parameters->getReprocessingBayerMode());

                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret !=  NO_ERROR) {
                    CLOGE("[F%d B%d]PutBuffers failed. bufDirection %d pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index,
                            bufferDirection, pipeId, ret);
                }

                ret = INVALID_OPERATION;
                break;
        }

#ifdef DEBUG_RAWDUMP
        ////////////////////////////////////////////////
        // YUV reprocessing bayer dump.
        if (m_configurations->checkBayerDumpEnable()
            && m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true) {
            ExynosCameraActivityFlash *flashMgr = components.activityControl->getFlashMgr();

            ret = m_dumpPreFlashBayerBuffer(frame, buffer, flashMgr);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]m_dumpPreFlashBayerBuffer() fail",
                    frame->getFrameCount(), buffer.index);
            }

            ret = m_dumpMainFlashBayerBuffer(frame, buffer, flashMgr);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]m_dumpMainFlashBayerBuffer() fail",
                    frame->getFrameCount(), buffer.index);
            }
        }
        ////////////////////////////////////////////////
#endif /* DEBUG_RAWDUMP */
    } else {
        /* No request for bayer image */
        CLOGV("[F%d B%d]Return internal bayer buffer. FLITE-3AA_%s bayerPipeId %d",
                frame->getFrameCount(), buffer.index,
                flite3aaM2M ? "M2M" : "OTF", pipeId);

        ret = m_bufferSupplier->putBuffer(buffer);
        if (ret !=  NO_ERROR) {
            CLOGE("[F%d B%d]PutBuffers failed. bufDirection %d pipeId %d ret %d",
                    frame->getFrameCount(), buffer.index,
                    bufferDirection, pipeId, ret);
        }
    }

    if (ret != NO_ERROR) {
        CLOGE("[F%d B%d]Handling bayer buffer failed."
                " isServiceBayer %d bufDirection %d pipeId %d ret %d",
                frame->getFrameCount(), buffer.index,
                frame->getStreamRequested(STREAM_TYPE_RAW),
                bufferDirection, pipeId, ret);
    }

#ifdef SUPPORT_DEPTH_MAP
    frame->setReleaseDepthBuffer(releaseDepthBuffer);
#endif

    return ret;

CHECK_RET_PUTBUFFER:
    /* Put the bayer buffer if there was an error during processing */
    if (ret != NO_ERROR) {
        CLOGE("[F%d B%d]Handling bayer buffer failed. Bayer buffer will be put."
                " isServiceBayer %d, bufDirection %d pipeId %d ret %d",
                frame->getFrameCount(), buffer.index,
                frame->getStreamRequested(STREAM_TYPE_RAW),
                bufferDirection, pipeId, ret);

        if (buffer.index >= 0) {
            if (m_bufferSupplier->putBuffer(buffer) !=  NO_ERROR) {
                // Do not taint 'ret' to print appropirate error log on next block.
                CLOGE("[F%d B%d]PutBuffers failed. bufDirection %d pipeId %d ret %d",
                        frame->getFrameCount(), buffer.index,
                        bufferDirection, bufferDirection, ret);
            }
        }
    }

SKIP_PUTBUFFER:
#ifdef SUPPORT_DEPTH_MAP
    frame->setReleaseDepthBuffer(releaseDepthBuffer);
#endif

    return ret;
}

#ifdef DEBUG_RAWDUMP
status_t ExynosCamera::m_dumpPreFlashBayerBuffer(ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer buffer, ExynosCameraActivityFlash *flashMgr)
{
    status_t ret = NO_ERROR;

    struct camera2_shot_ext *shot_ext = (struct camera2_shot_ext *) frame->getConstMeta();
    int frameCount = getMetaDmRequestFrameCount(shot_ext);
    bool preFlashDump = false;
    int cameraId = frame->getCameraId();

    ////////////////////////////////////////////////
    // Check condition
    CLOGV("[F%d] dumpToFile: check aePrecaptureTrigger(%d) captureIntent(%d) aeState(%d) getFlashStatus(%d)",
        frameCount,
        shot_ext->shot.dm.aa.aePrecaptureTrigger,
        shot_ext->shot.dm.aa.captureIntent,
        shot_ext->shot.dm.aa.aeState,
        flashMgr->getFlashStatus());

    struct ExynosCameraSensorInfoBase *sensorInfo = m_parameters[cameraId]->getSensorStaticInfo();

    if (sensorInfo->flashAvailable == ANDROID_FLASH_INFO_AVAILABLE_TRUE) {
        if (shot_ext->shot.dm.aa.aeState == AE_STATE_PRECAPTURE &&
            flashMgr->getFlashStatus() == AA_FLASHMODE_AUTO) {
            preFlashDump = true;
        }
    }

    ////////////////////////////////////////////////
    // Pre Flash dump
    if (preFlashDump == true) {
        bool bRet;
        char filePath[70];
        time_t rawtime;
        struct tm *timeinfo;

        memset(filePath, 0, sizeof(filePath));
        time(&rawtime);
        timeinfo = localtime(&rawtime);

        ////////////////////////////////////////////////
        // udm
        snprintf(filePath, sizeof(filePath), "/data/camera/preFlash_Raw%d_%02d%02d%02d_%02d%02d%02d_%d.bin",
            cameraId, timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
            timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec, frame->getFrameCount());

        bRet = dumpToFile((char *)filePath,
            (char *)&(shot_ext->shot.udm),
            sizeof(struct camera2_udm));
        if (bRet != true) {
            CLOGE("[F%d]dumpToFile(%s, %zu) fail", frameCount, filePath, sizeof(struct camera2_udm));
            ret = INVALID_OPERATION;
        } else {
            CLOGD("[F%d]dumpToFile(%s, %zu) succeed", frameCount, filePath, sizeof(struct camera2_udm));
        }

        ////////////////////////////////////////////////
        // preFlash bayer
        snprintf(filePath, sizeof(filePath), "/data/camera/preFlash_Raw%d_%02d%02d%02d_%02d%02d%02d_%d.raw",
            cameraId, timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
            timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec, frame->getFrameCount());

        bRet = dumpToFile((char *)filePath,
            buffer.addr[0],
            buffer.size[0]);
        if (bRet != true) {
            CLOGE("[F%d]dumpToFile(%s, %p, %d) fail", frameCount, filePath, buffer.addr[0], buffer.size[0]);
            ret = INVALID_OPERATION;
        } else {
            CLOGD("[F%d]dumpToFile(%s, %p, %d) succeed", frameCount, filePath, buffer.addr[0], buffer.size[0]);
        }
    }

    ////////////////////////////////////////////////

    return ret;
}

status_t ExynosCamera::m_dumpMainFlashBayerBuffer(ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer buffer, ExynosCameraActivityFlash *flashMgr)
{
    status_t ret = NO_ERROR;

    struct camera2_shot_ext *shot_ext = (struct camera2_shot_ext *) frame->getConstMeta();
    int frameCount = getMetaDmRequestFrameCount(shot_ext);
    bool flagBayerDump = false;
    int cameraId = frame->getCameraId();

    ////////////////////////////////////////////////
    // Bayer dump, when YUV Reprocessing
    ExynosCameraRequestSP_sprt_t request;

    request = m_requestMgr->getRunningRequest(frame->getFrameCount());
    if (request != NULL
        && request->getNumOfInputBuffer() == 0
        && request->hasStream(HAL_STREAM_ID_JPEG) == false) {

        ////////////////////////////////////////////////
        // Main Flash dump
        switch (shot_ext->shot.uctl.flashMode) {
        case CAMERA_FLASH_MODE_AUTO:
        case CAMERA_FLASH_MODE_ON:
        {
            int bestFlashFrameCount = flashMgr->getBestFlashShotFcount();

            if (frameCount == bestFlashFrameCount) {
                flagBayerDump = true;
                CLOGD("[F%d]dumpToFile:frameCount(%d) == bestFlashFrameCount(%d)(== Main Flash). so, dump",
                    frameCount, frameCount, bestFlashFrameCount);
            } else {
                CLOGV("[F%d]dumpToFile:frameCount(%d) != bestFlashFrameCount(%d)(== Main Flash). so. skip",
                    frameCount, frameCount, bestFlashFrameCount);
            }
            break;
        }
        default:
            if (shot_ext->shot.dm.aa.captureIntent == AA_CAPTURE_INTENT_STILL_CAPTURE) {
                flagBayerDump = true;
            }
            break;
        }
    }

    ////////////////////////////////////////////////
    // dump it.
    if (flagBayerDump == true) {
        bool bRet;
        char filePath[70];
        time_t rawtime;
        struct tm *timeinfo;

        memset(filePath, 0, sizeof(filePath));
        time(&rawtime);
        timeinfo = localtime(&rawtime);

        snprintf(filePath, sizeof(filePath), "/data/camera/MainFlash_Raw%d_%02d%02d%02d_%02d%02d%02d_%d.raw",
            cameraId, timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
            timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec, frame->getFrameCount());

        bRet = dumpToFile((char *)filePath,
            buffer.addr[0],
            buffer.size[0]);
        if (bRet != true) {
            CLOGE("[F%d]dumpToFile(%s, %p, %d) fail", frameCount, filePath, buffer.addr[0], buffer.size[0]);
            ret = INVALID_OPERATION;
        } else {
            CLOGD("[F%d]dumpToFile(%s, %p, %d) succeed", frameCount, filePath, buffer.addr[0], buffer.size[0]);
        }
    }

    ////////////////////////////////////////////////

    return ret;
}
#endif /* DEBUG_RAWDUMP */

#if defined (SUPPORT_DEPTH_MAP) || defined (SUPPORT_PD_IMAGE)
status_t ExynosCamera::m_handleDepthBuffer(ExynosCameraFrameSP_sptr_t frame, ExynosCameraRequestSP_sprt_t request)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer depthBuffer;
    uint32_t pipeDepthId = m_getBayerPipeId();
    entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_COMPLETE;
    ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
    int dstPos = factory->getNodeType(PIPE_VC1);
    camera3_buffer_status_t streamBufferStae = CAMERA3_BUFFER_STATUS_OK;
    int streamId = HAL_STREAM_ID_DEPTHMAP;

    if (frame == NULL) {
        CLOGE("Frame is NULL");
        return BAD_VALUE;
    }

    depthBuffer.index = -2;

    ret = frame->getDstBuffer(pipeDepthId, &depthBuffer, dstPos);
    if (ret != NO_ERROR) {
        if (request == NULL) {
            CLOGE("[F%d]Failed to get DepthMap buffer. ret %d",
                    frame->getFrameCount(), ret);
        } else {
            CLOGE("[R%d F%d]Failed to get DepthMap buffer. ret %d",
                    request->getKey(), frame->getFrameCount(), ret);
        }
    }

    ret = frame->getDstBufferState(pipeDepthId, &bufferState, dstPos);
    if (ret != NO_ERROR) {
        CLOGE("[F%d B%d]Failed to getDstBufferState. pos %d. ret %d",
                frame->getFrameCount(), depthBuffer.index, dstPos, ret);
    }

#ifdef SUPPORT_PD_IMAGE
    if (depthBuffer.index >= 0) {
        ret = m_bufferSupplier->putBuffer(depthBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to putBuffer. ret %d",
                    frame->getFrameCount(), depthBuffer.index, ret);
        }

        frame->setRequest(PIPE_VC1, false);
    }
    return ret;
#endif

    if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
        streamBufferStae = CAMERA3_BUFFER_STATUS_ERROR;
        CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                depthBuffer.index, frame->getFrameCount(), pipeDepthId);
    }

    if (request != NULL && frame->getStreamRequested(STREAM_TYPE_DEPTH)) {
        request->setStreamBufferStatus(streamId, streamBufferStae);
        frame->setRequest(PIPE_VC1, false);
        frame->setReleaseDepthBuffer(false);

        ret = m_sendDepthStreamResult(request, &depthBuffer, streamId);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d]Failed to m_sendDepthStreamResult. ret %d",
                    request->getKey(), frame->getFrameCount(), depthBuffer.index, ret);
        }
    }

    if (depthBuffer.index >= 0 && frame->getReleaseDepthBuffer() == true) {
        ret = m_bufferSupplier->putBuffer(depthBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to putBuffer. ret %d",
                    frame->getFrameCount(), depthBuffer.index, ret);
        }

        frame->setRequest(PIPE_VC1, false);
    }

    return ret;
}
#endif

status_t ExynosCamera::m_handleSensorGyroBuffer(ExynosCameraFrameSP_sptr_t frame)
{
    status_t funcRet = NO_ERROR;
    status_t ret = NO_ERROR;

    ////////////////////////////////////////////////
    // argument checking
    if (frame == NULL) {
        CLOGE("Frame is NULL. so, fail");
        return BAD_VALUE;
    }

    ////////////////////////////////////////////////
    // init variable
    ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];

    int pipeId           = m_getBayerPipeId();
    int sensorGyroPipeId = m_getSensorGyroPipeId();
    int dstPos           = factory->getNodeType(sensorGyroPipeId);

    ExynosCameraBuffer buffer;
    buffer.index = -2;

    entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_COMPLETE;
    camera3_buffer_status_t streamBufferStae = CAMERA3_BUFFER_STATUS_OK;

    ////////////////////////////////////////////////
    // get sensor gyro buffer
    ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
    if (ret != NO_ERROR) {
        CLOGE("[F%d]frame->getDstBuffer(pipeId(%d),dsPos(%d)) fail",
            frame->getFrameCount(), pipeId, dstPos);

        goto done;
    }

    ret = frame->getDstBufferState(pipeId, &bufferState, dstPos);
    if (ret != NO_ERROR) {
        CLOGE("[F%d]frame->getDstBufferState(pipeId(%d),dsPos(%d)) fail",
            frame->getFrameCount(), pipeId, dstPos);

        goto done;
    }

    if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
        CLOGE("[F%d] Dst buffer state is error index(%d), pipeId(%d)",
            frame->getFrameCount(), buffer.index, pipeId);

        goto done;
    }

#ifdef USES_SENSOR_GYRO_FACTORY_MODE
    if (m_configurations->getOisTestReqired(CONFIGURATION_OIS_TEST_GEA) == true) {
        uint8_t oisGea = 0xFF;

        ////////////////////////////////////////////////
        // create sensor gyro obj
        if (m_sensorGyroTest == NULL) {
            m_sensorGyroTest = (ExynosCameraFactoryTestSensorGyro *)ExynosCameraFactoryTestFactory::newFactoryTest(getCameraId(), "sensorGyroTest");

            ret = m_sensorGyroTest->create();
            if (ret != NO_ERROR) {
                CLOGE("[MotFactory] [F%d] m_sensorGyroTest->create() fail", frame->getFrameCount());
                goto done;
            }
        }

        ////////////////////////////////////////////////
        // use 3rd buffer
        struct camera2_shot_ext *shot_ext = (struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()];
        ret = frame->getMetaData(shot_ext);
        if (ret != NO_ERROR) {
            CLOGE("[MotFactory] [F%d] frame->getMetaData() fail", frame->getFrameCount());
            goto done;
        }

        if (frame->getFrameCount() < 3) {
            CLOGD("[MotFactory] skip [F%d]frame", frame->getFrameCount());
            goto done;
        }

        ////////////////////////////////////////////////
        // set buffer on invalid(== empty index);
        if (m_sensorGyroTest->flagValidBuffer(m_sensorGyroTestIndex) == false) {
            ret = m_sensorGyroTest->setBuffer(m_sensorGyroTestIndex, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("[MotFactory] [F%d] m_sensorGyroTest->setBuffer(m_sensorGyroTestIndex(%d), buffer(%d)) fail",
                    frame->getFrameCount(), m_sensorGyroTestIndex, buffer.index);
                goto done;
            }

            CLOGD("[MotFactory] [F%d(%d)] m_sensorGyroTest->setBuffer(m_sensorGyroTestIndex(%d), buffer(%d)) done",
                frame->getFrameCount(), getMetaDmRequestFrameCount(shot_ext), m_sensorGyroTestIndex, buffer.index);
        }

        ////////////////////////////////////////////////
        // get gyro self test result.
        if (m_sensorGyroTest->getMaxIndex() == m_sensorGyroTestIndex) {
            if (m_sensorGyroTest->flagChecked() == false) {
                ret = m_sensorGyroTest->check();
                if (ret != NO_ERROR) {
                    CLOGE("[MotFactory] [F%d] m_sensorGyroTest->check() fail",
                        frame->getFrameCount());
                    goto done;
                }
            }

            ////////////////////////////////////////////////
            // when there is vendor tag, update ois gea info
            sp<ExynosCameraVendorMetaData> vendorMeta = frame->getVendorMeta();
            if (vendorMeta) {
                oisGea = (uint8_t)m_sensorGyroTest->getResult();

                // 0x01 : OK
                // 0xFF : NG
                // 0xFE : Gyro communation error;
                CLOGI("[MotFactory] vendorMeta->update(EXYNOS_ANDROID_VENDOR_FACTORY_OIS_GEA, oisGea(0x%2X))  (ex : 0x01 : OK / 0xFF : NG / 0xFE : communation error)", oisGea);

                ret = vendorMeta->update(EXYNOS_ANDROID_VENDOR_FACTORY_OIS_GEA, &oisGea, 1);
                if (ret != NO_ERROR) {
                    CLOGE("[MotFactory] [F%d]vendorMeta->update(EXYNOS_ANDROID_VENDOR_FACTORY_OIS_GEA, oisGea(0x%2X)) fail",
                        frame->getFrameCount(), oisGea);

                    goto done;
                }
            }
        }
        ////////////////////////////////////////////////
    }
#endif

done:
    funcRet = ret;

    if (0 <= buffer.index) {
        ret = m_bufferSupplier->putBuffer(buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]m_bufferSupplier()->putBuffer(%d) fail",
                frame->getFrameCount(), buffer.index, buffer.index);
        }

        frame->setRequest(pipeId, false);
    }

    return funcRet;
}

status_t ExynosCamera::processCaptureRequest(camera3_capture_request *request)
{
    status_t ret = NO_ERROR;
    ExynosCamera::exynos_camera_state_t entryState = m_getState();
    ExynosCameraRequestSP_sprt_t req = NULL;
    ExynosCameraStream *streamInfo = NULL;
    uint32_t timeOutNs = 60 * 1000000; /* timeout default value is 60ms based on 15fps */
    uint32_t minFps = 0, maxFps = 0;
    int initialRequestCount = 0;
    uint32_t requiredRequestCount = -1;
    enum pipeline controlPipeId = (enum pipeline) m_parameters[m_cameraId]->getPerFrameControlPipe();
    camera3_stream_t *stream = NULL;
    EXYNOS_STREAM::STATE registerBuffer = EXYNOS_STREAM::HAL_STREAM_STS_UNREGISTERED;
    FrameFactoryList captureFactoryAddrList;
    bool flagFinishFactoryStart = false;
    if (m_getState() == EXYNOS_CAMERA_STATE_RUN)
        flagFinishFactoryStart = true;
#ifdef SUPPORT_LIMITED_HW_LEVEL_FALSH
    ExynosCameraStream *temp_stream = NULL;
    int temp_streamId = -1;
#endif

    /* 0. Check the validation of ExynosCamera */
    if (m_getState() == EXYNOS_CAMERA_STATE_ERROR) {
        CLOGE("ExynosCamera state is ERROR! Exynos Camera must be terminated by frame work.");
        ret = NO_INIT;
        goto req_err;
    }

    /* 1. Check the validation of request */
    if (request == NULL) {
        CLOGE("NULL request!");
        ret = BAD_VALUE;
        goto req_err;
    }

#ifdef DEBUG_STREAM_CONFIGURATIONS
    CLOGD("DEBUG_STREAM_CONFIGURATIONS:Capture request(%d) #out(%d)",
         request->frame_number, request->num_output_buffers);
#else
    CLOGV("Capture request(%d) #out(%d)",
         request->frame_number, request->num_output_buffers);
#endif

#ifdef DEBUG_IRIS_LEAK
#endif

#ifdef USE_DEBUG_PROPERTY
    // For Fence FD debugging
    if (request->input_buffer != NULL) {
        const camera3_stream_buffer* pStreamBuf = request->input_buffer;
        CLOG_PERFRAME(BUF, m_cameraId, m_name, nullptr, (void *)(pStreamBuf),
                request->frame_number, "[INPUT]");
        CLOGD("[R:%d] YUV reprocessing, num_output_buffers : %d", request->frame_number, request->num_output_buffers);
    }

    for(uint32_t i = 0; i < request->num_output_buffers; i++) {
        const camera3_stream_buffer* pStreamBuf = &(request->output_buffers[i]);
        CLOG_PERFRAME(BUF, m_cameraId, m_name, nullptr, (void *)(pStreamBuf),
                request->frame_number, "[OUTPUT%d]", i);
    }
#endif

    /* m_streamManager->dumpCurrentStreamList(); */

    /* 2. Check NULL for service metadata */
    if ((request->settings == NULL) && (m_requestMgr->isPrevRequest())) {
        CLOGE("Request%d: NULL and no prev request!!", request->frame_number);
        ret = BAD_VALUE;
        goto req_err;
    }

    /* 3. Check the registeration of input buffer on stream */
    if (request->input_buffer != NULL){
        stream = request->input_buffer->stream;
        streamInfo = static_cast<ExynosCameraStream*>(stream->priv);
        streamInfo->getRegisterBuffer(&registerBuffer);

        if (registerBuffer != EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED) {
            CLOGE("Request %d: Input buffer not from input stream!", request->frame_number);
            CLOGE("Bad Request %p, type %d format %x",
                    request->input_buffer->stream,
                    request->input_buffer->stream->stream_type,
                    request->input_buffer->stream->format);
            ret = BAD_VALUE;
            goto req_err;
        }
    }

    /* 4. Check the output buffer count */
    if ((request->num_output_buffers < 1) || (request->output_buffers == NULL)) {
        CLOGE("Request %d: No output buffers provided!", request->frame_number);
        ret = BAD_VALUE;
        goto req_err;
    }

#ifdef SUPPORT_LIMITED_HW_LEVEL_FALSH
    /* [HACK] check stream in request */
    for (int i = 0; i < request->num_output_buffers; i++) {
        temp_streamId = -1;
        temp_stream = static_cast<ExynosCameraStream *>(request->output_buffers[i].stream->priv);
        temp_stream->getID(&temp_streamId);
        if (temp_streamId == HAL_STREAM_ID_CALLBACK) {
            m_configurations->setModeValue(CONFIGURATION_CALLBACK_REQUEST_KEY_VALUE, request->frame_number);
            CLOGV("CONFIGURATION_CALLBACK_REQUEST_KEY_VALUE (%d)", m_configurations->getModeValue(CONFIGURATION_CALLBACK_REQUEST_KEY_VALUE));
        }
    }
#endif

    /* 5. Store request settings
     * Caution : All information must be copied into internal data structure
     * before receiving another request from service
     */
    ret = m_pushServiceRequest(request, req);

    /* check restart condition */
    ret = m_checkRestartStream(req);
    if (ret != NO_ERROR) {
        CLOGE("m_checkRestartStream failed [%d]", ret);
        goto req_err;
    }

#ifdef USES_SW_VDIS
    if (m_getState() == EXYNOS_CAMERA_STATE_CONFIGURED &&
            m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE)) {
        if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
            if (m_exCameraSolutionSWVdis != NULL) {
                m_exCameraSolutionSWVdis->configureStream();
            }
        } else {
            status_t ret = NO_ERROR;
            int streamId = HAL_STREAM_ID_VIDEO;
            int width = 0, height = 0;
            ExynosCameraStream *stream = NULL;
            m_streamManager->getStream(streamId, &stream);
            int portId = m_parameters[m_cameraId]->getRecordingPortId();
            ret = stream->getSize((uint32_t *)&width, (uint32_t *)&height);
            if (ret == NO_ERROR) {
                ret = m_parameters[m_cameraId]->checkHwYuvSize(width, height, portId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setHwYuvSize for PREVIEW stream(VDIS). size %dx%d outputPortId %d",
                            width, height, portId);
                }
            } else {
                CLOGE("get Stream Size fail ret(%d)", ret);
            }
        }
    }
#endif

    CLOGV("[R%d F%d] Push request in ServiceList. ServiceListSize %d",
            req->getKey(), req->getFrameCount(), m_requestMgr->getServiceRequestCount());

    /* 6. Push request in RunningList */
    ret = m_pushRunningRequest(req);
    if (ret != NO_ERROR) {
        CLOGE("m_pushRunningRequest failed [%d]", ret);
        ret = INVALID_OPERATION;
        goto req_err;
    } else {
        m_flushLockWait = true;
        {
            /* flush lock */
            Mutex::Autolock lock(m_flushLock);

            /* thie request will be flushed during flush() */
            if (entryState == EXYNOS_CAMERA_STATE_FLUSH ||
                    m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
                CLOGE("Request key:%d, out:%d can't accepted during flush()!! forcely Flush() again!(%d,%d)",
                        request->frame_number, request->num_output_buffers,
                        entryState, m_getState());
                m_requestMgr->flush();
                m_flushLockWait = false;
                goto req_err;
            }
        }
        m_flushLockWait = false;
    }

    /* 7. Get FactoryAddr */
    ret = m_setFactoryAddr(req);
    captureFactoryAddrList.clear();

    if (m_parameters[m_cameraId]->isUseVideoHQISP() == false)
        req->getFactoryAddrList(FRAME_FACTORY_TYPE_REPROCESSING, &captureFactoryAddrList);

    m_checkMultiCaptureMode(req);

#ifdef USE_DUAL_CAMERA
    if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
        // for reprocessing update
        ret = m_checkDualOperationMode(req, true, true, flagFinishFactoryStart, true);
        if (ret != NO_ERROR) {
            CLOGE("m_checkDualOperationMode fail! ret(%d)", ret);
        }
    }
#endif

    /* 8. Push request in m_requestPreviewWaitingList and m_requestCaptureWaitingList */
    m_requestPreviewWaitingLock.lock();
    m_requestPreviewWaitingList.push_back(req);
    m_requestPreviewWaitingLock.unlock();

    if (captureFactoryAddrList.empty() == false) {
        CLOGD("[R%d F%d] Push capture request in m_requestCaptureWaitingList.",
                req->getKey(), req->getFrameCount());
#ifdef USES_OFFLINE_CAPTURE
        m_offlineCapture->processCaptureRequest(req);
#endif
        m_requestCaptureWaitingLock.lock();
        m_requestCaptureWaitingList.push_back(req);
        if (m_mainCaptureThread != NULL) {
            m_mainCaptureThread->run(PRIORITY_URGENT_DISPLAY);
        }
        m_requestCaptureWaitingLock.unlock();
    }

    /* 9. Calculate the timeout value for processing request based on actual fps setting */
    m_configurations->getPreviewFpsRange(&minFps, &maxFps);
    timeOutNs = (1000 / ((minFps == 0) ? 15 : minFps)) * 1000000;

    /* 10. Process initial requests for preparing the stream */
    if (m_getState() == EXYNOS_CAMERA_STATE_CONFIGURED) {
        ret = m_transitState(EXYNOS_CAMERA_STATE_START);
        if (ret != NO_ERROR) {
            CLOGE("[R%d]Failed to transitState into START. ret %d", request->frame_number, ret);
            goto req_err;
        }

        m_checkUseOnePort();
        CLOGD("first frame: [R%d] Start FrameFactory. state %d ", request->frame_number, m_getState());
        setPreviewProperty(true);

        m_framefactoryCreateThread->join();
        m_dualFramefactoryCreateThread->join();
        if (m_framefactoryCreateResult != NO_ERROR || m_dualFramefactoryCreateResult != NO_ERROR) {
            CLOGE("Failed to create framefactory %d %d", m_framefactoryCreateResult, m_dualFramefactoryCreateResult);
            m_transitState(EXYNOS_CAMERA_STATE_ERROR);
            ret = NO_INIT;
            goto req_err;
        }

        if (m_scenario == SCENARIO_DUAL_REAR_ZOOM
#ifdef USE_DUAL_CAMERA
            && m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
#endif
        ) {
            if (processCaptureRequest_vendor_initDualSolutionZoom(request, ret) != NO_ERROR)
                goto req_err;

        } else if (m_scenario == SCENARIO_DUAL_REAR_PORTRAIT || m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT) {
            if (processCaptureRequest_vendor_initDualSolutionPortrait(request, ret) != NO_ERROR)
                goto req_err;
        }

        m_configurations->updateMetaParameter(req->getMetaParameters());

#ifdef TIME_LOGGER_STREAM_PERFORMANCE_ENABLE
        TIME_LOGGER_INIT(m_cameraId);
#endif
#ifdef USE_DUAL_CAMERA
        if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
            m_checkDualOperationMode(req, true, false, false);
            if (ret != NO_ERROR) {
                CLOGE("m_checkDualOperationMode fail! ret(%d)", ret);
            }
        }
#endif

        m_firstRequestFrameNumber = request->frame_number;

        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, SET_BUFFER_THREAD_JOIN_START, 0);
        m_setBuffersThread->join();
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, SET_BUFFER_THREAD_JOIN_END, 0);

        if (m_captureStreamExist == true
                || m_parameters[m_cameraId]->isUseVideoHQISP() == true) {
            m_startPictureBufferThread->run(PRIORITY_DEFAULT);
        }

        m_framefactoryCreateThread->join();
        if (m_framefactoryCreateResult != NO_ERROR) {
            CLOGE("Failed to create framefactory");
            m_transitState(EXYNOS_CAMERA_STATE_ERROR);
            ret = NO_INIT;
            goto req_err;
        }

        {
            /* for FAST AE Stable */
#ifdef USE_DUAL_CAMERA
            if (m_configurations->getDualOperationMode() == DUAL_OPERATION_MODE_SLAVE) {
                int32_t slaveCamId;
                int32_t slaveCamIdx;
                slaveCamIdx = m_getCurrentCamIdx(false, SUB_CAM);
                slaveCamId = m_camIdInfo.cameraId[slaveCamIdx];

                /* for FAST AE Stable */
                if (m_parameters[m_camIdInfo.cameraId[slaveCamIdx]]->checkFastenAeStableEnable() == true) {
                    ret = m_fastenAeStable(m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + slaveCamIdx]);
                    if (ret != NO_ERROR) {
                        CLOGE("m_fastenAeStable() failed");
                        m_transitState(EXYNOS_CAMERA_STATE_ERROR);
                        ret = NO_INIT;
                        goto req_err;
                    }

                    m_configurations->setUseFastenAeStable(false);
                }
            } else
#endif
            {
                /* for FAST AE Stable */
                if (m_parameters[m_cameraId]->checkFastenAeStableEnable() == true) {
                    ret = m_fastenAeStable(m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW]);
                    if (ret != NO_ERROR) {
                        CLOGE("m_fastenAeStable() failed");
                        m_transitState(EXYNOS_CAMERA_STATE_ERROR);
                        ret = NO_INIT;
                        goto req_err;
                    }

                    m_configurations->setUseFastenAeStable(false);
                }
            }
        }

        m_frameFactoryStartResult = NO_ERROR;
#ifdef USE_DUAL_CAMERA
        m_dualFrameFactoryStartResult = NO_ERROR;
#endif
        m_frameFactoryStartThread->run();

#ifdef USES_SENSOR_GYRO_FACTORY_MODE
        if (m_configurations->getOisTestReqired(CONFIGURATION_OIS_TEST_GEA) == true) {
            ////////////////////////////////////////////////
            // alloc sensor gyro buf
            if (m_configurations->getMode(CONFIGURATION_SENSOR_GYRO_MODE) == true) {
                int maxBufferCount = m_configurations->maxNumOfSensorBuffer();

                if (m_parameters[m_cameraId]->getSensorControlDelay() == 0) {
                    maxBufferCount -= SENSOR_REQUEST_DELAY;
                }

                ret = m_setSensorGyroBuffers(maxBufferCount);
                if (ret != NO_ERROR) {
                    CLOGE("m_setSensorGyroBuffers(%d) fail", maxBufferCount);
                }
            }

            ////////////////////////////////////////////////
            // increase from 0 to 1;
            CLOGI("[MotFactory] m_sensorGyroTestIndex(%d -> %d)", m_sensorGyroTestIndex, m_sensorGyroTestIndex + 1);
            m_sensorGyroTestIndex++;

            ////////////////////////////////////////////////
        }
#endif

#ifdef USES_SENSOR_LISTENER
        if (m_configurations->getMode(CONFIGURATION_VISION_MODE) == false) {
            if(m_sensorListenerThread != NULL) {
                m_sensorListenerThread->run();
            }
        }
#endif
    }
#ifdef USE_DUAL_CAMERA
    else if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        m_checkDualOperationMode(req, false, false, flagFinishFactoryStart);
        if (ret != NO_ERROR) {
            CLOGE("m_checkDualOperationMode fail! ret(%d)", ret);
        }
    }
#endif

    TIME_LOGGER_UPDATE(m_cameraId, request->frame_number, 0, INTERVAL, PROCESS_CAPTURE_REQUEST, 0);

    /* Adjust Initial Request Count
     * #sensor control delay > 0
     * #sensor control delay frames will be generated as internal frame.
     * => Initially required request count == Prepare frame count - #sensor control delay
     *
     * #sensor control delay == 0
     * Originally required prepare frame count + 1(HAL request margin) is required.
     * => Initially requred request count == Prepare frame count - SENSOR_REQUEST_DELAY + 1
     */
    if (m_parameters[m_cameraId]->getSensorControlDelay() > 0) {
        initialRequestCount = m_exynosconfig->current->pipeInfo.prepare[PIPE_3AA];
    } else {
        initialRequestCount = m_exynosconfig->current->pipeInfo.prepare[PIPE_3AA] + 1;
    }

    if (m_parameters[m_cameraId]->useServiceBatchMode() == true) {
        requiredRequestCount = 1;
    } else {
        requiredRequestCount = m_parameters[m_cameraId]->getBatchSize(controlPipeId);
        initialRequestCount *= m_parameters[m_cameraId]->getBatchSize(controlPipeId);
    }

    if (initialRequestCount < 1 || requiredRequestCount < 1) {
        CLOGW("Invalid initialRequestCount %d requiredRequestCount %dprepare %d sensorControlDelay %d/%d",
                initialRequestCount, requiredRequestCount,
                m_exynosconfig->current->pipeInfo.prepare[PIPE_3AA],
                m_parameters[m_cameraId]->getSensorControlDelay(),
                SENSOR_REQUEST_DELAY);
    }

	if ((minFps / MULTI_BUFFER_BASE_FPS) > 1)
        requiredRequestCount *= (minFps / MULTI_BUFFER_BASE_FPS);

    TIME_LOGGER_UPDATE(m_cameraId, request->frame_number, 0, DURATION, BLOCK_PROCESS_CAPTURE_REQUEST, true);

    CLOG_PERFORMANCE(FPS, m_cameraId, 0, INTERVAL, SERVICE_REQUEST, 0, req->getKey(), nullptr);
    CLOG_PERFRAME(PATH, m_cameraId, m_name, nullptr, nullptr, request->frame_number, "out(%d), requests(%d, %d), state(%d)",
            request->num_output_buffers,
            m_requestMgr->getServiceRequestCount(),
            m_requestMgr->getRunningRequestCount(),
            m_getState());

    while ((int)(request->frame_number - m_firstRequestFrameNumber) > initialRequestCount
            && m_requestMgr->getServiceRequestCount() > requiredRequestCount
            && m_getState() != EXYNOS_CAMERA_STATE_FLUSH) {
        status_t waitRet = NO_ERROR;
        m_captureResultDoneLock.lock();
        waitRet = m_captureResultDoneCondition.waitRelative(m_captureResultDoneLock, timeOutNs);
        if (waitRet == TIMED_OUT)
            CLOGV("Time out (m_processList:%zu / totalRequestCnt:%d)",
                    m_processList.size(), m_requestMgr->getAllRequestCount());
        m_captureResultDoneLock.unlock();
    }

    TIME_LOGGER_UPDATE(m_cameraId, request->frame_number, 0, DURATION, BLOCK_PROCESS_CAPTURE_REQUEST, false);

    captureFactoryAddrList.clear();

req_err:
    return ret;
}

status_t ExynosCamera::m_checkStreamBuffer(ExynosCameraFrameSP_sptr_t frame, ExynosCameraStream *stream,
                                            ExynosCameraBuffer *buffer, ExynosCameraRequestSP_sprt_t request,
                                            ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    entity_buffer_state_t bufferState;
    int streamId = -1;
    int pipeId = -1;
    int parentPipeId = -1;

    buffer->index = -2;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        ret = BAD_VALUE;
        goto func_exit;
    }

    if (stream == NULL) {
        CLOGE("stream is NULL");
        ret = BAD_VALUE;
        goto func_exit;
    }

    stream->getID(&streamId);

    parentPipeId = request->getParentStreamPipeId(streamId);
    pipeId = request->getStreamPipeId(streamId);

    if (parentPipeId != -1 && pipeId != -1) {
        ret = frame->getDstBuffer(parentPipeId, buffer, factory->getNodeType(pipeId));
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d] getDstBuffer fail. pipeId (%d) ret(%d)",
                request->getKey(), frame->getFrameCount(), pipeId, ret);
            goto func_exit;
        }

        ret = frame->getDstBufferState(parentPipeId, &bufferState, factory->getNodeType(pipeId));
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d] getDstBufferState fail. pipeId (%d) ret(%d)",
                request->getKey(), frame->getFrameCount(), pipeId, ret);
            goto func_exit;
        }
    }

    if ((frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
            == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED)
        && (((buffer->index) < 0) || (bufferState == ENTITY_BUFFER_STATE_ERROR))) {
        CLOGV("[R%d F%d] Pending resuest", request->getKey(), frame->getFrameCount());
        ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d] sendNotifyError fail. ret %d",
                frame->getFrameCount(),
                buffer->index,
                ret);
            goto func_exit;
        }
    }

func_exit:
    return ret;
}

bool ExynosCamera::m_isSkipBurstCaptureBuffer(__unused frame_type_t frameType)
{
    int isSkipBuffer = false;
    int ratio = 0;
    int runtime_fps = 30;
    int previewDurationTime = 0;

#ifdef USE_DUAL_CAMERA
    if (frameType == FRAME_TYPE_REPROCESSING_SLAVE) {
        previewDurationTime = m_previewDurationTime[1];
    } else
#endif
    {
        previewDurationTime = m_previewDurationTime[0];
    }

    if (previewDurationTime != 0) {
        runtime_fps = (int)(1000 / previewDurationTime);
    }

    int burstshotTargetFps = m_configurations->getModeValue(CONFIGURATION_BURSTSHOT_FPS_TARGET);

    { /* available up to 15fps */
        int calValue = (int)(burstshotTargetFps / 2);

        if (runtime_fps <= burstshotTargetFps + calValue) {
            ratio = 0;
        } else {
            ratio = (int)((runtime_fps + calValue) / burstshotTargetFps);
        }

        m_burstFps_history[3] = m_burstFps_history[2];
        m_burstFps_history[2] = m_burstFps_history[1];
        m_burstFps_history[1] = ratio;

        if ((m_burstFps_history[0] == -1)
            || (m_burstFps_history[1] == m_burstFps_history[2] && m_burstFps_history[1] == m_burstFps_history[3])) {
            m_burstFps_history[0] = m_burstFps_history[1];
        }

        if (ratio == 0 || m_burstFps_history[0] == 0) {
            m_captureResultToggle = 0;
        } else {
            ratio = m_burstFps_history[0];
            m_captureResultToggle = (m_captureResultToggle + 1) % ratio;
        }

        CLOGV("m_captureResultToggle(%d) m_previewDurationTime(%d) ratio(%d), targetFps(%d)",
                m_captureResultToggle, previewDurationTime, ratio, burstshotTargetFps);

        CLOGV("[%d][%d][%d][%d] ratio(%d)",
                m_burstFps_history[0], m_burstFps_history[1],
                m_burstFps_history[2], m_burstFps_history[3], ratio);

        if (m_captureResultToggle != 0) {
            isSkipBuffer = true;
        }
    }

    return isSkipBuffer;
}

status_t ExynosCamera::m_captureFrameHandler(ExynosCameraRequestSP_sprt_t request,
                                             ExynosCameraFrameFactory *targetfactory,
                                             frame_type_t frameType)
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameSP_sptr_t newFrame = NULL;
    struct camera2_shot_ext *shot_ext = NULL;
    struct camera2_shot_ext *service_shot_ext = NULL;
    int currentCameraId = 0;
    uint32_t requestKey = 0;
    bool captureFlag = false;
    bool rawStreamFlag = false;
    bool zslFlag = false;
    bool yuvCbStallFlag = false;
    bool vendorYuvStall = false;
    bool thumbnailCbFlag = false;
    bool isNeedThumbnail = false;
    bool depthStallStreamFlag = false;
    bool streamRequested[HAL_STREAM_ID_MAX] = {false};
    int pipeId = -1;
    int yuvStallPortUsage = YUV_STALL_USAGE_DSCALED;
    frame_handle_components_t components;
    uint32_t streamConfigBit = 0;
    uint32_t needDynamicBayerCount = FLASH_MAIN_TIMEOUT_COUNT * 2; /* margin : mutiply double */
    ExynosCameraActivitySpecialCapture *sCaptureMgr = NULL;
    ExynosCameraActivityFlash *flashMgr = NULL;
    camera3_stream_buffer_t* buffer = request->getInputBuffer();
    int dsInputPortId = request->getDsInputPortId();
    frame_type_t internalframeType = FRAME_TYPE_INTERNAL;
    bool flag3aaVraM2M = false;
    frame_queue_t *selectBayerQ;
    sp<mainCameraThread> selectBayerThread;
    ExynosRect zoomRect = {0, };
    ExynosRect activeZoomRect = {0, };
#ifdef SUPPORT_REMOSAIC_CAPTURE
    struct camera2_shot_ext remosaicShot;
#endif

    enum DUAL_OPERATION_MODE dualOperationMode = DUAL_OPERATION_MODE_NONE;
    bool fallback = false;
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        dualOperationMode = ExynosCameraFrame::convertDualModeByFrameType(frameType);
        fallback = m_configurations->isFallbackOn();

        // flush the other selector
        if (dualOperationMode != DUAL_OPERATION_MODE_SYNC) {
            for (int i = 0; i < m_camIdInfo.numOfSensors; i++) {
                int cameraId = m_camIdInfo.cameraId[i];

                if (cameraId == targetfactory->getCameraId()) continue;

                m_captureSelector[cameraId]->clearList();
                CLOGD("CAM%d clearList at CAM%d", cameraId, targetfactory->getCameraId());
            }
        }
    }
    m_createReprocessingFrameLock.lock();
#endif

    if (targetfactory == NULL) {
        CLOGE("targetfactory is NULL");
        return INVALID_OPERATION;
    }

#ifdef USE_DUAL_CAMERA
    if (frameType == FRAME_TYPE_REPROCESSING_SLAVE
        || frameType == FRAME_TYPE_INTERNAL_SLAVE
        || frameType == FRAME_TYPE_REPROCESSING_DUAL_SLAVE) {
        internalframeType = FRAME_TYPE_INTERNAL_SLAVE;
        selectBayerQ = m_selectDualSlaveBayerQ;
        selectBayerThread = m_selectDualSlaveBayerThread;
    } else
#endif
    {
        selectBayerQ = m_selectBayerQ;
        selectBayerThread = m_selectBayerThread;
    }

    m_getFrameHandleComponentsWrapper(frameType, &components);

#ifdef USE_SLSI_PLUGIN
    m_checkCaptureMode(request, components);
#endif

#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (m_configurations->getMode(CONFIGURATION_REMOSAIC_CAPTURE_MODE)) {
        targetfactory = m_frameFactory[FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING];
        frameType = FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION;
#ifdef USES_COMBINE_PLUGIN
        components.parameters->setSensorModeTransitionFrameCount(m_configurations->getModeValue(CONFIGURATION_CAPTURE_COUNT));
#endif
        m_startSensorModeTransition();
        m_getFrameHandleComponentsWrapper(frameType, &components);
    }
#endif //SUPPORT_REMOSAIC_CAPTURE

#ifdef USE_SLSI_PLUGIN
    m_prepareCaptureMode(request, frameType, components);
    bool nightShotBayerMode = m_configurations->getMode(CONFIGURATION_NIGHT_SHOT_BAYER_MODE);
    bool nightShotYuvMode = m_configurations->getMode(CONFIGURATION_NIGHT_SHOT_YUV_MODE);
    bool superNightShotBayerMode = m_configurations->getMode(CONFIGURATION_SUPER_NIGHT_SHOT_BAYER_MODE);
    bool hdrBayerMode = m_configurations->getMode(CONFIGURATION_HDR_BAYER_MODE);
    bool hdrYuvMode = m_configurations->getMode(CONFIGURATION_HDR_YUV_MODE);
    bool flashMultiFrameDenoiseYuvMode = m_configurations->getMode(CONFIGURATION_FLASH_MULTI_FRAME_DENOISE_YUV_MODE);
    bool beautyFaceYuvMode = m_configurations->getMode(CONFIGURATION_BEAUTY_FACE_YUV_MODE);
    bool superResolutionMode = m_configurations->getMode(CONFIGURATION_SUPER_RESOLUTION_MODE);
    bool oisDenoiseMode = m_configurations->getMode(CONFIGURATION_OIS_DENOISE_YUV_MODE);
    bool sportsYuvMode = m_configurations->getMode(CONFIGURATION_SPORTS_YUV_MODE);
    bool combineSingleCaptureMode = m_configurations->getMode(CONFIGURATION_COMBINE_SINGLE_CAPTURE_MODE);
#endif

    int32_t reprocessingBayerMode = components.parameters->getReprocessingBayerMode();
    currentCameraId = components.currentCameraId;

    flag3aaVraM2M = (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING,
                                    PIPE_VRA_REPROCESSING) == HW_CONNECTION_MODE_M2M);

    sCaptureMgr = components.activityControl->getSpecialCaptureMgr();
    flashMgr = components.activityControl->getFlashMgr();

    if (targetfactory == NULL) {
        CLOGE("targetfactory is NULL");
        return INVALID_OPERATION;
    }

    CLOGD("Capture request. requestKey %d frameCount %d frameType %d",
            request->getKey(),
            request->getFrameCount(),
            frameType);

    if (!m_isLogicalCam) {
        service_shot_ext = request->getServiceShot();
    } else {
        /* if no PhysCam Settings, it will return NULL */
        service_shot_ext = request->getServiceShotPhysCam(currentCameraId);
        if (!service_shot_ext)
            service_shot_ext = request->getServiceShot();
    }

    if (service_shot_ext == NULL) {
        CLOGE("Get service shot fail, requestKey(%d)", request->getKey());
        ret = INVALID_OPERATION;
        return ret;
    }

    *m_currentCaptureShot[currentCameraId] = *service_shot_ext;

    m_startPictureBufferThread->join();

    requestKey = request->getKey();

    /* Initialize the request flags in framefactory */
    targetfactory->initMetaV4l2Format();
    targetfactory->setRequest(PIPE_3AC_REPROCESSING, false);
    targetfactory->setRequest(PIPE_3AG_REPROCESSING, false);
#if defined(USES_CAMERA_EXYNOS_VPL) && defined(USE_EARLY_FD_REPROCES)
    targetfactory->setRequest(PIPE_3AF_REPROCESSING, false);
#endif
    targetfactory->setRequest(PIPE_ISPC_REPROCESSING, false);
    targetfactory->setRequest(PIPE_MCSC0_REPROCESSING, false);
    targetfactory->setRequest(PIPE_MCSC1_REPROCESSING, false);
    targetfactory->setRequest(PIPE_MCSC2_REPROCESSING, false);
    targetfactory->setRequest(PIPE_MCSC_JPEG_REPROCESSING, false);
    targetfactory->setRequest(PIPE_MCSC_THUMB_REPROCESSING, false);
    targetfactory->setRequest(PIPE_MCSC5_REPROCESSING, false);
#ifdef USE_VRA_FD
    targetfactory->setRequest(PIPE_VRA_REPROCESSING, false);
#endif
#if defined(USES_CAMERA_EXYNOS_VPL) && defined(USE_EARLY_FD_REPROCES)
    targetfactory->setRequest(PIPE_NFD_REPROCESSING, false);
#endif
#ifdef USE_RESERVED_NODE_PPJPEG_MCSCPORT
    targetfactory->setRequest(PIPE_MCSC_PP_REPROCESSING, false);
#endif
#if defined(USES_CAMERA_EXYNOS_LEC)
    targetfactory->setRequest(PIPE_PLUGIN_LEC_REPROCESSING, false);
#endif
#ifdef USE_CLAHE_REPROCESSING
    targetfactory->setRequest(PIPE_CLAHEC_REPROCESSING, false);
#endif

    if (components.parameters->isReprocessing() == true) {
        if (components.parameters->isUseHWFC()) {
            targetfactory->setRequest(PIPE_HWFC_JPEG_DST_REPROCESSING, false);
            targetfactory->setRequest(PIPE_HWFC_THUMB_DST_REPROCESSING, false);
        }
    }

#ifndef USE_SLSI_PLUGIN
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        targetfactory->setRequest(PIPE_SYNC_REPROCESSING, false);
        targetfactory->setRequest(PIPE_FUSION_REPROCESSING, false);

        if (m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
            if (dualOperationMode == DUAL_OPERATION_MODE_SYNC)
            {
                switch(frameType) {
                case FRAME_TYPE_REPROCESSING_DUAL_SLAVE:
                    targetfactory->setRequest(PIPE_SYNC_REPROCESSING, true);
                    break;
                case FRAME_TYPE_REPROCESSING_DUAL_MASTER:
                    targetfactory->setRequest(PIPE_SYNC_REPROCESSING, true);
                    targetfactory->setRequest(PIPE_FUSION_REPROCESSING, true);
                    break;
                case FRAME_TYPE_REPROCESSING:
                    break;
                default:
                    CLOGE("Unsupported frame type(%d)", (int)frameType);
                    break;
                }
            }
        }
    }
#endif
#endif

    /* set input buffers belonged to each stream as available */
    if (buffer != NULL) {
        int inputStreamId = 0;
        ExynosCameraStream *stream = static_cast<ExynosCameraStream *>(buffer->stream->priv);
        if(stream != NULL) {
            stream->getID(&inputStreamId);
            SET_STREAM_CONFIG_BIT(streamConfigBit, inputStreamId);

            CLOGD("requestKey %d buffer-StreamType(HAL_STREAM_ID_ZSL_INPUT[%d]) Buffer[%p], Stream[%p]",
                     request->getKey(), inputStreamId, buffer, stream);

            switch (inputStreamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_YUV_INPUT:
                CLOGD("requestKey %d buffer-StreamType(HAL_STREAM_ID_YUV_INPUT[%d])",
                         request->getKey(), inputStreamId);
                zslFlag = true;
                streamRequested[inputStreamId % HAL_STREAM_ID_MAX] = true;
#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
                targetfactory->setRequest(PIPE_SW_MCSC_REPEOCESSING, true);
#endif
                break;
            case HAL_STREAM_ID_ZSL_INPUT:
                CLOGD("requestKey %d buffer-StreamType(HAL_STREAM_ID_ZSL_INPUT[%d])",
                         request->getKey(), inputStreamId);
                zslFlag = true;
                streamRequested[inputStreamId % HAL_STREAM_ID_MAX] = true;
                break;
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                CLOGE("requestKey %d Invalid buffer-StreamType(%d)",
                         request->getKey(), inputStreamId);
                break;
            default:
                break;
            }
        } else {
            CLOGE(" Stream is null (%d)", request->getKey());
        }
    }

#ifdef SUPPORT_VENDOR_YUV_STALL
    vendorYuvStall = getVendorYUVStallMeta(request);
    if (vendorYuvStall) {
        /* set config bit for Vendor YUV Stall. */
        SET_STREAM_CONFIG_BIT(streamConfigBit, HAL_STREAM_ID_CALLBACK_STALL);
    }
#endif

    m_captureFrameHandler_vendor_updateConfigMode(request, targetfactory, frameType);

    {
        m_longExposureRemainCount = 0;
    }

    /* set output buffers belonged to each stream as available */
    for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
        int id = request->getStreamIdwithBufferIdx(i);
        int outputPortId = 0;
        int yuvStallPort = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX);
        yuvStallPort = m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT);
        yuvStallPortUsage = m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT_USAGE);
        SET_STREAM_CONFIG_BIT(streamConfigBit, id);

        switch (id % HAL_STREAM_ID_MAX) {
        case HAL_STREAM_ID_JPEG:
            CLOGD("requestKey %d buffer-StreamType(HAL_STREAM_ID_JPEG), YuvStallPortUsage()(%d) yuvStallPort(%d)",
                    request->getKey(), yuvStallPortUsage, yuvStallPort);

            streamRequested[id % HAL_STREAM_ID_MAX] = true;

            if (yuvStallPortUsage == YUV_STALL_USAGE_PICTURE) {
                pipeId = yuvStallPort + PIPE_MCSC0_REPROCESSING;
                targetfactory->setRequest(pipeId, true);
                dsInputPortId = yuvStallPort + MCSC_PORT_MAX;
            }

            if (yuvStallPortUsage != YUV_STALL_USAGE_PICTURE) {
#if defined(NUM_OF_M2M_MCSC_OUTPUT_PORTS) && (NUM_OF_M2M_MCSC_OUTPUT_PORTS == 1)
                targetfactory->setRequest(PIPE_ISPC_REPROCESSING, true);
#endif
                targetfactory->setRequest(PIPE_MCSC_JPEG_REPROCESSING, true);
                dsInputPortId = MCSC_PORT_3 + MCSC_PORT_MAX;

                shot_ext = request->getServiceShot();
                if (shot_ext == NULL) {
                    CLOGE("Get service shot fail. requestKey(%d)", request->getKey());

                    continue;
                }

                if (components.parameters->isReprocessing() == true && components.parameters->isUseHWFC() == true) {
                    isNeedThumbnail = (shot_ext->shot.ctl.jpeg.thumbnailSize[0] > 0
                            && shot_ext->shot.ctl.jpeg.thumbnailSize[1] > 0)? true : false;
                    targetfactory->setRequest(PIPE_MCSC_THUMB_REPROCESSING, isNeedThumbnail);
                    targetfactory->setRequest(PIPE_HWFC_JPEG_DST_REPROCESSING, true);
                    targetfactory->setRequest(PIPE_HWFC_THUMB_DST_REPROCESSING, isNeedThumbnail);
                }
            }

#ifdef USE_CLAHE_REPROCESSING
            if (m_configurations->checkClaheCaptureMode() == true) {
                CLOGD("[R%d]CLAHE enable in capture", request->getKey());
                targetfactory->setRequest(PIPE_CLAHEC_REPROCESSING, true);
            }
#endif

            captureFlag = true;
            break;
        case HAL_STREAM_ID_RAW:
            CLOGV("requestKey %d buffer-StreamType(HAL_STREAM_ID_RAW)",
                     request->getKey());

            streamRequested[id % HAL_STREAM_ID_MAX] = true;

            if (components.parameters->isUse3aaDNG()) {
                targetfactory->setRequest(PIPE_3AG_REPROCESSING, true);
            } else {
                targetfactory->setRequest(PIPE_3AC_REPROCESSING, true);
            }
            rawStreamFlag = true;
            break;
        case HAL_STREAM_ID_PREVIEW:
        case HAL_STREAM_ID_VIDEO:
        case HAL_STREAM_ID_VISION:
        case HAL_STREAM_ID_CALLBACK_PHYSICAL:
#ifdef SUPPORT_DEPTH_MAP
        case HAL_STREAM_ID_DEPTHMAP:
#endif
            break;
        case HAL_STREAM_ID_CALLBACK:
            if (zslFlag == false
                && vendorYuvStall == false
                ) {
                /* If there is no ZSL_INPUT stream buffer,
                * It will be processed through preview stream.
                */
                break;
            }
        case HAL_STREAM_ID_CALLBACK_STALL:
            CLOGD("requestKey %d buffer-StreamType(HAL_STREAM_ID_CALLBACK_STALL)",
                     request->getKey());

            streamRequested[id % HAL_STREAM_ID_MAX] = true;

            outputPortId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX);

            if (m_configurations->getMode(CONFIGURATION_VENDOR_YUV_STALL)) {
                m_configurations->setModeValue(CONFIGURATION_VENDOR_YUV_STALL_PORT, outputPortId);
                pipeId = (yuvStallPort) + PIPE_MCSC0_REPROCESSING;
            } else {
                pipeId = (outputPortId) + PIPE_MCSC0_REPROCESSING;
            }
            // TODO: support physical stream
#if 0
            if (id % HAL_STREAM_ID_MAX == HAL_STREAM_ID_CALLBACK_STALL) {
                const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();
                const camera3_stream_buffer_t *streamBuffer = &(bufferList[i]);

                int phyCamID = -1;
                if (streamBuffer->stream->physical_camera_id != NULL
                    && strlen(streamBuffer->stream->physical_camera_id) > 0) {
                    phyCamID = atoi(streamBuffer->stream->physical_camera_id);
                }

                if ((m_scenario == SCENARIO_DUAL_REAR_PORTRAIT && phyCamID >= 0)
                     || (m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT && phyCamID >= 0)) {
                    pipeId = (m_streamManager->getOutputPortId(id % HAL_STREAM_ID_MAX) % ExynosCameraParameters::YUV_MAX)
                        + PIPE_MCSC0_REPROCESSING;
                } else {
                    pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX)
                        + PIPE_MCSC0_REPROCESSING;
                }
            } else {
                pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX)
                    + PIPE_MCSC0_REPROCESSING;
            }
#endif
            targetfactory->setRequest(pipeId, true);
            dsInputPortId = (m_streamManager->getOutputPortId(id % HAL_STREAM_ID_MAX) % ExynosCameraParameters::YUV_MAX) + MCSC_PORT_MAX;
            captureFlag = true;
            yuvCbStallFlag = true;
            break;
        case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
            CLOGD("requestKey %d buffer-StreamType(HAL_STREAM_ID_THUMBNAIL_CALLBACK), YuvStallPortUsage()(%d)",
                    request->getKey(), yuvStallPortUsage);

            streamRequested[id % HAL_STREAM_ID_MAX] = true;

            thumbnailCbFlag = true;
            pipeId = yuvStallPort + PIPE_MCSC0_REPROCESSING;
            targetfactory->setRequest(pipeId, true);
            break;
#ifdef SUPPORT_DEPTH_MAP
        case HAL_STREAM_ID_DEPTHMAP_STALL:
            CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_DEPTHMAP_STALL)",
                    request->getKey(), i);

            streamRequested[id % HAL_STREAM_ID_MAX] = true;

            depthStallStreamFlag = true;
            break;
#endif
        default:
            CLOGE("requestKey %d Invalid buffer-StreamType(%d)",
                     request->getKey(), id);
            break;
        }
    }

#ifdef USE_DUAL_CAMERA
    if (frameType != FRAME_TYPE_REPROCESSING_DUAL_SLAVE)
#endif
    {
        m_checkRequestStreamChanged((char *)"Capture", streamConfigBit);
    }

    if (request->getNumOfInputBuffer() <= 0
        && (reprocessingBayerMode == REPROCESSING_BAYER_MODE_PURE_DYNAMIC
            || reprocessingBayerMode == REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC)
        && (m_currentCaptureShot[currentCameraId]->shot.ctl.flash.flashMode == CAM2_FLASH_MODE_SINGLE
            || flashMgr->getNeedCaptureFlash() == true
#ifdef USES_HIFI_LLS
            || m_configurations->getMode(CONFIGURATION_HIFI_LLS_MODE)
#endif
#ifdef USES_COMBINE_PLUGIN
            || nightShotBayerMode == true
            || nightShotYuvMode == true
            || superNightShotBayerMode == true
            || hdrBayerMode == true
            || hdrYuvMode == true
            || flashMultiFrameDenoiseYuvMode == true
            || beautyFaceYuvMode == true
            || superResolutionMode == true
            || oisDenoiseMode == true
            || sportsYuvMode == true
            || combineSingleCaptureMode == true
#endif
            )) {
        components.captureSelector->clearList();
        m_needDynamicBayerCountLock.lock();
        m_configurations->setModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT, needDynamicBayerCount);
        m_needDynamicBayerCountLock.unlock();
        CLOGD("needDynamicBayerCount(%d) NeedFlash(%d) flashMode(%d)", needDynamicBayerCount,
            flashMgr->getNeedCaptureFlash(),
            m_currentCaptureShot[currentCameraId]->shot.ctl.flash.flashMode);
    }

#ifdef OIS_CAPTURE
    if (m_configurations->getMode(CONFIGURATION_OIS_CAPTURE_MODE) == true) {
        m_captureFrameHandler_vendor_updateIntent(request, components);
    } else
#endif
    {
#ifdef USE_EXPOSURE_DYNAMIC_SHOT
        if (zslFlag == false
            && m_configurations->getCaptureExposureTime() > PERFRAME_CONTROL_CAMERA_EXPOSURE_TIME_MAX
            ) {
            unsigned int captureIntent = AA_CAPTURE_INTENT_STILL_CAPTURE_EXPOSURE_DYNAMIC_SHOT;
            unsigned int captureCount = m_configurations->getLongExposureShotCount();
            unsigned int mask = 0;
            int captureExposureTime = m_configurations->getCaptureExposureTime();
            int value;

            mask = (((captureIntent << 16) & 0xFFFF0000) | ((captureCount << 0) & 0x0000FFFF));
            value = mask;

            if (components.previewFactory == NULL) {
                CLOGE("FrameFactory is NULL!!");
            } else {
                ret = components.previewFactory->setControl(V4L2_CID_IS_CAPTURE_EXPOSURETIME, captureExposureTime, PIPE_3AA);
                if (ret) {
                    CLOGE("setControl() fail. ret(%d) captureExposureTime(%d)",
                            ret, captureExposureTime);
                } else {
                    CLOGD("setcontrol() V4L2_CID_IS_CAPTURE_EXPOSURETIME:(%d)", captureExposureTime);
                }

                ret = components.previewFactory->setControl(V4L2_CID_IS_INTENT, value, PIPE_3AA);
                if (ret) {
                    CLOGE("setcontrol(V4L2_CID_IS_INTENT) failed!!");
                } else {
                    CLOGD("setcontrol() V4L2_CID_IS_INTENT:(%d)", value);
                }
            }

            m_currentCaptureShot[currentCameraId]->shot.ctl.aa.captureIntent = (enum aa_capture_intent)captureIntent;
            m_configurations->setMode(CONFIGURATION_OIS_CAPTURE_MODE, true);
            sCaptureMgr->setCaptureStep(ExynosCameraActivitySpecialCapture::SCAPTURE_STEP_START);
            components.activityControl->setOISCaptureMode(true);
        }
#endif
    }

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
    ////////////////////////////////////////////////
    // about factory led calibration.
    if (m_configurations->getLedCalibrationEnable() == true) {
        ret = m_startLedCalibration(components.previewFactory);
        if (ret != NO_ERROR) {
            CLOGE("m_startLedCalibration() fail");
        }
    }
    ////////////////////////////////////////////////
#endif

    m_updateLatestInfoToShot(m_currentCaptureShot[currentCameraId], frameType, &components);
    m_updateVendorInfo(request, m_currentCaptureShot[currentCameraId], true);
    if (service_shot_ext != NULL) {
        m_updateFD(m_currentCaptureShot[currentCameraId],
                        service_shot_ext->shot.ctl.stats.faceDetectMode, dsInputPortId, true, flag3aaVraM2M);
    }
    components.parameters->setDsInputPortId(
        m_currentCaptureShot[currentCameraId]->shot.uctl.scalerUd.mcsc_sub_blk_port[INTERFACE_TYPE_DS],
        true);

    {
        m_captureFrameHandler_vendor_updateDualROI(request, components, frameType);
    }

    if (m_currentCaptureShot[currentCameraId]->fd_bypass == false) {
       if (components.parameters->getHwConnectionMode(PIPE_MCSC_REPROCESSING, PIPE_VRA_REPROCESSING) == HW_CONNECTION_MODE_M2M
#ifdef USE_DUAL_CAMERA
        && dualOperationMode != DUAL_OPERATION_MODE_SLAVE /* HACK: temp for dual capture */
        && frameType != FRAME_TYPE_REPROCESSING_DUAL_SLAVE/* HACK: temp for dual capture */
#endif
          ) {
#ifdef USE_VRA_FD
            targetfactory->setRequest(PIPE_MCSC5_REPROCESSING, true);
            targetfactory->setRequest(PIPE_VRA_REPROCESSING, true);
#endif
        }
#if defined(USES_CAMERA_EXYNOS_VPL) && defined(USE_EARLY_FD_REPROCES)
#ifdef USE_VRA_FD
        if (m_parameters[currentCameraId]->getNfdMode() == true)
#endif
        {
            targetfactory->setRequest(PIPE_NFD_REPROCESSING, true);
        }
        if (flag3aaVraM2M) {
            targetfactory->setRequest(PIPE_3AF_REPROCESSING, true);
        }
#endif
    }

#if defined(USE_DUAL_CAMERA) && defined(USES_COMBINE_PLUGIN)
    bool dualFrameUseOnePlugin = false;
#endif
    list<int> preSceanrio;
    map<int, int> scenarioList;
    map<int, int>::iterator iter;
    int pluginCnt = m_prepareCapturePlugin(targetfactory, frameType, preSceanrio, &scenarioList);
    int skipCaptureCount = 0;
    int captureCount = m_configurations->getModeValue(CONFIGURATION_CAPTURE_COUNT);
    int oldBayerLockCount = 0;

    if (components.captureSelector->getBayerFrameLock() == true) {
        oldBayerLockCount = components.parameters->getOldBayerFrameLockCount();
        captureCount += oldBayerLockCount;
    }

#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (frameType == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION) {
        internalframeType = FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION;
        m_updateMetaDataCaptureIntent(m_currentCaptureShot[currentCameraId], frameType);
    }
#endif //SUPPORT_REMOSAIC_CAPTURE

#ifdef USE_SLSI_PLUGIN
#ifdef USE_DUAL_CAMERA
    m_createReprocessingFrameLock.unlock();
#endif

    if (m_configurations->getMode(CONFIGURATION_HIFI_LLS_MODE)
        || oldBayerLockCount > 0
#ifdef USES_COMBINE_PLUGIN
        || nightShotBayerMode == true
        || nightShotYuvMode == true
        || superNightShotBayerMode == true
        || hdrBayerMode == true
        || hdrYuvMode == true
        || flashMultiFrameDenoiseYuvMode == true
        || beautyFaceYuvMode == true
        || superResolutionMode == true
        || oisDenoiseMode == true
        || sportsYuvMode == true
        || combineSingleCaptureMode == true
#endif
        ) {
        int pluginYuvStallPortUsage = false;
		int scenario = 0;
		int pluginPipeId = 0;

#ifdef USES_HIFI_LLS
        if (m_configurations->getMode(CONFIGURATION_HIFI_LLS_MODE)) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }
#endif

#ifdef USES_COMBINE_PLUGIN
#ifdef USE_DUAL_CAMERA
        if (dualOperationMode == DUAL_OPERATION_MODE_SYNC) {
            for (list<int>::iterator preScenarioIter = preSceanrio.begin()
                    ; preScenarioIter != preSceanrio.end() ; preScenarioIter++) {
                if ((*preScenarioIter) == PLUGIN_SCENARIO_COMBINE_REPROCESSING) {
                    dualFrameUseOnePlugin = true;
                    break;
                }
            }

            if (superNightShotBayerMode == true
                && (m_scenario == SCENARIO_DUAL_REAR_PORTRAIT || m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT)) {
                ret = m_createBokehSuperNightShotBayerAnchorFrame(request, targetfactory, internalframeType,
                                                                scenarioList, components,
                                                                selectBayerQ, selectBayerThread, captureCount);
                if (ret != NO_ERROR) {
                    CLOGE("createBokehSuperNightShotBayerAnchorFrame is fail. ret(%d)", ret);
                    return ret;
                }

                if (frameType == FRAME_TYPE_REPROCESSING_DUAL_SLAVE) {
                    CLOGD("Skip to create slave reprocessing frame by bokeh super night shot");
                    return NO_ERROR;
                }

                dualFrameUseOnePlugin = false;
                dualOperationMode = DUAL_OPERATION_MODE_MASTER;
                targetfactory->setRequest(PIPE_SYNC_REPROCESSING, false);
                frameType = FRAME_TYPE_REPROCESSING;
                skipCaptureCount = getBokehPrepareAnchorNum();
            }
        }
#endif

        if (nightShotYuvMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (hdrYuvMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (flashMultiFrameDenoiseYuvMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (beautyFaceYuvMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (superResolutionMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (oisDenoiseMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (sportsYuvMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }

        if (combineSingleCaptureMode == true) {
            pluginYuvStallPortUsage = yuvStallPortUsage;
        }
#endif

        for (int i = skipCaptureCount; i < (captureCount - 1); i++) {
            ExynosCameraFrameSP_sptr_t newMFStillFrame = NULL;

            ret = m_generateInternalFrame(targetfactory, &m_captureProcessList,
                    &m_captureProcessLock, newMFStillFrame, internalframeType);
            if (ret != NO_ERROR) {
                CLOGE("m_generateInternalFrame fail");
                return ret;
            } else if (newMFStillFrame == NULL) {
                CLOGE("new faame is NULL");
                return INVALID_OPERATION;
            }

            newMFStillFrame->setStreamRequested(STREAM_TYPE_RAW, true);
            newMFStillFrame->setStreamRequested(STREAM_TYPE_YUVCB_STALL, false);
            newMFStillFrame->setStreamRequested(STREAM_TYPE_THUMBNAIL_CB, false);
            newMFStillFrame->setStreamRequested(STREAM_TYPE_CAPTURE, false);
            newMFStillFrame->setStreamRequested(STREAM_TYPE_ZSL_YUV_INPUT, false);

            newMFStillFrame->setFrameYuvStallPortUsage(pluginYuvStallPortUsage);

#if defined (USE_DUAL_CAMERA) && defined(USES_COMBINE_PLUGIN)
            if (dualFrameUseOnePlugin == true) {
                newMFStillFrame->setFrameIndex(internalframeType == FRAME_TYPE_INTERNAL ? (i * 2) + 1 : (i * 2));
                newMFStillFrame->setMaxFrameIndex(captureCount * 2);
            } else
#endif
            {
                newMFStillFrame->setFrameIndex(i);
                newMFStillFrame->setMaxFrameIndex(captureCount);
            }
            newMFStillFrame->setMode(FRAME_MODE_MF_STILL, true);

            for(iter = scenarioList.begin() ; iter != scenarioList.end() ; iter++)
            {
                newMFStillFrame->setPPScenario(iter->first, iter->second);
            }

            ////////////////////////////////////////////////
            // copy vendor Tag.
            newMFStillFrame->setVendorMeta(request->getVendorMeta());

#ifdef USE_DUAL_CAMERA
            if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
                newMFStillFrame->setDualOperationMode(dualOperationMode);
                newMFStillFrame->setFallbackOn(fallback);

                // Store current zoom Info
                newMFStillFrame->setZoomRatio(m_configurations->getZoomRatio());
                newMFStillFrame->setActiveZoomRatio(components.parameters->getActiveZoomRatio());
                m_configurations->getZoomRect(&zoomRect);
                newMFStillFrame->setZoomRect(zoomRect);
                components.parameters->getActiveZoomRect(&activeZoomRect);
                newMFStillFrame->setActiveZoomRect(activeZoomRect);
            }
#endif
            ////////////////////////////////////////////////
            CFLOGD(newMFStillFrame, "[%d / %d][T%d] MFStill generate m_internalFrameCount(%d), dualOp(%d)",
                newMFStillFrame->getFrameIndex(), newMFStillFrame->getMaxFrameIndex(), internalframeType,
                m_internalFrameCount, dualOperationMode);

            if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
                CLOGD("[R%d F%d]Flush is in progress.",
                        request->getKey(), newMFStillFrame->getFrameCount());
                /* Generated frame is going to be deleted at flush() */
                return ret;
            }

            ret = newMFStillFrame->setMetaData(m_currentCaptureShot[currentCameraId]);
            if (ret != NO_ERROR) {
                CLOGE("Set metadata to frame fail, Frame count(%d), ret(%d)",
                        newMFStillFrame->getFrameCount(), ret);
            }

#if defined (USE_DUAL_CAMERA) && defined(USES_COMBINE_PLUGIN)
            if (dualFrameUseOnePlugin == false) {
                /* In bayer multiprocessing scenario, no fusion buffer is required. */
                ret = m_setupCaptureFactoryBuffers(request, newMFStillFrame);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d]Failed to setupCaptureStreamBuffer. ret %d",
                            request->getKey(), newMFStillFrame->getFrameCount(), ret);
                }
            }
#endif

            selectBayerQ->pushProcessQ(&newMFStillFrame);
            if (selectBayerThread != NULL && selectBayerThread->isRunning() == false) {
                selectBayerThread->run();
                CLOGI("Initiate selectBayerThread (%d)", selectBayerThread->getTid());
            }
        }
    }
#endif

    m_frameCountLock.lock();
    if (request->getFrameCount() == 0) {
        /* Must use the same framecount with internal frame */
        int frameCount = 0;
        m_requestMgr->setFrameCount(m_internalFrameCount++, request->getKey());
    }
    m_frameCountLock.unlock();

    {
        if (m_longExposureRemainCount > 0 && zslFlag == false) {
            for (int32_t i = 0; i < m_longExposureRemainCount; i++) {
                ExynosCameraFrameSP_sptr_t newLongExposureCaptureFrame = NULL;
                frame_type_t LongExposureframeType = frameType;

                if (i < m_longExposureRemainCount - 1) {
                    LongExposureframeType = internalframeType;
                    ret = m_generateInternalFrame(targetfactory, &m_captureProcessList,
                            &m_captureProcessLock, newLongExposureCaptureFrame, internalframeType);
                    if (ret != NO_ERROR) {
                        CLOGE("m_generateFrame fail");
                        return ret;
                    } else if (newLongExposureCaptureFrame == NULL) {
                        CLOGE("new frame is NULL");
                        return INVALID_OPERATION;
                    }

                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_RAW, false);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_YUVCB_STALL, yuvCbStallFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_CAPTURE, captureFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_ZSL_INPUT, zslFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_THUMBNAIL_CB, thumbnailCbFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_ZSL_YUV_INPUT, streamRequested[HAL_STREAM_ID_YUV_INPUT]);
                    newLongExposureCaptureFrame->setFrameYuvStallPortUsage(yuvStallPortUsage);
                } else {
                    bool useJpegFlag = streamRequested[HAL_STREAM_ID_JPEG];
                    ret = m_generateFrame(targetfactory, &m_captureProcessList, &m_captureProcessLock,
                            newLongExposureCaptureFrame, request, useJpegFlag);
                    if (ret != NO_ERROR) {
                        CLOGE("m_generateFrame fail");
                        return ret;
                    } else if (newLongExposureCaptureFrame == NULL) {
                        CLOGE("new faame is NULL");
                        return INVALID_OPERATION;
                    }

                    newLongExposureCaptureFrame->setFrameType(LongExposureframeType);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_RAW, rawStreamFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_YUVCB_STALL, yuvCbStallFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_CAPTURE, captureFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_ZSL_INPUT, zslFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_THUMBNAIL_CB, thumbnailCbFlag);
                    newLongExposureCaptureFrame->setStreamRequested(STREAM_TYPE_ZSL_YUV_INPUT, streamRequested[HAL_STREAM_ID_YUV_INPUT]);
                    newLongExposureCaptureFrame->setFrameYuvStallPortUsage(yuvStallPortUsage);

                    ret = m_setupCaptureFactoryBuffers(request, newLongExposureCaptureFrame);
                    if (ret != NO_ERROR) {
                        CLOGE("[R%d F%d]Failed to setupCaptureStreamBuffer. ret %d",
                                request->getKey(), newLongExposureCaptureFrame->getFrameCount(), ret);
                    }

                    m_checkUpdateResult(newLongExposureCaptureFrame, streamConfigBit);
                }

                newLongExposureCaptureFrame->setFrameIndex(i);
                newLongExposureCaptureFrame->setMaxFrameIndex(m_longExposureRemainCount);

                CFLOGD(newLongExposureCaptureFrame, "generate capture longExpFrame(%d), dualOp(%d)",
                        m_internalFrameCount, dualOperationMode);

                TIME_LOGGER_UPDATE(m_cameraId, request->getKey(), 0, USER_DATA, CREATE_CAPTURE_FRAME,
                                   newLongExposureCaptureFrame->getFrameCount());

                if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
                    CLOGD("[R%d F%d]Flush is in progress.",
                            request->getKey(), newLongExposureCaptureFrame->getFrameCount());
                    /* Generated frame is going to be deleted at flush() */
                    return ret;
                }
#ifdef USE_DUAL_CAMERA
                if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
                    newLongExposureCaptureFrame->setDualOperationMode(dualOperationMode);
                    newLongExposureCaptureFrame->setFallbackOn(fallback);

                    // Store current zoom Info
                    newLongExposureCaptureFrame->setZoomRatio(m_configurations->getZoomRatio());
                    newLongExposureCaptureFrame->setActiveZoomRatio(components.parameters->getActiveZoomRatio());
                    m_configurations->getZoomRect(&zoomRect);
                    newLongExposureCaptureFrame->setZoomRect(zoomRect);
                    components.parameters->getActiveZoomRect(&activeZoomRect);
                    newLongExposureCaptureFrame->setActiveZoomRect(activeZoomRect);
                }
#endif
                ret = newLongExposureCaptureFrame->setMetaData(m_currentCaptureShot[currentCameraId]);
                if (ret != NO_ERROR) {
                    CLOGE("Set metadata to frame fail, Frame count(%d), ret(%d)",
                            newLongExposureCaptureFrame->getFrameCount(), ret);
                }

                selectBayerQ->pushProcessQ(&newLongExposureCaptureFrame);
            }
        } else {
            int scenario = 0;
            int pluginPipeId = 0;
            bool useJpegFlag = streamRequested[HAL_STREAM_ID_JPEG];

            if (superNightShotBayerMode == true) {
                int v4l2Format = 0;
                camera_pixel_size pixelSize = CAMERA_PIXEL_SIZE_8BIT;
                components.parameters->getSuperNightBayerFormatIsp(&v4l2Format, &pixelSize);

                targetfactory->setMetaV4l2Format(PIPE_ISP_REPROCESSING,
                                        targetfactory->getNodeType(PIPE_ISP_REPROCESSING),
                                        v4l2Format, pixelSize);
            }

            ret = m_generateFrame(targetfactory, &m_captureProcessList, &m_captureProcessLock,
                    newFrame, request, useJpegFlag);

            if (ret != NO_ERROR) {
                CLOGE("m_generateFrame fail");
                return ret;
            } else if (newFrame == NULL) {
                CLOGE("new faame is NULL");
                return INVALID_OPERATION;
            }

            if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
                CLOGD("[R%d F%d]Flush is in progress.",
                        request->getKey(), newFrame->getFrameCount());
                /* Generated frame is going to be deleted at flush() */
                return ret;
            }

            TIME_LOGGER_UPDATE(m_cameraId, request->getKey(), 0, USER_DATA, CREATE_CAPTURE_FRAME, newFrame->getFrameCount());

            ret = newFrame->setMetaData(m_currentCaptureShot[currentCameraId]);
            if (ret != NO_ERROR) {
                CLOGE("Set metadata to frame fail, Frame count(%d), ret(%d)",
                        newFrame->getFrameCount(), ret);
            }

            newFrame->setFrameType(frameType);

            newFrame->setStreamRequested(STREAM_TYPE_RAW, rawStreamFlag);
            newFrame->setStreamRequested(STREAM_TYPE_CAPTURE, captureFlag);
            newFrame->setStreamRequested(STREAM_TYPE_ZSL_INPUT, zslFlag);
            newFrame->setStreamRequested(STREAM_TYPE_YUVCB_STALL, yuvCbStallFlag);
            newFrame->setStreamRequested(STREAM_TYPE_THUMBNAIL_CB, thumbnailCbFlag);
            newFrame->setStreamRequested(STREAM_TYPE_ZSL_YUV_INPUT, streamRequested[HAL_STREAM_ID_YUV_INPUT]);
            newFrame->setFrameYuvStallPortUsage(yuvStallPortUsage);
#ifdef CORRECT_TIMESTAMP_FOR_SENSORFUSION
            newFrame->setAdjustedTimestampFlag(zslFlag);
#endif
#ifdef SUPPORT_DEPTH_MAP
            newFrame->setStreamRequested(STREAM_TYPE_DEPTH_STALL, depthStallStreamFlag);
#endif
            for(iter = scenarioList.begin() ; iter != scenarioList.end() ; iter++)
            {
                newFrame->setPPScenario(iter->first, iter->second);
            }
            ret = m_setupCaptureFactoryBuffers(request, newFrame);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d]Failed to setupCaptureStreamBuffer. ret %d",
                        request->getKey(), newFrame->getFrameCount(), ret);
            }

            m_checkUpdateResult(newFrame, streamConfigBit);

#if defined(USE_DUAL_CAMERA) && defined(USES_COMBINE_PLUGIN)
            if (dualFrameUseOnePlugin == true) {
                int dualCaptureCount = captureCount * 2;
                newFrame->setFrameIndex(frameType == FRAME_TYPE_REPROCESSING_DUAL_MASTER
                                            ? dualCaptureCount - 1 : dualCaptureCount - 2);
                newFrame->setMaxFrameIndex(dualCaptureCount);
            } else
#endif
            {
                newFrame->setFrameIndex(captureCount - 1);
                newFrame->setMaxFrameIndex(captureCount);
            }
#ifdef USE_DUAL_CAMERA
            if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
                newFrame->setDualOperationMode(dualOperationMode);
                newFrame->setFallbackOn(fallback);

                // Store current zoom Info
                newFrame->setZoomRatio(m_configurations->getZoomRatio());
                newFrame->setActiveZoomRatio(components.parameters->getActiveZoomRatio());
                m_configurations->getZoomRect(&zoomRect);
                newFrame->setZoomRect(zoomRect);
                components.parameters->getActiveZoomRect(&activeZoomRect);
                newFrame->setActiveZoomRect(activeZoomRect);
            }
#endif
            CFLOGD(newFrame, "Generate capture frame. streamConfig %x, dualOp(%d)",
                    streamConfigBit, dualOperationMode);

            selectBayerQ->pushProcessQ(&newFrame);
        }
    }
#ifdef SEQUENTIAL_RAW_DUMP
    if (getDumpImagePropertyConfig() == 2) {
        setPropertyConfig(newFrame->getFrameCount(), SEQUENTIAL_RAW_DUMP_FRAME_COUNT);
        CLOGD("[R%d F%d] sequentialRawDump capture trigger, SEQUENTIAL_RAW_DUMP_FRAME_COUNT:%d",
                request->getKey(), newFrame->getFrameCount(), getPropertyConfig(SEQUENTIAL_RAW_DUMP_FRAME_COUNT));
    }
#endif

    if (selectBayerThread != NULL && selectBayerThread->isRunning() == false) {
        selectBayerThread->run();
        CLOGI("Initiate selectBayerThread (%d)", selectBayerThread->getTid());
    }

    return ret;
}

/* release all buffer to be appened to frame by selectorTag */
status_t ExynosCamera::m_releaseSelectorTagBuffers(ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameSelectorTag tag;
    ExynosCameraBuffer buffer;

    if (frame == NULL)
        return ret;

    /* lock for selectorTag */
    frame->lockSelectorTagList();

    while (frame->getFirstRawSelectorTag(&tag)) {
        buffer.index = -1;
        if (tag.isSrc)
            ret = frame->getSrcBuffer(tag.pipeId, &buffer, tag.bufPos);
        else
            ret = frame->getDstBuffer(tag.pipeId, &buffer, tag.bufPos);

        if (buffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for ISP. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
            }
        }
        frame->removeRawSelectorTag(&tag);
    }

    /* unlock for selectorTag */
    frame->unlockSelectorTagList();

    return ret;
}

status_t ExynosCamera::m_getBayerBuffer(uint32_t pipeId,
                                         uint32_t frameCount,
                                         ExynosCameraBuffer *buffer,
                                         ExynosCameraFrameSelector *selector,
                                         frame_type_t frameType,
                                         ExynosCameraFrameSP_sptr_t captureFrame,
                                         ExynosCameraFrameSP_dptr_t frame
#ifdef SUPPORT_DEPTH_MAP
                                         , ExynosCameraBuffer *depthMapBuffer
#endif
        )
{
    status_t ret = NO_ERROR;
    int dstPos = 0;
    int retryCount = 30; /* 200ms x 30 */
    ExynosCameraFrameSP_sptr_t inListFrame = NULL;
    ExynosCameraFrameSP_sptr_t bayerFrame = NULL;
    frame_handle_components_t components;

    m_getFrameHandleComponentsWrapper(captureFrame, &components);

    if (components.parameters->isReprocessing() == false || selector == NULL) {
        CLOGE("[F%d]INVALID_OPERATION, isReprocessing(%s) or selector is NULL",
                frameCount, components.parameters->isReprocessing() ? "True" : "False");
        ret = INVALID_OPERATION;
        goto CLEAN;
    }

#ifdef OIS_CAPTURE
    if (components.activityControl->getOISCaptureMode() == true) {
        retryCount = 9;
    }

    if (m_configurations->getCaptureExposureTime() > PERFRAME_CONTROL_CAMERA_EXPOSURE_TIME_MAX) {
        selector->setWaitTimeOISCapture(400000000);
    } else {
        selector->setWaitTimeOISCapture(130000000);
    }
#endif

#ifdef USE_LONGEXPOSURECAPTURE
    if (checkLongExposureCaptureMeta(captureFrame)) {
        retryCount = LONG_EXPSOTURECAPTURE_RETRY;
    }
#endif

    if (checkFirstFrameForMultiFrameCapture(captureFrame)) {
        /* TODO for bestShot */
    }

    selector->setWaitTime(200000000);

#ifdef SUPPORT_ME
RETRY_TO_SELECT_FRAME:
#endif

#ifdef USE_DUAL_BAYER_SYNC
    if (captureFrame->getDualOperationMode() == DUAL_OPERATION_MODE_SYNC
        && ExynosCameraFrame::isSlaveFrame(frameType) == true) {
        bayerFrame = m_waitAndPopBayerSyncFrame(components, frameCount);
    } else
#endif
    {
        bayerFrame = selector->selectCaptureFrames(1, frameCount, retryCount);
    }
    if (bayerFrame == NULL) {
        CLOGE("[F%d]bayerFrame is NULL", frameCount);
        ret = INVALID_OPERATION;
        goto CLEAN;
    }

#ifdef USE_DUAL_BAYER_SYNC
    if (captureFrame->getDualOperationMode() != DUAL_OPERATION_MODE_SYNC
        && bayerFrame->getPairFrame() != NULL) {
        selector->releasePairFrameBuffer(bayerFrame);
    }
#endif

    switch (components.parameters->getReprocessingBayerMode()) {
    case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON:
    case REPROCESSING_BAYER_MODE_PURE_DYNAMIC:
        dstPos = components.previewFactory->getNodeType(PIPE_VC0);
        break;
    case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON:
    case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC:
        dstPos = components.previewFactory->getNodeType(PIPE_3AC);
        break;
    default:
        break;
    }

#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (frameType == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION
        || frameType == FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION) {
        dstPos = components.previewFactory->getNodeType(PIPE_VC0);
    }
#endif //SUPPORT_REMOSAIC_CAPTURE

#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (frameType == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION
        || frameType == FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION) {
        int nRetry = 0;
        while(bayerFrame->getFrameType() != FRAME_TYPE_INTERNAL_SENSOR_TRANSITION
                && nRetry < SENSOR_MOODE_TRANSITION_FRAME_COUNT) {
            bayerFrame = selector->selectCaptureFrames(1, frameCount, retryCount);
            if (bayerFrame == NULL) {
                CLOGE("[F%d]bayerFrame is NULL", frameCount);
                ret = INVALID_OPERATION;
                goto CLEAN;
            }

            nRetry++;
        }

        if (nRetry == SENSOR_MOODE_TRANSITION_FRAME_COUNT) {
            CLOGE("[REMOSAIC] Failed to get remosaic frame, retry(%d)", nRetry);
            ret = INVALID_OPERATION;
            goto CLEAN;
        }

        CLOGD("[REMOSAIC] Getting remosaic bayer frame(%d)", bayerFrame->getFrameCount());
        dstPos = components.previewFactory->getNodeType(PIPE_VC0);
    }
#endif //SUPPORT_REMOSAIC_CAPTURE

    ret = bayerFrame->getDstBuffer(pipeId, buffer, dstPos);
    if (ret != NO_ERROR || buffer->index < 0) {
        CLOGE("[F%d B%d]Failed to getDstBuffer. pipeId %d pos %d ret %d",
                bayerFrame->getFrameCount(), buffer->index, pipeId, dstPos, ret);
        goto CLEAN;
    }

#ifdef SUPPORT_DEPTH_MAP
    if (bayerFrame->getRequest(PIPE_VC1)) {
        dstPos = components.previewFactory->getNodeType(PIPE_VC1);

        ret = bayerFrame->getDstBuffer(pipeId, depthMapBuffer, dstPos);
        if (ret != NO_ERROR || depthMapBuffer->index < 0) {
            CLOGE("[F%d B%d]Failed to get DepthMap buffer. ret %d",
                    bayerFrame->getFrameCount(), depthMapBuffer->index, ret);
        }
    }
#endif

    /* Wait to be enabled Metadata */
    retryCount = 12; /* 30ms * 12 */
    while (retryCount > 0) {
        if (bayerFrame->getMetaDataEnable() == false) {
            CLOGD("[F%d B%d]Failed to wait Metadata Enabled. ret %d retryCount %d",
                    bayerFrame->getFrameCount(), buffer->index, ret, retryCount);
        } else {
            CLOGI("[F%d B%d]Frame metadata is updated.",
                    bayerFrame->getFrameCount(), buffer->index);
            break;
        }

        retryCount--;
        usleep(DM_WAITING_TIME);
    }

    CLOGD("[F%d(%d) B%d T%d]Frame is selected timestamp(%jd)",
            bayerFrame->getFrameCount(), bayerFrame->getMetaFrameCount(), buffer->index,
            bayerFrame->getFrameType(), bayerFrame->getTimeStampBoot());

#ifdef DEBUG_RAWDUMP
    if (m_configurations->checkBayerDumpEnable()
        && m_parameters[m_cameraId]->getUsePureBayerReprocessing() == false
        && bayerFrame->getRequest(PIPE_VC0) == true) {
        ExynosCameraBuffer rawDumpBuffer;
        bool bRet;
        char filePath[70];
        time_t rawtime;
        struct tm *timeinfo;

        ret = bayerFrame->getDstBuffer(pipeId, &rawDumpBuffer, components.previewFactory->getNodeType(PIPE_VC0));
        if (ret != NO_ERROR || rawDumpBuffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getDstBuffer for RAW_DUMP. pipeId %d ret %d",
                    bayerFrame->getFrameCount(), rawDumpBuffer.index, pipeId, ret);
        } else {
            memset(filePath, 0, sizeof(filePath));
            time(&rawtime);
            timeinfo = localtime(&rawtime);
            snprintf(filePath, sizeof(filePath), "%sRaw%d_%02d%02d%02d_%02d%02d%02d_%d.raw",
                    CAMERA_DATA_PATH, m_cameraId, timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
                    timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec, bayerFrame->getFrameCount());

            bRet = dumpToFile((char *)filePath,
                    rawDumpBuffer.addr[0],
                    rawDumpBuffer.size[0]);
            if (bRet != true)
                CLOGE("couldn't make a raw file");

            m_bufferSupplier->putBuffer(rawDumpBuffer);
        }
    }
#endif

CLEAN:
    frame = bayerFrame;

    if (bayerFrame != NULL) {
        ret = m_searchFrameFromList(&m_processList, &m_processLock, bayerFrame->getFrameCount(), inListFrame);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]searchFrameFromList fail", bayerFrame->getFrameCount());
        } else {
            CLOGD("[F%d]Selected frame complete, Delete", bayerFrame->getFrameCount());
            bayerFrame = NULL;
        }
    }

    return ret;
}

bool ExynosCamera::m_isRequestEssential(ExynosCameraRequestSP_dptr_t request)
{
    CameraMetadata* serviceMeta = request->getServiceMeta();
    camera_metadata_entry_t entry;
    bool ret = false;

    /* Check AF Trigger */
    entry = serviceMeta->find(ANDROID_CONTROL_AF_TRIGGER);
    if (entry.count > 0) {
        if (entry.data.u8[0] == ANDROID_CONTROL_AF_TRIGGER_START
            || entry.data.u8[0] == ANDROID_CONTROL_AF_TRIGGER_CANCEL) {
            ret = true;
        }
    }

    return ret;
}

status_t ExynosCamera::m_updateResultShot(ExynosCameraFrameSP_sptr_t frame,
                                           ExynosCameraRequestSP_sprt_t request,
                                           struct camera2_shot_ext *src_ext,
                                           enum metadata_type metaType,
                                           frame_type_t frameType,
                                           int32_t physCamID)
{
    // TODO: More efficient implementation is required.
    Mutex::Autolock lock(m_updateMetaLock);

    status_t ret = NO_ERROR;
    struct camera2_shot_ext *dst_ext = NULL;
    uint8_t currentPipelineDepth = 0;
    uint32_t frameCount = 0;
    int Bv = 0;
    int shutter_speed = 0;
    int pre_burst_fps = 0;
    int burst_fps = 0;

    frame_handle_components_t components;
    m_getFrameHandleComponentsWrapper(frame, &components);

    if (src_ext == NULL) {
        CLOGE("src_ext is null.");
        return INVALID_OPERATION;
    }

    if (physCamID < 0) {
        dst_ext = request->getServiceShot();
        if (dst_ext == NULL) {
            CLOGE("getServiceShot failed.");
            return INVALID_OPERATION;
        }
    } else {
        CLOGV("Physical stream Case (%d)", physCamID);
        dst_ext = request->getServiceShotPhysCam(physCamID);
        if (dst_ext == NULL) {
            CLOGE("getServiceShotPhysCam (%d) is failed.", physCamID);
            return INVALID_OPERATION;
        }
    }

#ifndef DISABLE_THERMAL_META
    dst_ext->thermal = src_ext->thermal;
#endif
#ifndef DISABLE_USER_META
    memcpy(&dst_ext->user, &src_ext->user, sizeof(struct camera2_shot_ext_user));
#endif

    currentPipelineDepth = dst_ext->shot.dm.request.pipelineDepth;
    frameCount = dst_ext->shot.dm.request.frameCount;
    memcpy(&dst_ext->shot.dm, &src_ext->shot.dm, sizeof(struct camera2_dm));
    memcpy(&dst_ext->shot.udm, &src_ext->shot.udm, sizeof(struct camera2_udm));
    dst_ext->shot.dm.request.pipelineDepth = currentPipelineDepth;

    /* Keep previous sensor framecount */
    if (frameCount > 0) {
        dst_ext->shot.dm.request.frameCount = frameCount;
    }
    if (request->getSensorTimestamp() == 0) {
        request->setSensorTimestamp(src_ext->shot.udm.sensor.timeStampBoot);
    }

    dst_ext->shot.udm.sensor.timeStampBoot = request->getSensorTimestamp();

    switch (metaType) {
    case PARTIAL_NONE:
        if (src_ext->shot.ctl.stats.faceDetectMode > FACEDETECT_MODE_OFF
            && ((components.parameters->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M) ||
            (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_VRA) == HW_CONNECTION_MODE_M2M))) {
            /* When VRA works as M2M mode, FD metadata will be updated with the latest one in Parameters */
            request->setDisplayCameraId(frame->getCameraId());
#ifdef USE_DUAL_CAMERA
            int32_t displayCameraId = frame->getDisplayCameraId();
            request->setDisplayCameraId(displayCameraId);

            // set display's size info to request
            frame_size_info_t info;
            for (int i = FRAME_SIZE_BASE + 1; i < FRAME_SIZE_MAX; i++) {
                if (frame->getSizeInfo((frame_size_scenario_t)i, info, displayCameraId)) {
                    request->setSizeInfo((frame_size_scenario_t)i, info, displayCameraId);
                }
            }

            if (frameType == FRAME_TYPE_PREVIEW_DUAL_MASTER) {
                m_parameters[displayCameraId]->getFaceDetectMeta(dst_ext);
            }
            else
#endif
            {
                components.parameters->getFaceDetectMeta(dst_ext);
            }
        }
        break;
    case PARTIAL_3AA:
#ifdef LLS_CAPTURE
        {
            int LLS_value = 0;
            int pre_LLS_value = 0;

            LLS_value = components.parameters->getLLSValue();

            pre_LLS_value = m_configurations->getModeValue(CONFIGURATION_LLS_VALUE);

            if (LLS_value != pre_LLS_value) {
                m_configurations->setModeValue(CONFIGURATION_LLS_VALUE, LLS_value);
                CLOGD("LLS_value(%d)", LLS_value);
            }
        }
#endif

        Bv = dst_ext->shot.udm.internal.vendorSpecific[2];
        shutter_speed = dst_ext->shot.udm.ae.vendorSpecific[64];
        pre_burst_fps = m_configurations->getModeValue(CONFIGURATION_BURSTSHOT_FPS);

        if (pre_burst_fps != burst_fps) {
            m_configurations->setModeValue(CONFIGURATION_BURSTSHOT_FPS, burst_fps);
            CLOGD("burstshot_fps(%d) / Bv(%d) / Shutter speed(%d)", burst_fps, Bv, shutter_speed);
        }
        break;
    case PARTIAL_JPEG:
    default:
        /* no operation */
        break;
    }

    ret = m_metadataConverter->updateDynamicMeta(request, metaType, physCamID);

    CLOGV("[R%d F%d f%d M%d] Set result.",
            request->getKey(), request->getFrameCount(),
            dst_ext->shot.dm.request.frameCount, metaType);

    return ret;
}

status_t ExynosCamera::m_updateJpegPartialResultShot(ExynosCameraRequestSP_sprt_t request,
                                                    struct camera2_shot_ext *dst_ext,
                                                    ExynosCameraParameters *parameters)
{
    status_t ret = NO_ERROR;

    if (dst_ext == NULL) {
        CLOGE("dst Shot failed.");
        return INVALID_OPERATION;
    }

    parameters->setExifChangedAttribute(NULL, NULL, NULL, dst_ext);
    ret = m_metadataConverter->updateDynamicMeta(request, PARTIAL_JPEG);

    CLOGV("[F%d(%d)]Set result.",
            request->getFrameCount(), dst_ext->shot.dm.request.frameCount);

    return ret;
}

status_t ExynosCamera::m_setupFrameFactoryToRequest()
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameFactory *factory = NULL;
    ExynosCameraFrameFactory *factoryVision = NULL;
    ExynosCameraFrameFactory *factoryReprocessing = NULL;

    factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
    factoryVision = m_frameFactory[FRAME_FACTORY_TYPE_VISION];

    /* Do not use reprocessing in case of BDS off scenario */
    if (m_parameters[m_cameraId]->isUseVideoHQISP() == true)
        factoryReprocessing = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
    else
        factoryReprocessing = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING];

    if (factory != NULL && factoryReprocessing != NULL) {
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_PREVIEW, factory);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_VIDEO, factory);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_CALLBACK, factory);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_CALLBACK_PHYSICAL, factory);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_PREVIEW_VIDEO, factory);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_ZSL_OUTPUT, factory);
#ifdef SUPPORT_DEPTH_MAP
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_DEPTHMAP, factory);
#endif
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_VISION, factory);

        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_RAW, factoryReprocessing);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_RAW_PHYSICAL, factoryReprocessing);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_JPEG, factoryReprocessing);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_ZSL_INPUT, factoryReprocessing);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_CALLBACK_STALL, factoryReprocessing);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_THUMBNAIL_CALLBACK, factoryReprocessing);
#ifdef SUPPORT_DEPTH_MAP
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_DEPTHMAP_STALL, factoryReprocessing);
#endif
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_YUV_INPUT, factoryReprocessing);
    } else if (factoryVision != NULL) {
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_PREVIEW, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_VIDEO, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_CALLBACK, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_ZSL_OUTPUT, factoryVision);
#ifdef SUPPORT_DEPTH_MAP
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_DEPTHMAP, factoryVision);
#endif
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_VISION, factoryVision);

        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_RAW, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_JPEG, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_ZSL_INPUT, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_CALLBACK_STALL, factoryVision);
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_THUMBNAIL_CALLBACK, factoryVision);
#ifdef SUPPORT_DEPTH_MAP
        m_requestMgr->setRequestsInfo(HAL_STREAM_ID_DEPTHMAP_STALL, factoryVision);
#endif
    } else {
        if (factory == NULL) {
            CLOGE("FRAME_FACTORY_TYPE_CAPTURE_PREVIEW factory is NULL!!!!");
        }
        if (factoryReprocessing == NULL) {
            CLOGE("FRAME_FACTORY_TYPE_REPROCESSING factory is NULL!!!!");
        }
        if (factoryVision == NULL) {
            CLOGE("FRAME_FACTORY_TYPE_VISION factory is NULL!!!!");
        }
    }

    return ret;
}

status_t ExynosCamera::m_setupStreamInfoToRequestManager()
{
    status_t ret = NO_ERROR;
    List<int> keylist;
    List<int>::iterator iter;
    list<int> streamKeylist;
    int streamId = -1;

    m_streamManager->getStreamKeys(&keylist);
    for (iter = keylist.begin(); iter != keylist.end(); iter++) {
        streamId = *iter;
        switch(streamId % HAL_STREAM_ID_MAX) {
        case HAL_STREAM_ID_ZSL_INPUT:
        case HAL_STREAM_ID_YUV_INPUT:
            /* do not update input stream for requestMgr  */
            break;
        default:
            streamKeylist.push_back(streamId);
            break;
        }
    }

    m_requestMgr->setStreamInfos(streamKeylist);

    return ret;
}

status_t ExynosCamera::m_setStreamInfo(camera3_stream_configuration *streamList)
{
    int ret = OK;
    int id = 0;
    int recordingFps = 0;
    int highSpeedMode = -1;

    CLOGD("In");

    /* sanity check */
    if (streamList == NULL) {
        CLOGE("NULL stream configuration");
        return BAD_VALUE;
    }

    if (streamList->streams == NULL) {
        CLOGE("NULL stream list");
        return BAD_VALUE;
    }

    if (streamList->num_streams < 1) {
        CLOGE(" Bad number of streams requested: %d", streamList->num_streams);
        return BAD_VALUE;
    }

    /* check input stream */
    bool inputStreamExist = false;
    /* initialize variable */
    m_captureStreamExist = false;
    m_videoStreamExist = false;
    m_rawStreamExist = false;
    m_configurations->setMode(CONFIGURATION_YSUM_RECORDING_MODE, false);
    m_configurations->setMode(CONFIGURATION_HDR_RECORDING_MODE, false);

    for (size_t i = 0; i < streamList->num_streams; i++) {
        camera3_stream_t *newStream = streamList->streams[i];
        int option = 0;

        if (newStream == NULL) {
            CLOGE("Stream index %zu was NULL", i);
            return BAD_VALUE;
        }

        // for debug
        CLOGD("Stream(%p), ID(%zu), type(%d), usage(%#x) format(%#x) w(%d),h(%d), option(%#x)",
            newStream, i, newStream->stream_type, newStream->usage,
            newStream->format, (int)(newStream->width), (int)(newStream->height), option);

        if ((int)(newStream->width) <= 0
            || (int)(newStream->height) <= 0
            || newStream->format < 0
            || newStream->rotation < 0) {
            CLOGE("Invalid Stream(%p), ID(%zu), type(%d), usage(%#x) format(%#x) w(%d),h(%d), option(%#x)",
                newStream, i, newStream->stream_type, newStream->usage,
                newStream->format, (int)(newStream->width), (int)(newStream->height), option);
            return BAD_VALUE;
        }

        if ((newStream->stream_type == CAMERA3_STREAM_INPUT)
            || (newStream->stream_type == CAMERA3_STREAM_BIDIRECTIONAL)) {
            if (inputStreamExist == true) {
                CLOGE("Multiple input streams requested!");
                return BAD_VALUE;
            }
            inputStreamExist = true;
            m_captureStreamExist = true;
        }

        if (newStream->stream_type == CAMERA3_STREAM_OUTPUT) {
            if ((newStream->format == HAL_PIXEL_FORMAT_BLOB)
                || (newStream->format == HAL_PIXEL_FORMAT_RAW16)
                || (newStream->format == HAL_PIXEL_FORMAT_YCbCr_420_888
                    && (option & STREAM_OPTION_STALL_MASK))) {
                m_captureStreamExist = true;
            }

            if (newStream->format == HAL_PIXEL_FORMAT_RAW16
                && !(option & STREAM_OPTION_DEPTH10_MASK)) {
                m_rawStreamExist = true;
            }
        }

        if ((newStream->format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED
             || newStream->format == HAL_PIXEL_FORMAT_EXYNOS_YCrCb_420_SP_M)
            && (newStream->usage & GRALLOC1_CONSUMER_USAGE_VIDEO_ENCODER)) {
            CLOGI("recording stream checked");
            m_videoStreamExist = true;
        }

        // TODO: format validation
    }

    recordingFps = m_configurations->getModeValue(CONFIGURATION_RECORDING_FPS);

    if (streamList->operation_mode == CAMERA3_STREAM_CONFIGURATION_CONSTRAINED_HIGH_SPEED_MODE) {
        CLOGI("High speed mode is configured. StreamCount %d. m_videoStreamExist(%d) recordingFps(%d)",
                streamList->num_streams, m_videoStreamExist, recordingFps);

        if (recordingFps == 120) {
            highSpeedMode = CONFIG_MODE::HIGHSPEED_120;
        } else if (recordingFps == 240) {
            highSpeedMode = CONFIG_MODE::HIGHSPEED_240;
        } else if (recordingFps == 480) {
            highSpeedMode = CONFIG_MODE::HIGHSPEED_480;
        } else {
            highSpeedMode = m_highSpeedModeDecision(streamList);
        }
    } else {
        {
            if (m_videoStreamExist == true) {
                m_configurations->setMode(CONFIGURATION_YSUM_RECORDING_MODE, true);
                highSpeedMode = (recordingFps == 60) ? CONFIG_MODE::HIGHSPEED_60 : CONFIG_MODE::NORMAL;
            } else {
                highSpeedMode = CONFIG_MODE::NORMAL;
            }
        }
    }
    CLOGI("highSpeedMode = %d recordingFps = %d", highSpeedMode, recordingFps);

    m_configurations->setModeValue(CONFIGURATION_HIGHSPEED_MODE, highSpeedMode);
    m_exynosconfig = m_configurations->getConfig();

    /* 1. Invalidate all current streams */
    List<int> keylist;
    List<int>::iterator iter;
    ExynosCameraStream *stream = NULL;
    keylist.clear();
    m_streamManager->getStreamKeys(&keylist);
    for (iter = keylist.begin(); iter != keylist.end(); iter++) {
        m_streamManager->getStream(*iter, &stream);
        stream->setRegisterStream(EXYNOS_STREAM::HAL_STREAM_STS_INVALID);
        stream->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_UNREGISTERED);
    }

    /* 2. Remove dead streams */
    keylist.clear();
    stream = NULL;
    id = 0;
    EXYNOS_STREAM::STATE registerStream = EXYNOS_STREAM::HAL_STREAM_STS_INIT;
    m_streamManager->getStreamKeys(&keylist);
    for (iter = keylist.begin(); iter != keylist.end(); iter++) {
        m_streamManager->getStream(*iter, &stream);
        ret = stream->getRegisterStream(&registerStream);
        if (registerStream == EXYNOS_STREAM::HAL_STREAM_STS_INVALID){
            ret = stream->getID(&id);
            if (id < 0) {
                CLOGE("getID failed id(%d)", id);
                continue;
            }
            m_streamManager->deleteStream(id);
        }
    }

    /* 3. Update stream info */
    for (size_t i = 0; i < streamList->num_streams; i++) {
        stream = NULL;
        camera3_stream_t *newStream = streamList->streams[i];
        int phyCamID = -1;

        if (newStream->physical_camera_id != NULL && strlen(newStream->physical_camera_id) > 0) {
            phyCamID = atoi(newStream->physical_camera_id);
        }

        if (m_isLogicalCam && (phyCamID >= 0)) {
            // This should be configured here to decide the proper DualPreviewMode for Logical camera.
            m_configurations->setPhysStreamExistStatus(true);
        }

        if (phyCamID < 0) {
            /* new stream case */
            ret = m_enumStreamInfo(newStream);
            if (ret) {
                CLOGE("Register stream failed %p", newStream);
                return ret;
            }
        }
    }

    CLOGD("out");
    return ret;
}

int ExynosCamera::m_highSpeedModeDecision(camera3_stream_configuration *streamList)
{
    CLOGD("In");

    uint32_t maxStreamW = 0;
    uint32_t maxStreamH = 0;
    int maxFps = 0;
    int (*highSpeedVideoSizeList)[SIZE_OF_RESOLUTION] = NULL;
    int highSpeedVideoSizeListLength = 0;
    int highSpeedMode = -1;

    struct ExynosCameraSensorInfoBase *sensorStaticInfo = m_parameters[m_cameraId]->getSensorStaticInfo();

    if (streamList->operation_mode != CAMERA3_STREAM_CONFIGURATION_CONSTRAINED_HIGH_SPEED_MODE) {
        return CONFIG_MODE::NORMAL;
    }

    for (size_t i = 0; i < streamList->num_streams; i++) {
        camera3_stream_t *stream = streamList->streams[i];
        if (stream->stream_type == CAMERA3_STREAM_OUTPUT) {
            if (maxStreamW < stream->width)
                maxStreamW = stream->width;

            if (maxStreamH < stream->height)
                maxStreamH = stream->height;
        } else {
            continue;
        }
    }

    highSpeedVideoSizeList = sensorStaticInfo->highSpeedVideoList;
    highSpeedVideoSizeListLength = sensorStaticInfo->highSpeedVideoListMax;

    for (int i = 0; i < highSpeedVideoSizeListLength; i++) {
        if (highSpeedVideoSizeList[i][0] == maxStreamW &&
            highSpeedVideoSizeList[i][1] == maxStreamH) {
            maxFps = max(maxFps, highSpeedVideoSizeList[i][2]);
        }
    }

    if (maxFps == 120) {
        highSpeedMode = CONFIG_MODE::HIGHSPEED_120;
    } else if (maxFps == 240) {
        highSpeedMode = CONFIG_MODE::HIGHSPEED_240;
    } else if (maxFps == 480) {
        highSpeedMode = CONFIG_MODE::HIGHSPEED_480;
    } else {
        highSpeedMode = CONFIG_MODE::NORMAL;
    }

    CLOGD("out");
    return highSpeedMode;
}

status_t ExynosCamera::m_setExtraStreamInfo(camera3_stream_configuration *streamList)
{
    int ret = OK;

    CLOGD("In");

    for (size_t i = 0; i < streamList->num_streams; i++) {
        camera3_stream_t *newStream = streamList->streams[i];
        int phyCamID = -1;

        if (newStream->physical_camera_id != NULL && strlen(newStream->physical_camera_id) > 0) {
            phyCamID = atoi(newStream->physical_camera_id);
        }

        if (phyCamID < 0) {
            if (newStream->priv == NULL) {
                /* new stream case */
                ret = m_enumExtraStreamInfo(newStream);
                if (ret) {
                    CLOGE("Register stream failed %p", newStream);
                    return ret;
                }
            }
        }
    }

    /* 4. Update stream info physical streams */
    for (size_t i = 0; i < streamList->num_streams; i++) {
        camera3_stream_t *newStream = streamList->streams[i];
        int phyCamID = -1;

        if (newStream->physical_camera_id != NULL && strlen(newStream->physical_camera_id) > 0) {
            phyCamID = atoi(newStream->physical_camera_id);
        }

        if (phyCamID >= 0) {
            /* new stream case */
            ret = m_enumStreamInfo(newStream);
            if (ret) {
                CLOGE("Register stream failed %p", newStream);
                return ret;
            }
        }
    }

    CLOGD("out");
    return ret;
}

status_t ExynosCamera::m_enumStreamInfo(camera3_stream_t *stream)
{
    CLOGD("In");
    int ret = OK;
    ExynosCameraStream *newStream = NULL;
    int id = 0;
    int actualFormat = 0;
    camera_pixel_size pixelSize = CAMERA_PIXEL_SIZE_8BIT;
    int planeCount = 0;
    int requestBuffer = 0;
    int outputPortId = 0;
    int option = 0;
    int phyCamID = -1;
    EXYNOS_STREAM::STATE registerStream;
    EXYNOS_STREAM::STATE registerBuffer;
    cameraId_Info camIdInfo;

    registerStream = EXYNOS_STREAM::HAL_STREAM_STS_VALID;
    registerBuffer = EXYNOS_STREAM::HAL_STREAM_STS_UNREGISTERED;

    if (stream == NULL) {
        CLOGE("stream is NULL.");
        return INVALID_OPERATION;
    }

    /* default surface usage */
    stream->usage |= ExynosGraphicBufferUsage::YUV_RANGE_FULL;

    /* ToDo: need to Consideration about how to support each camera3_stream_rotation_t */
    if (stream->rotation != CAMERA3_STREAM_ROTATION_0) {
        CLOGE("Invalid stream rotation %d", stream->rotation);
        ret = BAD_VALUE;
        goto func_err;
    }


    if ((stream->physical_camera_id != NULL && strlen(stream->physical_camera_id) > 0)) {
        if (m_isLogicalCam) {
            phyCamID = atoi(stream->physical_camera_id);
            camIdInfo.serviceCameraId = phyCamID;
            getCameraIdInfo(&camIdInfo);
            phyCamID = camIdInfo.cameraId[MAIN_CAM];
            if (!(isCamPhysIDValid(m_camIdInfo.serviceCameraId, camIdInfo.cameraId[MAIN_CAM]))) {
                CLOGE("Physical ID is in valid for Logical Cam (serviceId = %d, %s)",
                    m_camIdInfo.serviceCameraId, stream->physical_camera_id);
                ret = BAD_VALUE;
                goto func_err;
            }
            CLOGD("Physical ID(%d, %s) mainCameraId(%d), m_cameraIds(%d, %d)",
                phyCamID, stream->physical_camera_id, camIdInfo.cameraId[MAIN_CAM], m_cameraIds[0], m_cameraIds[1]);
            m_configurations->setPhysStreamExistStatus(true);
        } else {
            CLOGE("Physical ID is enabled for Non Logical Cam (%s)", stream->physical_camera_id);
            ret = BAD_VALUE;
            goto func_err;
        }

        /* YUV/RAW streams can be Logical or Physical streams. */
    }

    switch (stream->stream_type) {
    case CAMERA3_STREAM_OUTPUT:
        // TODO: split this routine to function
        switch (stream->format) {
        case HAL_PIXEL_FORMAT_BLOB:
            CLOGD("HAL_PIXEL_FORMAT_BLOB format(%#x) usage(%#x) stream_type(%#x)",
                    stream->format, stream->usage, stream->stream_type);
            id = HAL_STREAM_ID_JPEG;
            actualFormat = HAL_PIXEL_FORMAT_BLOB;
            planeCount = 1;
            outputPortId = 0;
            requestBuffer = m_exynosconfig->current->bufInfo.num_request_burst_capture_buffers;
            break;
        case HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED:
        case HAL_PIXEL_FORMAT_EXYNOS_YCbCr_420_SP_M_SBWC: // Override format
        case HAL_PIXEL_FORMAT_EXYNOS_YCrCb_420_SP_M:
        case HAL_PIXEL_FORMAT_EXYNOS_YCbCr_P010_M:
            if ((stream->usage & GRALLOC1_CONSUMER_USAGE_GPU_TEXTURE || stream->usage & GRALLOC1_CONSUMER_USAGE_HWCOMPOSER)
                && (stream->usage & GRALLOC1_CONSUMER_USAGE_VIDEO_ENCODER)) {
                CLOGD("GRALLOC1_CONSUMER_USAGE_GPU_TEXTURE|HWCOMPOSER|VIDEO_ENCODER foramt(%#x) usage(%#x) stream_type(%#x), stream_option(%#x)",
                        stream->format, stream->usage, stream->stream_type, option);
                id = HAL_STREAM_ID_PREVIEW_VIDEO;
                actualFormat = HAL_PIXEL_FORMAT_EXYNOS_YCrCb_420_SP_M; /* NV12M */
                planeCount = 2;

                stream->data_space = HAL_DATASPACE_SDR_REC;

#ifdef USE_SERVICE_BATCH_MODE
                enum pipeline controlPipeId = (enum pipeline) m_parameters[m_cameraId]->getPerFrameControlPipe();
                int batchSize = m_parameters[m_cameraId]->getBatchSize(controlPipeId);
                if (batchSize > 1 && m_parameters[m_cameraId]->useServiceBatchMode() == true) {
                    CLOGD("Use service batch mode. Add HFR_MODE usage bit. batchSize %d", batchSize);
                    stream->usage |= GRALLOC1_PRODUCER_USAGE_HFR_MODE;
                }
#endif
                outputPortId = m_streamManager->getTotalYuvStreamCount();
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_video_buffers;
            } else if (stream->usage & GRALLOC1_CONSUMER_USAGE_GPU_TEXTURE
                || stream->usage & GRALLOC1_CONSUMER_USAGE_HWCOMPOSER) {
                CLOGD("GRALLOC1_CONSUMER_USAGE_GPU_TEXTURE|HWCOMPOSER foramt(%#x) usage(%#x) stream_type(%#x), stream_option(%#x)",
                    stream->format, stream->usage, stream->stream_type, option);
                id = HAL_STREAM_ID_PREVIEW;
                actualFormat = HAL_PIXEL_FORMAT_EXYNOS_YCrCb_420_SP_M;
                planeCount = 2;

                if (m_videoStreamExist == true) {
                    if (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true) {
                        stream->data_space = HAL_DATASPACE_HDR10_REC;

                        stream->usage |= (ExynosGraphicBufferUsage::VIDEO_PRIVATE_DATA)
                                         | (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);
                        planeCount = 3;
                    } else {
#ifdef ANDROIDQ_CAM_SERVICE_BUF_WA
                        stream->data_space = HAL_DATASPACE_SDR_PREVIEW;
#else
                        stream->data_space = HAL_DATASPACE_SDR_REC;
#endif
                    }
                } else {
                    stream->data_space = HAL_DATASPACE_SDR_PREVIEW;
                }

                /* Cached for PP Pipe */
                stream->usage |= (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);

                /* set Preview Size */
                m_configurations->setSize(CONFIGURATION_PREVIEW_SIZE, stream->width, stream->height);

                outputPortId = m_streamManager->getTotalYuvStreamCount();
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_preview_buffers;

#ifdef SUPPORT_COMPRESSION_PREVIEW_STREAM
                if (m_configurations->getMode(CONFIGURATION_COMPRESSION_PREVIEW_STREAM)) {
                    if (pixelSize == CAMERA_PIXEL_SIZE_10BIT) {
                        stream->format = HAL_PIXEL_FORMAT_EXYNOS_YCbCr_420_SP_M_10B_SBWC;
                    } else {
                        stream->format = HAL_PIXEL_FORMAT_EXYNOS_YCbCr_420_SP_M_SBWC;
                    }
                }
#endif

            } else if(stream->usage & GRALLOC1_CONSUMER_USAGE_VIDEO_ENCODER) {
                CLOGD("GRALLOC1_CONSUMER_USAGE_VIDEO_ENCODER format(%#x) usage(%#x) stream_type(%#x), stream_option(%#x)",
                    stream->format, stream->usage, stream->stream_type, option);
                id = HAL_STREAM_ID_VIDEO;
                actualFormat = HAL_PIXEL_FORMAT_EXYNOS_YCrCb_420_SP_M; /* NV12M */

                planeCount = 2;

                if ((m_configurations->getMode(CONFIGURATION_YSUM_RECORDING_MODE) == true) ||
                        (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true)) {
                    stream->usage |= (ExynosGraphicBufferUsage::VIDEO_PRIVATE_DATA)
                                     | (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);
                    planeCount = 3;

                    if (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true) {
                        actualFormat = HAL_PIXEL_FORMAT_EXYNOS_YCbCr_P010_M;
                        pixelSize = CAMERA_PIXEL_SIZE_10BIT;

                        /* overrideFormat format  */
                        stream->format = HAL_PIXEL_FORMAT_EXYNOS_YCbCr_P010_M;
                    }
                }

#ifdef SUPPORT_COMPRESSION_VIDEO_STREAM
                if (m_configurations->getMode(CONFIGURATION_COMPRESSION_VIDEO_STREAM)) {
                    if (pixelSize == CAMERA_PIXEL_SIZE_10BIT) {
                        stream->format = HAL_PIXEL_FORMAT_EXYNOS_YCbCr_420_SP_M_10B_SBWC;
                    } else {
                        stream->format = HAL_PIXEL_FORMAT_EXYNOS_YCbCr_420_SP_M_SBWC;
                    }
                } else
#endif
                {
                    /* override format of stream to  actualFormat  */
                    stream->format = actualFormat;
                }

                /* Cached for PP Pipe */
                stream->usage |= (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);
#ifdef USE_SERVICE_BATCH_MODE
                enum pipeline controlPipeId = (enum pipeline) m_parameters[m_cameraId]->getPerFrameControlPipe();
                int batchSize = m_parameters[m_cameraId]->getBatchSize(controlPipeId);
                if (batchSize > 1 && m_parameters[m_cameraId]->useServiceBatchMode() == true) {
                    CLOGD("Use service batch mode. Add HFR_MODE usage bit. batchSize %d", batchSize);
                    stream->usage |= GRALLOC1_PRODUCER_USAGE_HFR_MODE;
                }
#endif

                if (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true) {
                    stream->data_space = HAL_DATASPACE_HDR10_REC;
                } else {
                    stream->data_space = HAL_DATASPACE_SDR_REC;
                }

                /* set Video Size and Recording Mode(Hint) */
                m_configurations->setSize(CONFIGURATION_VIDEO_SIZE, stream->width, stream->height);
                m_configurations->setMode(CONFIGURATION_RECORDING_MODE, true);

                outputPortId = m_streamManager->getTotalYuvStreamCount();
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_video_buffers;
            } else if((stream->usage & GRALLOC1_CONSUMER_USAGE_CAMERA) && (stream->usage & GRALLOC1_PRODUCER_USAGE_CAMERA)) {
                CLOGD("GRALLOC1_USAGE_CAMERA(ZSL) format(%#x) usage(%#x) stream_type(%#x), stream_option(%#x)",
                      stream->format, stream->usage, stream->stream_type, option);
                id = HAL_STREAM_ID_ZSL_OUTPUT;
                actualFormat = HAL_PIXEL_FORMAT_RAW16;
                planeCount = 1;
                outputPortId = 0;
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_bayer_buffers;
            } else {
                CLOGE("HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED unknown usage(%#x)"
                    " format(%#x) stream_type(%#x), stream_option(%#x)",
                    stream->usage, stream->format, stream->stream_type, option);
                ret = BAD_VALUE;
                goto func_err;
            }
            break;
        case HAL_PIXEL_FORMAT_YCbCr_420_888:
            if ((option & STREAM_OPTION_STALL_MASK)
#ifdef ENABLE_YUV_STALL_FOR_SECOND_YUV
                   // HACK: second yuv
                   // TODO: need more condition for specific vendor tag
                || m_streamManager->findStream(HAL_STREAM_ID_CALLBACK)
#endif
               ) {
                CLOGD("HAL_PIXEL_FORMAT_YCbCr_420_888_STALL format(%#x) usage(%#x) stream_type(%#x)",
                    stream->format, stream->usage, stream->stream_type);
                id = HAL_STREAM_ID_CALLBACK_STALL;

                if (m_streamManager->getOutputPortId(id) >= 0
                    && ((m_scenario == SCENARIO_DUAL_REAR_PORTRAIT && phyCamID >= 0)
                         || (m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT && phyCamID >= 0))
                ) {
                    outputPortId = m_streamManager->getOutputPortId(id);
                } else {
                    outputPortId = m_streamManager->getTotalYuvStreamCount()
                                   + ExynosCameraParameters::YUV_STALL_0;
                }

                if (option & STREAM_OPTION_STITCHING) {
                    requestBuffer = m_exynosconfig->current->bufInfo.num_request_burst_capture_buffers;
                } else {
                    requestBuffer = m_exynosconfig->current->bufInfo.num_request_capture_buffers;
                }
#ifdef ENABLE_YUV_STALL_FOR_SECOND_YUV
                // HACK: second yuv
                // TODO: need more condition for specific vendor tag
                if (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK)) {
                    m_captureStreamExist = true;
                }
#endif
                /* Cached for PP Pipe */
                stream->usage |= (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);
            } else if (option & STREAM_OPTION_THUMBNAIL_CB_MASK) {
                CLOGD("HAL_PIXEL_FORMAT_YCbCr_420_888 THUMBNAIL_CALLBACK format (%#x) usage(%#x) stream_type(%#x)",
                    stream->format, stream->usage, stream->stream_type);
                id = HAL_STREAM_ID_THUMBNAIL_CALLBACK;
                outputPortId = 0;
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_burst_capture_buffers;
            } else if (phyCamID >= 0) {
                CLOGD("HAL_PIXEL_FORMAT_YCbCr_420_888 format(%#x) usage(%#x) stream_type(%#x) phyCamID (%d)",
                    stream->format, stream->usage, stream->stream_type, phyCamID);
                id = HAL_STREAM_ID_CALLBACK_PHYSICAL;
                outputPortId = m_streamManager->getTotalYuvStreamCount();
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_callback_buffers;
            } else {
                CLOGD("HAL_PIXEL_FORMAT_YCbCr_420_888 format(%#x) usage(%#x) stream_type(%#x)",
                    stream->format, stream->usage, stream->stream_type);

                id = HAL_STREAM_ID_CALLBACK;
                outputPortId = m_streamManager->getTotalYuvStreamCount();
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_callback_buffers;

                /* Cached for PP Pipe */
                stream->usage |= (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);
            }

            actualFormat = HAL_PIXEL_FORMAT_YCrCb_420_SP;
            planeCount = 1;
            break;
        /* case HAL_PIXEL_FORMAT_RAW_SENSOR: */
        case HAL_PIXEL_FORMAT_RAW16:
            CLOGD("HAL_PIXEL_FORMAT_RAW_XXX format(%#x) usage(%#x) stream_type(%#x) stream_option(%#x)",
                stream->format, stream->usage, stream->stream_type, option);
#ifdef SUPPORT_DEPTH_MAP
            if (option & STREAM_OPTION_DEPTH10_MASK && option & STREAM_OPTION_STALL_MASK) {
                id = HAL_STREAM_ID_DEPTHMAP_STALL;
                stream->usage |= GRALLOC_USAGE_SW_READ_OFTEN;   /* Cached & NeedSync */
                requestBuffer = NUM_DEPTHMAP_BUFFERS;
            } else if (option & STREAM_OPTION_DEPTH10_MASK) {
                id = HAL_STREAM_ID_DEPTHMAP;
                requestBuffer = NUM_DEPTHMAP_BUFFERS;
            } else
#endif
            {
                if (phyCamID >= 0) {
                    id = HAL_STREAM_ID_RAW_PHYSICAL;
                    CLOGD("HAL_PIXEL_FORMAT_RAW_XXX format(%#x) usage(%#x) stream_type(%#x) stream_option(%#x) phyCamID (%d)",
                        stream->format, stream->usage, stream->stream_type, option, phyCamID);
                } else {
                    id = HAL_STREAM_ID_RAW;
                }
                stream->usage |= GRALLOC_USAGE_SW_READ_OFTEN;   /* Cached & NeedSync */
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_raw_buffers;
            }
            actualFormat = HAL_PIXEL_FORMAT_RAW16;
            planeCount = 1;
            outputPortId = 0;
            break;
#if 0
#ifdef SUPPORT_DEPTH_MAP
        case HAL_PIXEL_FORMAT_Y16:
            CLOGD("HAL_PIXEL_FORMAT_Y16 format(%#x) usage(%#x) stream_type(%#x) stream_option(%#x)",
                stream->format, stream->usage, stream->stream_type, option);
            if (option & STREAM_OPTION_STALL_MASK) {
                id = HAL_STREAM_ID_DEPTHMAP_STALL;
                stream->usage |= GRALLOC_USAGE_SW_READ_OFTEN;   /* Cached & NeedSync */
            } else {
                id = HAL_STREAM_ID_DEPTHMAP;
            }
            actualFormat = HAL_PIXEL_FORMAT_Y16;
            planeCount = 1;
            outputPortId = 0;
            requestBuffer = m_exynosconfig->current->bufInfo.num_request_raw_buffers;
            break;
#endif
#endif
        case HAL_PIXEL_FORMAT_Y8:
            CLOGD("HAL_PIXEL_FORMAT_Y8 format(%#x) usage(%#x) stream_type(%#x) stream_option(%#x)",
                stream->format, stream->usage, stream->stream_type, option);
            id = HAL_STREAM_ID_VISION;
            actualFormat = HAL_PIXEL_FORMAT_Y8;
            planeCount = 1;
            outputPortId = 0;
            requestBuffer = RESERVED_NUM_SECURE_BUFFERS;
            break;
        default:
            CLOGE("Not supported image format(%#x) usage(%#x) stream_type(%#x)",
                 stream->format, stream->usage, stream->stream_type);
            ret = BAD_VALUE;
            goto func_err;
            break;
        }
        break;
    case CAMERA3_STREAM_INPUT:
    case CAMERA3_STREAM_BIDIRECTIONAL:
        ret = m_streamManager->increaseInputStreamCount(m_parameters[m_cameraId]->getInputStreamMaxNum());
        if (ret != NO_ERROR) {
            CLOGE("can not support more than %d input streams", m_parameters[m_cameraId]->getInputStreamMaxNum());
            goto func_err;
        }

        switch (stream->format) {
        /* case HAL_PIXEL_FORMAT_RAW_SENSOR: */
        case HAL_PIXEL_FORMAT_RAW16:
        case HAL_PIXEL_FORMAT_RAW_OPAQUE:
            CLOGD("HAL_PIXEL_FORMAT_RAW_XXX format(%#x) usage(%#x) stream_type(%#x)",
                 stream->format, stream->usage, stream->stream_type);
            if (phyCamID >= 0) {
                id = HAL_STREAM_ID_RAW_PHYSICAL;
                CLOGD("HAL_PIXEL_FORMAT_RAW_XXX format(%#x) usage(%#x) stream_type(%#x) phyCamID (%d)",
                    stream->format, stream->usage, stream->stream_type, phyCamID);
            } else {
                id = HAL_STREAM_ID_RAW;
            }
            actualFormat = HAL_PIXEL_FORMAT_RAW16;
            planeCount = 1;
            requestBuffer = m_exynosconfig->current->bufInfo.num_request_raw_buffers;
            break;
        case HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED:
            CLOGD("GRALLOC1_USAGE_CAMERA(ZSL) foramt(%#x) usage(%#x) stream_type(%#x)",
                stream->format, stream->usage, stream->stream_type);
            id = HAL_STREAM_ID_ZSL_INPUT;
            actualFormat = HAL_PIXEL_FORMAT_RAW16;

            /* Add camera usage to identify ZSL stream for Gralloc */
            stream->usage |= (GRALLOC1_CONSUMER_USAGE_CAMERA | GRALLOC1_PRODUCER_USAGE_CAMERA);

            planeCount = 1;
            requestBuffer = m_exynosconfig->current->bufInfo.num_request_raw_buffers;
            break;
        case HAL_PIXEL_FORMAT_YCbCr_420_888:
            CLOGD("HAL_PIXEL_FORMAT_YCbCr_420_888 format(%#x) usage(%#x) stream_type(%#x)",
                stream->format, stream->usage, stream->stream_type);

            stream->usage |= (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN);

            id = HAL_STREAM_ID_YUV_INPUT;
            outputPortId = 0;
            requestBuffer = m_exynosconfig->current->bufInfo.num_request_callback_buffers;
            actualFormat = HAL_PIXEL_FORMAT_YCrCb_420_SP;
            planeCount = 1;
            break;
        default:
            CLOGE("Not supported image format(%#x) usage(%#x) stream_type(%#x)",
                 stream->format, stream->usage, stream->stream_type);
            goto func_err;
        }
        break;
    default:
        CLOGE("Unknown stream_type(%#x) format(%#x) usage(%#x)",
             stream->stream_type, stream->format, stream->usage);
        ret = BAD_VALUE;
        goto func_err;
    }

    /* Update gralloc usage */
    switch (stream->stream_type) {
    case CAMERA3_STREAM_INPUT:
        stream->usage |= GRALLOC1_CONSUMER_USAGE_CAMERA;
        break;
    case CAMERA3_STREAM_OUTPUT:
        stream->usage |= GRALLOC1_PRODUCER_USAGE_CAMERA;
        break;
    case CAMERA3_STREAM_BIDIRECTIONAL:
        stream->usage |= (GRALLOC1_CONSUMER_USAGE_CAMERA
                          | GRALLOC1_PRODUCER_USAGE_CAMERA);
        break;
    default:
        CLOGE("Invalid stream_type %d", stream->stream_type);
        break;
    }

    ret = m_streamManager->createStream(id, stream, &newStream);
    if (ret != NO_ERROR) {
        CLOGE("createStream is NULL id(%d)", id);
        ret = BAD_VALUE;
        goto func_err;
    }

    newStream->setRegisterStream(registerStream);
    newStream->setRegisterBuffer(registerBuffer);
    newStream->setFormat(actualFormat, pixelSize);
    newStream->setPlaneCount(planeCount);
    newStream->setOutputPortId(outputPortId);
    newStream->setRequestBuffer(requestBuffer);
    if (phyCamID >= 0) {
       newStream->setPhysCameraID(phyCamID);
    }

func_err:
    CLOGD("Out");

    return ret;

}

status_t ExynosCamera::m_destroyPreviewFrameFactory() {
    status_t ret = NO_ERROR;

    for (int i = 0; i < MAX_NUM_SENSORS; i++) {
        if (m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i] != NULL) {
            if (m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i]->isCreated() == true) {
                ret = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i]->destroy();
                if (ret < 0) {
                    CLOGE("m_frameFactory[%d] destroy fail", FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i);
                }
            }
            SAFE_DELETE(m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i]);

            CLOGD("m_frameFactory[%d] destroyed", FRAME_FACTORY_TYPE_CAPTURE_PREVIEW + i);
        }
    }

    return ret;
}


status_t ExynosCamera::configureStreams(camera3_stream_configuration *stream_list)
{
    status_t ret = NO_ERROR;
    EXYNOS_STREAM::STATE registerStreamState = EXYNOS_STREAM::HAL_STREAM_STS_INIT;
    EXYNOS_STREAM::STATE registerbufferState = EXYNOS_STREAM::HAL_STREAM_STS_INIT;
    int width = 0, height = 0;
    int hwWidth = 0, hwHeight = 0;
    int streamPlaneCount = 0;
    int streamPixelFormat = 0;
    camera_pixel_size pixelSize = CAMERA_PIXEL_SIZE_8BIT;
    int outputPortId = 0;
    bool needMmap = false;
    bool existVideoMeta = false;
    bool videoStreamExistChanged = false;
#ifdef USE_DUAL_CAMERA
    bool isDualMode = m_configurations->getMode(CONFIGURATION_DUAL_MODE);
    enum DUAL_PREVIEW_MODE dualPreviewMode = DUAL_PREVIEW_MODE_MAX;
#endif
    bool isMainPhysicalStream = false, isSlavePhysicalStream = false;
    cameraId_Info physicalCamIdInfo;
    int physIdList[MAX_NUM_SENSORS] = {-1, };

    getLogicalCamPhysIDs(m_camIdInfo.serviceCameraId, physIdList);

    m_flushLockWait = false;

    CLOGD("In");
    getLogEnableProperty();
    m_flagFirstPreviewTimerOn = false;

#ifdef FPS_CHECK
    for (int i = 0; i < sizeof(m_debugFpsCount); i++)
        m_debugFpsCount[i] = 0;
#endif

    if (m_flagFirstPreviewTimerOn == false) {
        m_firstPreviewTimer.start();
        m_flagFirstPreviewTimerOn = true;

        CLOGD("m_firstPreviewTimer start");
    }
    /* sanity check for stream_list */
    if (stream_list == NULL) {
        CLOGE("NULL stream configuration");
        return BAD_VALUE;
    }

    if (stream_list->streams == NULL) {
        CLOGE("NULL stream list");
        return BAD_VALUE;
    }

    if (stream_list->num_streams < 1) {
        CLOGE("Bad number of streams requested: %d",
             stream_list->num_streams);
        return BAD_VALUE;
    }

    /* HACK :: restart frame factory */
    if (m_getState() > EXYNOS_CAMERA_STATE_INITIALIZE) {
        CLOGI("restart frame factory. state(%d)", m_getState());

        /* In case of preview with Recording, enter this block even if not restart */
        m_recordingEnabled = false;
        m_prevStreamBit = 0;

        if (m_framefactoryCreateThread->isRunning() == true)
            m_framefactoryCreateThread->join();

        if (m_dualFramefactoryCreateThread->isRunning() == true)
            m_dualFramefactoryCreateThread->join();

        if (m_getState() != EXYNOS_CAMERA_STATE_CONFIGURED) {
            ret = flush();
            if (ret != NO_ERROR) {
                CLOGE("Failed to flush. ret %d", ret);
                return ret;
            }
        }

        /* clear frame lists */
        m_removeInternalFrames(&m_processList, &m_processLock);

        if (isOfflineCaptureRunning() != true) {
            ret = m_clearList(&m_captureProcessList, &m_captureProcessLock);
            if (ret != NO_ERROR) {
                CLOGE("Failed to clearList(m_captureProcessList). ret %d", ret);
                /* continue */
            }

            for (int i = 0; i < MAX_NUM_SENSORS; i++) {
                if (m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i] != NULL) {
                    if (m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i]->isCreated() == true) {
                        ret = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i]->destroy();
                        if (ret < 0)
                            CLOGE("m_frameFactory[%d] destroy fail", FRAME_FACTORY_TYPE_REPROCESSING + i);
                    }
                    SAFE_DELETE(m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i]);

                    CLOGD("m_frameFactory[%d] destroyed", FRAME_FACTORY_TYPE_REPROCESSING + i);
                }
            }

            /* restart frame manager */
            m_frameMgr->stop();
            m_frameMgr->deleteAllFrame();
            m_frameMgr->start();

            m_setBuffersThread->join();
            m_startPictureBufferThread->join();

            m_bufferSupplier->deinit();

        } else {
            for (int i = 0; i < MAX_NUM_SENSORS; i++) {
                m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING + i] = NULL;
            }
        }
    }

#ifdef USES_OFFLINE_CAPTURE
    m_cameraSessionId = m_offlineCapture->configureCameraSession(stream_list->session_parameters);

    m_rearrangeResources(m_cameraSessionId);
#endif

    m_reInit();

    ret = m_configurations->reInit();
    if (ret != NO_ERROR) {
        CLOGE("Failed to reInit Configurations. ret %d", ret);
        return BAD_VALUE;
    }

    m_initLockFrameHoldCount();

    for (int i = 0; i < m_camIdInfo.numOfSensors; i++) {
        if (m_parameters[m_camIdInfo.cameraId[i]] != NULL) {
            ret = m_parameters[m_camIdInfo.cameraId[i]]->reInit();
            if (ret != NO_ERROR) {
                CLOGE("initMetadata() failed!! status(%d)", ret);
                return BAD_VALUE;
            }
        }
    }

#ifdef USE_DUAL_CAMERA
    if (isDualMode == true) {
        m_earlyOperationSensor = m_dualTransitionOperationSensor = DUAL_OPERATION_SENSOR_MAX;
        m_earlyDualOperationMode = DUAL_OPERATION_MODE_NONE;
        m_earlyMasterCameraId = m_cameraId;
        m_earlyDualRequestKey = -1;

        m_dualTransitionCount = 0;
        m_dualCaptureLockCount = 0;
        m_dualMultiCaptureLockflag = false;
        m_earlyTriggerRequestKey = 0;

#ifdef DUAL_DYNAMIC_HW_SYNC
        switch (m_scenario) {
        case SCENARIO_DUAL_REAR_PORTRAIT:
        case SCENARIO_DUAL_FRONT_PORTRAIT:
            m_configurations->setDualHwSyncOn(false);
            break;
        default:
            m_configurations->setDualHwSyncOn(false);
            break;
        }
        CLOGD("dualHwSyncOn(%d)", m_configurations->getDualHwSyncOn());
#endif
    }
#endif

    m_requestMgr->clearFrameFactory();
    m_requestMgr->clearStreamSequencer();

#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    m_configurations->setMode(CONFIGURATION_DYNAMIC_REMOSAIC_BUFFER_ALLOC_MODE,
                              DYNAMIC_REMOSAIC_BUFFER_ALLOC_ON_ALL);
#endif

    /* get SessionKeys Meta */
    m_metadataConverter->setSessionParams(stream_list->session_parameters);

    ret = m_setStreamInfo(stream_list);
    if (ret) {
        CLOGE("setStreams() failed!!");
        return ret;
    }

#ifdef USES_SW_VDIS
    if (m_exCameraSolutionSWVdis != NULL) {
        m_exCameraSolutionSWVdis->checkMode();
    }
#endif

    /* The setting is effective if USE_BDS_OFF is enabled */
    videoStreamExistChanged = m_parameters[m_cameraId]->setVideoStreamExistStatus(m_videoStreamExist);
    if (videoStreamExistChanged == true && m_parameters[m_cameraId]->check3aaBDSOff() == true) {
        CLOGD("videoStreamExist has been changed[%d -> %d]", !m_videoStreamExist, m_videoStreamExist);
        this->m_destroyPreviewFrameFactory();
    }

    ret = m_constructFrameFactory();
    if (ret != NO_ERROR) {
        CLOGE("Failed to constructFrameFactory. ret %d", ret);
        return ret;
    }

    if (m_frameFactoryQ->getSizeOfProcessQ() > 0) {
        m_framefactoryCreateThread->run();
    }

    ret = m_setupFrameFactoryToRequest();
    if (ret != NO_ERROR) {
        CLOGE("Failed to setupFrameFactoryToRequest. ret %d", ret);
        return ret;
    }

    /* clear previous settings */
    ret = m_requestMgr->clearPrevRequest();
    if (ret) {
        CLOGE("clearPrevRequest() failed!!");
        return ret;
    }

    m_requestMgr->resetResultRenew();

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, STREAM_BUFFER_ALLOC_START, 0);


#ifdef USE_DUAL_CAMERA
    /* Get DualPreviewMode after m_setStreamInfo() */
    dualPreviewMode = m_configurations->getDualPreviewMode();
#endif

    m_checkUseOnePort();
    m_checkVideoStreamPriority();

    ret = m_setExtraStreamInfo(stream_list);
    if (ret) {
        CLOGE("m_setExtraStreamInfo() failed!!");
        return ret;
    }

    ret = m_setupStreamInfoToRequestManager();
    if (ret != NO_ERROR) {
        CLOGE("Failed to m_setupStreamInfoToRequestManager. ret %d", ret);
        return ret;
    }

    int onePortId = -1, secondPortId = -1;
    m_getOnePortId(NULL, NULL, &onePortId, &secondPortId);
    m_configurations->setOnePortId(onePortId);
    m_configurations->setSecondPortId(secondPortId);
    CLOGD("set onePortId(%d), secondPortId(%d)", onePortId, secondPortId);

    /* Create service buffer manager at each stream */
    for (size_t i = 0; i < stream_list->num_streams; i++) {
        buffer_manager_tag_t bufTag;
        buffer_manager_configuration_t bufConfig;
        registerStreamState = EXYNOS_STREAM::HAL_STREAM_STS_INIT;
        registerbufferState = EXYNOS_STREAM::HAL_STREAM_STS_INIT;
        int startIndex = 0;
        int maxBufferCount = 0;
        int id = -1;
        int32_t physCamID = -1;
        camera_pixel_comp_info pixelCompInfo = NO_COMP;

        camera3_stream_t *newStream = stream_list->streams[i];
        ExynosCameraStream *privStreamInfo = static_cast<ExynosCameraStream*>(newStream->priv);
        physCamID = privStreamInfo->getPhysCameraID();
        privStreamInfo->getID(&id);
        width = newStream->width;
        height = newStream->height;
        bufConfig.needMmap = (newStream->usage & (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN));

        CLOGI("list_index %zu streamId %d", i, id);
        CLOGD("stream_type %d", newStream->stream_type);
        CLOGD("size %dx%d", width, height);
        CLOGD("format %x", newStream->format);
        CLOGD("usage %x", newStream->usage);
        CLOGD("max_buffers %d", newStream->max_buffers);
        CLOGD("needMmap %d", bufConfig.needMmap);
        CLOGD("physCamID %d", physCamID);

        privStreamInfo->getRegisterStream(&registerStreamState);
        privStreamInfo->getRegisterBuffer(&registerbufferState);
        privStreamInfo->getPlaneCount(&streamPlaneCount);
        privStreamInfo->getFormat(&streamPixelFormat, &pixelSize);

        if (registerStreamState == EXYNOS_STREAM::HAL_STREAM_STS_INVALID) {
            CLOGE("Invalid stream index %zu id %d", i, id);
            return BAD_VALUE;
        }
        if (registerbufferState != EXYNOS_STREAM::HAL_STREAM_STS_UNREGISTERED) {
            CLOGE("privStreamInfo->registerBuffer state error!!");
            return BAD_VALUE;
        }

        CLOGD("registerStream %d registerbuffer %d", registerStreamState, registerbufferState);

        if ((registerStreamState == EXYNOS_STREAM::HAL_STREAM_STS_VALID) &&
            (registerbufferState == EXYNOS_STREAM::HAL_STREAM_STS_UNREGISTERED)) {
            switch (id % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_RAW:
                m_parameters[m_cameraId]->setUseSensorPackedBayer(false);

                /* set startIndex as the next internal buffer index */
                maxBufferCount = m_exynosconfig->current->bufInfo.num_request_raw_buffers;

                if (m_parameters[m_cameraId]->isUse3aaDNG() == true) {
                    bufTag.pipeId[0] = PIPE_3AG_REPROCESSING;
                    maxBufferCount = m_exynosconfig->current->bufInfo.num_picture_buffers;
                } else {
                    bufTag.pipeId[0] = PIPE_3AC_REPROCESSING;
                }
//                bufTag.pipeId[1] = PIPE_PLUGIN_PRE1_REPROCESSING;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(RAW)");
                ret = m_bufferSupplier->createBufferManager("RAW_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create RAW_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = width * height * 2;
                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc RAW_STREAM_BUF. ret %d", ret);
                    return ret;
                }

#if defined(USE_RAW_REVERSE_PROCESSING) && defined(USE_SW_RAW_REVERSE_PROCESSING)
                if (m_parameters[m_cameraId]->isUseRawReverseReprocessing() == true) {
                    bufTag.pipeId[0] = PIPE_3AC_REPROCESSING;
                    bufTag.pipeId[1] = PIPE_PLUGIN_PRE1_REPROCESSING;
                    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

                    CLOGD("Create buffer manager(RAW_INTERNAL)");
                    ret = m_bufferSupplier->createBufferManager("RAW_INTERNAL_BUF", m_ionAllocator, bufTag);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to create RAW_INTERNAL_STREAM_BUF. ret %d", ret);
                        return ret;
                    }

                    /* same with raw buffer information except for below setting */
                    bufConfig.startBufIndex = 0;
#ifdef CAMERA_PACKED_BAYER_ENABLE
                    bufConfig.bytesPerLine[0] = getBayerLineSize(width, m_parameters[m_cameraId]->getBayerFormat(PIPE_3AC_REPROCESSING));
                    bufConfig.size[0] = bufConfig.bytesPerLine[0] * height;
#endif
                    bufConfig.reqBufCount = 2;
                    bufConfig.allowedMaxBufCount = 2;
                    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;

                    CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                            streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                    ret = m_allocBuffers(bufTag, bufConfig);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to alloc RAW_INTERNAL_BUF. ret %d", ret);
                        return ret;
                    }
                }
#endif

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
#ifdef SUPPORT_VENDOR_DYNAMIC_SENSORMODE_BY_STREAM_SIZE
                updateVendorSensorConfiguration(m_configurations, m_cameraId, width, height);
#endif
                break;
            case HAL_STREAM_ID_ZSL_OUTPUT:
                /* set startIndex as the next internal buffer index */
                startIndex = m_configurations->maxNumOfSensorBuffer();
                maxBufferCount = m_exynosconfig->current->bufInfo.num_bayer_buffers - startIndex;

                if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true) {
                    bufTag.pipeId[0] = PIPE_VC0;
                } else {
                    bufTag.pipeId[0] = PIPE_3AC;
                }

                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(ZSL_OUT)");
                ret = m_bufferSupplier->createBufferManager("ZSL_OUT_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create ZSL_OUT_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = width * height * 2;
                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc ZSL_OUT_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_ZSL_INPUT:
                /* Check support for ZSL input */
                if(m_parameters[m_cameraId]->isSupportZSLInput() == false) {
                    CLOGE("ZSL input is not supported, but streamID [%d] is specified.", id);
                    return INVALID_OPERATION;
                }

                /* Set startIndex as the next internal buffer index */
                startIndex = m_configurations->maxNumOfSensorBuffer();
                maxBufferCount = m_exynosconfig->current->bufInfo.num_bayer_buffers - startIndex;

                if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true) {
                    bufTag.pipeId[0] = PIPE_3AA_REPROCESSING;
                } else {
                    bufTag.pipeId[0] = PIPE_ISP_REPROCESSING;
                }

                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(ZSL_INPUT)");
                ret =  m_bufferSupplier->createBufferManager("ZSL_INPUT_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create ZSL_INPUT_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = width * height * 2;
                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc ZSL_INPUT_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_YUV_INPUT:
                /* Check support for ZSL input */
                if(m_parameters[m_cameraId]->isSupportZSLInput() == false) {
                    CLOGE("ZSL input is not supported, but streamID [%d] is specified.", id);
                    return INVALID_OPERATION;
                }

                ret = m_parameters[m_cameraId]->setSize(HW_INFO_HW_YUV_INPUT_SIZE, width, height, 0);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setSize for HW_INFO_HW_YUV_INPUT_SIZE stream. size %dx%d outputPortId %d",
                             width, height, outputPortId);
                }

                /* Set startIndex as the next internal buffer index */
                startIndex = m_configurations->maxNumOfSensorBuffer();
                maxBufferCount = m_exynosconfig->current->bufInfo.num_bayer_buffers - startIndex;

                if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true) {
                    bufTag.pipeId[0] = PIPE_3AA_REPROCESSING;
                } else {
                    bufTag.pipeId[0] = PIPE_ISP_REPROCESSING;
                }
#ifdef USE_SLSI_PLUGIN
                bufTag.pipeId[1] = PIPE_PLUGIN_PRE1_REPROCESSING;
#endif

                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(YUV_INPUT)");
                ret =  m_bufferSupplier->createBufferManager("YUV_INPUT_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create ZSL_INPUT_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = (width * height * 3) / 2;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc ZSL_INPUT_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_PREVIEW:
                ret = privStreamInfo->getOutputPortId(&outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getOutputPortId for PREVIEW stream");
                    return ret;
                }

                m_parameters[m_cameraId]->setPreviewPortId(outputPortId);

                ret = m_parameters[m_cameraId]->checkYuvSize(width, height, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvSize for PREVIEW stream. size %dx%d outputPortId %d",
                             width, height, outputPortId);
                    return ret;
                }

                hwWidth = width;
                hwHeight = height;

                ret = m_parameters[m_cameraId]->checkHwYuvSize(hwWidth, hwHeight, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setHwYuvSize for PREVIEW stream. size %dx%d outputPortId %d",
                             hwWidth, hwHeight, outputPortId);
                    return ret;
                }

                ret = m_configurations->checkYuvFormat(streamPixelFormat, pixelSize, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvFormat for PREVIEW stream. format %x outputPortId %d",
                             streamPixelFormat, outputPortId);
                    return ret;
                }

                {
                    maxBufferCount = m_exynosconfig->current->bufInfo.num_preview_buffers;
                }

                ret = m_configurations->setYuvBufferCount(maxBufferCount, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setYuvBufferCount for PREVIEW stream. maxBufferCount %d outputPortId %d",
                             maxBufferCount, outputPortId);
                    return ret;
                }

#ifdef USE_DUAL_CAMERA
                if (isDualMode == true) {
                    for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                        if (m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
                            m_parameters[m_camIdInfo.cameraId[slave_idx]]->setPreviewPortId(outputPortId);

                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkYuvSize(width, height, outputPortId);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to checkYuvSize for PREVIEW stream. size %dx%d outputPortId %d slave_idx %d",
                                        width, height, outputPortId, slave_idx);
                                return ret;
                            }

                            hwWidth = width;
                            hwHeight = height;

                            int mainSensorMaxW = 0, mainSensorMaxH = 0;
                            int subSensorMaxW = 0, subSensorMaxH = 0;
                            m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                            m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);
                            bool isSameSensorSize = (mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH) ? true : false;

                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkHwYuvSize(hwWidth, hwHeight, outputPortId, isSameSensorSize);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to setHwYuvSize for PREVIEW stream. size %dx%d outputPortId %d slave_idx %d",
                                         hwWidth, hwHeight, outputPortId, slave_idx);
                                return ret;
                            }
                        }
                    }
                }
#endif

                needMmap = bufConfig.needMmap;

                if (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true) {
                    existVideoMeta = true;
                }

                {
#ifdef USE_DUAL_CAMERA
                    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
                        && m_configurations->getDynamicMode(DYNAMIC_DUAL_FORCE_SWITCHING) == false) {
                        if (m_flagVideoStreamPriority == true) {
                            bufTag.pipeId[0] = PIPE_GSC;
                        } else {
                            bufTag.pipeId[0] = PIPE_FUSION;
                        }
                    } else
#endif
#ifdef USES_COMBINE_PLUGIN
                    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                        bufTag.pipeId[0] = PIPE_PLUGIN1;
                        bufTag.pipeId[1] = PIPE_PLUGIN_PREVIEW;
                    } else
#endif
                    {
                        bufTag.pipeId[0] = (outputPortId % ExynosCameraParameters::YUV_MAX)
                                           + PIPE_MCSC0;
                    }
                }
#ifdef USES_SW_VDIS
#ifdef USE_SW_VDIS_WITH_PREVIEW
                if (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE) == true) {
                    if (m_exCameraSolutionSWVdis != NULL) {
                        bufTag.pipeId[1] = m_exCameraSolutionSWVdis->getPipeId()+1;
                    }
                }
#endif
#endif

                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(PREVIEW)");
                ret = m_bufferSupplier->createBufferManager("PREVIEW_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create PREVIEW_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
#ifdef SUPPORT_COMPRESSION_PREVIEW_STREAM
                if (m_configurations->getMode(CONFIGURATION_COMPRESSION_PREVIEW_STREAM)) {
#ifdef SBWC_COMP_TYPE
                    pixelCompInfo = SBWC_COMP_TYPE;
#else
                    pixelCompInfo = COMP;
#endif
                }
#endif
                getYuvPlaneSize(HAL_PIXEL_FORMAT_2_V4L2_PIX(streamPixelFormat), bufConfig.size, width, height, pixelSize, pixelCompInfo);

                if (existVideoMeta == true) {
                    bufConfig.size[streamPlaneCount - 1] = EXYNOS_CAMERA_VIDEO_META_PLANE_SIZE;
                }
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.needMmap = needMmap;
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, planeSize[1] = %d, planeSize[2] = %d,\
                        bytesPerLine[0] = %d, outputPortId = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.size[1], bufConfig.size[2],
                        bufConfig.bytesPerLine[0], outputPortId);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc PREVIEW_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_VIDEO:
                CLOGD("setRecordingHint");

                ret = privStreamInfo->getOutputPortId(&outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getOutputPortId for VIDEO stream");
                    return ret;
                }

                m_parameters[m_cameraId]->setRecordingPortId(outputPortId);
#ifdef USES_COMBINE_PLUGIN
                if ((m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0)) {
                    m_parameters[m_cameraId]->setAlternativePreviewPortId(outputPortId);
                }
#endif
#ifdef USE_DUAL_CAMERA
                if (m_scenario == SCENARIO_DUAL_REAR_ZOOM
                    && m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
                    m_parameters[m_cameraId]->setAlternativePreviewPortId(outputPortId);
                }
#endif

                ret = m_parameters[m_cameraId]->checkYuvSize(width, height, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvSize for VIDEO stream. size %dx%d outputPortId %d",
                             width, height, outputPortId);
                    return ret;
                }

                hwWidth = width;
                hwHeight = height;

                ret = m_parameters[m_cameraId]->checkHwYuvSize(hwWidth, hwHeight, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setHwYuvSize for VIDEO stream. size %dx%d outputPortId %d",
                             hwWidth, hwHeight, outputPortId);
                    return ret;
                }

                ret = m_configurations->checkYuvFormat(streamPixelFormat, pixelSize, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvFormat for VIDEO stream. format %x outputPortId %d",
                             streamPixelFormat, outputPortId);
                    return ret;
                }

#ifdef USE_DUAL_CAMERA
                if (m_parameters[m_cameraId]->getAlternativePreviewPortId() >= 0) {
                    startIndex = DUAL_NUM_REQUEST_VIDEO_BUFFER;
                    maxBufferCount = m_exynosconfig->current->bufInfo.num_recording_buffers - DUAL_NUM_REQUEST_VIDEO_BUFFER;
                    ret = m_configurations->setYuvBufferCount(maxBufferCount + DUAL_NUM_REQUEST_VIDEO_BUFFER, outputPortId);
                } else
#endif /* USE_DUAL_CAMERA */
                {
                    startIndex = 0;
                    maxBufferCount = m_exynosconfig->current->bufInfo.num_recording_buffers;
                    ret = m_configurations->setYuvBufferCount(maxBufferCount, outputPortId);
                }

                if (ret != NO_ERROR) {
                    CLOGE("Failed to setYuvBufferCount for VIDEO stream. maxBufferCount %d outputPortId %d",
                             maxBufferCount, outputPortId);
                    return ret;
                }

#ifdef USE_DUAL_CAMERA
                if (isDualMode == true) {
                    for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                        if (m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
                            m_parameters[m_camIdInfo.cameraId[slave_idx]]->setRecordingPortId(outputPortId);

                            if (m_scenario == SCENARIO_DUAL_REAR_ZOOM
                                && m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
                                m_parameters[m_camIdInfo.cameraId[slave_idx]]->setAlternativePreviewPortId(outputPortId);
                            }

                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkYuvSize(width, height, outputPortId);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to checkYuvSize for VIDEO stream. size %dx%d outputPortId %d",
                                         width, height, outputPortId);
                                return ret;
                            }

                            int mainSensorMaxW = 0, mainSensorMaxH = 0;
                            int subSensorMaxW = 0, subSensorMaxH = 0;
                            m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                            m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);
                            bool isSameSensorSize = (mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH) ? true : false;

                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkHwYuvSize(hwWidth, hwHeight, outputPortId, isSameSensorSize);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to setHwYuvSize for VIDEO stream. size %dx%d outputPortId %d",
                                         hwWidth, hwHeight, outputPortId);
                                return ret;
                            }
                        }
                    }
                }
#endif

                if ((m_configurations->getMode(CONFIGURATION_YSUM_RECORDING_MODE) == true)
                        || (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true)) {
                    existVideoMeta = true;
                }

                if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_GDC) == true) {
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
                    bufTag.pipeId[0] = PIPE_GDC;
#else
                    if (m_flagUseOnePort == false)
                        bufTag.pipeId[0] = PIPE_GDC;
#endif
                } else {
                    {
#ifdef USE_DUAL_CAMERA
                        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                            if (m_flagVideoStreamPriority == true) {
                                int alternativePreviewPortId = m_parameters[m_cameraId]->getAlternativePreviewPortId();

                                bufTag.pipeId[0] = PIPE_FUSION;

                                if (alternativePreviewPortId >= 0) {
                                    bufTag.pipeId[1] = (alternativePreviewPortId % ExynosCameraParameters::YUV_MAX)
                                                        + PIPE_MCSC0;
                                }
                            } else {
                                bufTag.pipeId[0] = PIPE_GSC;
                            }
                        } else
#endif
                        {
                            bufTag.pipeId[0] = (outputPortId % ExynosCameraParameters::YUV_MAX)
                                               + PIPE_MCSC0;
                        }
                    }
                }
#ifdef USES_SW_VDIS
                if (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE) == true) {
                    if (m_exCameraSolutionSWVdis != NULL) {
                        bufTag.pipeId[1] = m_exCameraSolutionSWVdis->getPipeId();
                    }
                } else
#endif
                {
#ifdef USES_COMBINE_PLUGIN
                    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                        bufTag.pipeId[1] = PIPE_PLUGIN_RECORDING;
                    }
#endif
                }

                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(VIDEO)");
                ret =  m_bufferSupplier->createBufferManager("VIDEO_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create VIDEO_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
#ifdef SUPPORT_COMPRESSION_VIDEO_STREAM
                if (m_configurations->getMode(CONFIGURATION_COMPRESSION_VIDEO_STREAM)) {
#ifdef SBWC_COMP_TYPE
                    pixelCompInfo = SBWC_COMP_TYPE;
#else
                    pixelCompInfo = COMP;
#endif
                }
#endif
                getYuvPlaneSize(HAL_PIXEL_FORMAT_2_V4L2_PIX(streamPixelFormat), bufConfig.size, width, height, pixelSize, pixelCompInfo);

                if (existVideoMeta == true) {
                    bufConfig.size[streamPlaneCount - 1] = EXYNOS_CAMERA_VIDEO_META_PLANE_SIZE;
                 }

                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;
#ifdef USES_SW_VDIS
                bufConfig.needMmap = needMmap;
#endif

                CLOGD("planeCount = %d+1, planeSize[0] = %d, planeSize[1] = %d, planeSize[2] = %d, \
                        bytesPerLine[0] = %d, outputPortId = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.size[1], bufConfig.size[2],
                        bufConfig.bytesPerLine[0], outputPortId);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc VIDEO_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_PREVIEW_VIDEO:
//                m_parameters[m_cameraId]->setVideoSize(width, height);
//                m_parameters[m_cameraId]->setRecordingHint(true);
                CLOGD("setRecordingHint");

                ret = privStreamInfo->getOutputPortId(&outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getOutputPortId for PREVIEW_VIDEO stream");
                    return ret;
                }

                m_parameters[m_cameraId]->setRecordingPortId(outputPortId);
                m_parameters[m_cameraId]->setPreviewPortId(outputPortId);

                ret = m_parameters[m_cameraId]->checkYuvSize(width, height, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvSize for PREVIEW_VIDEO stream. size %dx%d outputPortId %d",
                            width, height, outputPortId);
                    return ret;
                }

                hwWidth = width;
                hwHeight = height;

                ret = m_parameters[m_cameraId]->checkHwYuvSize(hwWidth, hwHeight, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkHwYuvSize for PREVIEW_VIDEO stream. size %dx%d outputPortId %d",
                            hwWidth, hwHeight, outputPortId);
                    return ret;
                }

                ret = m_configurations->checkYuvFormat(streamPixelFormat, pixelSize, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvFormat for PREVIEW_VIDEO stream. format %x outputPortId %d",
                            streamPixelFormat, outputPortId);
                    return ret;
                }

                maxBufferCount = m_exynosconfig->current->bufInfo.num_recording_buffers;
                ret = m_configurations->setYuvBufferCount(maxBufferCount, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setYuvBufferCount for PREVIEW_VIDEO stream. maxBufferCount %d outputPortId %d",
                            maxBufferCount, outputPortId);
                    return ret;
                }

#ifdef USES_COMBINE_PLUGIN
                if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                    bufTag.pipeId[0] = PIPE_PLUGIN1;
                } else
#endif
                {
                    bufTag.pipeId[0] = (outputPortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                }
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(PREVIEW_VIDEO)");
                ret =  m_bufferSupplier->createBufferManager("PREVIEW_VIDEO_STREAM_BUF", m_ionAllocator, bufTag, newStream);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create PREVIEW_VIDEO_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                if (m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true) {
                    existVideoMeta = true;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                getYuvPlaneSize(HAL_PIXEL_FORMAT_2_V4L2_PIX(streamPixelFormat), bufConfig.size, width, height, pixelSize);

                if (existVideoMeta == true) {
                    bufConfig.size[streamPlaneCount - 1] = EXYNOS_CAMERA_VIDEO_META_PLANE_SIZE;
                }

                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, planeSize[1] = %d, \
                        bytesPerLine[0] = %d, outputPortId = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.size[1],
                        bufConfig.bytesPerLine[0], outputPortId);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc PREVIEW_VIDEO_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);

                break;
            case HAL_STREAM_ID_JPEG:
                ret = m_parameters[m_cameraId]->checkPictureSize(width, height);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkPictureSize for JPEG stream. size %dx%d",
                             width, height);
                    return ret;
                }

                for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                    if (m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
                        int mainSensorMaxW = 0, mainSensorMaxH = 0;
                        int subSensorMaxW = 0, subSensorMaxH = 0;
                        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                        m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);

                        bool isSameSensorSize = (mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH) ? true : false;
                        ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkPictureSize(width, height, isSameSensorSize);
                        if (ret != NO_ERROR) {
                            CLOGE("Failed to setHwYuvSize for JPEG stream. size %dx%d outputPortId %d slave_idx %d",
                                     hwWidth, hwHeight, outputPortId, slave_idx);
                            return ret;
                        }
                    }
                }
                maxBufferCount = m_exynosconfig->current->bufInfo.num_picture_buffers;

                bufTag.pipeId[0] = PIPE_JPEG;
                bufTag.pipeId[1] = PIPE_JPEG0_REPROCESSING;
                bufTag.pipeId[2] = PIPE_HWFC_JPEG_DST_REPROCESSING;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(JPEG)");
                ret = m_bufferSupplier->createBufferManager("JPEG_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create JPEG_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;

                {
                    bufConfig.size[0] = width * height * getJPEGMaxBPPSize();
                }

                {
                    bufConfig.reqBufCount = maxBufferCount;
                    bufConfig.allowedMaxBufCount = maxBufferCount;
                }
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[1]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc JPEG_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);

#ifdef SUPPORT_VENDOR_DYNAMIC_SENSORMODE_BY_STREAM_SIZE
                updateVendorSensorConfiguration(m_configurations, m_cameraId, width, height);
#endif
                break;
            case HAL_STREAM_ID_CALLBACK:
                ret = privStreamInfo->getOutputPortId(&outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getOutputPortId for CALLBACK stream");
                    return ret;
                }

                m_parameters[m_cameraId]->setPreviewCbPortId(outputPortId);

                ret = m_parameters[m_cameraId]->checkYuvSize(width, height, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvSize for CALLBACK stream. size %dx%d outputPortId %d",
                             width, height, outputPortId);
                    return ret;
                }

                hwWidth = width;
                hwHeight = height;

                ret = m_parameters[m_cameraId]->checkHwYuvSize(hwWidth, hwHeight, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setHwYuvSize for CALLBACK stream. size %dx%d outputPortId %d",
                             hwWidth, hwHeight, outputPortId);
                    return ret;
                }

                ret = m_configurations->checkYuvFormat(streamPixelFormat, pixelSize, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvFormat for CALLBACK stream. format %x outputPortId %d",
                             streamPixelFormat, outputPortId);
                    return ret;
                }

                maxBufferCount = m_exynosconfig->current->bufInfo.num_preview_cb_buffers;
                ret = m_configurations->setYuvBufferCount(maxBufferCount, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setYuvBufferCount for CALLBACK stream. maxBufferCount %d outputPortId %d",
                             maxBufferCount, outputPortId);
                    return ret;
                }

#ifdef USE_DUAL_CAMERA
                for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                    if (isDualMode == true && m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
                        m_parameters[m_camIdInfo.cameraId[slave_idx]]->setPreviewCbPortId(outputPortId);

                        ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkYuvSize(width, height, outputPortId);
                        if (ret != NO_ERROR) {
                            CLOGE("Failed to checkYuvSize for CALLBACK stream. size %dx%d outputPortId %d",
                                    width, height, outputPortId);
                            return ret;
                        }

                        hwWidth = width;
                        hwHeight = height;

                        int mainSensorMaxW = 0, mainSensorMaxH = 0;
                        int subSensorMaxW = 0, subSensorMaxH = 0;
                        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                        m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);
                        bool isSameSensorSize = (mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH) ? true : false;

                        ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkHwYuvSize(hwWidth, hwHeight, outputPortId, isSameSensorSize);
                        if (ret != NO_ERROR) {
                            CLOGE("Failed to setHwYuvSize for CALLBACK stream. size %dx%d outputPortId %d",
                                     hwWidth, hwHeight, outputPortId);
                            return ret;
                        }
                    }
                }
#endif

                /* Set reprocessing stream YUV size for ZSL_INPUT */
                {
                    int stallOutputPortId = ExynosCameraParameters::YUV_STALL_0 + outputPortId;

                    ret = m_parameters[m_cameraId]->checkYuvSize(width, height, stallOutputPortId);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to checkYuvSize for CALLBACK_ZSL stream. size %dx%d outputPortId %d",
                                width, height, stallOutputPortId);
                        return ret;
                    }

                    hwWidth = width;
                    hwHeight = height;

                    ret = m_parameters[m_cameraId]->checkHwYuvSize(hwWidth, hwHeight, stallOutputPortId);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to setHwYuvSize for CALLBACK_ZSL stream. size %dx%d outputPortId %d",
                                 hwWidth, hwHeight, stallOutputPortId);
                        return ret;
                    }

                    ret = m_configurations->checkYuvFormat(streamPixelFormat, pixelSize, stallOutputPortId);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to checkYuvFormat for CALLBACK_ZSL stream. format %x outputPortId %d",
                                streamPixelFormat, stallOutputPortId);
                        return ret;
                    }

                    ret = m_configurations->setYuvBufferCount(maxBufferCount, stallOutputPortId);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to setYuvBufferCount for CALLBACK_ZSL stream. maxBufferCount %d outputPortId %d",
                                maxBufferCount, stallOutputPortId);
                        return ret;
                    }

#ifdef USE_DUAL_CAMERA
                    for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                        if (isDualMode == true && m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkYuvSize(width, height, stallOutputPortId);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to checkYuvSize for CALLBACK_ZSL stream. size %dx%d outputPortId %d",
                                        width, height, stallOutputPortId);
                                return ret;
                            }

                            int mainSensorMaxW = 0, mainSensorMaxH = 0;
                            int subSensorMaxW = 0, subSensorMaxH = 0;
                            m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                            m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);
                            bool isSameSensorSize = (mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH) ? true : false;

                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkHwYuvSize(hwWidth, hwHeight, stallOutputPortId, isSameSensorSize);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to setHwYuvSize for CALLBACK_ZSL stream. size %dx%d outputPortId %d",
                                        hwWidth, hwHeight, stallOutputPortId);
                                return ret;
                            }
                        }
                    }
#endif
                }

#ifdef USE_DUAL_CAMERA
                if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
                    bufTag.pipeId[0] = PIPE_FUSION_CLONE;
                    if (m_videoStreamExist == false) {
                        bufTag.pipeId[2] = PIPE_GSC_CLONE;
                    }
                } else
#endif
#ifdef SUPPORT_PREVIEW_PLUGIN_YUV_STREAM
                if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                    bufTag.pipeId[0] = PIPE_PLUGIN_CALLBACK;
                } else
#endif
                {
                    bufTag.pipeId[0] = (outputPortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                }
                bufTag.pipeId[1] = (outputPortId % ExynosCameraParameters::YUV_MAX)
                                   + PIPE_MCSC0_REPROCESSING;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(PREVIEW_CB)");
                ret = m_bufferSupplier->createBufferManager("PREVIEW_CB_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create PREVIEW_CB_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = (width * height * 3) / 2;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d, outputPortId = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.bytesPerLine[0], outputPortId);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc PREVIEW_CB_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_CALLBACK_STALL:
                isMainPhysicalStream = false;
                isSlavePhysicalStream = false;
                physicalCamIdInfo.serviceCameraId = physCamID;
                getCameraIdInfo(&physicalCamIdInfo);

                if (physCamID > -1 && physicalCamIdInfo.cameraId[MAIN_CAM] == m_cameraIds[MAIN_CAM]) {
                    isMainPhysicalStream = true;
                }

                if (physCamID > -1 && physicalCamIdInfo.cameraId[MAIN_CAM] == m_cameraIds[SUB_CAM]) {
                    isSlavePhysicalStream = true;
                }

                ret = privStreamInfo->getOutputPortId(&outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getOutputPortId for CALLBACK_STALL stream");
                    return ret;
                }

                if (isSlavePhysicalStream == false) {
                    ret = m_parameters[m_cameraId]->checkYuvSize(width, height, outputPortId, true);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to checkPictureSize for CALLBACK_STALL stream. size %dx%d",
                                width, height);
                        return ret;
                    }

                    hwWidth = width;
                    hwHeight = height;

                    ret = m_parameters[m_cameraId]->checkHwYuvSize(hwWidth, hwHeight, outputPortId);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to setHwYuvSize for CALLBACK_STALL stream. size %dx%d outputPortId %d",
                                 hwWidth, hwHeight, outputPortId);
                        return ret;
                    }
                }

                ret = m_configurations->checkYuvFormat(streamPixelFormat, pixelSize, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to checkYuvFormat for CALLBACK_STALL stream. format %x outputPortId %d",
                            streamPixelFormat, outputPortId);
                    return ret;
                }

                maxBufferCount = m_exynosconfig->current->bufInfo.num_picture_buffers;
                ret = m_configurations->setYuvBufferCount(maxBufferCount, outputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setYuvBufferCount for CALLBACK_STALL stream. maxBufferCount %d outputPortId %d",
                             maxBufferCount, outputPortId);
                    return ret;
                }

#ifdef USE_DUAL_CAMERA
                for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                    if ((isMainPhysicalStream == false) && m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
#ifdef SUPPORT_MULTI_STREAM_CAPTURE
                        int mainSensorMaxW = 0, mainSensorMaxH = 0;
                        int subSensorMaxW = 0, subSensorMaxH = 0;

                        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                        m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);

                        if ((isSlavePhysicalStream == false && mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH)
                            || (physicalCamIdInfo.cameraId[MAIN_CAM] == m_cameraIds[slave_idx]))
#endif
                        {
                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkYuvSize(width, height, outputPortId, true);
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to checkPictureSize for CALLBACK_STALL stream. size %dx%d",
                                        width, height);
                                return ret;
                            }

                            hwWidth = width;
                            hwHeight = height;

                            int mainSensorMaxW = 0, mainSensorMaxH = 0;
                            int subSensorMaxW = 0, subSensorMaxH = 0;
                            m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&mainSensorMaxW, (uint32_t *)&mainSensorMaxH);
                            m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&subSensorMaxW, (uint32_t *)&subSensorMaxH);
                            bool isSameSensorSize = (mainSensorMaxW == subSensorMaxW && mainSensorMaxH == subSensorMaxH) ? true : false;

                            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->checkHwYuvSize(hwWidth, hwHeight, outputPortId, isSameSensorSize);
                            if (ret != NO_ERROR) {
                                if (isSlavePhysicalStream == false) {
                                    CLOGE("Failed to setHwYuvSize for CALLBACK_STALL stream. size %dx%d outputPortId %d",
                                            hwWidth, hwHeight, outputPortId);
                                    return ret;
                                }
                            }

                            if (isSlavePhysicalStream == true) {
                                m_parameters[m_camIdInfo.cameraId[slave_idx]]->setSize(HW_INFO_HW_PICTURE_SIZE, width, height);
                                m_parameters[m_camIdInfo.cameraId[slave_idx]]->setSize(HW_INFO_HW_MAX_PICTURE_SIZE, width, height);
                            }
                        }
                    }
                }

#endif

                if (isSlavePhysicalStream == false) {
                    int index  = 0;
                    bufTag.pipeId[index++] = (outputPortId % ExynosCameraParameters::YUV_MAX)
                                       + PIPE_MCSC0_REPROCESSING;
                    bufTag.reserved.i32 = id;
                    bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                    CLOGD("Create buffer manager(CAPTURE_CB_STALL)");
                    ret = m_bufferSupplier->createBufferManager("CAPTURE_CB_STALL_STREAM_BUF",
                                                                m_ionAllocator, bufTag, newStream, streamPixelFormat);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to create CAPTURE_CB_STALL_STREAM_BUF. ret %d", ret);
                        return ret;
                    }

                } else {
                    bufTag.pipeId[0] = (outputPortId % ExynosCameraParameters::YUV_MAX)
                                       + PIPE_MCSC0_REPROCESSING + PIPE_CLONE_START;
                    bufTag.reserved.i32 = id;
                    bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                    CLOGD("Create buffer manager(CAPTURE_CB_STALL_CLONE)");
                    ret = m_bufferSupplier->createBufferManager("CAPTURE_CB_STALL_CLONE_STREAM_BUF",
                                                                m_ionAllocator, bufTag, newStream, streamPixelFormat);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to create CAPTURE_CB_STALL_CLONE_STREAM_BUF. ret %d", ret);
                        return ret;
                    }
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = (width * height * 3) / 2;
                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d, outputPortId = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.bytesPerLine[0], outputPortId);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc CAPTURE_CB_STALL_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
                /* Share CALLBACK_STALL port */
                maxBufferCount = m_exynosconfig->current->bufInfo.num_picture_buffers;

                bufTag.pipeId[0] = PIPE_GSC_REPROCESSING2;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(THUMBNAIL)");
                ret = m_bufferSupplier->createBufferManager("THUMBNAIL_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create THUMBNAIL_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount;
                bufConfig.size[0] = (width * height * 3) / 2;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = false;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount,
                        bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc THUMBNAIL_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
                m_parameters[m_cameraId]->setDepthMapSize(width, height);
                m_configurations->setMode(CONFIGURATION_DEPTH_MAP_MODE, true);

                maxBufferCount = NUM_DEPTHMAP_BUFFERS;

                bufTag.pipeId[0] = PIPE_VC1;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(DEPTH)");
                ret = m_bufferSupplier->createBufferManager("DEPTH_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create DEPTH_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = width * height * 2;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc RAW_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            case HAL_STREAM_ID_DEPTHMAP_STALL:
                ret = m_setDepthInternalBuffer();
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_setDepthInternalBuffer. ret %d", ret);
                    return ret;
                }

                /* Set startIndex as the next internal buffer index */
                startIndex = NUM_DEPTHMAP_BUFFERS;
                maxBufferCount = m_exynosconfig->current->bufInfo.num_bayer_buffers - startIndex;

                bufTag.pipeId[0] = PIPE_VC1;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(DEPTH_STALL)");
                ret = m_bufferSupplier->createBufferManager("DEPTH_STALL_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create DEPTH_STALL_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = width * height * 2;
                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc DEPTH_STALL_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
#endif
            case HAL_STREAM_ID_VISION:
                /* set startIndex as the next internal buffer index */
                // startIndex = m_configurations->maxNumOfSensorBuffer();
                maxBufferCount = RESERVED_NUM_SECURE_BUFFERS; //m_exynosconfig->current->bufInfo.num_bayer_buffers - startIndex;

                bufTag.pipeId[0] = PIPE_VC0;
                bufTag.reserved.i32 = id;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

                CLOGD("Create buffer manager(VISION)");
                ret = m_bufferSupplier->createBufferManager("VISION_STREAM_BUF", m_ionAllocator, bufTag, newStream, streamPixelFormat);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create VISION_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                bufConfig.planeCount = streamPlaneCount + 1;
                bufConfig.size[0] = width * height;
                bufConfig.startBufIndex = startIndex;
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.reservedMemoryCount = 0;

                CLOGD("planeCount = %d+1, planeSize[0] = %d, bytesPerLine[0] = %d",
                        streamPlaneCount, bufConfig.size[0], bufConfig.bytesPerLine[0]);

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc VISION_STREAM_BUF. ret %d", ret);
                    return ret;
                }

                privStreamInfo->setRegisterBuffer(EXYNOS_STREAM::HAL_STREAM_STS_REGISTERED);
                break;
            default:
                CLOGE("privStreamInfo->id is invalid !! id(%d)", id);
                ret = BAD_VALUE;
                break;
            }
        }
    }

    TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, STREAM_BUFFER_ALLOC_END, 0);

#ifdef USE_DUAL_CAMERA
    // Set Yuv Format of previewCbPort same as previewPort
    // To make FUSION_BUF have PIPE_MCSC0 and PIPE_MCSC1.
    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
        int previewoutputPortId = m_parameters[m_cameraId]->getPreviewPortId();
        int previewCboutputPortId = m_parameters[m_cameraId]->getPreviewCbPortId();

        if (previewoutputPortId > -1 && previewCboutputPortId > -1) {
            int format = m_configurations->getYuvFormat(previewoutputPortId);
            m_configurations->setYuvFormat(format, previewCboutputPortId);

            int previewWidth = 0, previewHeight = 0;
            m_parameters[m_cameraId]->getSize(HW_INFO_HW_YUV_SIZE,
                                            (uint32_t *)&previewWidth, (uint32_t *)&previewHeight, previewoutputPortId);
            if (ret != NO_ERROR) {
                CLOGE("Failed to getSize for HW_INFO_HW_YUV_SIZE. previewoutputPortId %d", previewoutputPortId);
                return ret;
            }

            ret = m_parameters[m_cameraId]->setSize(HW_INFO_HW_YUV_SIZE,
                                                    previewWidth, previewHeight, previewCboutputPortId);
            if (ret != NO_ERROR) {
                CLOGE("Failed to setSize for HW_INFO_HW_YUV_SIZE. size %dx%d previewCboutputPortId %d",
                         previewWidth, previewHeight, previewCboutputPortId);
                return ret;
            }

            for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
                m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_HW_YUV_SIZE,
                                                (uint32_t *)&previewWidth, (uint32_t *)&previewHeight, previewoutputPortId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getSize for HW_INFO_HW_YUV_SIZE. previewoutputPortId %d", previewoutputPortId);
                    return ret;
                }

                if (m_parameters[m_camIdInfo.cameraId[slave_idx]] != NULL) {
                    ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->setSize(HW_INFO_HW_YUV_SIZE,
                                                previewWidth, previewHeight, previewCboutputPortId);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to setSize for HW_INFO_HW_YUV_SIZE. size %dx%d previewCboutputPortId %d",
                                 previewWidth, previewHeight, previewCboutputPortId);
                        return ret;
                    }
                }
            }
        }
    }
#endif

#if defined(USE_DUAL_CAMERA) || \
    defined(USES_HIFI_LLS) || \
    defined(USES_COMBINE_PLUGIN)
    {
#ifdef USE_NV21JPEG_REMAIN_MCSCPORT
    int stall_port = -1;
    int yuvStreamIdMap[ExynosCameraParameters::YUV_OUTPUT_PORT_ID_MAX] = {0};
    m_streamManager->dumpYuvStreamId();
    m_streamManager->getYuvStreamIdList(yuvStreamIdMap);
    stall_port = getAvailableStallPort(ExynosCameraParameters::YUV_STALL_0, ExynosCameraParameters::YUV_STALL_MAX, yuvStreamIdMap);
    if (stall_port < 0) {
        CLOGE("Failed reserved stall port(%d)", stall_port);
    } else {
        CLOGD("reserved stall port(%d)", stall_port);
        m_configurations->setModeValue(CONFIGURATION_YUV_STALL_PORT, stall_port%ExynosCameraParameters::YUV_MAX);
    }
#else
#ifdef USE_RESERVED_NODE_PPJPEG_MCSCPORT
    m_configurations->setModeValue(CONFIGURATION_YUV_STALL_PORT, VIRTUAL_MCSC_PORT_6);
    CLOGD("reserved stall port(%d)", VIRTUAL_MCSC_PORT_6);
#endif
#endif
    }
#endif

    /*
     * NOTICE: Join is to avoid PIP scanario's problem.
     * The problem is that back camera's EOS was not finished, but front camera opened.
     * Two instance was actually different but driver accepts same instance.
     */
    if (m_framefactoryCreateThread->isRunning() == true) {
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FACTORY_CREATE_THREAD_JOIN_START, 0);
        m_framefactoryCreateThread->join();
        TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FACTORY_CREATE_THREAD_JOIN_END, 0);
        if (m_framefactoryCreateResult != NO_ERROR) {
            CLOGE("Failed to create framefactory");
            m_transitState(EXYNOS_CAMERA_STATE_ERROR);
            return NO_INIT;
        }
    }

    if (m_dualFrameFactoryQ->getSizeOfProcessQ() > 0) {
        m_dualFramefactoryCreateThread->run();
    }

    m_parameters[m_cameraId]->updateBinningScaleRatio();

    /* assume that Stall stream and jpeg stream have the same size */
    if (m_streamManager->findStream(HAL_STREAM_ID_JPEG) == false
        && m_streamManager->findStream(HAL_STREAM_ID_CALLBACK_STALL) == true) {
        int yuvStallPort = (m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK_STALL) % ExynosCameraParameters::YUV_MAX) + ExynosCameraParameters::YUV_MAX;

        m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&width, (uint32_t *)&height, yuvStallPort);

        ret = m_parameters[m_cameraId]->checkPictureSize(width, height);
        if (ret != NO_ERROR) {
            CLOGE("Failed to checkPictureSize for JPEG stream. size %dx%d",
                     width, height);
            return ret;
        }
    }

    if (m_scenario == SCENARIO_DUAL_REAR_ZOOM
#ifdef USE_DUAL_CAMERA
        && dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION
#endif
        ) {
#ifdef USE_DUAL_CAMERA
        int previewW = 0, previewH = 0;
        int previewOutputPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);

        m_parameters[m_cameraId]->getSize(HW_INFO_HW_YUV_SIZE, (uint32_t *)&previewW, (uint32_t *)&previewH, previewOutputPortId);

        /* Main */
        ret = m_parameters[m_cameraId]->adjustDualSolutionSize(previewW, previewH);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setDualSolutionRefSize. size %dx%d outputPortId %d",
                previewW, previewH, previewOutputPortId);
            return ret;
        }

        for (int slave_idx = 1; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
            m_parameters[m_camIdInfo.cameraId[slave_idx]]->getSize(HW_INFO_HW_YUV_SIZE, (uint32_t *)&previewW, (uint32_t *)&previewH, previewOutputPortId);

            /* Sub */
            ret = m_parameters[m_camIdInfo.cameraId[slave_idx]]->adjustDualSolutionSize(previewW, previewH);
            if (ret != NO_ERROR) {
                CLOGE("Failed to setDualSolutionRefSize. size %dx%d outputPortId %d",
                    previewW, previewH, previewOutputPortId);
                return ret;
            }
        }
#endif
    }

    /* Check the validation of stream configuration */
    ret = m_checkStreamInfo();
    if (ret != NO_ERROR) {
        CLOGE("checkStremaInfo() failed!!");
        return ret;
    }

    m_configurations->getSize(CONFIGURATION_MAX_YUV_SIZE, (uint32_t *)&width, (uint32_t *)&height);
    CLOGD("MaxYuvSize:%dx%d ratio:%d", width, height, m_parameters[m_cameraId]->getYuvSizeRatioId());

#ifdef USES_SW_VDIS
    if (m_exCameraSolutionSWVdis != NULL) {
        m_exCameraSolutionSWVdis->storeOriginalSize();
    }
#endif

#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_setupAdaptiveBuffer();
    if (ret != NO_ERROR) {
        CLOGE("m_setupAdaptiveBuffer() failed!!");
        return ret;
    }
#endif

    m_setBuffersThread->run(PRIORITY_DEFAULT);

    ret = m_checkDynamicBayerMode();
    if (ret != NO_ERROR) {
        CLOGE("checkDynamicBayerMode() failed!!");
        return ret;
    }

#ifdef USE_ALWAYS_FD_ON
    if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE)
        && m_configurations->getModeValue(CONFIGURATION_HIGHSPEED_MODE) <= CONFIG_MODE::HIGHSPEED_60) {
        m_configurations->setMode(CONFIGURATION_ALWAYS_FD_ON_MODE, true);
        CLOGD("support VIDEO FDAE scenario video(%d) configMode(%d)", m_configurations->getMode(CONFIGURATION_RECORDING_MODE), m_configurations->getModeValue(CONFIGURATION_HIGHSPEED_MODE));
    }
#endif

    m_initLockFrameHoldCount();

    ret = m_transitState(EXYNOS_CAMERA_STATE_CONFIGURED);
    if (ret != NO_ERROR) {
        CLOGE("Failed to transitState into CONFIGURED. ret %d", ret);
    }

    CLOGD("Out");
    return ret;
}

status_t ExynosCamera::m_updateTimestamp(ExynosCameraRequestSP_sprt_t request,
                                            ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer *timestampBuffer)
{
    struct camera2_shot_ext *shot_ext = NULL;
    status_t ret = NO_ERROR;

    /* handle meta data */
    shot_ext = (struct camera2_shot_ext *) timestampBuffer->addr[timestampBuffer->getMetaPlaneIndex()];
    if (shot_ext == NULL) {
        CLOGE("shot_ext is NULL. framecount %d buffer %d",
                 frame->getFrameCount(), timestampBuffer->index);
        return INVALID_OPERATION;
    }

#ifdef CORRECT_TIMESTAMP_FOR_SENSORFUSION
    if (frame->getAdjustedTimestampFlag() == true ||
        (request != NULL && request->getSensorTimestamp() != 0)) {
        CLOGV("frame %d is already adjust timestamp", frame->getFrameCount());
    } else {
        uint64_t exposureTime = 0;
        uint64_t oldTimeStamp = 0;
        exposureTime = (uint64_t)shot_ext->shot.dm.sensor.exposureTime;

        oldTimeStamp = shot_ext->shot.udm.sensor.timeStampBoot;

        shot_ext->shot.udm.sensor.timeStampBoot -= (exposureTime);
#ifdef CORRECTION_SENSORFUSION
        shot_ext->shot.udm.sensor.timeStampBoot += CORRECTION_SENSORFUSION;
#endif

        CLOGV("[F%d] exp.time(%ju) timeStamp(%ju -> %ju)",
            frame->getFrameCount(), exposureTime,
            oldTimeStamp, shot_ext->shot.udm.sensor.timeStampBoot);

#ifdef USE_DUAL_CAMERA
        if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE
            && frame->getFrameType() != FRAME_TYPE_REPROCESSING_DUAL_SLAVE)
#endif
        {
            if (request != NULL) {
                request->setSensorTimestamp(shot_ext->shot.udm.sensor.timeStampBoot);
            }
        }

        frame->setAdjustedTimestampFlag(true);
    }
#endif

    /* HACK: W/A for timeStamp reversion */
    if (shot_ext->shot.udm.sensor.timeStampBoot < m_lastFrametime) {
        CLOGV("Timestamp is lower than lastFrametime!"
            "frameCount(%d) shot_ext.timestamp(%ju) m_lastFrametime(%ju)",
            frame->getFrameCount(), shot_ext->shot.udm.sensor.timeStampBoot, m_lastFrametime);
        //shot_ext->shot.udm.sensor.timeStampBoot = m_lastFrametime + 15000000;
    }
    m_lastFrametime = shot_ext->shot.udm.sensor.timeStampBoot;

    return ret;
}

status_t ExynosCamera::m_enumExtraStreamInfo(camera3_stream_t *stream)
{
    CLOGD("In");
    int ret = OK;
    ExynosCameraStream *newStream = NULL;
    int id = 0;
    int actualFormat = 0;
    camera_pixel_size pixelSize = CAMERA_PIXEL_SIZE_8BIT;
    int planeCount = 0;
    int requestBuffer = 0;
    int outputPortId = 0;
    int option = 0;
    int phyCamID = -1;
    EXYNOS_STREAM::STATE registerStream;
    EXYNOS_STREAM::STATE registerBuffer;
    cameraId_Info camIdInfo;

    registerStream = EXYNOS_STREAM::HAL_STREAM_STS_VALID;
    registerBuffer = EXYNOS_STREAM::HAL_STREAM_STS_UNREGISTERED;

    if (stream == NULL) {
        CLOGE("stream is NULL.");
        return INVALID_OPERATION;
    }

    /* ToDo: need to Consideration about how to support each camera3_stream_rotation_t */
    if (stream->rotation != CAMERA3_STREAM_ROTATION_0) {
        CLOGE("Invalid stream rotation %d", stream->rotation);
        ret = BAD_VALUE;
        goto func_err;
    }

    if ((stream->physical_camera_id != NULL && strlen(stream->physical_camera_id) > 0)) {
        if (m_isLogicalCam) {
            phyCamID = atoi(stream->physical_camera_id);
            camIdInfo.serviceCameraId = phyCamID;
            getCameraIdInfo(&camIdInfo);
            phyCamID = camIdInfo.cameraId[MAIN_CAM];
            if (!(isCamPhysIDValid(m_camIdInfo.serviceCameraId, camIdInfo.cameraId[MAIN_CAM]))) {
                CLOGE("Physical ID is in valid for Logical Cam (serviceId = %d, %s)",
                    m_camIdInfo.serviceCameraId, stream->physical_camera_id);
                ret = BAD_VALUE;
                goto func_err;
            }
            CLOGD("Physical ID(%d, %s) mainCameraId(%d), m_cameraIds(%d, %d)",
                phyCamID, stream->physical_camera_id, camIdInfo.cameraId[MAIN_CAM], m_cameraIds[0], m_cameraIds[1]);
            m_configurations->setPhysStreamExistStatus(true);
        } else {
            CLOGE("Physical ID is enabled for Non Logical Cam (%s)", stream->physical_camera_id);
            ret = BAD_VALUE;
            goto func_err;
        }

        /* YUV/RAW streams can be Logical or Physical streams. */
    }

    switch (stream->stream_type) {
    case CAMERA3_STREAM_OUTPUT:
        // TODO: split this routine to function
        switch (stream->format) {
        case HAL_PIXEL_FORMAT_YCbCr_420_888:
            if (option & STREAM_OPTION_STALL_MASK) {
                goto func_err;
            } else if (option & STREAM_OPTION_THUMBNAIL_CB_MASK) {
                goto func_err;
            } else if (phyCamID >= 0) {
                goto func_err;
            } else {
                CLOGD("HAL_PIXEL_FORMAT_YCbCr_420_888 format(%#x) usage(%#x) stream_type(%#x)",
                    stream->format, stream->usage, stream->stream_type);

                id = HAL_STREAM_ID_CALLBACK;
                outputPortId = m_streamManager->getTotalYuvStreamCount();
                requestBuffer = m_exynosconfig->current->bufInfo.num_request_callback_buffers;

            }

            /* set PreviewCb Size */
            m_configurations->setSize(CONFIGURATION_PREVIEW_CB_SIZE, stream->width, stream->height);

            actualFormat = HAL_PIXEL_FORMAT_YCrCb_420_SP;
            planeCount = 1;
            break;
        default:
            break;
        }
    default:
        break;
    }

    /* Update gralloc usage */
    switch (stream->stream_type) {
    case CAMERA3_STREAM_INPUT:
        stream->usage |= GRALLOC1_CONSUMER_USAGE_CAMERA;
        break;
    case CAMERA3_STREAM_OUTPUT:
        stream->usage |= GRALLOC1_PRODUCER_USAGE_CAMERA;
        break;
    case CAMERA3_STREAM_BIDIRECTIONAL:
        stream->usage |= (GRALLOC1_CONSUMER_USAGE_CAMERA
                          | GRALLOC1_PRODUCER_USAGE_CAMERA);
        break;
    default:
        CLOGE("Invalid stream_type %d", stream->stream_type);
        break;
    }

    ret = m_streamManager->createStream(id, stream, &newStream);
    if (ret != NO_ERROR) {
        CLOGE("createStream is NULL id(%d)", id);
        ret = BAD_VALUE;
        goto func_err;
    }

    newStream->setRegisterStream(registerStream);
    newStream->setRegisterBuffer(registerBuffer);
    newStream->setFormat(actualFormat, pixelSize);
    newStream->setPlaneCount(planeCount);
    newStream->setOutputPortId(outputPortId);
    newStream->setRequestBuffer(requestBuffer);

    if (phyCamID >= 0) {
       newStream->setPhysCameraID(phyCamID);
    }

func_err:
    CLOGD("Out");

    return ret;

}

void ExynosCamera::m_getOnePortId(ExynosCameraRequestSP_sprt_t request, bool *isOnlyPhysStreams, int32_t *port1, int32_t *port2)
{
    bool isOnlyPhysStreamsPresent = false;
    int32_t onePortId = -1;
    int32_t secondPortId = -1;
    //if (!request)
    //    return;

#if defined(USE_SW_MCSC) && (USE_SW_MCSC == 1)
    /*
     * In case of using PIPE_SW_MCSC,
     * The largest size of stream becomes output of the MCSC, and the other one becomes output of the SW_MCSC.
     * onePortId == MCSC output portId, secondPortId == SW_MCSC output portId
     * there is no case of using all of preview/video/previewCB stream in hardware level limited
     * (ex) video stream size > preview stream size
     *    [MCSC] -> videoBuf -> [SWMCSC] -> previewBuf
     */
    if (m_streamManager->findStream(HAL_STREAM_ID_PREVIEW) == true) {
        if (m_streamManager->findStream(HAL_STREAM_ID_VIDEO) == true) {
            if (m_compareStreamPriority(HAL_STREAM_ID_PREVIEW, HAL_STREAM_ID_VIDEO) == true) {
                onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
                secondPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO);
            } else {
                onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO);
                secondPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
            }
        } else if (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK) == true) {
            if (m_compareStreamPriority(HAL_STREAM_ID_PREVIEW, HAL_STREAM_ID_CALLBACK) == true) {
                onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
                secondPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
            } else {
                onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
                secondPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
            }
        } else {
            onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
            secondPortId = -1;
        }
    } else if (m_streamManager->findStream(HAL_STREAM_ID_VIDEO) == true) {
        if (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK) == true) {
            if (m_compareStreamPriority(HAL_STREAM_ID_VIDEO, HAL_STREAM_ID_CALLBACK) == true) {
                onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO);
                secondPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
            } else {
                onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
                secondPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO);
            }
        } else {
            onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO);
            secondPortId = -1;
        }
    } else if (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK) == true) {
        onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
        secondPortId = -1;
    } else {
        onePortId = -1;
        secondPortId = -1;
    }
#else
    //NOTE: could be multiple CALLBACK streams
    //Priority1: HAL_STREAM_ID_PREVIEW
    //Priority2: HAL_STREAM_ID_CALLBACK
    //Priority3: HAL_STREAM_ID_CALLBACK_PHYSICAL
    if (m_streamManager->findStream(HAL_STREAM_ID_PREVIEW) == true) {
        onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
    } else if (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK) == true) {
        onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
    } else if (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK_PHYSICAL) == true) {
        isOnlyPhysStreamsPresent = true;
        onePortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK_PHYSICAL);
    } else {
        onePortId = -1;
    }
#endif

    if (isOnlyPhysStreams) {
        *isOnlyPhysStreams = isOnlyPhysStreamsPresent;
    }
    if (port1) {
        *port1 = onePortId;
    }
    if (port2) {
        *port2 = secondPortId;
    }
}

status_t ExynosCamera::m_previewFrameHandler(ExynosCameraRequestSP_sprt_t request,
                                             ExynosCameraFrameFactory *targetfactory,
                                             frame_type_t frameType)
{
    status_t ret = NO_ERROR;
    frame_handle_components_t components;
    ExynosCameraFrameSP_sptr_t newFrame = NULL;
    ExynosCameraBuffer buffer;
    struct camera2_shot_ext *service_shot_ext = NULL;
    int currentCameraId = 0;
    uint32_t requestKey = 0;
    uint32_t needDynamicBayerCount = 0;
    bool captureFlag = false;
    bool zslInputFlag = false;
    bool rawStreamFlag = false;
    bool zslStreamFlag = false;
    bool depthStreamFlag = false;
    bool needDynamicBayer = false;
    bool usePureBayer = false;
    bool requestVC0 = false;
    bool request3AP = false;
    bool requestGMV = false;
    bool requestMCSC = false;
    bool vendorYuvStall = false;
    int32_t reprocessingBayerMode = REPROCESSING_BAYER_MODE_NONE;
    enum pipeline controlPipeId = MAX_PIPE_NUM;
    int pipeId = -1;
    int onePortId = -1;
    int secondPortId = -1;
    int ysumPortId = -1;
    int sensorGyroPipeId = -1;
    bool isDualSolutionEnabled = false;
    int dstPos = 0;
    uint32_t streamConfigBit = 0;
    const buffer_manager_tag_t initBufTag;
    buffer_manager_tag_t bufTag;
    bool flag3aaVraM2M = false;
    camera3_stream_buffer_t *inputBuffer = request->getInputBuffer();
    ExynosRect bayerCropRegion = {0, };
    requestKey = request->getKey();
    ExynosRect zoomRect = {0, };
    ExynosRect activeZoomRect = {0, };
#ifdef USE_DUAL_CAMERA
    bool isDualMode = m_configurations->getMode(CONFIGURATION_DUAL_MODE);
    enum DUAL_PREVIEW_MODE dualPreviewMode = m_configurations->getDualPreviewMode();
#endif
    bool isOnlyPhysStreamsPresent = false;
    int alternativePreviewPortId = -1;
    float requestZoomRatio = request->getMetaParameters()->m_zoomRatio; /* zoom ratio by current request */

    enum DUAL_OPERATION_MODE dualOperationMode = DUAL_OPERATION_MODE_NONE;
    bool fallback = false;
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        dualOperationMode = ExynosCameraFrame::convertDualModeByFrameType(frameType);
        fallback = m_configurations->isFallbackOn();
    }
#endif
    m_getFrameHandleComponentsWrapper(frameType, &components);
    currentCameraId = components.currentCameraId;

    requestVC0 = (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);
    request3AP = (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M);
    requestGMV = m_configurations->getMode(CONFIGURATION_GMV_MODE);
    requestMCSC = (components.parameters->getHwConnectionMode(PIPE_ISP, PIPE_MCSC) == HW_CONNECTION_MODE_M2M);
    flag3aaVraM2M = (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_VRA) == HW_CONNECTION_MODE_M2M);
    reprocessingBayerMode = components.parameters->getReprocessingBayerMode();
    controlPipeId = (enum pipeline) components.parameters->getPerFrameControlPipe();
    alternativePreviewPortId = components.parameters->getAlternativePreviewPortId();

    /* Initialize the request flags in framefactory */
    targetfactory->setRequest(PIPE_VC0, requestVC0);
    targetfactory->setRequest(PIPE_3AA, requestVC0);
    targetfactory->setRequest(PIPE_3AC, false);
    targetfactory->setRequest(PIPE_3AP, request3AP);
    targetfactory->setRequest(PIPE_3AF, false);
    targetfactory->setRequest(PIPE_ME, requestGMV);
    targetfactory->setRequest(PIPE_GMV, requestGMV);
    targetfactory->setRequest(PIPE_ISP, request3AP);
    targetfactory->setRequest(PIPE_ISPC, false);
    targetfactory->setRequest(PIPE_MCSC, requestMCSC);
    targetfactory->setRequest(PIPE_MCSC0, false);
    targetfactory->setRequest(PIPE_MCSC1, false);
    targetfactory->setRequest(PIPE_MCSC2, false);
    targetfactory->setRequest(PIPE_MCSC_JPEG, false);
    targetfactory->setRequest(PIPE_MCSC_THUMB, false);
#ifdef SUPPORT_HW_GDC
    targetfactory->setRequest(PIPE_GDC, false);
#endif
#ifdef USE_SLSI_PLUGIN
    for (int i = PIPE_PLUGIN_BASE; i <= PIPE_PLUGIN_MAX; i++)
        targetfactory->setRequest(i, false);
#endif
#ifdef USES_CAMERA_EXYNOS_VPL
    targetfactory->setRequest(PIPE_NFD, false);
#endif
    targetfactory->setRequest(PIPE_MCSC5, false);
    targetfactory->setRequest(PIPE_GSC, false);
#ifdef USE_VRA_FD
    targetfactory->setRequest(PIPE_VRA, false);
#endif
#ifdef USE_CLAHE_PREVIEW
    targetfactory->setRequest(PIPE_CLAHEC, false);
#endif
#ifdef USE_SW_MCSC
    targetfactory->setRequest(PIPE_SW_MCSC, false);
#endif
    targetfactory->setRequest(PIPE_HFD, false);
#ifdef SUPPORT_DEPTH_MAP
    targetfactory->setRequest(PIPE_VC1, m_flagUseInternalDepthMap);
#endif
#ifdef SUPPORT_ME
    if (m_parameters[m_cameraId]->getLLSOn() == true)
        targetfactory->setRequest(PIPE_ME, true);
    else
        targetfactory->setRequest(PIPE_ME, false);
#endif
#ifdef SUPPORT_PD_IMAGE
    if (m_parameters[currentCameraId]->isPDImageSupported())
        targetfactory->setRequest(PIPE_VC1, true);
#endif

    bool flagUseOnePort = m_flagUseOnePort;

#ifdef USES_COMBINE_PLUGIN
    if ((m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0)
#ifdef USE_DUAL_CAMERA
            && (isDualMode == false)
#endif
            && (request->hasStream(HAL_STREAM_ID_VIDEO) == false)) {
        flagUseOnePort = false;
    }
#endif

    if (m_flagUseOnePort) {
        m_getOnePortId(request, &isOnlyPhysStreamsPresent, &onePortId, &secondPortId);
        // alternativePreviewPortId is only used when m_flagVideoStreamPriority equals to true
        if (m_flagVideoStreamPriority && alternativePreviewPortId >= 0) {
            onePortId = alternativePreviewPortId;
        }
#ifdef USES_SW_VDIS
        if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
            onePortId = alternativePreviewPortId;
        }
#endif
    }

    /* To decide the dynamic bayer request flag for JPEG capture */
    switch (reprocessingBayerMode) {
    case REPROCESSING_BAYER_MODE_NONE :
        needDynamicBayer = false;
        break;
    case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON :
        targetfactory->setRequest(PIPE_VC0, true);
        needDynamicBayer = false;
        usePureBayer = true;
        break;
    case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON :
        targetfactory->setRequest(PIPE_3AC, true);
        needDynamicBayer = false;
        usePureBayer = false;
        break;
    case REPROCESSING_BAYER_MODE_PURE_DYNAMIC :
        needDynamicBayer = true;
        usePureBayer = true;
        break;
    case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC :
        needDynamicBayer = true;
        usePureBayer = false;
        break;
    default :
        break;
    }

#ifdef USE_DUAL_CAMERA
    if (frameType == FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
       /* Setting DMA-out request flag based on stream configuration */
       for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
           int id = request->getStreamIdwithBufferIdx(i);
           SET_STREAM_CONFIG_BIT(streamConfigBit, id);

           switch (id % HAL_STREAM_ID_MAX) {
               case HAL_STREAM_ID_PREVIEW:
               case HAL_STREAM_ID_CALLBACK:
               case HAL_STREAM_ID_VIDEO:
               case HAL_STREAM_ID_PREVIEW_VIDEO:
               case HAL_STREAM_ID_CALLBACK_PHYSICAL:
                   if (onePortId != -1) {
                       pipeId = (onePortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                   } else {
                       pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                   }
                   targetfactory->setRequest(pipeId, true);

                   CLOGV("request %d outputBuffer-Index %zu stream_id : %d streamConfigBit : %x  onePortId = %d pipeId = %d",
                         request->getKey(), i, id, streamConfigBit, onePortId, pipeId);
                   break;
               default:
                     break;
           }
       }
       goto GENERATE_FRAME;
    } else
#endif
    {
        /* Check ZSL_INPUT stream */
        if(inputBuffer != NULL) {
            int inputStreamId = 0;
            ExynosCameraStream *stream = static_cast<ExynosCameraStream *>(inputBuffer->stream->priv);

            if(stream != NULL) {
                stream->getID(&inputStreamId);
                SET_STREAM_CONFIG_BIT(streamConfigBit, inputStreamId);

                switch (inputStreamId % HAL_STREAM_ID_MAX) {
                case HAL_STREAM_ID_ZSL_INPUT:
                case HAL_STREAM_ID_YUV_INPUT:
                    zslInputFlag = true;
                    break;
                case HAL_STREAM_ID_JPEG:
                case HAL_STREAM_ID_PREVIEW:
                case HAL_STREAM_ID_VIDEO:
                case HAL_STREAM_ID_CALLBACK:
                case HAL_STREAM_ID_CALLBACK_PHYSICAL:
                case HAL_STREAM_ID_CALLBACK_STALL:
                case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
                case HAL_STREAM_ID_DEPTHMAP:
                case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                case HAL_STREAM_ID_VISION:
                    CLOGE("requestKey %d Invalid buffer-StreamType(%d)",
                            request->getKey(), inputStreamId);
                    break;
                default:
                    break;
                }
            } else {
                CLOGE("Stream is null (%d)", request->getKey());
            }
        }

#ifdef SUPPORT_VENDOR_YUV_STALL
        vendorYuvStall = getVendorYUVStallMeta(request);
#endif

        /* Setting DMA-out request flag based on stream configuration */
        for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
            int id = request->getStreamIdwithBufferIdx(i);
            SET_STREAM_CONFIG_BIT(streamConfigBit, id);

            switch (id % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_RAW:
                CLOGV("requestKey %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_RAW)",
                         request->getKey(), i);
                targetfactory->setRequest(PIPE_VC0, true);
                rawStreamFlag = true;
                break;
            case HAL_STREAM_ID_ZSL_OUTPUT:
                CLOGV("request(%d) outputBuffer-Index(%zu) buffer-StreamType(HAL_STREAM_ID_ZSL)",
                         request->getKey(), i);
                if (usePureBayer == true)
                    targetfactory->setRequest(PIPE_VC0, true);
                else
                    targetfactory->setRequest(PIPE_3AC, true);
                zslStreamFlag = true;
                break;
            case HAL_STREAM_ID_PREVIEW:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_PREVIEW)",
                         request->getKey(), i);

                if (onePortId != -1) {
                    if (request->getDsInputPortId() != MCSC_PORT_NONE)
                        request->setDsInputPortId(onePortId);
                    pipeId = (onePortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                } else {
                    pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                }

                targetfactory->setRequest(pipeId, true);
                break;
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_CALLBACK_PHYSICAL:
                if (zslInputFlag == true
                    || (vendorYuvStall == true
#ifdef ENABLE_YUV_STALL_FOR_SECOND_YUV
                        // HACK: second yuv
                        // TODO: need more condition for specific vendor tag
                        && (id != HAL_STREAM_ID_CALLBACK)
#endif
                    )) {
                    /* If there is ZSL_INPUT stream buffer,
                    * It will be processed through reprocessing stream.
                    */
                    if (vendorYuvStall == true) {
                        /* set config bit for Vendor YUV Stall. */
                        SET_STREAM_CONFIG_BIT(streamConfigBit, HAL_STREAM_ID_CALLBACK_STALL);
                    }
                    break;
                }

                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_CALLBACK)",
                    request->getKey(), i);
                if (onePortId != -1) {
                    pipeId = (onePortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                } else {
                    pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                }
                targetfactory->setRequest(pipeId, true);
                break;
            case HAL_STREAM_ID_VIDEO:
                m_recordingEnabled = true;
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_VIDEO)",
                         request->getKey(), i);
#ifdef USES_COMBINE_PLUGIN
                /*
                 * HACK: Only single scenario:
                 * COMBINE_PLUGIN does not yet support video streaming.
                 * The Vidoe stream is output directly from the MCSC.
                 */
#ifdef USE_DUAL_CAMERA
                if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION &&
                        onePortId != -1) {
                    pipeId = (onePortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                } else
#endif
#else
                if (onePortId != -1) {
                    pipeId = (onePortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                } else
#endif
                {
                    pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                }
                targetfactory->setRequest(pipeId, true);
                ysumPortId = m_streamManager->getOutputPortId(id);
#ifdef SUPPORT_HW_GDC
                if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_GDC) == true) {
                    targetfactory->setRequest(PIPE_GDC, true);
                    m_previewStreamGDCThread->run(PRIORITY_URGENT_DISPLAY);
                }
#endif
#ifdef USE_CLAHE_PREVIEW
                targetfactory->setRequest(PIPE_CLAHEC, true);
#endif
                break;
            case HAL_STREAM_ID_PREVIEW_VIDEO:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_PREVIEW_VIDEO)",
                        request->getKey(), i);
                if (onePortId != -1) {
                    pipeId = (onePortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                } else {
                    pipeId = (m_streamManager->getOutputPortId(id) % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                }
                targetfactory->setRequest(pipeId, true);
                m_recordingEnabled = true;
                break;
            case HAL_STREAM_ID_JPEG:
                CLOGD("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_JPEG)",
                         request->getKey(), i);
                if ((needDynamicBayer == true) && (zslInputFlag == false)) {
                    if(components.parameters->getUsePureBayerReprocessing()) {
                        targetfactory->setRequest(PIPE_VC0, true);
                    } else {
                        targetfactory->setRequest(PIPE_3AC, true);
                    }
                }

                if(components.parameters->isUseVideoHQISP()) {
                    targetfactory->setRequest(PIPE_MCSC_JPEG, true);
                    if (m_captureStreamThread->isRunning() == false)
                        m_captureStreamThread->run(PRIORITY_DEFAULT);
                }

                captureFlag = true;
                break;
            case HAL_STREAM_ID_CALLBACK_STALL:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_CALLBACK_STALL)",
                         request->getKey(), i);
                if ((needDynamicBayer == true) && (zslInputFlag == false)) {
                    if(components.parameters->getUsePureBayerReprocessing()) {
                        targetfactory->setRequest(PIPE_VC0, true);
                    } else {
                        targetfactory->setRequest(PIPE_3AC, true);
                    }
                }
                captureFlag = true;
                break;
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_THUMBNAIL_CALLBACK)",
                        request->getKey(), i);
                break;
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_DEPTHMAP)",
                        request->getKey(), i);
                targetfactory->setRequest(PIPE_VC1, true);
                depthStreamFlag = true;
                break;
            case HAL_STREAM_ID_DEPTHMAP_STALL:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_DEPTHMAP_STALL)",
                        request->getKey(), i);
                break;
#endif
            case HAL_STREAM_ID_VISION:
                CLOGV("request %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_VISION)",
                        request->getKey(), i);
                break;
            default:
                CLOGE("Invalid stream ID %d", id);
                break;
            }
        }
#ifdef USES_SW_VDIS
#ifdef SUPPORT_ME
        targetfactory->setRequest(PIPE_ME, m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE));
#endif
        targetfactory->setRequest(PIPE_VDIS, m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE));
#ifdef USE_SW_VDIS_WITH_PREVIEW
        if ((m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0)) {
            if (request->hasStream(HAL_STREAM_ID_VIDEO)) {
                int previewPortId = components.parameters->getPreviewPortId();
                targetfactory->setRequest(PIPE_MCSC0 + previewPortId, false);
            }
        } else {
            targetfactory->setRequest(PIPE_VDIS, false);
        }
#endif
#endif
    }

#ifdef USES_COMBINE_PLUGIN
    //HACK: TODO: it should be moved to ExynosCameraMultiPlugInManager
    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
        targetfactory->setRequest(PIPE_PLUGIN1, true);
        if (request->hasStream(HAL_STREAM_ID_VIDEO)) {
            int previewPortId = components.parameters->getPreviewPortId();
            targetfactory->setRequest(PIPE_MCSC0 + previewPortId, false);
        }
    }
#endif

#ifdef USE_DUAL_CAMERA
    if (frameType != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
    {
        m_checkRequestStreamChanged((char *)"Preview", streamConfigBit);
    }

    m_needDynamicBayerCountLock.lock();
    needDynamicBayerCount = m_configurations->getModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT);
    if (needDynamicBayerCount > 0) {
        m_configurations->setModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT, needDynamicBayerCount - 1);
        m_needDynamicBayerCountLock.unlock();
        CLOGD("request %d needDynamicBayerCount %d",
                request->getKey(), needDynamicBayerCount);


        needDynamicBayer = true;

        if(components.parameters->getUsePureBayerReprocessing()) {
            targetfactory->setRequest(PIPE_VC0, true);
        } else {
            targetfactory->setRequest(PIPE_3AC, true);
        }
    } else {
        m_needDynamicBayerCountLock.unlock();
    }

    m_previewFrameHandler_vendor_updateRequest(targetfactory);

#ifndef USES_COMBINE_PLUGIN
    /*
     * COMBINE_PLUGIN does not yet support video streaming.
     * The Vidoe stream is output directly from the MCSC.
     */
    if (m_videoStreamExist == true && onePortId != -1) {
        if (m_flagVideoStreamPriority) {
            // VIDEO STREAM => GSC => PREVIEW STREAM
            if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true)
                targetfactory->setRequest(PIPE_GSC, true);
        } else {
            // PREVIEW STREAM => GSC => VIDEO STREAM
            if (request->hasStream(HAL_STREAM_ID_VIDEO) == true)
                targetfactory->setRequest(PIPE_GSC, true);
        }
    }
#endif

#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
    if (secondPortId > -1 && request->hasStream(m_streamManager->getYuvStreamId(secondPortId))) {
        targetfactory->setRequest(PIPE_SW_MCSC, true);
    }
#endif

#ifdef DEBUG_RAWDUMP
    if (m_configurations->checkBayerDumpEnable()) {
        targetfactory->setRequest(PIPE_VC0, true);
    }
#endif

#ifdef USE_DUAL_CAMERA
GENERATE_FRAME:
#endif

#ifdef USE_DUAL_CAMERA
    if (isDualMode == true) {
        targetfactory->setRequest(PIPE_BAYER_SYNC, false);
        targetfactory->setRequest(PIPE_SYNC, false);
        targetfactory->setRequest(PIPE_FUSION, false);

        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
            isDualSolutionEnabled = true;
        }

        if (isDualSolutionEnabled == true) {
#ifdef USE_DUAL_BAYER_SYNC
            if ((targetfactory->getRequest(PIPE_VC0) == true)
                || (targetfactory->getRequest(PIPE_3AC) == true)) {
                targetfactory->setRequest(PIPE_BAYER_SYNC, true);
            }
#endif

            targetfactory->setRequest(PIPE_SYNC, true);
            switch(frameType) {
            case FRAME_TYPE_PREVIEW_DUAL_SLAVE:
                break;
            case FRAME_TYPE_PREVIEW_DUAL_MASTER:
            default:
                targetfactory->setRequest(PIPE_FUSION, true);
                break;
            }
        }
    }
#endif

#ifdef USES_COMBINE_PLUGIN
    /*
     * HACK: If Dual is enabled, the function of PIPE_PLUGIN1 is performed in DUAL FUSION Plugin pipe.
     *
     * We need features that support multiple solutions in one plugin for a specific vendor.
     * The ability to integrate multiple plugin solutions into one is not yet complete.
     * For this, the handling codes of the plugins should be integrated,
     * and the plugins of the preview path should be able to load several libaries like the pluin of the capture path.
     * However, should not load per-frame libraries as capture plugins.
     *
     * We plan to add pluing code for this part.
     */
    if (isDualMode == true) {
        for (int pluginPipeId = PIPE_PLUGIN_BASE; pluginPipeId < PIPE_PLUGIN_MAX; pluginPipeId++) {
            targetfactory->setRequest(pluginPipeId, false);
        }
    }
#endif

    if (!m_isLogicalCam) {
        service_shot_ext = request->getServiceShot();
    } else {
        /* if no PhysCam Settings, it will return NULL */
        service_shot_ext = request->getServiceShotPhysCam(currentCameraId);
        if (!service_shot_ext)
            service_shot_ext = request->getServiceShot();
    }
    if (service_shot_ext == NULL) {
        CLOGE("Get service shot fail, requestKey(%d)", request->getKey());
        ret = INVALID_OPERATION;
        return ret;
    }

    *m_currentPreviewShot[currentCameraId] = *service_shot_ext;

    if ((m_recordingEnabled == true) && (ysumPortId < 0) && (request->hasStream(HAL_STREAM_ID_PREVIEW))) {
        /* The buffer from the preview port is used as the recording buffer */
        components.parameters->setYsumPordId(components.parameters->getPreviewPortId(), m_currentPreviewShot[currentCameraId]);
    } else {
        components.parameters->setYsumPordId(ysumPortId, m_currentPreviewShot[currentCameraId]);
    }

    if ((m_recordingEnabled == true) && (ysumPortId < 0) && (request->hasStream(HAL_STREAM_ID_PREVIEW))) {
        /* The buffer from the preview port is used as the recording buffer */
        components.parameters->setYsumPordId(components.parameters->getPreviewPortId(),
                                                m_currentPreviewShot[currentCameraId]);
    } else {
        components.parameters->setYsumPordId(ysumPortId, m_currentPreviewShot[currentCameraId]);
    }

    m_updateShotInfoLock.lock();
    m_updateLatestInfoToShot(m_currentPreviewShot[currentCameraId], frameType, &components);
    if (service_shot_ext != NULL) {
#ifdef USE_SW_VDIS_WITH_PREVIEW
#ifdef USE_ALWAYS_FD_ON
        if (m_configurations->getMode(CONFIGURATION_ALWAYS_FD_ON_MODE)
            && m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
            request->setDsInputPortId(components.parameters->getRecordingPortId());
        }
#endif
#endif
        m_updateFD(m_currentPreviewShot[currentCameraId], service_shot_ext->shot.ctl.stats.faceDetectMode,
                        request->getDsInputPortId(), false, flag3aaVraM2M);
    }
    components.parameters->setDsInputPortId(m_currentPreviewShot[currentCameraId]->shot.uctl.scalerUd.mcsc_sub_blk_port[INTERFACE_TYPE_DS], false);

    if (captureFlag == true || rawStreamFlag == true) {
        m_updateExposureTime(m_currentPreviewShot[currentCameraId]);
    }

    if (m_currentPreviewShot[currentCameraId]->fd_bypass == false) {
#ifdef USES_CAMERA_EXYNOS_VPL
#ifdef USE_VRA_FD
        if (m_parameters[m_cameraId]->getNfdMode() == true)
#endif
        {
            targetfactory->setRequest(PIPE_NFD,true);

            if (m_previewStreamNFDThread->isRunning() == false) {
                CLOGI("m_previewStreamNFDThread run E");
                m_previewStreamNFDThread->run(PRIORITY_URGENT_DISPLAY);
                CLOGI("m_previewStreamNFDThread run X");
            }
        }
#endif
        if (flag3aaVraM2M) {
            targetfactory->setRequest(PIPE_3AF, true);
#ifdef USE_VRA_FD
            targetfactory->setRequest(PIPE_VRA, true);
#endif
            /* TODO: need to check HFD */
            } else if (components.parameters->getHwConnectionMode(PIPE_MCSC, PIPE_VRA)
                                            == HW_CONNECTION_MODE_M2M) {
                targetfactory->setRequest(PIPE_MCSC5, true);
                targetfactory->setRequest(PIPE_VRA, true);
#ifdef SUPPORT_HFD
            if (m_currentPreviewShot[currentCameraId]->hfd.hfd_enable == true) {
                targetfactory->setRequest(PIPE_HFD, true);
            }
#endif
        }
    }
#if defined(BOARD_CAMERA_EARLY_FD) && defined(USE_ALWAYS_FD_OFF)
    else if (true) {
        targetfactory->setRequest(PIPE_3AF, true);
    }
#endif

    /* Set framecount into request */
    m_frameCountLock.lock();
    if (request->getFrameCount() == 0
#ifdef USE_DUAL_CAMERA
            && (frameType != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
       ) {
        m_requestMgr->setFrameCount(m_internalFrameCount++, request->getKey());
    }
    m_frameCountLock.unlock();

    /* Generate frame for YUV stream */
    ret = m_generateFrame(targetfactory, &m_processList, &m_processLock, newFrame, request);
    m_updateShotInfoLock.unlock();

    if (ret != NO_ERROR) {
        CLOGE("[F%d]Failed to generateRequestFrame.", m_internalFrameCount - 1);
        goto CLEAN;
    } else if (newFrame == NULL) {
        CLOGE("[F%d]newFrame is NULL.", m_internalFrameCount - 1);
        goto CLEAN;
    }

    CLOGV("[R%d F%d]Generate preview frame. streamConfig %x",
            request->getKey(), newFrame->getFrameCount(), streamConfigBit);

    if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGD("[R%d F%d]Flush is in progress.", request->getKey(), newFrame->getFrameCount());
        /* Generated frame is going to be deleted at flush() */
        if (captureFlag == true) {
            CLOGI("[R%d F%d]setFrameCapture true.", request->getKey(), newFrame->getFrameCount());
            newFrame->setStreamRequested(STREAM_TYPE_CAPTURE, captureFlag);
        }
        goto CLEAN;
    }

    TIME_LOGGER_UPDATE(m_cameraId, request->getKey(), 0, USER_DATA, CREATE_PREVIEW_FRAME, newFrame->getFrameCount());

    {
        /* BcropRegion is calculated in m_generateFrame    */
        /* so that updatePreviewStatRoi should be set here.*/
        ExynosRect tempRect;
        components.parameters->getStatCropSize(&tempRect, &bayerCropRegion);
    }
    components.parameters->updatePreviewStatRoi(m_currentPreviewShot[currentCameraId], &bayerCropRegion);
    components.parameters->updateDisplayStatRoi(newFrame, m_currentPreviewShot[currentCameraId]);

    /* Set control metadata to frame */
    ret = newFrame->setMetaData(m_currentPreviewShot[currentCameraId]);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d]Set metadata to frame fail. ret %d",
                 request->getKey(), newFrame->getFrameCount(), ret);
    }

    newFrame->setFrameType(frameType);
    newFrame->setNeedDynamicBayer(needDynamicBayer);

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
        /* Slave 3AA input region is different with master's */
        m_adjustSlave3AARegion(&components, newFrame);
    }
#endif

    newFrame->setStreamRequested(STREAM_TYPE_RAW, rawStreamFlag);
    newFrame->setStreamRequested(STREAM_TYPE_ZSL_OUTPUT, zslStreamFlag);
    newFrame->setStreamRequested(STREAM_TYPE_DEPTH, depthStreamFlag);

    newFrame->setZoomRatio(m_configurations->getZoomRatio());
    newFrame->setActiveZoomRatio(components.parameters->getActiveZoomRatio());

    m_configurations->getZoomRect(&zoomRect);
    newFrame->setZoomRect(zoomRect);
    components.parameters->getActiveZoomRect(&activeZoomRect);
    newFrame->setActiveZoomRect(activeZoomRect);

    if (onePortId > -1) {
        newFrame->setOnePortId(onePortId);
        if (secondPortId > -1) {
            newFrame->setSecondPortId(secondPortId);
        }
        newFrame->setUseOnePort(true);
        newFrame->setPhysStreamOnlyStatus(isOnlyPhysStreamsPresent);
        CLOGV("setOnePortId = %d setSecondPortId = %d isOnlyPhysStreamsPresent = %d", onePortId, secondPortId, isOnlyPhysStreamsPresent);
    }

    if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
        if (isDualSolutionEnabled == false) {
            newFrame->setMode(FRAME_MODE_DUAL_ZOOM_SOLUTION, DISABLE);
        } else {
            newFrame->setMode(FRAME_MODE_DUAL_ZOOM_SOLUTION, ENABLE);
        }
    } else if (m_scenario == SCENARIO_DUAL_REAR_PORTRAIT
        || m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT) {
        if (isDualSolutionEnabled == false) {
            newFrame->setMode(FRAME_MODE_DUAL_ZOOM_SOLUTION, DISABLE);
        } else {
            newFrame->setMode(FRAME_MODE_DUAL_ZOOM_SOLUTION, ENABLE);
        }
    }

    newFrame->setActiveZoomMargin(components.parameters->getActiveZoomMargin());

    if (captureFlag == true) {
        CLOGI("[F%d]setFrameCapture true.", newFrame->getFrameCount());
        newFrame->setStreamRequested(STREAM_TYPE_CAPTURE, captureFlag);
    }

#ifdef USES_COMBINE_PLUGIN
    //HACK: TODO: it should be moved to ExynosCameraMultiPlugInManager
    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
        newFrame->setPPScenario(PIPE_PLUGIN1, PLUGIN_SCENARIO_COMBINE_PREVIEW);
    }
#endif

#ifdef USE_DUAL_CAMERA
    if (m_parameters[m_cameraId]->getReprocessingBayerMode() == REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC) {
        switch (frameType) {
        case FRAME_TYPE_PREVIEW_DUAL_SLAVE:
            /* slave : check dynamic bayer count */
            if (android_atomic_or(0, &m_needSlaveDynamicBayerCount) > 0)
                newFrame->setRequest(PIPE_3AC, true);
            break;
        case FRAME_TYPE_PREVIEW_DUAL_MASTER:
            /* master : increase dynamic bayer count */
            if (newFrame->getRequest(PIPE_3AC))
                android_atomic_inc(&m_needSlaveDynamicBayerCount);
            break;
        default:
            break;
        }
    }

    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        newFrame->setDualOperationMode(dualOperationMode);
        newFrame->setFallbackOn(fallback);

        // set default expected displayCameraId
        // but it can be changed at fusion lib
        const struct camera2_shot_ext *shot_ext = newFrame->getConstMeta();
        int expectedDisplayCameraId = shot_ext->shot.uctl.masterCamera;
        newFrame->setDisplayCameraId(expectedDisplayCameraId);
    }

    if (frameType != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
    {
        /* Set service stream buffers to frame */
        if (components.parameters->getBatchSize(controlPipeId) > 1
            && components.parameters->useServiceBatchMode() == false) {
            ret = m_setupBatchFactoryBuffers(request, newFrame, targetfactory);
        } else {
            ret = m_setupPreviewFactoryBuffers(request, newFrame, targetfactory);
        }
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d T%d]Failed to setupPreviewStreamBuffer. ret %d",
                    request->getKey(), newFrame->getFrameCount(), newFrame->getFrameType(), ret);
        }
    }

    m_checkUpdateResult(newFrame, streamConfigBit);
    pipeId = m_getBayerPipeId();

    /* Attach VC0 buffer & push frame to VC0 */
    if (newFrame->getRequest(PIPE_VC0) == true
        && zslStreamFlag == false) {
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_VC0;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
        buffer.index = -2;
        dstPos = targetfactory->getNodeType(bufTag.pipeId[0]);

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to get Internal Bayer Buffer. ret %d",
                    newFrame->getFrameCount(), ret);
        }

        CLOGV("[F%d B%d]Use Internal Bayer Buffer",
                newFrame->getFrameCount(), buffer.index);

        if (buffer.index < 0) {
            CLOGW("[F%d B%d]Invalid bayer buffer index. Skip to pushFrame",
                    newFrame->getFrameCount(), buffer.index);
            newFrame->setRequest(bufTag.pipeId[0], false);
        } else {
            ret = newFrame->setDstBufferState(pipeId, ENTITY_BUFFER_STATE_REQUESTED, dstPos);
            if (ret != NO_ERROR) {
                CLOGE("Failed to setDstBufferState. pipeId %d(%d) pos %d",
                        pipeId, bufTag.pipeId[0], dstPos);
                newFrame->setRequest(bufTag.pipeId[0], false);
            } else {
                ret = newFrame->setDstBuffer(pipeId, buffer, dstPos);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setDstBuffer. pipeId %d(%d) pos %d",
                            pipeId, bufTag.pipeId[0], dstPos);
                    newFrame->setRequest(bufTag.pipeId[0], false);
                }
            }
        }
    }

#if defined(SUPPORT_DEPTH_MAP) || defined(SUPPORT_PD_IMAGE)
    if (newFrame->getRequest(PIPE_VC1) == true
#ifdef SUPPORT_DEPTH_MAP
        && m_flagUseInternalDepthMap == true
#endif
        ) {
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_VC1;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
        buffer.index = -2;
        dstPos = targetfactory->getNodeType(bufTag.pipeId[0]);

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to get Internal Depth Buffer. ret %d",
                    newFrame->getFrameCount(), ret);
        }

        CLOGV("[F%d B%d]Use Internal Depth Buffer",
                newFrame->getFrameCount(), buffer.index);

        if (buffer.index < 0) {
            CLOGW("[F%d B%d]Invalid bayer buffer index. Skip to pushFrame",
                    newFrame->getFrameCount(), buffer.index);
            newFrame->setRequest(bufTag.pipeId[0], false);
        } else {
            ret = newFrame->setDstBufferState(pipeId, ENTITY_BUFFER_STATE_REQUESTED, dstPos);
            if (ret == NO_ERROR) {
                ret = newFrame->setDstBuffer(pipeId, buffer, dstPos);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to setDstBuffer. pipeId %d(%d) pos %d",
                            pipeId, bufTag.pipeId[0], dstPos);
                    newFrame->setRequest(bufTag.pipeId[0], false);
                }
            } else {
                CLOGE("Failed to setDstBufferState. pipeId %d(%d) pos %d",
                        pipeId, bufTag.pipeId[0], dstPos);
                newFrame->setRequest(bufTag.pipeId[0], false);
            }
        }
    }
#endif

    ////////////////////////////////////////////////
    // get sensor gyro buf
    sensorGyroPipeId = m_getSensorGyroPipeId();

    if (newFrame->getRequest(sensorGyroPipeId) == true) {
        int dstPos = targetfactory->getNodeType(sensorGyroPipeId);

        ret = m_getBuffer(newFrame,
                          pipeId,
                          sensorGyroPipeId,
                          dstPos,
                          BUFFER_MANAGER_ION_TYPE);
        if (ret != NO_ERROR) {
            CLOGE("[F%d] m_getBuffer(newFrame, pipeId(%d), sensorGyroPipeId(%d), dstPos(%d), BUFFER_MANAGER_ION_TYPE) fail",
                newFrame->getFrameCount(), pipeId, sensorGyroPipeId, dstPos);
        }
    }

    ////////////////////////////////////////////////

#ifdef USES_SENSOR_LISTENER
    m_getSensorListenerData(&components);
#endif
    if(components.parameters->isUseVideoHQISP() && captureFlag == true) {
        ret = m_setupCaptureFactoryBuffers(request, newFrame);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d]Failed to setupCaptureStreamBuffer. ret %d",
                    request->getKey(), newFrame->getFrameCount(), ret);
        }
    }

    /* Attach SrcBuffer */
    ret = m_setupEntity(pipeId, newFrame);
    if (ret != NO_ERROR) {
        CLOGW("[F%d]Failed to setupEntity. pipeId %d", newFrame->getFrameCount(), pipeId);
    } else {
        targetfactory->pushFrameToPipe(newFrame, pipeId);
    }

CLEAN:
    return ret;
}

status_t ExynosCamera:: m_visionFrameHandler(ExynosCameraRequestSP_sprt_t request,
                                             ExynosCameraFrameFactory *targetfactory,
                                             frame_type_t frameType)
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameSP_sptr_t newFrame = NULL;
    ExynosCameraBuffer buffer;
    struct camera2_shot_ext *service_shot_ext = NULL;
    int currentCameraId = 0;
    uint32_t requestKey = 0;
    int pipeId = m_getBayerPipeId();
    int sensorGyroPipeId = m_getSensorGyroPipeId();
    uint32_t streamConfigBit = 0;
    const buffer_manager_tag_t initBufTag;
    buffer_manager_tag_t bufTag;
    frame_handle_components_t components;
    m_getFrameHandleComponentsWrapper(frameType, &components);
    currentCameraId = components.currentCameraId;

    int shutterSpeed = 0;
    int gain = 0;
    int irLedWidth = 0;
    int irLedDelay = 0;
    int irLedCurrent = 0;
    int irLedOnTime = 0;

    bool visionStreamFlag = false;

    requestKey = request->getKey();

    /* Initialize the request flags in framefactory */
    targetfactory->setRequest(PIPE_VC0, false);
    targetfactory->setRequest(PIPE_3AC, false);
    targetfactory->setRequest(PIPE_3AP, false);
    targetfactory->setRequest(PIPE_MCSC0, false);
    targetfactory->setRequest(PIPE_MCSC1, false);
    targetfactory->setRequest(PIPE_MCSC2, false);
#ifdef SUPPORT_DEPTH_MAP
    targetfactory->setRequest(PIPE_VC1, false);
#endif

    /* Check ZSL_INPUT stream */
    camera3_stream_buffer_t *inputBuffer = request->getInputBuffer();
    if(inputBuffer != NULL) {
        int inputStreamId = 0;
        ExynosCameraStream *stream = static_cast<ExynosCameraStream *>(inputBuffer->stream->priv);
        if(stream != NULL) {
            stream->getID(&inputStreamId);
            SET_STREAM_CONFIG_BIT(streamConfigBit, inputStreamId);

            switch (inputStreamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_ZSL_INPUT:
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_PREVIEW_VIDEO:
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
            case HAL_STREAM_ID_VISION:
                CLOGE("requestKey %d Invalid buffer-StreamType(%d)",
                        request->getKey(), inputStreamId);
                break;
            default:
                break;
            }
        } else {
            CLOGE("Stream is null (%d)", request->getKey());
        }
    }

    /* Setting DMA-out request flag based on stream configuration */
    for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
        int id = request->getStreamIdwithBufferIdx(i);
        SET_STREAM_CONFIG_BIT(streamConfigBit, id);

        switch (id % HAL_STREAM_ID_MAX) {
        case HAL_STREAM_ID_VISION:
            CLOGV("requestKey %d outputBuffer-Index %zu buffer-StreamType(HAL_STREAM_ID_VISION)",
                     request->getKey(), i);
            targetfactory->setRequest(PIPE_VC0, true);
            visionStreamFlag = true;
            break;
        case HAL_STREAM_ID_RAW:
        case HAL_STREAM_ID_ZSL_OUTPUT:
        case HAL_STREAM_ID_PREVIEW:
        case HAL_STREAM_ID_CALLBACK:
        case HAL_STREAM_ID_VIDEO:
        case HAL_STREAM_ID_PREVIEW_VIDEO:
        case HAL_STREAM_ID_JPEG:
        case HAL_STREAM_ID_CALLBACK_STALL:
        case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
        case HAL_STREAM_ID_DEPTHMAP:
        case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
            CLOGE("requestKey %d Invalid buffer-StreamType(%d)",
                    request->getKey(), id);
            break;
        default:
            CLOGE("Invalid stream ID %d", id);
            break;
        }
    }

    m_checkRequestStreamChanged((char *)"Vision", streamConfigBit);

    service_shot_ext = request->getServiceShot();
    if (service_shot_ext == NULL) {
        CLOGE("Get service shot fail, requestKey(%d)", request->getKey());
        ret = INVALID_OPERATION;
        return ret;
    }

    *m_currentVisionShot[currentCameraId] = *service_shot_ext;
    m_updateCropRegion(m_currentVisionShot[currentCameraId], &components, frameType, false);
    if (service_shot_ext != NULL) {
        m_updateFD(m_currentVisionShot[currentCameraId], service_shot_ext->shot.ctl.stats.faceDetectMode, request->getDsInputPortId(), false);
    }
    components.parameters->setDsInputPortId(m_currentVisionShot[currentCameraId]->shot.uctl.scalerUd.mcsc_sub_blk_port[INTERFACE_TYPE_DS], false);
    m_updateEdgeNoiseMode(m_currentVisionShot[currentCameraId], false);
    m_updateExposureTime(m_currentVisionShot[currentCameraId]);
    m_updateMasterCam(m_currentVisionShot[currentCameraId], false);

    /* Set framecount into request */
    m_frameCountLock.lock();
    if (request->getFrameCount() == 0) {
        m_requestMgr->setFrameCount(m_internalFrameCount++, request->getKey());
    }
    m_frameCountLock.unlock();

    /* Generate frame for YUV stream */
    ret = m_generateFrame(targetfactory, &m_processList, &m_processLock, newFrame, request);
    if (ret != NO_ERROR) {
        CLOGE("[F%d]Failed to generateRequestFrame.", m_internalFrameCount - 1);
        goto CLEAN;
    } else if (newFrame == NULL) {
        CLOGE("[F%d]newFrame is NULL.", m_internalFrameCount - 1);
        goto CLEAN;
    }

    CLOGV("[R%d F%d]Generate vision frame. streamConfig %x",
            request->getKey(), newFrame->getFrameCount(), streamConfigBit);

    if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGD("[R%d F%d]Flush is in progress.", request->getKey(), newFrame->getFrameCount());
        /* Generated frame is going to be deleted at flush() */
        goto CLEAN;
    }

    newFrame->setStreamRequested(STREAM_TYPE_VISION, visionStreamFlag);

    /* Set control metadata to frame */
    ret = newFrame->setMetaData(m_currentVisionShot[currentCameraId]);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d]Set metadata to frame fail. ret %d",
                 request->getKey(), newFrame->getFrameCount(), ret);
    }

    /* Set service stream buffers to frame */
    ret = m_setupVisionFactoryBuffers(request, newFrame);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d]Failed to setupPreviewStreamBuffer. ret %d",
                request->getKey(), newFrame->getFrameCount(), ret);
    }

    m_checkUpdateResult(newFrame, streamConfigBit);

    /* Attach SrcBuffer */
    ret = m_setupEntity(pipeId, newFrame);
    if (ret != NO_ERROR) {
        CLOGW("[F%d]Failed to setupEntity. pipeId %d", newFrame->getFrameCount(), pipeId);
    } else {
        targetfactory->pushFrameToPipe(newFrame, pipeId);
    }

CLEAN:
    return ret;
}

status_t ExynosCamera::m_handleInternalFrame(ExynosCameraFrameSP_sptr_t frame, int pipeId,
                                                ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameEntity *entity = NULL;
    ExynosCameraBuffer buffer;
    ExynosCameraRequestSP_sprt_t request = NULL;

    struct camera2_shot_ext resultShot;
    struct camera2_shot_ext *shot_ext = NULL;
    uint32_t framecount = 0;
    int dstPos = 0;
    frame_handle_components_t components;

    int sensorGyroPipeId = m_getSensorGyroPipeId();

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    if (factory == NULL) {
        CLOGE("frame Factory is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    entity = frame->getFrameDoneFirstEntity(pipeId);
    if (entity == NULL) {
        CLOGE("current entity is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);

    if (frame->getHasRequest() == true
        && frame->isCompleteForResultUpdate() == false) {
        request = m_requestMgr->getRunningRequest(frame->getFrameCount());
        if (request == NULL) {
            CLOGE("[F%d]request is NULL. pipeId %d",
                    frame->getFrameCount(), pipeId);
            return INVALID_OPERATION;
        }
    }

    switch(pipeId) {
    case PIPE_3AA:
        /* Notify ShotDone to mainThread */
        framecount = frame->getFrameCount();
        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_OTF) {
#ifdef USE_DUAL_CAMERA
            if (frame->isSlaveFrame()) {
                m_slaveShotDoneQ->pushProcessQ(&frame);
            } else
#endif
            {
                m_shotDoneQ->pushProcessQ(&frame);
            }
        }

        ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
        if (ret < 0) {
            CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                    entity->getPipeId(), ret);
            return ret;
        }

        if (buffer.index < 0) {
            CLOGE("[F%d B%d]Invalid buffer index. pipeId(%d)",
                    frame->getFrameCount(),
                    buffer.index,
                    entity->getPipeId());
            return BAD_VALUE;
        }

        shot_ext = (struct camera2_shot_ext *) buffer.addr[buffer.getMetaPlaneIndex()];
        frame->setMetaDataEnable(true);
        components.parameters->updateMetaDataParam(shot_ext);

#ifdef USE_DUAL_CAMERA
        /* for only switching case */
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_SWITCHING
            || frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
            m_updateBeforeForceSwitchSolution(frame, pipeId);
        }
#endif

        if (frame->getHasRequest() == true) {
            ret = m_updateTimestamp(request, frame, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to update timestamp. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }
        }

        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) != HW_CONNECTION_MODE_M2M) {
            CLOGV("[F%d(%d) B%d]Return 3AS Buffer.",
                    frame->getFrameCount(),
                    getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                    buffer.index);

            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for 3AS. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }
        }

        /* Handle bayer buffer */
        if (frame->getRequest(PIPE_VC0) == true || frame->getRequest(PIPE_3AC) == true) {
            ret = m_handleBayerBuffer(frame, request, pipeId, frame->getRequest(PIPE_BAYER_SYNC));
            if (ret < NO_ERROR) {
                CLOGE("Handle bayer buffer failed, framecount(%d), pipeId(%d), ret(%d)",
                        frame->getFrameCount(), entity->getPipeId(), ret);
            }
        }
#ifdef USE_DUAL_CAMERA
        else {
            if (frame->getRequest(PIPE_BAYER_SYNC) == true) {
                frame->setEntityState(PIPE_BAYER_SYNC, ENTITY_STATE_COMPLETE);
            }
        }
#endif

#if defined (SUPPORT_DEPTH_MAP) || defined (SUPPORT_PD_IMAGE)
#ifdef USE_DUAL_CAMERA
        if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
        {
            if (frame->getRequest(PIPE_VC1) == true) {
                ret = m_handleDepthBuffer(frame, request);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Handle deptg buffer failed. pipeId %d ret %d",
                             frame->getFrameCount(), pipeId, ret);
                }
            }
        }
#endif

        ////////////////////////////////////////////////
        // handling sensor gyro buffer
        if (frame->getRequest(sensorGyroPipeId) == true) {
            ret = m_handleSensorGyroBuffer(frame);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]m_handleSensorGyroBuffer() fail. sensorGyroPipeId %d",
                    frame->getFrameCount(), sensorGyroPipeId);
            }
        }

        ////////////////////////////////////////////////

        if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
            if (frame->getRequest(PIPE_3AP) == true) {
                /* Send the bayer buffer to 3AA Pipe */
                dstPos = factory->getNodeType(PIPE_3AP);
                ret = frame->getDstBuffer(entity->getPipeId(), &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            entity->getPipeId(), ret);
                }
                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), entity->getPipeId());
                }

                ret = m_setupEntity(PIPE_ISP, frame, &buffer, NULL);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)", PIPE_ISP, ret);
                }

                factory->pushFrameToPipe(frame, PIPE_ISP);
            }
        }
        break;

    case PIPE_FLITE:
        /* TODO: HACK: Will be removed, this is driver's job */
        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) != HW_CONNECTION_MODE_M2M) {
            android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):PIPE_FLITE cannot come to %s when Flite3aaOtf. so, assert!!!!",
                    __FUNCTION__, __LINE__, __FUNCTION__);
        } else {
            /* Notify ShotDone to mainThread */
            framecount = frame->getFrameCount();
#ifdef USE_DUAL_CAMERA
            if (frame->isSlaveFrame()) {
                m_slaveShotDoneQ->pushProcessQ(&frame);
            } else
#endif
            {
                m_shotDoneQ->pushProcessQ(&frame);
            }

            /* handle src Buffer */
            ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
            if (ret != NO_ERROR) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)", entity->getPipeId(), ret);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for FLITE. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                }
            }

            if (frame->getRequest(PIPE_VC0) == true) {
                /* Send the bayer buffer to 3AA Pipe */
                dstPos = factory->getNodeType(PIPE_VC0);

                ret = frame->getDstBuffer(entity->getPipeId(), &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                             entity->getPipeId(), ret);
                    return ret;
                }

                CLOGV("Deliver Flite Buffer to 3AA. driver->framecount %d hal->framecount %d",
                        getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                        frame->getFrameCount());

                ret = m_setupEntity(PIPE_3AA, frame, &buffer, NULL);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                             PIPE_3AA, ret);
                    return ret;
                }

                factory->pushFrameToPipe(frame, PIPE_3AA);
            }
        }
        break;

    case PIPE_ISP:
        ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
        if (ret != NO_ERROR) {
            CLOGE("Failed to getSrcBuffer. pipeId %d ret %d",
                     entity->getPipeId(), ret);
        }
        if (buffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for ISP. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }
        }
        break;

    case PIPE_MCSC:
        ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
        if (ret != NO_ERROR) {
            CLOGE("Failed to getSrcBuffer. pipeId %d ret %d",
                     entity->getPipeId(), ret);
            return ret;
        }

        if (buffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }
        }
        break;

#ifdef USE_DUAL_CAMERA
    case PIPE_BAYER_SYNC:
    {
        ret = m_handleBayerBuffer(frame, request, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Handle bayer buffer failed. pipeId %d(%s) ret %d",
                    frame->getFrameCount(), pipeId,
                    (frame->getRequest(PIPE_VC0) == true) ? "PIPE_VC0" : "PIPE_3AC",
                    ret);
        }
        break;
    }
#endif

    default:
        CLOGE("Invalid pipe ID");
        break;
    }

    ret = frame->setEntityState(entity->getPipeId(), ENTITY_STATE_COMPLETE);
    if (ret < 0) {
        CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
             entity->getPipeId(), ENTITY_STATE_COMPLETE, ret);
        return ret;
    }

    if (frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == pipeId
        && frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == true) {
        ret = frame->getMetaData(&resultShot);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d]Failed to getMetaData. ret %d",
                    request->getKey(), frame->getFrameCount(), ret);
        }

        ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_3AA);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d(%d) B%d]Failed to m_updateResultShot. ret %d",
                    request->getKey(),
                    frame->getFrameCount(),
                    resultShot.shot.dm.request.frameCount,
                    buffer.index, ret);
            return ret;
        }

        if (request->getCallbackDone(EXYNOS_REQUEST_RESULT::CALLBACK_NOTIFY_ONLY) == false
            && request->getNumOfInputBuffer() < 1
#ifdef USE_DUAL_CAMERA
            && (!(frame->getFrameType() == FRAME_TYPE_TRANSITION ||
                    frame->getFrameType() == FRAME_TYPE_TRANSITION_SLAVE))
#endif
           ) {
            m_sendNotifyShutter(request);
            m_sendPartialMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_3AA);
        }

        frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                                        ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
    }

    if (frame->isComplete() == true) {
        ret = m_removeFrameFromList(&m_processList, &m_processLock, frame);
        if (ret < 0) {
            CLOGE("remove frame from processList fail, ret(%d)", ret);
        }

        CLOGV("frame complete, frameCount %d FrameType %d",
                frame->getFrameCount(), frame->getFrameType());
        frame = NULL;
    }

    return ret;
}

status_t ExynosCamera::m_handleYUVPhysStreamResult(ExynosCameraFrameSP_sptr_t frame,
                            ExynosCameraBuffer *buffer,
                            ExynosCameraRequestSP_sprt_t request,
                            int32_t camID,
                            camera3_buffer_status_t streamBufferState)
{
    status_t ret = NO_ERROR;
    int physCamId;

#ifndef USE_LCAM
    return ret;
#else
    if (!request) {
        CLOGE("request is NULL");
        return NO_ERROR;
    }

    for (size_t i = 0; i < request->getNumOfOutputBuffer(); i++) {
        int id = request->getStreamIdwithBufferIdx(i);

        switch (id % HAL_STREAM_ID_MAX) {
        case HAL_STREAM_ID_CALLBACK_PHYSICAL:
            physCamId = m_streamManager->getPhysCameraID(id);
            CLOGV("camID = %d physCamId = %d, streamID = %d", camID, physCamId, id);
            if (physCamId == camID) {
                //send result
                m_copyOnePortBuf2PhysStreamBuf(request, frame, buffer, id, streamBufferState);
                return NO_ERROR;
            }
            break;
        default:
            break;
        }
    }

    return ret;
#endif
}

status_t ExynosCamera::m_handlePreviewFrame(ExynosCameraFrameSP_sptr_t frame, int pipeId,
                                                ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    struct camera2_shot_ext *shot_ext = NULL;
    struct camera2_shot_ext resultShot = {0};
    uint32_t framecount = 0;
    int capturePipeId = -1;
    int sensorGyroPipeId = m_getSensorGyroPipeId();
    int streamId = -1;
    int dstPos = 0;
    bool isFrameComplete = false;
    ExynosCameraRequestSP_sprt_t request = NULL;
    ExynosCameraRequestSP_sprt_t curRequest = NULL;
    entity_buffer_state_t bufferState;
    camera3_buffer_status_t streamBufferState = CAMERA3_BUFFER_STATUS_OK;
    __unused int flipHorizontal = 0;
    frame_handle_components_t components;
    bool isOnlyPhysStreamsPresent = false;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    if (factory == NULL) {
        CLOGE("frame Factory is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);
    ExynosCameraActivityAutofocus *autoFocusMgr = components.activityControl->getAutoFocusMgr();

#ifdef USE_DUAL_CAMERA
    enum DUAL_PREVIEW_MODE dualPreviewMode = m_configurations->getDualPreviewMode();
    isOnlyPhysStreamsPresent = frame->getPhysStreamOnlyStatus();
#endif

    if (frame->isCompleteForResultUpdate() == false
#ifdef USE_DUAL_CAMERA
            && (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
       ) {
        request = m_requestMgr->getRunningRequest(frame->getFrameCount());
        if (request == NULL) {
            CLOGE("[F%d T%d]request is NULL. pipeId %d, resultState[%d, %d, %d]",
                    frame->getFrameCount(), frame->getFrameType(), pipeId,
                    frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL),
                    frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_BUFFER),
                    frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL));
        }
    }

#ifdef FPS_CHECK
    m_debugFpsCheck((enum pipeline)pipeId);
#endif

#ifdef SUPPORT_ME
    ret = m_handleMeBuffer(frame, factory->getNodeType(PIPE_ME));
    if (ret != NO_ERROR) {
        CLOGE("F%d] Failed to handle Me buffer, PipeId(%d)", frame->getFrameCount(), pipeId);
    }
#endif

    switch (pipeId) {
    case PIPE_FLITE:
        /* 1. Handle bayer buffer */
        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) != HW_CONNECTION_MODE_M2M) {
            android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):[F%d]PIPE_FLITE cannot come to %s when Flite3aaOtf. so, assert!!!!",
                    __FUNCTION__, __LINE__, frame->getFrameCount(), __FUNCTION__);
        }

        /* Notify ShotDone to mainThread */
        framecount = frame->getFrameCount();
#ifdef USE_DUAL_CAMERA
        if (frame->isSlaveFrame()) {
            m_slaveShotDoneQ->pushProcessQ(&frame);
        } else
#endif
        {
            m_shotDoneQ->pushProcessQ(&frame);
        }

        /* Return dummy-shot buffer */
        buffer.index = -2;

        ret = frame->getSrcBuffer(pipeId, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer for PIPE_FLITE. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        ret = frame->getSrcBufferState(pipeId, &bufferState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getSrcBufferState for PIPE_FLITE. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            CLOGE("[F%d B%d]Src buffer state is error for PIPE_FLITE.",
                    frame->getFrameCount(), buffer.index);

            if ((frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
                    == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED)
#ifdef USE_DUAL_CAMERA
                && frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE
#endif
                ) {
                if (request != NULL) {
                    ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to sendNotifyError. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                        return ret;
                    }
                }
            }
        }

        ret = m_bufferSupplier->putBuffer(buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to putBuffer for FLITE. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        /* Send the bayer buffer to 3AA Pipe */
        dstPos = factory->getNodeType(PIPE_VC0);
        buffer.index = -2;

        ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getDstBuffer for PIPE_VC0. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        ret = frame->getDstBufferState(pipeId, &bufferState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getDstBufferState for PIPE_VC0. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            CLOGE("[F%d B%d]Dst buffer state is error for PIPE_VC0.",
                    frame->getFrameCount(), buffer.index);

            if ((frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
                    == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED)
#ifdef USE_DUAL_CAMERA
                && frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE
#endif
                ) {
                if (request != NULL) {
                    ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to sendNotifyError. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                        return ret;
                    }
                }
            }
        }

        ////////////////////////////////////////////////
        // handling sensor gyro buffer
        if (frame->getRequest(sensorGyroPipeId) == true) {
            ret = m_handleSensorGyroBuffer(frame);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]m_handleSensorGyroBuffer() fail. sensorGyroPipeId %d",
                    frame->getFrameCount(), sensorGyroPipeId);
            }
        }

        ////////////////////////////////////////////////

        ret = m_setupEntity(PIPE_3AA, frame, &buffer, NULL);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to setupEntity for PIPE_3AA(PIPE_VC0). ret %d",
                     frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        factory->pushFrameToPipe(frame, PIPE_3AA);
        break;

    case PIPE_3AA:
        /* Notify ShotDone to mainThread */
        framecount = frame->getFrameCount();

        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_OTF) {
#ifdef USE_DUAL_CAMERA
            if (frame->isSlaveFrame()) {
                m_slaveShotDoneQ->pushProcessQ(&frame);
            } else
#endif
            {
                m_shotDoneQ->pushProcessQ(&frame);
            }
        }

        ret = frame->getSrcBuffer(pipeId, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer for PIPE_3AA. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        if (frame->getRequest(PIPE_BAYER_SYNC)) {
            // forcely complete the bayer sync pipe
            if (frame->getRequest(PIPE_VC0) == false && frame->getRequest(PIPE_3AC) == false) {
                ret = frame->setEntityState(PIPE_BAYER_SYNC, ENTITY_STATE_COMPLETE);
                if (ret < 0) {
                    CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
                            pipeId, ENTITY_STATE_COMPLETE, ret);
                }
            }
        }

        ret = frame->getSrcBufferState(pipeId, &bufferState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getSrcBufferState for PIPE_3AA. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            CLOGE("[F%d B%d]Src buffer state is error for PIPE_3AA. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            if ((frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
                    == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED)
#ifdef USE_DUAL_CAMERA
                && frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE
#endif
                ) {
                if (request != NULL) {
                    ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d] sendNotifyError fail. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }
            if (buffer.index >= 0) {
                CLOGD("[F%d B%d]Return 3AA Buffer.",
                        frame->getFrameCount(), buffer.index);

                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for 3AA. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
                }
            }

            /* Return 3AP buffer */
            dstPos = factory->getNodeType(PIPE_3AP);

            buffer.index = -2;

            ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                        pipeId, ret);
            }

            if (buffer.index < 0) {
                CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
            } else {
                CLOGD("[F%d B%d]Return 3AP Buffer.",
                        frame->getFrameCount(), buffer.index);
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for 3AA. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                }
            }

            /* Return VC0 buffer */
            if (frame->getRequest(PIPE_VC0) == true) {
                dstPos = factory->getNodeType(PIPE_VC0);

                buffer.index = -2;

                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
                } else {
                    CLOGD("[F%d B%d]Return VC0 Buffer.",
                            frame->getFrameCount(), buffer.index);
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for 3AA. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }

#ifdef SUPPORT_DEPTH_MAP
            /* Return VC1 buffer */
            if (frame->getRequest(PIPE_VC1) == true) {
                dstPos = factory->getNodeType(PIPE_VC1);

                buffer.index = -2;

                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
                } else {
                    CLOGD("[F%d B%d]Return VC1 Buffer.",
                            frame->getFrameCount(), buffer.index);
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for 3AA. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }
#endif

            /* Return 3AC buffer */
            if (frame->getRequest(PIPE_3AC) == true) {
                dstPos = factory->getNodeType(PIPE_3AC);

                buffer.index = -2;

                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
                } else {
                    CLOGD("[F%d B%d]Return 3AC Buffer.",
                            frame->getFrameCount(), buffer.index);
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for 3AA. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }

            /* Return 3AF buffer */
            if (frame->getRequest(PIPE_3AF) == true) {
                dstPos = factory->getNodeType(PIPE_3AF);

                buffer.index = -2;

                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
                } else {
                    CLOGD("[F%d B%d]Return 3AF Buffer.",
                            frame->getFrameCount(), buffer.index);
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for 3AA. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }

            frame->setFrameState(FRAME_STATE_SKIPPED);
            factory->pushFrameToPipe(frame, PIPE_ISP);
            break;
        }

        frame->setMetaDataEnable(true);
        shot_ext = (struct camera2_shot_ext *) buffer.addr[buffer.getMetaPlaneIndex()];
        components.parameters->updateMetaDataParam(shot_ext);

#ifdef USE_DUAL_CAMERA
        /* for only switching case */
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_SWITCHING
            || frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
            m_updateBeforeForceSwitchSolution(frame, pipeId);
        }
#endif

#ifdef USE_DUAL_CAMERA
#if 0
        // TODO: need to handle current disp cam type
        if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
            if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_MASTER
                && (current disp cam type) {
                struct camera2_shot_ext src_shot_ext;
                int32_t slaveCamId, slaveCamIdx;
                slaveCamIdx = m_getCurrentCamIdx(false, SUB_CAM);
                slaveCamId = m_camIdInfo.cameraId[slaveCamIdx];

                frame->getMetaData(&src_shot_ext);
                /* update slave's aeState to Master */
                if (m_parameters[slaveCamId]->getAeState() >= AE_STATE_INACTIVE) {
                    src_shot_ext.shot.dm.aa.aeState = (enum ae_state)(m_parameters[slaveCamId]->getAeState());
                }
                /* update slave's sceneDetectionInfo to Master */
                if (m_parameters[slaveCamId]->getSceneDetectIndex() >= SCENE_INDEX_INVALID) {
                    src_shot_ext.shot.udm.scene_index = (enum camera2_scene_index)m_parameters[slaveCamId]->getSceneDetectIndex();
                }
                frame->setMetaData(&src_shot_ext);
            } else if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE
                || frame->getFrameType() == FRAME_TYPE_PREVIEW_SLAVE) {
                /* AeState */
                components.parameters->storeAeState((int)(shot_ext->shot.dm.aa.aeState));
                /* SceneDetectionInfo - scene_index */
                components.parameters->storeSceneDetectIndex((int)(shot_ext->shot.udm.scene_index));
            }
        }
#endif
#endif

        ret = m_updateTimestamp(request, frame, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to update timestamp. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        /* Return dummy-shot buffer */
        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) != HW_CONNECTION_MODE_M2M) {
            CLOGV("[F%d(%d) B%d]Return 3AS Buffer.",
                    frame->getFrameCount(),
                    frame->getMetaFrameCount(),
                    buffer.index);

            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for 3AS. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }
        }

        /* Handle bayer buffer */
        if (frame->getRequest(PIPE_VC0) == true || frame->getRequest(PIPE_3AC) == true) {
            ret = m_handleBayerBuffer(frame, request, pipeId, frame->getRequest(PIPE_BAYER_SYNC));
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Handle bayer buffer failed. pipeId %d(%s) ret %d",
                        frame->getFrameCount(), pipeId,
                        (frame->getRequest(PIPE_VC0) == true) ? "PIPE_VC0" : "PIPE_3AC",
                        ret);
            }
        }

#if defined (SUPPORT_DEPTH_MAP) || defined (SUPPORT_PD_IMAGE)
#ifdef USE_DUAL_CAMERA
        if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
        {
            if (frame->getRequest(PIPE_VC1) == true) {
                ret = m_handleDepthBuffer(frame, request);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Handle deptg buffer failed. pipeId %d ret %d",
                             frame->getFrameCount(), pipeId, ret);
                }
            }
        }
#endif

        ////////////////////////////////////////////////
        // handling sensor gyro buffer
        if (frame->getRequest(sensorGyroPipeId) == true) {
            ret = m_handleSensorGyroBuffer(frame);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]m_handleSensorGyroBuffer() fail. sensorGyroPipeId %d",
                    frame->getFrameCount(), sensorGyroPipeId);
            }
        }

        ////////////////////////////////////////////////

        /* Return VRA buffer */
        if (frame->getRequest(PIPE_3AF) == true) {
#if defined(BOARD_CAMERA_EARLY_FD) && defined(USE_ALWAYS_FD_OFF)
#elif defined(USES_CAMERA_EXYNOS_VPL)
            if (frame->getRequest(PIPE_NFD) == false)

#endif
            {
                dstPos = factory->getNodeType(PIPE_3AF);
                buffer.index = -2;
                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
                } else {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for 3AF. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }

#ifdef USE_VRA_FD
            if (frame->getRequest(PIPE_VRA) == true) {
                    /* Send the 3AA downscaled Yuv buffer to VRA Pipe */

                    dstPos = factory->getNodeType(PIPE_3AF);
                    ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                    if (ret != NO_ERROR) {
                    CLOGE("Failed to getDst buffer, pipeId(%d), ret(%d)", PIPE_3AF, ret);
                    }

                    if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d) outport(%d)",
                            buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId, PIPE_3AF);

                    ret = frame->setSrcBufferState(PIPE_VRA, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                            frame->getFrameCount(), PIPE_VRA, ret);
                    }
                    } else {
                    ret = m_setupEntity(PIPE_VRA, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                PIPE_VRA, ret);
                    }
                    }

                    if (factory->checkPipeThreadRunning(PIPE_VRA) == false) {
                        factory->startThread(PIPE_VRA);
                    }
                    factory->pushFrameToPipe(frame, PIPE_VRA);
            }
#endif

#ifdef USES_CAMERA_EXYNOS_VPL
            /* Send the 3AA downscaled Yuv buffer also to NFD Pipe*/
            if (frame->getRequest(PIPE_NFD) == true) {
                CLOGV("[F%d B%d] srcPipeId(%d) -> dstPipeId(PIPE_NFD) ", frame->getFrameCount(), buffer.index, pipeId);

                dstPos = factory->getNodeType(PIPE_3AF);
                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);

                if (ret != NO_ERROR) {
                    CLOGE("Failed to getDst buffer, pipeId(%d), ret(%d)", PIPE_3AF, ret);
                }

                if (buffer.index < 0) {
                    ret = frame->setSrcBufferState(PIPE_NFD, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                frame->getFrameCount(), buffer.index, PIPE_NFD, ret);
                    }
                } else {
                    ret = m_setupEntity(PIPE_NFD, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to setSrcBuffer. PIPE_NFD, ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                        return ret;
                    }

                    camera2_stream *shot_stream = NULL;
                    ExynosRect cropRect;

                    // NFD src cropRect setting
                    shot_stream = (camera2_stream *)buffer.addr[buffer.getMetaPlaneIndex()];
                    cropRect.x = shot_stream->output_crop_region[0];
                    cropRect.y = shot_stream->output_crop_region[1];
                    cropRect.w = shot_stream->output_crop_region[2];
                    cropRect.h = shot_stream->output_crop_region[3];
                    cropRect.fullW = MAX_VRA_INPUT_WIDTH;
                    cropRect.fullH = MAX_VRA_INPUT_HEIGHT;
                    cropRect.colorFormat = m_parameters[m_cameraId]->getHW3AFdFormat();

                    CLOGV("[F%d] NFD src size: %d, %d, %d x %d",
                            frame->getFrameCount(), cropRect.x, cropRect.y, cropRect.w, cropRect.h);
                    ret = frame->setSrcRect(PIPE_NFD, cropRect);
                    if (ret < 0){
                        CLOGE("[F%d]Failed to setSrcRect. ret %d", frame->getFrameCount(), ret);
                    }

                }

                if (factory->checkPipeThreadRunning(PIPE_NFD) == false) {
                    factory->startThread(PIPE_NFD);
                }

                factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[PIPE_NFD], PIPE_NFD);
                factory->pushFrameToPipe(frame, PIPE_NFD);
            }
#endif
        } else {
#ifdef USES_CAMERA_EXYNOS_VPL
            if (frame->getRequest(PIPE_NFD) == true) {
                ret = frame->setEntityState(PIPE_NFD, ENTITY_STATE_COMPLETE);
                if (ret < 0) {
                    CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
                            pipeId, ENTITY_STATE_COMPLETE, ret);
                }
            }
#endif
        }
#ifdef USES_CAMERA_EXYNOS_VPL
        if (frame->getRequest(PIPE_NFD) == false) {
            frame_queue_t *pipeFrameDoneQ;
            ret = factory->getOutputFrameQToPipe(&pipeFrameDoneQ, PIPE_NFD);

            if (factory->checkPipeThreadRunning(PIPE_NFD) == true && pipeFrameDoneQ->getSizeOfProcessQ() == 0) {
                factory->stopThread(PIPE_NFD);
            }
        }
#endif

        if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
            /* Send the bayer buffer to 3AA Pipe */
            dstPos = factory->getNodeType(PIPE_3AP);

            ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                         pipeId, ret);
            }
            if (buffer.index < 0) {
                frame->setFrameState(FRAME_STATE_SKIPPED);
                CFLOGE(frame, "Invalid buffer index(%d), framecount(%d), type(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), frame->getFrameType(), pipeId);
            }

            ret = m_setupEntity(PIPE_ISP, frame, &buffer, NULL);
            if (ret != NO_ERROR) {
                CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                         PIPE_ISP, ret);
            }

            if (m_flagFirstPreviewTimerOn == true) {
                CLOGI("first frame(F%d(%d) T%d) 3AA DONE",
                        frame->getFrameCount(), frame->getMetaFrameCount(), frame->getFrameType());
            }

            if (frame->getRequest(PIPE_GMV) == true) {
                factory->pushFrameToPipe(frame, PIPE_GMV);
            } else {
                factory->pushFrameToPipe(frame, PIPE_ISP);
            }
            break;
        }

    case PIPE_ISP:
        if (pipeId == PIPE_ISP) {
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("Failed to getSrcBuffer. pipeId %d ret %d",
                        pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                    buffer.index, frame->getFrameCount(), pipeId);


            if ((frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
                    == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED)
#ifdef USE_DUAL_CAMERA
                && frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE
#endif
                ) {
                    if (request != NULL) {
                        ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                        if (ret != NO_ERROR) {
                            CLOGE("[F%d B%d] sendNotifyError fail. ret %d",
                                    frame->getFrameCount(), buffer.index, ret);
                            return ret;
                        }
                    }
                }
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for ISP. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    break;
                }
            }
        }

        if (m_flagFirstPreviewTimerOn == true) {
            CLOGI("first frame(F%d(%d)), type(%d) ISP DONE",
                    frame->getFrameCount(), frame->getMetaFrameCount(), frame->getFrameType());
        }

        if (frame->getRequest(PIPE_ISPC) == true) {
            ret = frame->getDstBuffer(pipeId, &buffer, factory->getNodeType(PIPE_ISPC));
            if (ret != NO_ERROR) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                        pipeId, ret);
            } else if (buffer.index < 0) {
                CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            } else {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for ISP. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    break;
                }
            }
        }

        if (components.parameters->getHwConnectionMode(PIPE_ISP, PIPE_MCSC) == HW_CONNECTION_MODE_M2M) {
            break;
        }

    case PIPE_MCSC:
    {
        if (pipeId == PIPE_MCSC) {
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret < 0) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                         pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    break;
                }
            }

            CLOGV("Return MCSC Buffer. driver->framecount %d hal->framecount %d",
                    getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                    frame->getFrameCount());
        }

#ifdef USE_DUAL_CAMERA
        bool isFusionReady = true;

        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION && frame->getRequest(PIPE_SYNC) == true) {
            capturePipeId = (frame->getOnePortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;

            ret = frame->getDstBuffer(pipeId, &buffer, factory->getNodeType(capturePipeId));
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                        pipeId, ret);
            }

            if (buffer.index < 0) {
                CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d) OnePortId(%d) capturePipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId, frame->getOnePortId(), capturePipeId);
                frame->setFrameState(FRAME_STATE_SKIPPED);
            } else {
                if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
                    if (frame->getRequest(PIPE_FUSION) == true) {
                        ret = m_setSrcBuffer(PIPE_FUSION, frame, &buffer);
                        if (ret != NO_ERROR) {
                            CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                    PIPE_FUSION, ret);
                        }
                    } else {
                        ret = frame->getSrcBufferState(PIPE_FUSION, &bufferState);
                        if (ret < 0) {
                            CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", PIPE_FUSION, ret);
                            return ret;
                        }

                        if (bufferState == ENTITY_BUFFER_STATE_REQUESTED) {
                            ret = m_setSrcBuffer(PIPE_FUSION, frame, &buffer);
                            if (ret < 0) {
                                CLOGE("m_setSrcBuffer fail, pipeId(%d), ret(%d)", PIPE_FUSION, ret);
                                return ret;
                            }
                        }

                        frame->setFrameState(FRAME_STATE_SKIPPED);
                    }
                } else {
                    ret = frame->setSrcBuffer(PIPE_SYNC, buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                                PIPE_SYNC, ret);
                    }
                }
            }

            // HACK: try to wait fusion pipe is ready
            // TODO: use frameFactory starting first
            {
                int count = 100;
                ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
                while (count-- && !(isFusionReady = factory->checkPipeStarted(PIPE_FUSION))) {
                    usleep(500); /* 0.5ms */
                }

                if (isFusionReady == false) {
                    CFLOGE(frame, "not ready for fusion pipe..");
                    frame->setFrameState(FRAME_STATE_SKIPPED);
                } else {
                    factory->pushFrameToPipe(frame, PIPE_SYNC);
                }
            }
        }
#endif

        if (frame->getFrameState() == FRAME_STATE_SKIPPED) {
            CLOGW("[F%d T%d] Skipped frame. Force callback result. frameCount %d",
                frame->getFrameCount(), frame->getFrameType(), frame->getFrameCount());
#ifdef USE_DUAL_CAMERA
            if (frame->getRequest(PIPE_SYNC) == false || isFusionReady == false)
#endif
            {
                if (request != NULL) {
                    ret = m_sendForceYuvStreamResult(request, frame, factory);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to forceResultCallback. frameCount %d", frame->getFrameCount());
                        return ret;
                    }
                } else {
                    CLOGE("[F%d FT%d]request is null. All buffers should be putBuffer!!!",
                            frame->getFrameCount(), frame->getFrameType());
                }
            }

            /* Return internal buffers */
            m_handlePreviewFrame_vendor_handleBuffer(request, frame, pipeId, factory, components, ret);

            /* Return VRA buffer */
            if ((frame->getRequest(PIPE_VRA) == true) &&
				(frame->getRequest(PIPE_MCSC5) == true)) {
                ExynosCameraBuffer srcBuffer;

                srcBuffer.index = -2;
                ret = frame->getDstBuffer(pipeId, &srcBuffer, factory->getNodeType(PIPE_MCSC5));
                if (ret != NO_ERROR) {
                    CLOGE("Failed to getDst buffer, pipeId(%d), ret(%d)", PIPE_MCSC5, ret);
                } else {
                    if (srcBuffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(srcBuffer);
                        if (ret != NO_ERROR) {
                            CLOGE("Failed to putBuffer. pipeId(%d), ret(%d)", PIPE_MCSC5, ret);
                        }
                    }
                }
            }

#ifdef USE_DUAL_CAMERA
            if (frame->getRequest(PIPE_SYNC) == false || isFusionReady == false)
#endif
            {
                frame->setFrameState(FRAME_STATE_COMPLETE);
                if (frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
                    == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED) {
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                                                    ExynosCameraFrame::RESULT_UPDATE_STATUS_READY);
                    pipeId = frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL);
                }
            }
        } else {
            if (m_flagFirstPreviewTimerOn == true) {
                m_firstPreviewTimer.stop();
                m_flagFirstPreviewTimerOn = false;

                CLOGD("m_firstPreviewTimer stop");

                CLOGD("============= First Preview time ==================");
                CLOGD("= configureStream ~ first frame  : %d msec", (int)m_firstPreviewTimer.durationMsecs());
                CLOGD("===================================================");
                autoFocusMgr->displayAFInfo();
#ifdef TIME_LOGGER_LAUNCH_ENABLE
                TIME_LOGGER_UPDATE(m_cameraId, 0, 0, CUMULATIVE_CNT, FIRST_PREVIEW, 0);
                TIME_LOGGER_SAVE(m_cameraId);
#endif
            }

#ifdef USE_DUAL_CAMERA
            if (frame->getRequest(PIPE_SYNC) == false)
#endif
            {
                /* set N-1 zoomRatio in Frame */
                if (m_configurations->getAppliedZoomRatio() < 1.0f) {
                    frame->setAppliedZoomRatio(frame->getZoomRatio());
                } else {
                    frame->setAppliedZoomRatio(m_configurations->getAppliedZoomRatio());
                }

                m_configurations->setAppliedZoomRatio(frame->getZoomRatio());
            }

            /* PIPE_MCSC 0, 1, 2 */
            for (int i = 0; i < m_streamManager->getTotalYuvStreamCount(); i++) {
                capturePipeId = PIPE_MCSC0 + i;
                if (frame->getRequest(capturePipeId) == true) {
                    streamId = m_streamManager->getYuvStreamId(i);
#ifdef USES_COMBINE_PLUGIN
                    int pluginPipeId = PIPE_PLUGIN1;

                    // Combine PlugIn
                    // 1. Check if Combine PlugIn Request is true
                    // 2. In case of Only Preview or Recording Stream port's buffer
                    //    ex. Normal
                    //        <preview port>   -> [PlugIn] -> preview buffer -> [GSC] -> callback buffer
                    //    ex. Recording w/o EIS
                    //        <preview port>   -> [PlugIn] -> preview buffer
                    //        <recording port> -> [PlugIn] -> recording buffer -> [GSC] -> preview buffer
                    //    ex. Recording w/  EIS
                    //        <preview port>   -> [PlugIn] -> internal buffer -> [EIS] -> preview buffer
                    //        <recording port> -> [PlugIn] -> internal buffer -> [EIS] -> preview buffer
                    //                                                                 -> recording buffer
                    //    * callback buffer will be processed from plugIn's output

                    if ((frame->getRequest(pluginPipeId) == true)
#ifndef SUPPORT_PREVIEW_PLUGIN_YUV_STREAM
                        && ((streamId % HAL_STREAM_ID_MAX) != HAL_STREAM_ID_CALLBACK)
#endif
                           ) {
                        if (frame->getRequest(capturePipeId) == true) {
                            ret = m_handleCombinePreviewFrame(frame, factory,
                                                            pipeId, factory->getNodeType(capturePipeId),
                                                            pluginPipeId);
                            if (ret != NO_ERROR) {
                                CLOGE("failed to m_handleCombinePreviewFrame, ret(%d)", ret);
                            }
                        }
                        continue;
                    }
#endif
                    if ((m_configurations->getMode(CONFIGURATION_YSUM_RECORDING_MODE) == true)
                            && ((m_parameters[m_cameraId]->getYsumPordId() % ExynosCameraParameters::YUV_MAX) == i)
                            && (request != NULL)) {
                        /* Update YSUM value for YSUM recording */
                        ret = m_updateYsumValue(frame, request);
                        if (ret != NO_ERROR) {
                            CLOGE("failed to setYsumValue, ret(%d)", ret);
                            return ret;
                        }
                    }

#ifdef USE_DUAL_CAMERA
                    if (components.parameters->isAlternativePreviewPortId(i)
                        && frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                        streamId = HAL_STREAM_ID_PREVIEW;
                    }

                    if (frame->getRequest(PIPE_SYNC) == true) {
                        /* In case of dual camera, send preview stream after pipe_fusion */
                        continue;
                    } else
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
                    if (frame->getRequest(PIPE_SW_MCSC) == true) {
                        int onePipeId = (m_configurations->getOnePortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                        if (capturePipeId == onePipeId) {
                            ret = m_handleSwmcscPreviewFrame(frame, factory, pipeId,
                                        factory->getNodeType(onePipeId), PIPE_SW_MCSC);
                            if (ret != NO_ERROR) {
                                CLOGE("failed to m_handleSwmcscPreviewFrame, ret(%d)", ret);
                            }
                        }
                        //do not call sendYuvStreamResult for delay to update servie buffer after MCSC.
                        continue;
                    } else
#endif
#ifdef SUPPORT_HW_GDC
                    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_GDC) == true
                        && (streamId % HAL_STREAM_ID_MAX) == HAL_STREAM_ID_VIDEO) {
                        m_gdcQ->pushProcessQ(&frame);
                    } else
#endif
#ifdef USE_CLAHE_PREVIEW
                    if ((m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true)
                            && (m_parameters[m_cameraId]->getRecordingPortId() == i)) {

                        ret = frame->getDstBuffer(pipeId, &buffer, factory->getNodeType(capturePipeId));
                        if (ret != NO_ERROR || buffer.index < 0) {
                            CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                                    capturePipeId, buffer.index, frame->getFrameCount(), ret);
                            return ret;
                        }

                        ret = m_setupEntity(PIPE_CLAHE, frame, &buffer, NULL);
                        if (ret != NO_ERROR) {
                            CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                    PIPE_CLAHE, ret);
                        }

                        factory->pushFrameToPipe(frame, PIPE_CLAHE);
                    } else
#else
#ifdef USES_SW_VDIS
                    if ( (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0)
                            && ((streamId % HAL_STREAM_ID_MAX) == HAL_STREAM_ID_VIDEO)) {
                        if (m_exCameraSolutionSWVdis != NULL) {
                            ret = m_exCameraSolutionSWVdis->handleFrame(ExynosCameraSolutionSWVdis::SOLUTION_PROCESS_PRE,
                                                                        frame, pipeId, capturePipeId, factory);
                            if (ret == NO_ERROR) {
                                /* Push frame to VDIS pipe */
                                int vdisPipeId = m_exCameraSolutionSWVdis->getPipeId();
                                factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[vdisPipeId], vdisPipeId);
                                factory->pushFrameToPipe(frame, vdisPipeId);

                                if (factory->checkPipeThreadRunning(vdisPipeId) == false) {
                                    factory->startThread(vdisPipeId);
                                }

                                //return ret;
                                //continue;
                            }
                        } else {
                            /* NOP : fall through */
                        }
                    }else
#endif
#endif
                    {
                        ret = frame->getDstBuffer(pipeId, &buffer, factory->getNodeType(capturePipeId));
                        if (ret != NO_ERROR || buffer.index < 0) {
                            CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                                    capturePipeId, buffer.index, frame->getFrameCount(), ret);
                            return ret;
                        }

                        ret = frame->getDstBufferState(pipeId, &bufferState, factory->getNodeType(capturePipeId));
                        if (ret < 0) {
                            CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                            return ret;
                        }

                        if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                            streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                            CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                                    buffer.index, frame->getFrameCount(), pipeId);
                        }

#ifdef USE_DUAL_CAMERA
                        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_SWITCHING
                            || frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                            m_updateAfterForceSwitchSolution(frame);
                        }
#endif

                        if (request != NULL) {
                            request->setStreamBufferStatus(streamId, streamBufferState);
                        }

                        {
                            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                                CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                                        buffer.index, frame->getFrameCount(), pipeId);
                            }

                            if (request != NULL) {
                                request->setStreamBufferStatus(streamId, streamBufferState);

                                {
#ifdef USE_DUAL_CAMERA
                                    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
                                        && frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE
                                        && frame->getRequest(PIPE_GSC) == true) {
                                        if (request->hasStream(streamId) == true) {
                                            /* Use GSC for preview while run */
                                            ret = m_setupPreviewGSC(frame, request, pipeId, capturePipeId, true, PP_SCENARIO_NONE);
                                            if (ret != NO_ERROR) {
                                                CLOGE("m_setupPreviewGSC(Pipe:%d) failed, Fcount(%d), ret(%d)",
                                                        pipeId, frame->getFrameCount(), ret);
                                                return ret;
                                            }

                                            if (m_gscPreviewCbThread->isRunning() == false) {
                                                m_gscPreviewCbThread->run();
                                            }

                                            factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[PIPE_GSC], PIPE_GSC);
                                            factory->pushFrameToPipe(frame, PIPE_GSC);
                                            if (factory->checkPipeThreadRunning(PIPE_GSC) == false) {
                                                factory->startThread(PIPE_GSC);
                                            }
                                        }
                                    } else
#endif
                                    {
                                        ////////////////////////////////////////////////
                                        // when some condtion, skip preview
                                        bool skipFlag = frame->isSkipPreview();

                                        ////////////////////////////////////////////////

                                        ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, skipFlag,
                                                frame->getStreamTimestamp(), frame->getParameters());
                                        if (ret != NO_ERROR) {
                                            CLOGE("Failed to resultCallback."
                                                    " pipeId %d bufferIndex %d frameCount %d streamId %d ret %d",
                                                    capturePipeId, buffer.index, frame->getFrameCount(), streamId, ret);
                                            return ret;
                                        }
                                    }
                                }
                            } else {
                                if (buffer.index >= 0) {
                                    ret = m_bufferSupplier->putBuffer(buffer);
                                    if (ret !=  NO_ERROR) {
                                        CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                                frame->getFrameCount(), buffer.index, pipeId, ret);
                                    }
                                }
                            }
                        }
                    }
                }
            }

            if (frame->getRequest(PIPE_MCSC_JPEG) == true) {
                ret = m_handleYuvCaptureFrame(frame);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_handleYuvCaptureFrame. pipeId %d ret %d", pipeId, ret);
                }
            }

            if (components.parameters->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M) {
                if (frame->getRequest(PIPE_VRA) == true) {
                    if (frame->getRequest(PIPE_MCSC5) == true) {
                        /* Send the Yuv buffer to VRA Pipe */
                        dstPos = factory->getNodeType(PIPE_MCSC5);

                        ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                        if (ret < 0) {
                            CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                                    pipeId, ret);
                        }

                        if (buffer.index < 0) {
                            CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                                    buffer.index, frame->getFrameCount(), pipeId);

                            ret = frame->setSrcBufferState(PIPE_VRA, ENTITY_BUFFER_STATE_ERROR);
                            if (ret != NO_ERROR) {
                                CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                        frame->getFrameCount(), PIPE_VRA, ret);
                            }
                        } else {
                            ret = m_setupEntity(PIPE_VRA, frame, &buffer, NULL);
                            if (ret != NO_ERROR) {
                                CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                        PIPE_VRA, ret);
                            }
                        }

#if 0 /* test dump code */
                        {
                            bool bRet;
                            char filePath[70];

                            memset(filePath, 0, sizeof(filePath));
                            snprintf(filePath, sizeof(filePath), "/data/camera/VRA_Input_FT%d_F%d.nv21",
                                frame->getFrameType(), frame->getFrameCount());

                            if (frame->getFrameCount()%10 == 0) {
                                bRet = dumpToFile((char *)filePath, buffer.addr[0], buffer.size[0]);
                                if (bRet != true)
                                    CLOGE("couldn't make a raw file");
                            }
                        }
#endif
                        if (factory->checkPipeThreadRunning(PIPE_VRA) == false) {
                            factory->startThread(PIPE_VRA);
                        }
                        factory->pushFrameToPipe(frame, PIPE_VRA);

#ifdef USES_CAMERA_EXYNOS_VPL
                        /* Send the 3AA downscaled Yuv buffer also to NFD Pipe*/
                        if (frame->getRequest(PIPE_NFD) == true) {
                            dstPos = factory->getNodeType(PIPE_MCSC5);

                            ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                            if (ret < 0) {
                                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", pipeId, ret);
                            }

                            if (buffer.index < 0) {
                                CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                                        buffer.index, frame->getFrameCount(), pipeId);

                                ret = frame->setSrcBufferState(PIPE_NFD, ENTITY_BUFFER_STATE_ERROR);
                                if (ret != NO_ERROR) {
                                    CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                            frame->getFrameCount(), PIPE_NFD, ret);
                                }
                            } else {
                                ret = m_setupEntity(PIPE_NFD, frame, &buffer, NULL);
                                if (ret != NO_ERROR) {
                                    CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                            PIPE_NFD, ret);
                                }
                            }

                            camera2_stream *shot_stream = NULL;
                            ExynosRect cropRect;

                            // NFD src cropRect setting
                            shot_stream = (camera2_stream *)buffer.addr[buffer.getMetaPlaneIndex()];
                            cropRect.x = shot_stream->output_crop_region[0];
                            cropRect.y = shot_stream->output_crop_region[1];
                            cropRect.w = shot_stream->output_crop_region[2];
                            cropRect.h = shot_stream->output_crop_region[3];
                            cropRect.fullW = shot_stream->output_crop_region[2];
                            cropRect.fullH = shot_stream->output_crop_region[3];
                            cropRect.colorFormat = m_parameters[m_cameraId]->getHwVraInputFormat();

                            CLOGV("[F%d] NFD src size: %d, %d, %d x %d",
                                    frame->getFrameCount(), cropRect.x, cropRect.y, cropRect.w, cropRect.h);
                            ret = frame->setSrcRect(PIPE_NFD, cropRect);
                            if (ret < 0){
                                CLOGE("[F%d]Failed to setSrcRect. ret %d", frame->getFrameCount(), ret);
                            }

                            if (factory->checkPipeThreadRunning(PIPE_NFD) == false) {
                                factory->startThread(PIPE_NFD);
                            }

                            factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[PIPE_NFD], PIPE_NFD);
                            factory->pushFrameToPipe(frame, PIPE_NFD);
                        } else {
                            ret = frame->setEntityState(PIPE_NFD, ENTITY_STATE_COMPLETE);
                            if (ret < 0) {
                                CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
                                        pipeId, ENTITY_STATE_COMPLETE, ret);
                            }
                        }
#endif
                    } else {
                        int curNumRequest = frame->getNumRequestPipe();
                        frame->setRequest(PIPE_VRA, false);
                        frame->setNumRequestPipe(--curNumRequest);
                    }
                }
            }
        }
        break;
    }
#ifdef USE_CLAHE_PREVIEW
    case PIPE_CLAHE:
        if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
            if (pipeId == PIPE_CLAHE) {
                ret = frame->getSrcBuffer(pipeId, &buffer);
                if (ret < 0) {
                    CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                    return ret;
                }

                ret = frame->getSrcBufferState(pipeId, &bufferState);
                if (ret < 0) {
                    CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }

                if (buffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                        break;
                    }
                }
            }

            int capturePipeId = PIPE_CLAHEC;
            int streamId = HAL_STREAM_ID_VIDEO;

#ifdef USES_SW_VDIS
            if ( (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0)
                    && ((streamId % HAL_STREAM_ID_MAX) == HAL_STREAM_ID_VIDEO)) {
                if (m_exCameraSolutionSWVdis != NULL) {
                    ret = m_exCameraSolutionSWVdis->handleFrame(ExynosCameraSolutionSWVdis::SOLUTION_PROCESS_PRE,
                            frame, pipeId, capturePipeId, factory);
                    if (ret == NO_ERROR) {
                        /* Push frame to VDIS pipe */
                        int vdisPipeId = m_exCameraSolutionSWVdis->getPipeId();
                        factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[vdisPipeId], vdisPipeId);
                        factory->pushFrameToPipe(frame, vdisPipeId);

                        if (factory->checkPipeThreadRunning(vdisPipeId) == false) {
                            factory->startThread(vdisPipeId);
                        }

                        //return ret;
                        //continue;
                    }
                } else {
                    /* NOP : fall through */
                }
            } else
#endif
            {
                ret = frame->getDstBuffer(pipeId, &buffer, factory->getNodeType(capturePipeId));
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                            capturePipeId, buffer.index, frame->getFrameCount(), ret);
                    return ret;
                }

                ret = frame->getDstBufferState(pipeId, &bufferState, factory->getNodeType(capturePipeId));
                if (ret < 0) {
                    CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }

                if (request != NULL) {
                    request->setStreamBufferStatus(streamId, streamBufferState);
                }

                {
                    if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                        streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                        CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                                buffer.index, frame->getFrameCount(), pipeId);
                    }

                    if (request != NULL) {
                        request->setStreamBufferStatus(streamId, streamBufferState);
                        {
                            ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, frame->isSkipPreview(),
                                    frame->getStreamTimestamp(), frame->getParameters());
                            if (ret != NO_ERROR) {
                                CLOGE("Failed to resultCallback."
                                        " pipeId %d bufferIndex %d frameCount %d streamId %d ret %d",
                                        capturePipeId, buffer.index, frame->getFrameCount(), streamId, ret);
                                return ret;
                            }
                        }
                    } else {
                        if (buffer.index >= 0) {
                            ret = m_bufferSupplier->putBuffer(buffer);
                            if (ret !=  NO_ERROR) {
                                CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                        frame->getFrameCount(), buffer.index, pipeId, ret);
                            }
                        }
                    }
                }
            }
        }
        break;
#endif
    case PIPE_GMV:
        ret = frame->getSrcBuffer(pipeId, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d ret %d",
                    frame->getFrameCount(), buffer.index, pipeId, ret);
            return ret;
        }

        ret = frame->getSrcBufferState(pipeId, &bufferState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getSrcBufferState. pipeId %d ret %d",
                    frame->getFrameCount(), buffer.index, pipeId, ret);
            /* continue */
        }

        ret = m_bufferSupplier->putBuffer(buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to putBuffer for PIPE_GMV. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            /* continue */
        }

        factory->pushFrameToPipe(frame, PIPE_ISP);
        break;
    case PIPE_VRA:
        if (pipeId == PIPE_VRA) {
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("Failed to getSrcBuffer. pipeId %d ret %d",
                        pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

#ifdef SUPPORT_HFD
            if (frame->getRequest(PIPE_HFD) == true) {
                if (buffer.index < 0 || bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    ret = frame->setSrcBufferState(PIPE_HFD, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                frame->getFrameCount(), buffer.index, PIPE_HFD, ret);
                    }
                } else {
                    ret = m_setupEntity(PIPE_HFD, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to setSrcBuffer. PIPE_HFD, ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                        return ret;
                    }
                }

                factory->pushFrameToPipe(frame, PIPE_HFD);
            } else
#endif
            {
                if (buffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for VRA. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                } else {
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }
            }

#ifdef USE_DUAL_CAMERA
            if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
                /* already this frame was completed in sync pipe */
                return ret;
            }
#endif
        }
        break;
    case PIPE_GDC:
        if (pipeId == PIPE_GDC) {
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret < 0) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                        pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    break;
                }
            }

            CLOGV("Return GDC Buffer. driver->framecount %d hal->framecount %d",
                    getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                    frame->getFrameCount());
        }

        if (frame->getRequest(pipeId) == true) {
            streamId = HAL_STREAM_ID_VIDEO;

            ret = frame->getDstBuffer(pipeId, &buffer);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getDstBuffer. pipeId %d ret %d",
                        frame->getFrameCount(), buffer.index,
                        pipeId, ret);
                return ret;
            }

            ret = frame->getDstBufferState(pipeId, &bufferState);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to getDstBufferState. pipeId %d ret %d",
                        frame->getFrameCount(),
                        pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("[F%d B%d]DstBufferState is ERROR. pipeId %d",
                        frame->getFrameCount(), buffer.index,
                        pipeId);
            }

            if (request != NULL) {
                request->setStreamBufferStatus(streamId, streamBufferState);

                ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, frame->isSkipPreview(),
                                            frame->getStreamTimestamp(), frame->getParameters());
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d B%d S%d]Failed to sendYuvStreamResult. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, streamId,
                            ret);
                    return ret;
                }
            } else {
                if (buffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret !=  NO_ERROR) {
                        CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                frame->getFrameCount(), buffer.index, pipeId, ret);
                    }
                }
            }
        }
        break;

#ifdef SUPPORT_HFD
    case PIPE_HFD:
        entity_state_t entityState;
        ret = frame->getSrcBuffer(pipeId, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d ret %d",
                    frame->getFrameCount(), buffer.index, pipeId, ret);
            return ret;
        }

        ret = frame->getSrcBufferState(pipeId, &bufferState);
        if (ret < 0) {
            CLOGE("[F%d B%d]getSrcBufferState fail. pipeId %d, ret %d",
                    frame->getFrameCount(), buffer.index, pipeId, ret);
            return ret;
        }

        if (buffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for HFD. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                break;
            }
        }

        ret = frame->getEntityState(pipeId, &entityState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to getEntityState. pipeId %d",
                    frame->getFrameCount(), pipeId);
            break;
        }

        if (entityState == ENTITY_STATE_FRAME_DONE) {
            ret = m_updateFDAEMetadata(frame);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to updateFDAEMetadata. ret %d",
                        frame->getFrameCount(), ret);
                /* continue */
            }
        }

        break;
#endif

#ifdef USES_CAMERA_EXYNOS_VPL
    case PIPE_NFD:
        {
#if !defined(USE_VRA_FD)
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret < 0) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                         pipeId, ret);
                break;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                break;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for NFD. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    break;
                }
            }

            CLOGV("Return NFD Buffer. driver->framecount %d hal->framecount %d",
                    getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                    frame->getFrameCount());
#endif

            if (bufferState != ENTITY_BUFFER_STATE_ERROR) {
                entity_state_t entityState = ENTITY_STATE_FRAME_DONE;
                ret = frame->getEntityState(pipeId, &entityState);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to getEntityState. pipeId %d",
                            frame->getFrameCount(), pipeId);
                    break;
                }

                if (entityState == ENTITY_STATE_FRAME_DONE) {
                    ret = m_updateNFDInfo(frame);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to updateNFDInfo. ret %d", frame->getFrameCount(), ret);
                    }
                    ret = m_updateFaceDetectMeta(frame);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to m_updateFaceDetectMeta. ret %d", frame->getFrameCount(), ret);
                    }
                }
            }
        }
        break;
#endif

#ifdef USE_DUAL_CAMERA
    case PIPE_BAYER_SYNC:
    {
        ret = m_handleBayerBuffer(frame, request, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Handle bayer buffer failed. pipeId %d(%s) ret %d",
                    frame->getFrameCount(), pipeId,
                    (frame->getRequest(PIPE_VC0) == true) ? "PIPE_VC0" : "PIPE_3AC",
                    ret);
        }
        break;
    }

    case PIPE_SYNC:
        {
            int pipeId_next = -1;

            if (frame->getFrameState() == FRAME_STATE_SKIPPED
                && dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                ExynosCameraBuffer dstBuffer;
                int srcpipeId = -1;
                dstBuffer.index = -2;

                if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
                    srcpipeId = PIPE_SYNC;
                } else {
                    srcpipeId = PIPE_FUSION;
                }

                ret = frame->getSrcBuffer(srcpipeId, &dstBuffer);
                if (ret != NO_ERROR) {
                    CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                            srcpipeId, ret);
                }

                if (dstBuffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(dstBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for HFD. ret %d",
                                frame->getFrameCount(), dstBuffer.index, ret);
                    }
                }

                if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
                    if (request != NULL) {
                        ret = m_sendForceYuvStreamResult(request, frame, factory);
                        if (ret != NO_ERROR) {
                            CLOGE("Failed to forceResultCallback. frameCount %d", frame->getFrameCount());
                            return ret;
                        }
                    } else {
                        CLOGE("[F%d]request is null. All buffers should be putBuffer!!!",
                                frame->getFrameCount());
                    }

                    // return slave buffer
                    dstBuffer.index = -2;
                    ret = frame->getDstBuffer(pipeId, &dstBuffer);
                    if (dstBuffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(dstBuffer);
                        if (ret != NO_ERROR) {
                            CFLOGE(frame, "Failed to putBuffer. ret %d", ret);
                        }
                    }

                    /* Return internal buffers */
                    if (frame->getInternalBufTagPipeId() >= 0) {
                        ExynosCameraBuffer dstBuffer;
                        int nodePipeId = PIPE_FUSION;

                        dstBuffer.index = -2;

                        ret = frame->getDstBuffer(nodePipeId, &dstBuffer, factory->getNodeType(nodePipeId));
                        if (ret != NO_ERROR) {
                            CLOGE("Failed to getDst buffer, pipeId(%d), ret(%d)", pipeId, ret);
                        } else {
                            if (dstBuffer.index >= 0) {
                                ret = m_bufferSupplier->putBuffer(dstBuffer);
                                if (ret != NO_ERROR) {
                                    CLOGE("Failed to putBuffer. pipeId(%d), ret(%d)", pipeId, ret);
                                }
                            }
                        }
                    }

                    frame->setFrameState(FRAME_STATE_COMPLETE);
                    if (frame->getStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL)
                        == ExynosCameraFrame::RESULT_UPDATE_STATUS_REQUIRED) {
                        frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                                                        ExynosCameraFrame::RESULT_UPDATE_STATUS_READY);
                        pipeId = frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL);
                    }
                } else {
                    /* my life is over anymore in dual slave frame */
                    frame->setFrameState(FRAME_STATE_COMPLETE);
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                            ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_BUFFER,
                            ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                            ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                }
                break;
            }

            if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_MASTER) {
                if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
                    pipeId_next = PIPE_FUSION;

                    if (frame->getFrameState() != FRAME_STATE_SKIPPED) {
                        buffer.index = -2;
                        ret = frame->getDstBuffer(pipeId, &buffer);
                        if (buffer.index < 0) {
                            CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                                    buffer.index, frame->getFrameCount(), pipeId);
                        } else {
                            ret = frame->setSrcBuffer(pipeId_next, buffer, OUTPUT_NODE_2);
                            if (ret != NO_ERROR) {
                                CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)", pipeId_next, ret);
                            }
                        }
                    }
                }
            } else if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_SLAVE) {
                if (frame->getFrameState() == FRAME_STATE_SKIPPED) {
                    if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                        capturePipeId = (frame->getOnePortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                    }

                    buffer.index = -2;
                    ret = frame->getDstBuffer(PIPE_ISP, &buffer, factory->getNodeType(capturePipeId));
                    if (ret != NO_ERROR) {
                        CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", PIPE_ISP, ret);
                    }

                    if (buffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret != NO_ERROR) {
                            CLOGE("[F%d B%d]Failed to putBuffer for PIPE_SYNC. ret %d",
                                    frame->getFrameCount(), buffer.index, ret);
                        }
                    }
                }

                /* my life is over anymore in dual slave frame */
                frame->setFrameState(FRAME_STATE_COMPLETE);
                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                        ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_BUFFER,
                        ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                        ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                break;
            } else if (frame->getFrameType() == FRAME_TYPE_PREVIEW) {
                pipeId_next = PIPE_FUSION;
            } else if(frame->getFrameType() == FRAME_TYPE_PREVIEW_SLAVE) {
                /* main(master) frame factory only have pipe fusion.
                you should be connect main(master) frame factory about all frame type. */
                factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
                pipeId_next = PIPE_FUSION;
            }

            if (pipeId_next == PIPE_FUSION) {
                ret = m_updateSizeBeforeDualFusion(frame, pipeId);
                if (ret != NO_ERROR) {
                    CLOGE("m_updateSizeBeforeDualFusion(framecount(%d), pipeId(%d)", frame->getFrameCount(), pipeId);
                }

#ifdef USE_DUAL_CAMERA
                /* Check Condition for Dual Camera*/
                if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                    m_updateBeforeDualSolution(frame, pipeId_next);
                }
#endif
            }

            if (pipeId_next >= 0) {
                factory->pushFrameToPipe(frame, pipeId_next);
            }
        }
        break;

    case PIPE_FUSION:
        if (pipeId == PIPE_FUSION) {

            int32_t slaveCamId, slaveCamIdx;
            slaveCamIdx = m_getCurrentCamIdx(false, SUB_CAM);
            slaveCamId = m_camIdInfo.cameraId[slaveCamIdx];

            /* OUTPUT_NODE_1 */
            buffer.index = -2;
            ret = frame->getSrcBuffer(pipeId, &buffer, OUTPUT_NODE_1);
            if (ret < 0) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                         pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            m_configurations->setDualDisplayCameraId(frame->getDisplayCameraId());
            request->setDisplayCameraId(frame->getDisplayCameraId());
            m_handleYUVPhysStreamResult(frame, &buffer, request,
                        slaveCamId, streamBufferState);

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                }
            }

            /* OUTPUT_NODE_2 */
            buffer.index = -2;
            ret = frame->getSrcBuffer(pipeId, &buffer, OUTPUT_NODE_2);
            if (ret < 0) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                         pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            m_handleYUVPhysStreamResult(frame, &buffer, request,
                        m_camIdInfo.cameraId[0], streamBufferState);

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                }
            }

#ifdef USE_DUAL_CAMERA
            m_updateAfterDualSolution(frame);
#endif

#if 0
            CLOGV("Return FUSION Buffer. driver->framecount %d hal->framecount %d",
                    getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                    frame->getFrameCount());
#endif
        }

#ifdef USES_SW_VDIS
        if (m_exCameraSolutionSWVdis != NULL && frame->getRequest(PIPE_VDIS)) {
            int capturePipeId = 0;
            ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
            ret = m_exCameraSolutionSWVdis->handleFrame(ExynosCameraSolutionSWVdis::SOLUTION_PROCESS_PRE,
                    frame, pipeId, capturePipeId, factory);
            if (ret == NO_ERROR) {
                /* Push frame to VDIS pipe */
                int vdisPipeId = m_exCameraSolutionSWVdis->getPipeId();
                factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[vdisPipeId], vdisPipeId);
                factory->pushFrameToPipe(frame, vdisPipeId);

                if (factory->checkPipeThreadRunning(vdisPipeId) == false) {
                    factory->startThread(vdisPipeId);
                }
            }
        } else
#endif
        {
            if (frame->getFrameState() == FRAME_STATE_SKIPPED) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
            }

            if (frame->getRequest(pipeId) == true) {
                int colorFormat = components.parameters->getHwPreviewFormat();
                streamId = m_streamManager->getYuvStreamId(frame->getOnePortId());
                CLOGV("OnePortId = %d streamId = %d FrameCount = %d", frame->getOnePortId(), streamId, frame->getFrameCount());
                if (streamId >= 0) {
                    colorFormat = m_configurations->getYuvFormat(frame->getOnePortId());
                } else {
                    streamId = HAL_STREAM_ID_PREVIEW;
                    colorFormat = components.parameters->getHwPreviewFormat();
                }

                int planeCount = getYuvPlaneCount(colorFormat);

                buffer.index = -2;
                ret = frame->getDstBuffer(pipeId, &buffer);
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("[F%d B%d]Failed to getDstBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index,
                            pipeId, ret);
                    //return ret;
                    break;
                }

                ret = frame->getDstBufferState(pipeId, &bufferState);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to getDstBufferState. pipeId %d ret %d",
                            frame->getFrameCount(),
                            pipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("[F%d B%d]DstBufferState is ERROR. pipeId %d",
                            frame->getFrameCount(), buffer.index,
                            pipeId);
                }

                /* DEST BUFFER  of PIPE_FUION */
                for (int plane = 0; plane < planeCount; plane++) {
                    if (m_ionClient >= 0)
                        exynos_ion_sync_fd(m_ionClient, buffer.fd[plane]);
                }

                if ((request != NULL)
                    && (!isOnlyPhysStreamsPresent)) {
                    int portId = frame->getOnePortId();
                    streamId = m_streamManager->getYuvStreamId(portId);

                    if (request->hasStream(HAL_STREAM_ID_VIDEO) == false
                        && m_flagVideoStreamPriority == false) {
                        int previewPortId = components.parameters->getPreviewPortId();

                        if (request != NULL) {
                            bool copyBuffer = false;
                            int copyStreamId = HAL_STREAM_ID_PREVIEW;

                            if (request->hasStream(HAL_STREAM_ID_CALLBACK_CPY) == true) {
                                copyBuffer = true;
                                copyStreamId = HAL_STREAM_ID_CALLBACK_CPY;
                            } else if (request->hasStream(HAL_STREAM_ID_CALLBACK) == true && previewPortId == portId) {
                                copyBuffer = true;
                                copyStreamId = HAL_STREAM_ID_CALLBACK;
                            }

                            if (copyBuffer == true) {
                                // In case of no preview stream buffer, just send the result to service
                                if (request->hasStream(HAL_STREAM_ID_PREVIEW) == false) {
                                    streamId = copyStreamId;
                                } else {
                                    request->setStreamBufferStatus(copyStreamId, streamBufferState);
                                    m_copyPreviewCbThreadFunc(request, frame, &buffer);
                                }
                            }
                        }

                        request->setStreamBufferStatus(streamId, streamBufferState);
                        ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, frame->isSkipPreview(),
                                                    frame->getStreamTimestamp(), frame->getParameters());
                        if (ret != NO_ERROR) {
                            CLOGE("[R%d F%d B%d S%d]Failed to sendYuvStreamResult. ret %d",
                                    request->getKey(), frame->getFrameCount(), buffer.index, streamId,
                                    ret);
                            return ret;
                        }
                    } else {
#ifdef USE_DUAL_CAMERA
                        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                            ret = m_setupPreviewGSC(frame, request, PIPE_FUSION, PIPE_FUSION, true);

                            if (ret != NO_ERROR) {
                                CLOGE("m_setupPreviewGSC(Pipe:%d) failed, Fcount(%d), ret(%d)",
                                    pipeId, frame->getFrameCount(), ret);
                                return ret;
                            }

                            if (m_gscPreviewCbThread->isRunning() == false) {
                                m_gscPreviewCbThread->run();
                            }

                            factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[PIPE_GSC], PIPE_GSC);
                            factory->pushFrameToPipe(frame, PIPE_GSC);
                            if (factory->checkPipeThreadRunning(PIPE_GSC) == false) {
                                factory->startThread(PIPE_GSC);
                            }
                        } else
#endif
                        {
                            ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, frame->isSkipPreview(),
                                                        frame->getStreamTimestamp(), frame->getParameters());
                            if (ret != NO_ERROR) {
                                CLOGE("[R%d F%d B%d S%d]Failed to sendYuvStreamResult. ret %d",
                                        request->getKey(), frame->getFrameCount(), buffer.index, streamId,
                                        ret);
                                return ret;
                            }
                        }
                    }
                }
            } else {
                if (buffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret !=  NO_ERROR) {
                        CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                frame->getFrameCount(), buffer.index, pipeId, ret);
                    }
                }
            }
        }
        break;
#endif
    case PIPE_VDIS:
#ifdef USES_SW_VDIS
        m_handleVdisFrame(frame, request, pipeId, factory);
#endif //USES_SW_VDIS
        break;
    case PIPE_PLUGIN_BASE ... PIPE_PLUGIN_MAX:
        // TODO: HACK
        // push next plugIn pipe
#ifdef USES_COMBINE_PLUGIN
        for (int i = 0; i < m_streamManager->getTotalYuvStreamCount(); i++) {
            capturePipeId = PIPE_MCSC0 + i;
            if (frame->getRequest(capturePipeId) == false) {
                continue;
            }

            if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                /* put Src buffer */
                buffer.index = -2;
                ret = frame->getSrcBuffer(pipeId, &buffer);
                if (ret < 0) {
                    CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                    return ret;
                }

                ret = frame->getSrcBufferState(pipeId, &bufferState);
                if (ret < 0) {
                    CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }

                if (buffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for PIPE_PLIGIN. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }

#ifdef USES_SW_VDIS
                if (m_exCameraSolutionSWVdis != NULL && frame->getRequest(PIPE_VDIS)) {
                    int capturePipeId = 0;
                    ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
                    ret = m_exCameraSolutionSWVdis->handleFrame(ExynosCameraSolutionSWVdis::SOLUTION_PROCESS_PRE,
                            frame, pipeId, capturePipeId, factory);
                    if (ret == NO_ERROR) {
                        /* Push frame to VDIS pipe */
                        int vdisPipeId = m_exCameraSolutionSWVdis->getPipeId();
                        factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[vdisPipeId], vdisPipeId);
                        factory->pushFrameToPipe(frame, vdisPipeId);

                        if (factory->checkPipeThreadRunning(vdisPipeId) == false) {
                            factory->startThread(vdisPipeId);
                        }
                    }
                    continue;
                }
#endif
                /* Send result by dst buffer */
                //dstPos = factory->getNodeType(pipeId);
                //ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                ret = frame->getDstBuffer(pipeId, &buffer);
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                            pipeId, buffer.index, frame->getFrameCount(), ret);
                    return ret;
                }

                //ret = frame->getDstBufferState(pipeId, &bufferState, dstPos);
                ret = frame->getDstBufferState(pipeId, &bufferState);
                if (ret < 0) {
                    CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }

                if (request != NULL) {
#ifdef SUPPORT_PREVIEW_PLUGIN_YUV_STREAM
                    if (request->hasStream(HAL_STREAM_ID_CALLBACK) == true) {
                        request->setStreamBufferStatus(HAL_STREAM_ID_CALLBACK, streamBufferState);
                        m_copyPreviewCbThreadFunc(request, frame, &buffer);
                    }
#endif
                    if (request->hasStream(HAL_STREAM_ID_VIDEO) == true) {
                        if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
                            ret = m_copyStreamBuf(frame, HAL_STREAM_ID_VIDEO, HAL_STREAM_ID_PREVIEW);
                            if (ret != NO_ERROR) {
                                CFLOGE(frame, "Failed to copyStreamBuf");
                            }
                        }
                        ret = m_sendYuvStreamResult(frame, request, &buffer, HAL_STREAM_ID_VIDEO, frame->isSkipPreview(),
                                frame->getStreamTimestamp(), frame->getParameters());
                        if (ret != NO_ERROR) {
                            CFLOGE(frame, "[B%d S%d] Failed to sendYuvStreamResult. ret %d",
                                    buffer.index, HAL_STREAM_ID_PREVIEW, ret);
                        }

                        // get copied preview buffer
                        int pipeId = frame->getServiceBufferPipeId(HAL_STREAM_ID_PREVIEW);
                        int bufPos = frame->getServiceBufferPosition(HAL_STREAM_ID_PREVIEW);
                        frame->getDstBuffer(pipeId, &buffer, bufPos);
                        if (ret != NO_ERROR || buffer.index < 0) {
                            CFLOGE(frame, "Failed to getDstBuf(pipe%d, pos:%d)", pipeId, bufPos);
                        }
                    }

                    if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
                        request->setStreamBufferStatus(HAL_STREAM_ID_PREVIEW, streamBufferState);

                        ////////////////////////////////////////////////
                        // when some condtion, skip preview
                        bool skipFlag = frame->isSkipPreview();

                        ////////////////////////////////////////////////

                        ret = m_sendYuvStreamResult(frame, request, &buffer, HAL_STREAM_ID_PREVIEW, skipFlag,
                                                    frame->getStreamTimestamp(), frame->getParameters());
                        if (ret != NO_ERROR) {
                            CLOGE("[R%d F%d B%d S%d]Failed to sendYuvStreamResult. ret %d",
                                    request->getKey(), frame->getFrameCount(), buffer.index, HAL_STREAM_ID_PREVIEW, ret);
                            return ret;
                        }
                    }

                    if (buffer.tag.managerType != BUFFER_MANAGER_SERVICE_GRALLOC_TYPE) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret !=  NO_ERROR) {
                            CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                    frame->getFrameCount(), buffer.index, pipeId, ret);
                        }
                    }
                } else {
                    if (buffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret !=  NO_ERROR) {
                            CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                    frame->getFrameCount(), buffer.index, pipeId, ret);
                        }
                    }
                }
            }
        }
#endif
        break;
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
    case PIPE_SW_MCSC:
    {
        // use MCSC5 port for VRA
        if (frame->getRequest(PIPE_MCSC5) == true) {
            /* Send the Yuv buffer to VRA Pipe */
            dstPos = factory->getNodeType(PIPE_MCSC5);

            ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",pipeId, ret);
            }
            if (buffer.index < 0) {
                CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);

                ret = frame->setSrcBufferState(PIPE_VRA, ENTITY_BUFFER_STATE_ERROR);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                            frame->getFrameCount(), PIPE_VRA, ret);
                }
            } else {
                ret = m_setupEntity(PIPE_VRA, frame, &buffer, NULL);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",PIPE_VRA, ret);
                }
            }
            if (factory->checkPipeThreadRunning(PIPE_VRA) == false) {
                factory->startThread(PIPE_VRA);
            }
            factory->pushFrameToPipe(frame, PIPE_VRA);
        }
        /* send yuv stream result of SW_MCSC output from secondPortId */
        int secondPipeId = (m_configurations->getSecondPortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
        streamId = m_streamManager->getYuvStreamId(m_configurations->getSecondPortId());
        if (request->hasStream(streamId)) {
#ifdef SUPPORT_HW_GDC
            if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_GDC) == true
                    && (streamId == HAL_STREAM_ID_VIDEO)) {
                m_gdcQ->pushProcessQ(&frame);
            } else
#endif
            {
                dstPos = factory->getNodeType(secondPipeId);
                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                            pipeId, buffer.index, frame->getFrameCount(), ret);
                    return ret;
                }

                ret = frame->getDstBufferState(pipeId, &bufferState, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }

                if (request != NULL) {
                    request->setStreamBufferStatus(streamId, streamBufferState);
                    ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, false,
                            frame->getStreamTimestamp(), frame->getParameters());

                    if (ret != NO_ERROR) {
                        CLOGE("Failed to m_sendYuvStreamResult"
                                " pipeId %d bufferIndex %d frameCount %d streamId %d ret %d",
                                pipeId, buffer.index, frame->getFrameCount(), streamId, ret);
                        return ret;
                    }
                } else {
                    if (buffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret !=  NO_ERROR) {
                            CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                    frame->getFrameCount(), buffer.index, pipeId, ret);
                        }
                    }
                }
            }
        }
        /* send yuv stream result of MCSC output from onePortId */
        int onePipeId = (m_configurations->getOnePortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
        streamId = m_streamManager->getYuvStreamId(m_configurations->getOnePortId());
        if (request->hasStream(streamId)) {
#ifdef SUPPORT_HW_GDC
            if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_GDC) == true
                    && (streamId == HAL_STREAM_ID_VIDEO)) {
                m_gdcQ->pushProcessQ(&frame);
            } else
#endif
            {
                int leaderPipeId = PIPE_ISP;
                dstPos = factory->getNodeType(onePipeId);
                ret = frame->getDstBuffer(leaderPipeId, &buffer, dstPos);
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                            leaderPipeId, buffer.index, frame->getFrameCount(), ret);
                    return ret;
                }

                ret = frame->getDstBufferState(leaderPipeId, &bufferState, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", leaderPipeId, ret);
                    return ret;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                    CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), leaderPipeId);
                }

                if (request != NULL) {
                    request->setStreamBufferStatus(streamId, streamBufferState);
                    ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, false,
                            frame->getStreamTimestamp(), frame->getParameters());

                    if (ret != NO_ERROR) {
                        CLOGE("Failed to m_sendYuvStreamResult"
                                " pipeId %d bufferIndex %d frameCount %d streamId %d ret %d",
                                leaderPipeId, buffer.index, frame->getFrameCount(), streamId, ret);
                        return ret;
                    }
                } else {
                    if (buffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret !=  NO_ERROR) {
                            CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                                    frame->getFrameCount(), buffer.index, leaderPipeId, ret);
                        }
                    }
                }
            }
        } else {
            /* if MCSC output is internal buffer, put src buffer */
            buffer.index = -2;
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret < 0) {
                CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)",
                        pipeId, ret);
                return ret;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
                return ret;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for PIPE_SW_MCSC srcBuffer. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                }
            }
        }
        break;
    }
#endif
    default:
        CLOGE("Invalid pipe ID(%d)", pipeId);
        break;
    }

    m_frameCompleteLock.lock();
    ret = frame->setEntityState(pipeId, ENTITY_STATE_COMPLETE);
    if (ret < 0) {
        CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
            pipeId, ENTITY_STATE_COMPLETE, ret);
        m_frameCompleteLock.unlock();
        return ret;
    }

    isFrameComplete = frame->isComplete();
    m_frameCompleteLock.unlock();

    if (request != NULL) {
#ifdef USE_DUAL_CAMERA
        /* don't update result state for dual_slave frame */
        if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
#endif
        {
            if (frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == pipeId
                && frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == true) {
                if (request->getCallbackDone(EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_3AA) == false) {
                    ret = frame->getMetaData(&resultShot);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to getMetaData. ret %d", frame->getFrameCount(), ret);
                    }

#ifdef USES_SW_VDIS
                    if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0 &&
                            frame->getRequest(PIPE_VDIS) == true) {
                        if (m_exCameraSolutionSWVdis != NULL) {
                            uint64_t newTimeStamp = m_exCameraSolutionSWVdis->adjustTimeStamp(frame->getFrameCount());
                            if (newTimeStamp > 0) {
                                resultShot.shot.udm.sensor.timeStampBoot = newTimeStamp;
                            }
                        }
                    }
#endif
                    for (int batchIndex = 0; batchIndex < components.parameters->getBatchSize((enum pipeline)pipeId); batchIndex++) {
                        if (batchIndex > 0) {
                            if (m_parameters[m_cameraId]->useServiceBatchMode() == true) {
                                break;
                            }

                            curRequest = m_requestMgr->getRunningRequest(frame->getFrameCount() + batchIndex);
                            if (curRequest == NULL) {
                                CLOGE("[F%d]Request is NULL", frame->getFrameCount() + batchIndex);
                                continue;
                            }
                            resultShot.shot.udm.sensor.timeStampBoot += resultShot.shot.dm.sensor.frameDuration;
                        } else {
                            curRequest = request;
                        }

                        if (curRequest != NULL) {
#ifdef USES_SW_VDIS
                            if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
                                curRequest->setSensorTimestamp(0);
                            }
#endif

                            ret = m_updateResultShot(frame, curRequest, &resultShot, PARTIAL_3AA);
                            if (ret != NO_ERROR) {
                                CLOGE("[F%d(%d) B%d]Failed to m_updateResultShot. ret %d",
                                        frame->getFrameCount(),
                                        resultShot.shot.dm.request.frameCount,
                                        buffer.index, ret);
                                return ret;
                            }

                            if (curRequest->getCallbackDone(EXYNOS_REQUEST_RESULT::CALLBACK_NOTIFY_ONLY) == false) {
                                m_sendNotifyShutter(curRequest);
                                m_sendPartialMeta(curRequest, EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_3AA);
                            }
                        }
                    }
                }

                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                                                ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
            }

            if (frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == pipeId
                && (frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == true)) {
                ret = frame->getMetaData(&resultShot);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to getMetaData. ret %d", frame->getFrameCount(), ret);
                }

                for (int batchIndex = 0; batchIndex < components.parameters->getBatchSize((enum pipeline)pipeId); batchIndex++) {
                    if (batchIndex > 0) {
                        if (m_parameters[m_cameraId]->useServiceBatchMode() == true) {
                            break;
                        }

                        curRequest = m_requestMgr->getRunningRequest(frame->getFrameCount() + batchIndex);
                        if (curRequest == NULL) {
                            CLOGE("[F%d]Request is NULL", frame->getFrameCount() + batchIndex);
                            continue;
                        }
                        resultShot.shot.udm.sensor.timeStampBoot += resultShot.shot.dm.sensor.frameDuration;
                    } else {
                        curRequest = request;
                    }

                    /* update N-1 zoomRatio */
                    resultShot.shot.udm.zoomRatio = frame->getAppliedZoomRatio();

                    ret = m_updateResultShot(frame, curRequest, &resultShot, PARTIAL_NONE, (frame_type_t)frame->getFrameType());
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d(%d)]Failed to m_updateResultShot. ret %d",
                                frame->getFrameCount(), resultShot.shot.dm.request.frameCount, ret);
                        return ret;
                    }

#ifdef USE_DUAL_CAMERA
                    /* update result state for physical cameras */
                    {
                        int numOfPhysCam = curRequest->getNumOfPhysCamSettings();
                        int32_t *physIDs;
                        int32_t masterCameraId, slaveCameraId;
                        if (numOfPhysCam > 0) {
                            masterCameraId = m_camIdInfo.cameraId[MAIN_CAM];
                            slaveCameraId = m_camIdInfo.cameraId[SUB_CAM];
                            physIDs = curRequest->getAllPhysCamInternalIDs();
                        }

                        for (int i = 0; i < numOfPhysCam; i++) {
                            bool needMetaUpdate = true;
                            int port = OUTPUT_NODE_1;
                            int physCamID = -1;
                            frame_type_t frameType = FRAME_TYPE_BASE;
                            /*
                             * Usually Logical camera meta & master camera meta is same.
                             * Can't we use the logical camera meta for Physical Camera (master).
                             */
                            if (physIDs[i] == masterCameraId) {
                                physCamID = masterCameraId;
                                frameType = FRAME_TYPE_PREVIEW;
                            } else if (physIDs[i] == slaveCameraId) {
                                physCamID = slaveCameraId;
                                frameType = FRAME_TYPE_PREVIEW_SLAVE;
                                if (frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_MASTER)
                                    port = OUTPUT_NODE_2;
                            } else {
                                needMetaUpdate = false;
                                continue;
                            }

                            if (needMetaUpdate) {
                                ret = frame->getMetaData(&resultShot, port);
                                if (ret != NO_ERROR) {
                                    CLOGE("[F%d]Failed to getMetaData. CameraId(%d), port(%d) ret %d",
                                        frame->getFrameCount(), masterCameraId, port, ret);
                                    continue;
                                }

                                ret = m_updateResultShot(frame, curRequest, &resultShot, PARTIAL_NONE,
                                            frameType, physCamID);
                                if (ret != NO_ERROR) {
                                    CLOGE("[F%d(%d)]Failed to m_updateResultShot. CameraId(%d), ret %d",
                                            frame->getFrameCount(), resultShot.shot.dm.request.frameCount, physCamID, ret);
                                    continue;
                                }
                            }
                        }
                    }
#endif

                    ret = m_sendMeta(curRequest, EXYNOS_REQUEST_RESULT::CALLBACK_ALL_RESULT);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to sendMeta. ret %d",
                                frame->getFrameCount(), ret);
                    }
                }

                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                                                ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
            }
        }
    }

    if (isFrameComplete == true) {
        ret = m_removeFrameFromList(&m_processList, &m_processLock, frame);
        if (ret < 0) {
            CLOGE("remove frame from processList fail, ret(%d)", ret);
        }

        CLOGV("frame complete, frameCount %d FrameType %d",
                frame->getFrameCount(), frame->getFrameType());
        frame = NULL;
    }

    return ret;
}

status_t ExynosCamera::m_handleVisionFrame(ExynosCameraFrameSP_sptr_t frame, int pipeId,
                                                ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameEntity *entity = NULL;
    ExynosCameraBuffer buffer;
    struct camera2_shot_ext *shot_ext = NULL;
    struct camera2_shot_ext resultShot = {0};
    uint32_t framecount = 0;
    int streamId = HAL_STREAM_ID_VISION;
    int dstPos = 0;
    ExynosCameraRequestSP_sprt_t request = NULL;
    entity_buffer_state_t bufferState;
    camera3_buffer_status_t streamBufferState = CAMERA3_BUFFER_STATUS_OK;
    frame_handle_components_t components;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    if (factory == NULL) {
        CLOGE("frame Factory is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);

    if (frame->isCompleteForResultUpdate() == false) {
        request = m_requestMgr->getRunningRequest(frame->getFrameCount());
        if (request == NULL) {
            CLOGE("[F%d]request is NULL. pipeId %d",
                    frame->getFrameCount(), pipeId);
            return INVALID_OPERATION;
        }
    }

    entity = frame->getFrameDoneFirstEntity(pipeId);
    if (entity == NULL) {
        if (request != NULL) {
            CLOGE("[R%d F%d]current entity is NULL. pipeId %d",
                request->getKey(), frame->getFrameCount(), pipeId);
        }
        return INVALID_OPERATION;
    }

    switch(pipeId) {
    case PIPE_FLITE:
        /* 1. Handle bayer buffer */
        if (components.parameters->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) != HW_CONNECTION_MODE_M2M) {
            android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):[F%d]PIPE_FLITE cannot come to %s when Flite3aaOtf. so, assert!!!!",
                    __FUNCTION__, __LINE__, frame->getFrameCount(), __FUNCTION__);
        }

        /* Notify ShotDone to mainThread */
        framecount = frame->getFrameCount();
        m_shotDoneQ->pushProcessQ(&frame);

        /* Return dummy-shot buffer */
        buffer.index = -2;

        ret = frame->getSrcBuffer(pipeId, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer for PIPE_FLITE. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        ret = frame->getSrcBufferState(pipeId, &bufferState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getSrcBufferState for PIPE_FLITE. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            CLOGE("[F%d B%d]Src buffer state is error for PIPE_FLITE.",
                    frame->getFrameCount(), buffer.index);

            if (request != NULL) {
                ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to sendNotifyError. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    return ret;
                }
            }
        }
        if (buffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for FLITE. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                return ret;
            }
        }

        dstPos = factory->getNodeType(PIPE_VC0);
        buffer.index = -2;

        ret = frame->getDstBuffer(entity->getPipeId(), &buffer, dstPos);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getDstBuffer for PIPE_VC0. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        ret = frame->getDstBufferState(entity->getPipeId(), &bufferState);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to getDstBufferState for PIPE_VC0. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            CLOGE("[F%d B%d]Dst buffer state is error for PIPE_VC0.",
                    frame->getFrameCount(), buffer.index);

            streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
        }

        if (request != NULL) {
            request->setStreamBufferStatus(streamId, streamBufferState);
        }

        shot_ext = (struct camera2_shot_ext *) buffer.addr[buffer.getMetaPlaneIndex()];
        frame->setMetaDataEnable(true);

        ret = m_updateTimestamp(request, frame, &buffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to update timestamp. ret %d",
                    frame->getFrameCount(), buffer.index, ret);
            return ret;
        }

        if (request != NULL) {
            if (m_flagFirstPreviewTimerOn == true) {
                m_firstPreviewTimer.stop();
                m_flagFirstPreviewTimerOn = false;

                CLOGD("m_firstPreviewTimer stop");

                CLOGD("============= First Preview time ==================");
                CLOGD("= configureStream ~ first frame  : %d msec", (int)m_firstPreviewTimer.durationMsecs());
                CLOGD("===================================================");
            }

            ret = m_sendVisionStreamResult(request, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("Failed to resultCallback."
                        " PIPE_VC0 bufferIndex %d frameCount %d streamId %d ret %d",
                        buffer.index, frame->getFrameCount(), streamId, ret);
                return ret;
            }
        } else {
            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for FLITE. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    return ret;
                }
            }
        }

        break;
    }

    ret = frame->setEntityState(entity->getPipeId(), ENTITY_STATE_COMPLETE);
    if (ret < 0) {
        CLOGE("ERR(%s[%d]):setEntityState fail, pipeId(%d), state(%d), ret(%d)",
                __FUNCTION__, __LINE__, entity->getPipeId(), ENTITY_STATE_COMPLETE, ret);
        return ret;
    }

    if (request != NULL) {
        if (frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == pipeId
            && frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == true) {
            ret = frame->getMetaData(&resultShot);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d]Failed to getMetaData. ret %d",
                        request->getKey(), frame->getFrameCount(), ret);
            }

            ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_3AA);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d(%d)]Failed to m_updateResultShot. ret %d",
                        request->getKey(),
                        frame->getFrameCount(),
                        resultShot.shot.dm.request.frameCount,
                        ret);
                return ret;
            }

            if (request->getCallbackDone(EXYNOS_REQUEST_RESULT::CALLBACK_NOTIFY_ONLY) == false) {
                m_sendNotifyShutter(request);
                m_sendPartialMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_3AA);
            }

            frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                                            ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
        }

        if (frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == pipeId
            && (frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == true)) {
            ret = frame->getMetaData(&resultShot);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d]Failed to getMetaData. ret %d",
                        request->getKey(), frame->getFrameCount(), ret);
            }

            ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_NONE, (frame_type_t)frame->getFrameType());
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d(%d)]Failed to m_updateResultShot. ret %d",
                        request->getKey(),
                        frame->getFrameCount(),
                        resultShot.shot.dm.request.frameCount,
                        ret);
                return ret;
            }

            ret = m_sendMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_ALL_RESULT);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to sendMeta. ret %d",
                        frame->getFrameCount(), ret);
            }

            frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                                            ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
        }
    }

    if (frame->isComplete() == true) {
        ret = m_removeFrameFromList(&m_processList, &m_processLock, frame);
        if (ret < 0) {
            CLOGE("remove frame from processList fail, ret(%d)", ret);
        }

        CLOGV("frame complete, frameCount %d FrameType %d",
                frame->getFrameCount(), frame->getFrameType());
        frame = NULL;
    }

    return ret;
}

status_t ExynosCamera::m_sendPartialMeta(ExynosCameraRequestSP_sprt_t request,
                                         EXYNOS_REQUEST_RESULT::TYPE type)
{
    ResultRequest resultRequest = NULL;
    uint32_t frameNumber = 0;
    camera3_capture_result_t *requestResult = NULL;
    CameraMetadata resultMeta;

    status_t ret = OK;

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(request);

    resultRequest = requestMgr->createResultRequest(request->getKey(), request->getFrameCount(), type);
    if (resultRequest == NULL) {
        CLOGE("[R%d F%d] createResultRequest fail. PARTIAL_META",
                request->getKey(), request->getFrameCount());
        ret = INVALID_OPERATION;
        return ret;
    }

    requestResult = resultRequest->getCaptureResult();
    if (requestResult == NULL) {
        CLOGE("[R%d F%d] getCaptureResult fail. PARTIAL_META",
                request->getKey(), request->getFrameCount());
        ret = INVALID_OPERATION;
        return ret;
    }

    frameNumber = request->getKey();
    request->setRequestLock();

    {
        resultMeta = request->get3AAResultMeta();
    }
    request->setRequestUnlock();

    requestResult->frame_number = frameNumber;
    requestResult->result = resultMeta.release();
    requestResult->num_output_buffers = 0;
    requestResult->output_buffers = NULL;
    requestResult->input_buffer = NULL;
    requestResult->partial_result = 1;

    CLOGV("framecount %d request %d", request->getFrameCount(), request->getKey());

    requestMgr->pushResultRequest(resultRequest);

    return ret;
}

void ExynosCamera::m_checkEntranceLux(struct camera2_shot_ext *meta_shot_ext) {
    uint32_t data = 0;

    if (m_checkFirstFrameLux == false
        || m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
        m_checkFirstFrameLux = false;
        return;
    }

    data = (int32_t)meta_shot_ext->shot.udm.ae.vendorSpecific[399];

    m_checkFirstFrameLux = false;
}

status_t ExynosCamera::m_sendYuvStreamResult(ExynosCameraFrameSP_sptr_t frame,
                                             ExynosCameraRequestSP_sprt_t request,
                                             ExynosCameraBuffer *buffer, int streamId, bool skipBuffer,
                                             __unused uint64_t streamTimeStamp, ExynosCameraParameters *params
                                             )
{
    status_t ret = NO_ERROR;
    ExynosCameraStream *stream = NULL;
    camera3_stream_buffer_t *streamBuffer = NULL;
    camera3_capture_result_t *requestResult = NULL;
    ResultRequest resultRequest = NULL;
    bool OISCapture_activated = false;
    uint32_t dispFps = EXYNOS_CAMERA_PREVIEW_FPS_REFERENCE;
    uint32_t maxFps, minFps;
    int ratio = 1;
    int LowLightSkipFcount = 0;
    bool skipStream = false;
    uint32_t frameCount = request->getFrameCount();

    if (buffer == NULL) {
        CLOGE("buffer is NULL");
        return BAD_VALUE;
    }

    ret = m_streamManager->getStream(streamId, &stream);
    if (ret != NO_ERROR) {
        CLOGE("Failed to get stream %d from streamMgr", streamId);
        return INVALID_OPERATION;
    }

    m_configurations->getPreviewFpsRange(&minFps, &maxFps);

#ifndef USE_CAMERA_EXYNOS850_META
#ifndef USE_CAMERA_EXYNOS3830_META
    if (skipBuffer == false) {
        ret = m_updateDisplayRegion(frame, request, streamId);
        if (ret != NO_ERROR) {
            CFLOGW(frame, "fail to update displayRegion");
        }
    }
#endif
#endif

    for (int batchIndex = 0; batchIndex < buffer->batchSize; batchIndex++) {
        if (batchIndex > 0) {
            /* Get next request */
            request = m_requestMgr->getRunningRequest(frameCount + batchIndex);
            if (request == NULL) {
                CLOGE("[F%d]Request is NULL", frameCount + batchIndex);
                continue;
            }
        }

        resultRequest = m_requestMgr->createResultRequest(request->getKey(), request->getFrameCount(),
                                                          EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
        if (resultRequest == NULL) {
            CLOGE("[R%d F%d S%d] createResultRequest fail.",
                    request->getKey(), request->getFrameCount(), streamId);
            ret = INVALID_OPERATION;
            continue;
        }

        requestResult = resultRequest->getCaptureResult();
        if (requestResult == NULL) {
            CLOGE("[R%d F%d S%d] getCaptureResult fail.",
                    request->getKey(), request->getFrameCount(), streamId);
            ret = INVALID_OPERATION;
            continue;
        }

        streamBuffer = resultRequest->getStreamBuffer();
        if (streamBuffer == NULL) {
            CLOGE("[R%d F%d S%d] getStreamBuffer fail.",
                    request->getKey(), request->getFrameCount(), streamId);
            ret = INVALID_OPERATION;
            continue;
        }

        ret = stream->getStream(&(streamBuffer->stream));
        if (ret != NO_ERROR) {
            CLOGE("Failed to get stream %d from ExynosCameraStream", streamId);
            continue;
        }

        streamBuffer->buffer = buffer->handle[batchIndex];

        m_configurations->getFrameSkipCount(&LowLightSkipFcount);

        if (LowLightSkipFcount > 0)
            skipStream = true;

        if ((maxFps > dispFps)
            && (request->hasStream(HAL_STREAM_ID_VIDEO) == false)
            && (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_PREVIEW)) {
            ratio = (int)((maxFps * 10 / dispFps) / buffer->batchSize / 10);
            m_displayPreviewToggle = (m_displayPreviewToggle + 1) % ratio;
            skipStream = (m_displayPreviewToggle == 0) ? false : true;
        }

        ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status,
                OISCapture_activated | skipStream | skipBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d S%d B%d]Failed to checkStreamBufferStatus.",
                    request->getKey(), request->getFrameCount(), streamId, buffer->index);
            continue;
        }

        if ((m_configurations->getMode(CONFIGURATION_YSUM_RECORDING_MODE) == true)
            && (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_VIDEO)
            && (request->getStreamBufferStatus(streamId) == CAMERA3_BUFFER_STATUS_OK)) {
            struct ysum_data ysumdata;
            request->getYsumValue(&ysumdata);
            ret = updateYsumBuffer(&ysumdata, buffer);
            if (ret != NO_ERROR) {
                CLOGE("updateYsumBuffer fail, bufferIndex(%d), ret(%d)", buffer->index, ret);
                return ret;
            }
        }

        if ((m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true)
            && ((streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_PREVIEW)
                || (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_VIDEO))
            && (request->getStreamBufferStatus(streamId) == CAMERA3_BUFFER_STATUS_OK)) {
            ret = updateHDRBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("updateHDRBuffer fail, bufferIndex(%d), ret(%d)", buffer->index, ret);
                return ret;
            }
        }

#ifdef DEBUG_DISPLAY_BUFFER
        {
            int displayId = -1;
            if (request->hasStream(HAL_STREAM_ID_PREVIEW)) {
                displayId = HAL_STREAM_ID_PREVIEW;
            } else if (request->hasStream(HAL_STREAM_ID_CALLBACK)) {
                displayId = HAL_STREAM_ID_CALLBACK;
            }

            if (streamBuffer->status != CAMERA3_BUFFER_STATUS_ERROR
                && (streamId % HAL_STREAM_ID_MAX == displayId)
                && (streamBuffer->stream->usage & (GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN))
                && buffer->size[0] > 3000
                && buffer->addr[0][0] == 0 && buffer->addr[0][10] == 0 && buffer->addr[0][100] == 0
                && buffer->addr[0][1000] == 0 && buffer->addr[0][2000] == 0 && buffer->addr[0][3000] == 0) {
                CLOGD("[R%d id:%d shotmode%d]: %d, %d, %d, %d, %d, %d Green image buffer detected!!!",
                    request->getKey(), streamId, m_configurations->getModeValue(CONFIGURATION_SHOT_MODE),
                    buffer->addr[0][1], buffer->addr[0][11], buffer->addr[0][101],
                    buffer->addr[0][1001], buffer->addr[0][2001], buffer->addr[0][2999]);
            }
        }
#endif

        streamBuffer->acquire_fence = -1;
        streamBuffer->release_fence = -1;

        /* construct result for service */
        requestResult->frame_number = request->getKey();
        requestResult->result = NULL;
        requestResult->input_buffer = request->getInputBuffer();
        requestResult->num_output_buffers = 1;
        requestResult->output_buffers = streamBuffer;
        requestResult->partial_result = 0;

        CLOGV("frame number(%d), #out(%d) streamId(%d)",
                requestResult->frame_number, requestResult->num_output_buffers, streamId);

        m_requestMgr->pushResultRequest(resultRequest);
    }

    ret = m_bufferSupplier->putBuffer(*buffer);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d B%d]Failed to putBuffer. ret %d",
                request->getKey(), request->getFrameCount(), buffer->index, ret);
    }

    return ret;
}

status_t ExynosCamera::m_sendYuvStreamStallResult(ExynosCameraRequestSP_sprt_t request,
                                                   ExynosCameraBuffer *buffer, int streamId)
{
    status_t ret = NO_ERROR;
    ExynosCameraStream *stream = NULL;
    camera3_stream_buffer_t *streamBuffer = NULL;
    camera3_capture_result_t *requestResult = NULL;
    ResultRequest resultRequest = NULL;

    ret = m_streamManager->getStream(streamId, &stream);
    if (ret != NO_ERROR) {
        CLOGE("Failed to get stream %d from streamMgr", streamId);
        return INVALID_OPERATION;
    }

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(request);

    resultRequest = requestMgr->createResultRequest(request->getKey(), request->getFrameCount(),
            EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
    if (resultRequest == NULL) {
        CLOGE("[R%d F%d S%d] createResultRequest fail.",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    requestResult = resultRequest->getCaptureResult();
    if (requestResult == NULL) {
        CLOGE("[R%d F%d S%d] getCaptureResult fail.",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    streamBuffer = resultRequest->getStreamBuffer();
    if (streamBuffer == NULL) {
        CLOGE("[R%d F%d S%d] getStreamBuffer fail.",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    ret = stream->getStream(&(streamBuffer->stream));
    if (ret != NO_ERROR) {
        CLOGE("Failed to get stream %d from ExynosCameraStream", streamId);
        return INVALID_OPERATION;
    }

    streamBuffer->buffer = buffer->handle[0];

    ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d S%d B%d]Failed to checkStreamBufferStatus.",
                request->getKey(), request->getFrameCount(), streamId, buffer->index);
        return ret;
    }

    streamBuffer->acquire_fence = -1;
    streamBuffer->release_fence = -1;

    /* construct result for service */
    requestResult->frame_number = request->getKey();
    requestResult->result = NULL;
    requestResult->num_output_buffers = 1;
    requestResult->output_buffers = streamBuffer;
    requestResult->input_buffer = request->getInputBuffer();
    requestResult->partial_result = 0;

    CLOGV("frame number(%d), #out(%d)",
            requestResult->frame_number, requestResult->num_output_buffers);

    requestMgr->pushResultRequest(resultRequest);

    ret = m_bufferSupplier->putBuffer(*buffer);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d B%d]Failed to putBuffer. ret %d",
                request->getKey(), request->getFrameCount(), buffer->index, ret);
    }

    return ret;
}

status_t ExynosCamera::m_sendThumbnailStreamResult(ExynosCameraRequestSP_sprt_t request,
                                                    ExynosCameraBuffer *buffer, int streamId)
{
    status_t ret = NO_ERROR;
    ExynosCameraStream *stream = NULL;
    camera3_stream_buffer_t *streamBuffer = NULL;
    camera3_capture_result_t *requestResult = NULL;
    ResultRequest resultRequest = NULL;

    if (buffer == NULL) {
        CLOGE("buffer is NULL");
        return BAD_VALUE;
    }

    ret = m_streamManager->getStream(streamId, &stream);
    if (ret != NO_ERROR) {
        CLOGE("Failed to get stream %d from streamMgr", streamId);
        return INVALID_OPERATION;
    }

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(request);

    resultRequest = requestMgr->createResultRequest(request->getKey(), request->getFrameCount(),
            EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
    if (resultRequest == NULL) {
        CLOGE("[R%d F%d S%d] createResultRequest fail.",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    requestResult = resultRequest->getCaptureResult();
    if (requestResult == NULL) {
        CLOGE("[R%d F%d S%d] getCaptureResult fail.",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    streamBuffer = resultRequest->getStreamBuffer();
    if (streamBuffer == NULL) {
        CLOGE("[R%d F%d S%d] getStreamBuffer fail.",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    ret = stream->getStream(&(streamBuffer->stream));
    if (ret != NO_ERROR) {
        CLOGE("Failed to get stream %d from ExynosCameraStream", streamId);
        return INVALID_OPERATION;
    }

    streamBuffer->buffer = buffer->handle[0];

    ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d S%d B%d]Failed to checkStreamBufferStatus.",
                request->getKey(), request->getFrameCount(), streamId, buffer->index);
        return ret;
    }

    streamBuffer->acquire_fence = -1;
    streamBuffer->release_fence = -1;

    /* construct result for service */
    requestResult->frame_number = request->getKey();
    requestResult->result = NULL;
    requestResult->num_output_buffers = 1;
    requestResult->output_buffers = streamBuffer;
    requestResult->input_buffer = request->getInputBuffer();
    requestResult->partial_result = 0;

    CLOGD("frame number(%d), #out(%d)",
            requestResult->frame_number, requestResult->num_output_buffers);

    requestMgr->pushResultRequest(resultRequest);

    ret = m_bufferSupplier->putBuffer(*buffer);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d B%d]Failed to putBuffer. ret %d",
                request->getKey(), request->getFrameCount(), buffer->index, ret);
    }

    return ret;
}

#ifdef SUPPORT_DEPTH_MAP
status_t ExynosCamera::m_sendDepthStreamResult(ExynosCameraRequestSP_sprt_t request,
                                                ExynosCameraBuffer *buffer, int streamId)
{
    status_t ret = NO_ERROR;
    ExynosCameraStream *stream = NULL;
    camera3_stream_buffer_t *streamBuffer = NULL;
    ResultRequest resultRequest = NULL;
    camera3_capture_result_t *requestResult = NULL;
    bool bufferSkip = false;

    /* 1. Get stream object for RAW */
    ret = m_streamManager->getStream(streamId, &stream);
    if (ret < 0) {
        CLOGE("getStream is failed, from streammanager. Id error:(%d)", streamId);
        return ret;
    }

    resultRequest = m_requestMgr->createResultRequest(request->getKey(), request->getFrameCount(),
                                        EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
    if (resultRequest == NULL) {
        CLOGE("[R%d F%d] createResultRequest fail. streamId (%d)",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    requestResult = resultRequest->getCaptureResult();
    if (requestResult == NULL) {
        CLOGE("[R%d F%d] getCaptureResult fail. streamId (%d)",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    streamBuffer = resultRequest->getStreamBuffer();
    if (streamBuffer == NULL) {
        CLOGE("[R%d F%d] getStreamBuffer fail. streamId (%d)",
                request->getKey(), request->getFrameCount(), streamId);
        ret = INVALID_OPERATION;
        return ret;
    }

    /* 2. Get camera3_stream structure from stream object */
    ret = stream->getStream(&(streamBuffer->stream));
    if (ret < 0) {
        CLOGE("getStream is failed, from exynoscamerastream. Id error:(%d)", streamId);
        return ret;
    }

    /* 3. Get the service buffer handle */
    streamBuffer->buffer = buffer->handle[0];

    if (buffer->index < 0) {
        bufferSkip = true;
    }

    /* 4. Update the remained buffer info */
    ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status, bufferSkip);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d S%d B%d]Failed to checkStreamBufferStatus.",
                request->getKey(), request->getFrameCount(),
                streamId, buffer->index);
        return ret;
    }

    streamBuffer->acquire_fence = -1;
    streamBuffer->release_fence = -1;

    /* 5. Create new result for RAW buffer */
    requestResult->frame_number = request->getKey();
    requestResult->result = NULL;
    requestResult->num_output_buffers = 1;
    requestResult->output_buffers = streamBuffer;
    requestResult->input_buffer = NULL;
    requestResult->partial_result = 0;

    CLOGV("frame number(%d), #out(%d)",
            requestResult->frame_number, requestResult->num_output_buffers);

    /* 6. Request to callback the result to request manager */
    m_requestMgr->pushResultRequest(resultRequest);

    ret = m_bufferSupplier->putBuffer(*buffer);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d B%d]Failed to putBuffer. ret %d",
                request->getKey(), request->getFrameCount(), buffer->index, ret);
    }

    CLOGV("request->frame_number(%d), request->getNumOfOutputBuffer(%d)"
            " request->getCompleteBufferCount(%d) frame->getFrameCapture(%d)",
            request->getKey(),
            request->getNumOfOutputBuffer(),
            request->getCompleteBufferCount(),
            request->getFrameCount());

    CLOGV("streamBuffer info: stream (%p), handle(%p)",
            streamBuffer->stream, streamBuffer->buffer);

    return ret;
}
#endif

status_t ExynosCamera::m_sendVisionStreamResult(ExynosCameraRequestSP_sprt_t request, ExynosCameraBuffer *buffer)
{
    status_t ret = NO_ERROR;
    ExynosCameraStream *stream = NULL;
    camera3_stream_buffer_t *streamBuffer = NULL;
    ResultRequest resultRequest = NULL;
    camera3_capture_result_t *requestResult = NULL;
    bool skipPreview = false;
    int option = 0;

    /* 1. Get stream object for VISION */
    ret = m_streamManager->getStream(HAL_STREAM_ID_VISION, &stream);
    if (ret < 0) {
        CLOGE("getStream is failed, from streammanager. Id error:HAL_STREAM_ID_VISION");
        return ret;
    }

    resultRequest = m_requestMgr->createResultRequest(request->getKey(), request->getFrameCount(),
                                        EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
    if (resultRequest == NULL) {
        CLOGE("[R%d F%d] createResultRequest fail. streamId HAL_STREAM_ID_VISION",
                request->getKey(), request->getFrameCount());
        ret = INVALID_OPERATION;
        return ret;
    }

    requestResult = resultRequest->getCaptureResult();
    if (requestResult == NULL) {
        CLOGE("[R%d F%d] getCaptureResult fail. streamId HAL_STREAM_ID_VISION",
                request->getKey(), request->getFrameCount());
        ret = INVALID_OPERATION;
        return ret;
    }

    streamBuffer = resultRequest->getStreamBuffer();
    if (streamBuffer == NULL) {
        CLOGE("[R%d F%d] getStreamBuffer fail. streamId HAL_STREAM_ID_VISION",
                request->getKey(), request->getFrameCount());
        ret = INVALID_OPERATION;
        return ret;
    }

    /* 2. Get camera3_stream structure from stream object */
    ret = stream->getStream(&(streamBuffer->stream));
    if (ret < 0) {
        CLOGE("getStream is failed, from ExynosCameraStream. Id error:HAL_STREAM_ID_VISION");
        return ret;
    }

    /* 3. Get the bayer buffer from frame */
    streamBuffer->buffer = buffer->handle[0];

    if ((option & STREAM_OPTION_IRIS_MASK)
        && m_visionFps == 30) {
        m_displayPreviewToggle = (m_displayPreviewToggle + 1) % 2;
        skipPreview = (m_displayPreviewToggle == 0) ? false : true;

        CLOGV("skip iris frame fcount(%d) skip(%d)", request->getFrameCount(), skipPreview);
    }

    /* 4. Get the service buffer handle from buffer manager */
    ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status, skipPreview);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d S%d]Failed to checkStreamBufferStatus.",
            request->getKey(), request->getFrameCount(),
            HAL_STREAM_ID_VISION);
        return ret;
    }

    /* 5. Update the remained buffer info */
    streamBuffer->acquire_fence = -1;
    streamBuffer->release_fence = -1;

    /* construct result for service */
    requestResult->frame_number = request->getKey();
    requestResult->result = NULL;
    requestResult->num_output_buffers = 1;
    requestResult->output_buffers = streamBuffer;
    requestResult->input_buffer = request->getInputBuffer();
    requestResult->partial_result = 0;

    CLOGV("frame number(%d), #out(%d)",
            requestResult->frame_number, requestResult->num_output_buffers);

    /* 6. Request to callback the result to request manager */
    m_requestMgr->pushResultRequest(resultRequest);

    ret = m_bufferSupplier->putBuffer(*buffer);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d B%d]Failed to putBuffer. ret %d",
                request->getKey(), request->getFrameCount(), buffer->index, ret);
    }

    CLOGV("request->frame_number(%d), request->getNumOfOutputBuffer(%d)"
            "request->getCompleteBufferCount(%d) frame->getFrameCapture(%d)",
            request->getKey(), request->getNumOfOutputBuffer(),
            request->getCompleteBufferCount(), request->getFrameCount());

    CLOGV("streamBuffer info: stream (%p), handle(%p)",
            streamBuffer->stream, streamBuffer->buffer);

    return ret;
}

status_t ExynosCamera::m_setupVisionPipeline(void)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    CLOGI("++IN++");

    int ret = 0;
    ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_VISION];
    ExynosCameraBuffer dstBuf;
    uint32_t pipeId = PIPE_FLITE;
    uint32_t nodePipeId = PIPE_VC0;
    enum NODE_TYPE nodeType;

    factory->setRequest(PIPE_VC0, true);

    m_setSetfile();

    nodeType = factory->getNodeType(nodePipeId);

    /* set initial value for Secure Camera*/
    m_shutterSpeed = (int32_t) (m_configurations->getExposureTime() / 100000);
    m_gain = m_configurations->getGain();
    m_irLedWidth = (int32_t) (m_configurations->getLedPulseWidth() / 100000);
    m_irLedDelay = (int32_t) (m_configurations->getLedPulseDelay() / 100000);
    m_irLedCurrent = m_configurations->getLedCurrent();
    m_irLedOnTime = (int32_t) (m_configurations->getLedMaxTime() / 1000);
    m_visionFps = 30;

    ret = factory->setControl(V4L2_CID_SENSOR_SET_FRAME_RATE, m_visionFps, pipeId);
    if (ret < 0)
        CLOGE("FLITE setControl fail, ret(%d)", ret);

    ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
    if (ret != NO_ERROR) {
        CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
        return ret;
    }

    factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[pipeId], pipeId);

    CLOGI("--OUT--");

    return NO_ERROR;
}

status_t ExynosCamera::m_setupReprocessingPipeline(ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    uint32_t pipeId = MAX_PIPE_NUM;
    int flipHorizontal = 0;
    int flipVertical = 0;
    enum NODE_TYPE nodeType;

    int cameraId = factory->getCameraId();
    bool flag3aaIspM2M = (m_parameters[cameraId]->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M);
    bool flagIspMcscM2M = (m_parameters[cameraId]->getHwConnectionMode(PIPE_ISP_REPROCESSING, PIPE_MCSC_REPROCESSING) == HW_CONNECTION_MODE_M2M);
    bool flagMcscVraM2M = (m_parameters[cameraId]->getHwConnectionMode(PIPE_MCSC_REPROCESSING, PIPE_VRA_REPROCESSING) == HW_CONNECTION_MODE_M2M);
    bool flag3aaVraM2M = (m_parameters[cameraId]->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_VRA_REPROCESSING) == HW_CONNECTION_MODE_M2M);
#ifdef USE_CLAHE_REPROCESSING
    bool flagMcscClaheM2M = (m_parameters[cameraId]->getHwConnectionMode(PIPE_MCSC_REPROCESSING, PIPE_CLAHE_REPROCESSING) == HW_CONNECTION_MODE_M2M);
#endif
    bool flagRemosaic = false;


#ifdef USE_REMOSAIC_SENSOR
    if (factory->getFactoryType() == FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING) {
        flag3aaIspM2M = true;
        flagRemosaic = true;
    }
#endif //SUPPORT_REMOSAIC_CAPTURE

    if (flag3aaVraM2M)
        flagMcscVraM2M = false;

    flipHorizontal = m_configurations->getModeValue(CONFIGURATION_FLIP_HORIZONTAL);
    flipVertical   = m_configurations->getModeValue(CONFIGURATION_FLIP_VERTICAL);

    if (flagRemosaic == false
#ifdef USES_COMBINE_PLUGIN
        || flagRemosaic == true
#endif
        )
    {
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_HIFI) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_NIGHT_SHOT_BAYER) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_SUPER_NIGHT_SHOT_BAYER) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_HDR_BAYER)) {
            /* LLS PlugIn */
        pipeId = PIPE_PLUGIN_PRE1_REPROCESSING;

        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }
        factory->setOutputFrameQToPipe(m_bayerStreamQ, pipeId);
    }
    }

    /* Setting BufferSupplier basd on H/W pipeline */
    pipeId = PIPE_3AA_REPROCESSING;

    if (flag3aaIspM2M == true) {
        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }

        /* TODO : Consider the M2M Reprocessing Scenario */
        factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);

        pipeId = PIPE_ISP_REPROCESSING;
    }

    /* TODO : Consider the M2M Reprocessing Scenario */
    factory->setFrameDoneQToPipe(m_reprocessingDoneQ, pipeId);

    if (flagIspMcscM2M == true) {
        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }

        /* TODO : Consider the M2M Reprocessing Scenario */
        factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);

        pipeId = PIPE_MCSC_REPROCESSING;
    }

    ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
    if (ret != NO_ERROR) {
        CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
        return ret;
    }

    /* TODO : Consider the M2M Reprocessing Scenario */
    factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);

#ifdef USE_CLAHE_REPROCESSING
    if (flagMcscClaheM2M == true) {
        pipeId = PIPE_CLAHE_REPROCESSING;

        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }
    }

    /* TODO : Consider the M2M Reprocessing Scenario */
    factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);
#endif

    if (cameraId == m_cameraId
#ifdef USES_DUAL_FRONT_PORTRAIT
        || (m_scenario == SCENARIO_DUAL_FRONT_PORTRAIT && cameraId == m_cameraIds[SUB_CAM])
#endif
        ) {
        for (int dstPipeId = PIPE_MCSC0_REPROCESSING; dstPipeId <= PIPE_MCSC5_REPROCESSING; dstPipeId++) {
            nodeType = factory->getNodeType(dstPipeId);

            factory->setControl(V4L2_CID_HFLIP, flipHorizontal, pipeId, nodeType);

            factory->setControl(V4L2_CID_VFLIP, flipVertical, pipeId, nodeType);

            CLOGD("set flipHorizontal(%d) / flipVertical(%d) Reprocessing dstPipeId(%d)",
                flipHorizontal, flipVertical, dstPipeId);
        }
    }

    if (flagMcscVraM2M || flag3aaVraM2M) {
#ifdef USE_VRA_FD
        pipeId = PIPE_VRA_REPROCESSING;
#else
        pipeId = PIPE_NFD_REPROCESSING;
#endif

        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }

        /* TODO : Consider the M2M Reprocessing Scenario */
        factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);
    }

    if (m_parameters[m_cameraId]->isUseHWFC() == false ||
            (m_parameters[m_cameraId]->isUseHWFC() == true && m_parameters[m_cameraId]->isHWFCOnDemand() == true)) {
        pipeId = PIPE_JPEG_REPROCESSING;

        CLOGD("set buffer supplier to PIPE_JPEG_REPROCESSING");
        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }
    }

#ifdef USE_DUAL_CAMERA
    if (flagRemosaic == false
        && cameraId == m_cameraId
        && m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
        pipeId = PIPE_SYNC_REPROCESSING;

        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }

        /* Setting OutputFrameQ/FrameDoneQ to Pipe */
        factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);

#ifndef USES_COMBINE_PLUGIN
        if (m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
            pipeId = PIPE_FUSION_REPROCESSING;

            ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
            if (ret != NO_ERROR) {
                CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
                return ret;
            }

            /* Setting OutputFrameQ/FrameDoneQ to Pipe */
            factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);
        }
#endif
    }
#endif

    if (flagRemosaic == false
#ifdef USES_COMBINE_PLUGIN
        || flagRemosaic == true
#endif
        )
    {
#if defined(USES_HIFI_LLS) || \
    defined(USES_COMBINE_PLUGIN)
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_HIFILLS) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_NIGHT_SHOT_YUV) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_HDR_YUV) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_FLASH_MULTI_FRAME_DENOISE_YUV) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_BEAUTY_FACE_YUV) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_SUPER_RESOLUTION) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_OIS_DENOISE_YUV) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_SPORTS_YUV) ||
        m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_COMBINE_SINGLE_CAPTURE)) {
            /* LLS PlugIn */
        pipeId = PIPE_PLUGIN_POST1_REPROCESSING;

        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }
    }
#endif

#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_HIFI)) {
            /* LLS PlugIn */
        pipeId = PIPE_SW_MCSC_REPEOCESSING;
        ret = factory->setBufferSupplierToPipe(m_bufferSupplier, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to setBufferSupplierToPipe into pipeId %d", pipeId);
            return ret;
        }

        factory->setFrameDoneQToPipe(m_reprocessingDoneQ, pipeId);
        factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);
    }
#endif
    }

    return ret;
}

status_t ExynosCamera::m_selectBayerHandler(uint32_t pipeID, ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer *bayerBuffer,__unused ExynosCameraFrameSP_sptr_t bayerFrame, ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    buffer_manager_tag_t bufTag;
    ExynosCameraBuffer dstBuffer;
    bool needBayerProcessingThread = false;
    camera2_stream *shot_stream = NULL;
    ExynosRect cropRect;
    int32_t scenario = -1;

    /* dstbuffer setting */
    switch (pipeID) {
    case PIPE_REMOSAIC_REPROCESSING:
        //PIPE_REMOSAIC dst buffer setting
        //m_setupCaptureFrame(uint32_t pipeID);
        {
        buffer_manager_tag_t bufTag;
        bufTag.pipeId[0] = PIPE_3AA_REPROCESSING;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
#else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#endif
        ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
        if (ret != NO_ERROR || dstBuffer.index < 0) {
            CLOGE("[F%d B%d T%d P%d]Failed to getBuffer. ret %d",
                    frame->getFrameCount(), dstBuffer.index,
                    frame->getFrameType(), bufTag.pipeId[0], ret);
        }

        CLOGD("[F%d B%d T%d P%d] getBuffer. ret %d",
                frame->getFrameCount(), dstBuffer.index,
                frame->getFrameType(), bufTag.pipeId[0], ret);

        ret = frame->setDstBufferState(pipeID, ENTITY_BUFFER_STATE_REQUESTED);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to setDstBufferState. ret %d",
                    frame->getFrameCount(), dstBuffer.index, ret);
        }

        ret = frame->setDstBuffer(pipeID, dstBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to setDstBuffer. ret %d",
                    frame->getFrameCount(), dstBuffer.index, ret);
        }

        //m_setupCaputureGSC();

        int maxPictureW = 0, maxPictureH = 0;
        ExynosRect srcRect, dstRect;

        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_PICTURE_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);

        CLOGD("size (%dx%d)", maxPictureW, maxPictureH);

        srcRect.x = 0;
        srcRect.y = 0;
        srcRect.w = maxPictureW;
        srcRect.h = maxPictureH;
        srcRect.fullW = maxPictureW;
        srcRect.fullH = maxPictureH;
        //srcRect.colorFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_3AA_REPROCESSING);
        srcRect.colorFormat = V4L2_PIX_FMT_RGB565;
        ret = frame->setSrcRect(pipeID, srcRect);
        if (ret != NO_ERROR) {
            CLOGE("setSrcRect(Pipe:%d) failed, Fcount(%d), ret(%d)",
                    pipeID, frame->getFrameCount(), ret);
        }

        dstRect = srcRect;
#ifdef SUPPORT_REMOSAIC_ROTATION
        SWAP(int, dstRect.x, dstRect.y);
        SWAP(int, dstRect.w, dstRect.h);
        SWAP(int, dstRect.fullW, dstRect.fullH);
        frame->setRotation(pipeID, REMOSAIC_ROTATION);
#endif

        ret = frame->setDstRect(pipeID, dstRect);
        if (ret != NO_ERROR) {
            CLOGE("setDstRect(Pipe:%d) failed, Fcount(%d), ret(%d)",
                    pipeID, frame->getFrameCount(), ret);
        }
        }
        break;
    case PIPE_LLS_REPROCESSING:
#ifdef SUPPORT_ME
        {
            /* ME buffer setting */
            int meSrcPipeId = m_parameters[m_cameraId]->getLeaderPipeOfMe();
            int dstPos = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW]->getNodeType(PIPE_ME);
            ExynosCameraBuffer meBuffer;

            bayerFrame->getDstBuffer(meSrcPipeId, &meBuffer, dstPos);
            if (meBuffer.index < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), dstPos(%d) ret(%d)",
                        meSrcPipeId, dstPos, ret);
            } else {
                /* move to buffer position and set */
                ret = frame->setDstBuffer(pipeID, meBuffer, OTF_NODE_1);
                if (ret < 0) {
                    CLOGE("[F%d B%d]Failed to setSrcBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), meBuffer.index, pipeID, ret);
                }

                frame->addSelectorTag(m_captureSelector[m_cameraId]->getId(),
                        pipeID, OTF_NODE_1, true /* isSrc */);
            }
        }
#endif

        /* bayer buffer setting */
        shot_stream = (camera2_stream *)bayerBuffer->addr[bayerBuffer->getMetaPlaneIndex()];
        cropRect.x = shot_stream->output_crop_region[0];
        cropRect.y = shot_stream->output_crop_region[1];
        cropRect.w = shot_stream->output_crop_region[2];
        cropRect.h = shot_stream->output_crop_region[3];
        cropRect.fullW = shot_stream->output_crop_region[2];
        cropRect.fullH = shot_stream->output_crop_region[3];
        cropRect.colorFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_ISP_REPROCESSING);

        ret = frame->setSrcRect(pipeID, cropRect);
        if (ret < 0)
            CLOGE("[F%d]Failed to setSrcRect. ret %d", frame->getFrameCount(), ret);

        ret = frame->setDstRect(pipeID, cropRect);
        if (ret < 0)
            CLOGE("[F%d]Failed to setDstRect. ret %d", frame->getFrameCount(), ret);

        /* getting dst buffer in last frame */
        if (frame->getFrameType() != FRAME_TYPE_INTERNAL) {
            bufTag.pipeId[0] = pipeID;
            bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
            switch (frame->getFrameType()) {
            case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
            case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
                bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
                break;
            default:
                break;
            }
#endif
            ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
            if (ret < 0 || dstBuffer.index < 0) {
                CLOGE("[F%d B%d]Failed to get dstBuffer. ret %d",
                        frame->getFrameCount(), dstBuffer.index, ret);
            }
        } else {
            frame->setDstBufferState(pipeID, ENTITY_BUFFER_STATE_NOREQ);
            if (ret < 0)
                CLOGE("[F%d]Failed to set dstBuffer state. ret %d", frame->getFrameCount(), ret);
        }
        break;
    case PIPE_PLUGIN_PRE1_REPROCESSING:
    {
        scenario = frame->getPPScenario(pipeID);

        switch (scenario) {
        case PLUGIN_SCENARIO_HIFI_REPROCESSING:
        {
            /* bayer buffer setting */
            ExynosRect yuvInputSize;
            m_parameters[m_cameraId]->getSize(HW_INFO_HW_YUV_INPUT_SIZE, (uint32_t*)&yuvInputSize.w, (uint32_t*)&yuvInputSize.h, 0);

            shot_stream = (camera2_stream *)bayerBuffer->addr[bayerBuffer->getMetaPlaneIndex()];
            cropRect.x = yuvInputSize.x;
            cropRect.y = yuvInputSize.y;
            cropRect.w = yuvInputSize.w;
            cropRect.h = yuvInputSize.h;
            cropRect.fullW = cropRect.w;
            cropRect.fullH = cropRect.h;
            cropRect.colorFormat = V4L2_PIX_FMT_NV21;

            ret = frame->setSrcRect(pipeID, cropRect);
            if (ret < 0)
                CLOGE("[F%d]Failed to setSrcRect. ret %d", frame->getFrameCount(), ret);

            ret = frame->setDstRect(pipeID, cropRect);
            if (ret < 0)
                CLOGE("[F%d]Failed to setDstRect. ret %d", frame->getFrameCount(), ret);

            /* getting dst buffer in last frame */
            if (frame->getFrameType() != FRAME_TYPE_INTERNAL) {
#if 0
                dstBuffer = *bayerBuffer;
#else
                bufTag.pipeId[0] = PIPE_MCSC0_REPROCESSING;
                bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
                switch (frame->getFrameType()) {
                case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
                case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
                    bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
                    break;
                default:
                    break;
                }
#endif
                ret = m_checkBufferAvailable(bufTag.pipeId[0], bufTag.managerType);
                if (ret != NO_ERROR) {
                    CLOGE("Waiting buffer for Pipe(%d) timeout. ret %d", bufTag.pipeId[0], ret);
                    return INVALID_OPERATION;
                }

                ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
                if (ret < 0 || dstBuffer.index < 0) {
                    CLOGE("[F%d B%d]Failed to get dstBuffer. ret %d",
                        frame->getFrameCount(), dstBuffer.index, ret);
                }
#endif
            }
            else {
                frame->setDstBufferState(pipeID, ENTITY_BUFFER_STATE_NOREQ);
                if (ret < 0)
                    CLOGE("[F%d]Failed to set dstBuffer state. ret %d", frame->getFrameCount(), ret);
            }
            break;

        }
#ifdef USE_SLSI_PLUGIN
        case PLUGIN_SCENARIO_COMBINE_REPROCESSING:
        {
            ////////////////////////////////////////////////
            // set next pipe
            int pipeId_next = PIPE_PLUGIN_PRE1_REPROCESSING;

            ////////////////////////////////////////////////
            // setup Plugin
            ret = m_setupCapturePlugIn(frame,
                pipeID,
                pipeId_next,
                pipeId_next,
                bayerBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d] m_setupCapturePlugIn(frame(%d), pipeId(%d), pipeId_next(%d) pipeId_next(%d) bayerBuffer(%d) dstBuffer(%d)) fail",
                    frame->getFrameCount(),
                    frame->getFrameCount(),
                    pipeID,
                    pipeId_next,
                    pipeId_next,
                    bayerBuffer->index,
                    dstBuffer.index);
                goto CLEAN;
            }

            ////////////////////////////////////////////////
            break;
        }
#endif
        default:
        {
            CLOGE("[F%d] Invalid Scenario(scenario). so, fail",
                frame->getFrameCount(), scenario);
            break;
        }
        }

        break;
    }
    default:
        break;
    }

    ret = m_setupEntity(pipeID, frame, bayerBuffer, dstBuffer.index < 0 ? NULL : &dstBuffer);
    if (ret < 0) {
        CLOGE("setupEntity fail, bayerPipeId(%d), ret(%d)",
                pipeID, ret);
        goto CLEAN;
    }

    /* add selectorTag to release all buffers after done of these buffers */
    frame->addSelectorTag(m_captureSelector[m_cameraId]->getId(),
            pipeID, OUTPUT_NODE_1, true /* isSrc */);

    /* queing for different path */
    switch (pipeID) {
        case PIPE_PLUGIN_PRE1_REPROCESSING:
            if (frame->getDualOperationMode() == DUAL_OPERATION_MODE_SYNC) {
                /* Pre plugin only use master */
                factory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING];
                CFLOGI(frame, "force change reprocessing factory for Dual bayer pipe(%d)", pipeID);
            }
            [[fallthrough]];
        case PIPE_REMOSAIC_REPROCESSING:
        case PIPE_LLS_REPROCESSING:
            factory->setOutputFrameQToPipe(m_bayerStreamQ, pipeID);
            factory->pushFrameToPipe(frame, pipeID);
            needBayerProcessingThread = true;
            break;
        default:
#ifdef USE_DUAL_CAMERA
            if (m_configurations->getMode(CONFIGURATION_SUPER_NIGHT_SHOT_BAYER_MODE) == true
                && frame->getMode(FRAME_MODE_DUAL_BOKEH_ANCHOR) == true) {
                m_prepareBokehAnchorCaptureQ->pushProcessQ(&frame);
                if (m_prepareBokehAnchorCaptureThread != NULL && m_prepareBokehAnchorCaptureThread->isRunning() == false) {
                    m_prepareBokehAnchorCaptureThread->run();
                    CLOGI("Initiate prepareBokehAnchorCaptureThread (%d)", m_prepareBokehAnchorCaptureThread->getTid());
                }
            } else
#endif
            {
                m_captureQ->pushProcessQ(&frame);
            }
            break;
    }

#ifdef USES_OFFLINE_CAPTURE
    if (m_requestMgr->getRunningRequest(frame->getFrameCount()) != NULL) {
        ExynosCameraRequestSP_sprt_t request = m_requestMgr->getRunningRequest(frame->getFrameCount());
        struct camera2_shot_ext resultShot;

        m_offlineCapture->resultHandler(m_requestMgr,
                                        request,
                                        EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_SHUTTER);

        if (m_offlineCapture->isOfflineCaptureFrame(frame)) {
            ExynosCameraBuffer buffer;
            uint32_t nodeType = (uint32_t)factory->getNodeType(PIPE_JPEG0_REPROCESSING);

            ret = frame->getDstBuffer(PIPE_JPEG_REPROCESSING, &buffer, nodeType);
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", PIPE_JPEG_REPROCESSING, ret);
            }

            CLOGD("[OFFLINE] sendJpegResult buffer(%d)", buffer.index);

            m_sendJpegStreamResult(request, &buffer, 0);

            {
                native_handle_t* tempHandle = const_cast<native_handle_t*>(*(buffer.handle[0]));

                int curPlaneCount = tempHandle->numFds;
                if (curPlaneCount < 1) {
                    android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]) planeCount(%d)", __FUNCTION__, __LINE__, curPlaneCount);
                }

                CLOGD("numFds(%d)", tempHandle->numFds);

                int newFd = -1;
                for (int i = 0; i < curPlaneCount; i++) {
                    if (tempHandle->data[i] < 0) {
                        CLOGE("Invalid FD %d for plane %d", tempHandle->data[i], i);
                        continue;
                    }

                    newFd = dup(tempHandle->data[i]);
                    CLOGD("serviceFD(%d), dupFD(%d)", tempHandle->data[i], newFd);
                }

                CLOGD("tempFD(%d), originFD(%d)", tempHandle->data[0], ((buffer_handle_t)(*(buffer.handle[0])))->data[0]);

                buffer_manager_tag_t bufTag;
                const buffer_manager_tag_t initBufTag;
                bufTag = initBufTag;
                bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;
                bufTag.pipeId[0] = PIPE_JPEG0_REPROCESSING;

                ExynosCameraBuffer newBuffer;
                newBuffer.handle[0] = buffer.handle[0];
                m_bufferSupplier->getBuffer(bufTag, &newBuffer);

                char *addr = (char *)mmap(NULL, buffer.size[0], PROT_READ | PROT_WRITE, MAP_SHARED, newFd, 0);
                if (addr == (char *)MAP_FAILED || addr == NULL) {
                    CLOGE("ion_map(size=%d) failed, (fd=%d), (%s)", buffer.size[0], newFd, strerror(errno));
                    close(newFd);
                } else {
                    CLOGD("newFd buffer address(%p)", addr);
                    newBuffer.addr[0] = addr;
                    newBuffer.fd[0] = newFd;
                }

                uint32_t leaderPipeId = PIPE_JPEG_REPROCESSING;
                uint32_t nodeType = (uint32_t)m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING]->getNodeType(bufTag.pipeId[0]);

                ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, nodeType);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d B%d]Failed to setDstBufferState. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, ret);
                }

                ret = frame->setDstBuffer(leaderPipeId, newBuffer, nodeType);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d B%d]Failed to setDstBuffer. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, ret);
                }

                CLOGD("[OFFLINE] leaderPipeId(%d), bufTag.pipeId[0](%d) buffer.index(%d), buffer.addr(%p) fd(%d)", leaderPipeId, bufTag.pipeId[0], newBuffer.index, newBuffer.addr[0], newBuffer.fd[0]);

            }

            {

                ret = frame->getMetaData(&resultShot);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to getMetaData. ret %d", frame->getFrameCount(), ret);
                }

                ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_NONE, (frame_type_t)frame->getFrameType());
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d(%d)]Failed to m_updateResultShot. ret %d",
                                                                               request->getKey(),
                                                                               frame->getFrameCount(),
                                                                               resultShot.shot.dm.request.frameCount,
                                                                               ret);
                }

                ret = m_sendMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_ALL_RESULT);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d]Failed to sendMeta. ret %d",
                                                               request->getKey(),
                                                               frame->getFrameCount(),
                                                               ret);
                }

                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                                                ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
            }
        }
    } else {
        CLOGD("[OFFLINE] request is NULL which is made by internal frame");
    }
#endif

    if (needBayerProcessingThread == true &&
            m_bayerStreamThread != NULL && m_bayerStreamThread->isRunning() == false) {
        m_bayerStreamThread->run();
        CLOGI("[F%d T%d]Initiate bayerStreamThread (%d)",
                frame->getFrameCount(), frame->getFrameType(),
                m_bayerStreamThread->getTid());
    } else {
        CLOGI("[F%d T%d]bayerStreamThread (%d, %d, run:%d)",
                frame->getFrameCount(), frame->getFrameType(),
                needBayerProcessingThread, m_bayerStreamThread != NULL,
                m_bayerStreamThread->isRunning());
    }

CLEAN:
    return ret;
}

bool ExynosCamera::m_selectBayerThreadFunc()
{
    ExynosCameraFrameSP_sptr_t frame = NULL;
    status_t ret = NO_ERROR;
    frame_handle_components_t components;
    exynos_camera_state_t state = m_getState();

    if (state == EXYNOS_CAMERA_STATE_ERROR ||
            state == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGI("Thread exit reason state(%d)", state);
        return false;
    }

    ret = m_selectBayerQ->waitAndPopProcessQ(&frame);
    if (ret != NO_ERROR) {
        if (ret == TIMED_OUT) {
            CLOGV("Wait timeout");
        } else {
            CLOGE("Failed to waitAndPopProcessQ. ret %d",
                     ret);
        }
        goto CLEAN;
    } else if (frame == NULL) {
        CLOGE("frame is NULL!!");
        goto CLEAN;
    }

    if (m_selectBayer(frame) == false)
        CLOGW("can't select bayer..(%d)", frame->getFrameCount());

CLEAN:
    return true;
}

#ifdef USE_DUAL_CAMERA
bool ExynosCamera::m_selectDualSlaveBayerThreadFunc()
{
    ExynosCameraFrameSP_sptr_t frame = NULL;
    status_t ret = NO_ERROR;
    exynos_camera_state_t state = m_getState();

    if (state == EXYNOS_CAMERA_STATE_ERROR ||
            state == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGI("Thread exit reason state(%d)", state);
        return false;
    }

    ret = m_selectDualSlaveBayerQ->waitAndPopProcessQ(&frame);
    if (ret != NO_ERROR) {
        if (ret == TIMED_OUT) {
            CLOGV("Wait timeout");
        } else {
            CLOGE("Failed to waitAndPopProcessQ. ret %d",
                     ret);
        }
        goto CLEAN;
    } else if (frame == NULL) {
        CLOGE("frame is NULL!!");
        goto CLEAN;
    }

    if (m_selectBayer(frame) == false)
        CLOGW("can't select dual slave bayer..(%d)", frame->getFrameCount());

CLEAN:
    return true;
}

bool ExynosCamera::m_createReprocessingFrameThreadFunc(void)
{
    create_frame_info *frameInfo = NULL;
    factory_handler_t frameCreateHandler = NULL;
    ExynosCameraFrameFactory *factory = NULL;

    status_t ret = m_createReprocessingFrameQ->waitAndPopProcessQ(&frameInfo);
    if (ret != NO_ERROR) {
        if (ret == TIMED_OUT) {
            CLOGV("Wait timeout");
        } else {
            CLOGE("Failed to waitAndPopProcessQ. ret %d",
                     ret);
        }
        goto CLEAN;
    } else if (frameInfo == NULL) {
        CLOGE("frame is NULL!!");
        goto CLEAN;
    }

    factory = frameInfo->factory;
    if (factory == NULL) {
        CLOGE("factory is NULL!!");
        goto CLEAN;
    }

    frameCreateHandler = factory->getFrameCreateHandler();
    (this->*frameCreateHandler)(frameInfo->request, factory, frameInfo->frameType);

CLEAN:
    SAFE_DELETE(frameInfo);
    if (m_getState() != EXYNOS_CAMERA_STATE_FLUSH && m_selectBayerQ->getSizeOfProcessQ() > 0) {
        return true;
    } else {
        return false;
    }
}
#endif

bool ExynosCamera::m_selectBayer(ExynosCameraFrameSP_sptr_t frame)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;
    ExynosCameraFrameSP_sptr_t bayerFrame = NULL;
    ExynosCameraBuffer bayerBuffer;
    camera2_shot_ext *shot_ext = NULL;
    enum FRAME_TYPE frameType;
    uint32_t pipeID = 0;
    uint32_t dstPipeId = 0;
    ExynosCameraRequestSP_sprt_t request = NULL;
    uint64_t captureExposureTime = 0L;
    ExynosCameraDurationTimer timer;
    ExynosCameraFrameFactory *factory = NULL;
    frame_handle_components_t components;
    frame_handle_components_t slaveComponents;
    ExynosCameraActivityAutofocus *autoFocusMgr = NULL;
    ExynosCameraActivitySpecialCapture *sCaptureMgr = NULL;
    ExynosCameraActivityFlash *flashMgr = NULL;

#ifdef USES_CAMERA_EXYNOS_LEC
    uint32_t lecPipeId = PIPE_PLUGIN_LEC_REPROCESSING;
#endif
#ifdef SUPPORT_DEPTH_MAP
    ExynosCameraBuffer depthMapBuffer;
    depthMapBuffer.index = -2;
#endif
    bool retry = false;
    bayerBuffer.index = -2;

#ifdef SUPPORT_REMOSAIC_CAPTURE
    int remosaicCaptureRetry = 0;
#endif
    int reprocessingBayerMode = -1;

    captureExposureTime = m_configurations->getCaptureExposureTime();
    frameType = (enum FRAME_TYPE) frame->getFrameType();

#ifdef USE_DUAL_CAMERA
    if (frameType != FRAME_TYPE_REPROCESSING_DUAL_SLAVE)
#endif
    {
        if (!frame->getStreamRequested(STREAM_TYPE_CAPTURE) && !frame->getStreamRequested(STREAM_TYPE_RAW)) {
            CLOGW("[F%d]frame is not capture frame", frame->getFrameCount());
            goto CLEAN;
        }
    }

    CLOGD("[F%d T%d U%d]Start to select Bayer.",
            frame->getFrameCount(), frameType, frame->getUniqueKey());

    if ((frameType != FRAME_TYPE_INTERNAL
#ifdef SUPPORT_REMOSAIC_CAPTURE
        && frameType != FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION
#endif
#ifdef USE_DUAL_CAMERA
        && frameType != FRAME_TYPE_INTERNAL_SLAVE
#endif
#ifdef FAST_SHUTTER_NOTIFY
        ) || (frame->getHasRequest() == true
            && frame->getFrameSpecialCaptureStep() == SCAPTURE_STEP_COUNT_1)
#else
    )
#endif
        ) {
        request = m_requestMgr->getRunningRequest(frame->getFrameCount());
        if (request == NULL) {
            CLOGE("getRequest failed ");
            goto CLEAN;
        }
    }

#if 0
#ifdef USE_DUAL_CAMERA
    if (frameType == FRAME_TYPE_REPROCESSING_DUAL_SLAVE) {
        enum FRAME_FACTORY_TYPE factoryType = frame->getFactoryType();
        factory = m_frameFactory[factoryType];
    } else
#endif
    {
        factory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING];
    }
#endif

    m_getFrameHandleComponentsWrapper(frame, &components);
    autoFocusMgr = components.activityControl->getAutoFocusMgr();
    sCaptureMgr = components.activityControl->getSpecialCaptureMgr();
    flashMgr = components.activityControl->getFlashMgr();

    factory = components.reprocessingFactory;

    reprocessingBayerMode = components.parameters->getReprocessingBayerMode();

#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (frameType == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION
        || frameType == FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION) {
        CLOGD("[REMOSAIC] reprocessingBayerMode is PURE_DYNAMIC");
        reprocessingBayerMode = REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON;
    }
#endif // SUPPORT_REMOSAIC_CAPTURE

    switch (reprocessingBayerMode) {
    case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON:
        CLOGD("[F%d T%d]PURE_ALWAYS_REPROCESISNG%s Start",
                frame->getFrameCount(), frame->getFrameType(),
                (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) ? "_ZSL" : "");
        break;
    case REPROCESSING_BAYER_MODE_PURE_DYNAMIC:
        CLOGD("[F%d T%d]PURE_DYNAMIC_REPROCESISNG%s Start",
                frame->getFrameCount(), frame->getFrameType(),
                (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) ? "_ZSL" : "");
        break;
    case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON:
        CLOGD("[F%d T%d]PROCESSED_ALWAYS_REPROCESISNG%s Start",
                frame->getFrameCount(), frame->getFrameType(),
                (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) ? "_ZSL" : "");
        break;
    case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC:
        CLOGD("[F%d T%d]PROCESSED_DYNAMIC_REPROCESISNG%s Start",
                frame->getFrameCount(), frame->getFrameType(),
                (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) ? "_ZSL" : "");
        break;
    default:
        break;
    }

    if (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) {
        ret = m_getBayerServiceBuffer(frame, &bayerBuffer, request);
    } else {
        do {
            ret = NO_ERROR;
            retry = false;
            camera2_shot_ext frameShot;
            frame->getMetaData(&frameShot);

            if (frameShot.shot.ctl.flash.flashMode == CAM2_FLASH_MODE_SINGLE
                && flashMgr->getNeedFlash() == false) {
                CLOGW("[F%d B%d]Invalid flash buffer. Retry.",
                        frame->getFrameCount(), bayerBuffer.index);
                retry = true;
                usleep(3000);
            } else {
                uint32_t frameCount = frame->getFrameCount();

                if (frame->getMode(FRAME_MODE_MF_STILL)) {
                    /* HIFILLS always use the latest bayer */
                    frameCount = 0;
                }

                ret = m_getBayerBuffer(m_getBayerPipeId(),
                        frameCount,
                        &bayerBuffer,
                        components.captureSelector,
                        frameType,
                        frame,
                        bayerFrame
#ifdef SUPPORT_DEPTH_MAP
                        , &depthMapBuffer
#endif
                        );
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to m_getBayerBuffer. ret %d",
                            frameCount, ret);
                    goto CLEAN;
                }

                struct camera2_shot_ext src_ext;
                struct camera2_shot_ext *buffer_ext = NULL;
                bayerFrame->getMetaData(&src_ext);
                buffer_ext = (struct camera2_shot_ext*)bayerBuffer.addr[bayerBuffer.getMetaPlaneIndex()];
                updateMetadataUser(&src_ext, &frameShot, buffer_ext);
                frame->setMetaData(&frameShot);
            }

#ifdef SUPPORT_REMOSAIC_CAPTURE
            if ((frameType == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION || frameType == FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION)
                && remosaicCaptureRetry < SENSOR_MOODE_TRANSITION_FRAME_COUNT) {
                if (bayerFrame->getFrameType() == FRAME_TYPE_INTERNAL_SENSOR_TRANSITION) {
                    CLOGD("[F%d T%d] Getting remosaic bayer frame, retryCount(%d)",
                            bayerFrame->getFrameCount(), bayerFrame->getFrameType(),
                            remosaicCaptureRetry);
                } else {
                    CLOGW("[F%d T%d] retry get Remosaic frame for bayer buffer. retryCount(%d)",
                            bayerFrame->getFrameCount(), bayerFrame->getFrameType(),
                            remosaicCaptureRetry);
                    retry = true;
                    remosaicCaptureRetry++;
                }
            } else if (remosaicCaptureRetry == SENSOR_MOODE_TRANSITION_FRAME_COUNT) {
                CLOGE("[F%d T%d] Failed to get remosaic frame, retryCount(%d)",
                        bayerFrame->getFrameCount(), bayerFrame->getFrameType(),
                        remosaicCaptureRetry);
                retry = false;
            }
#endif //SUPPORT_REMOSAIC_CAPTURE

            bool flagForceRecovery = (components.parameters->getReprocessingBayerMode() == REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC) ? true : false;

            if (retry == false
                && m_checkValidBayerBufferSize((camera2_stream *) bayerBuffer.addr[bayerBuffer.getMetaPlaneIndex()],
                                                    frame, flagForceRecovery) == false) {
                CFLOGW(frame, "Invalid bayer buffer size(index %d).. Retry.", bayerBuffer.index);
                retry = true;
            }

#ifdef USE_DUAL_BAYER_SYNC
            if (retry == false
                && frame->isSlaveFrame() == false
                && frame->getDualOperationMode() == DUAL_OPERATION_MODE_SYNC
                && bayerFrame != NULL) {
                ret = m_pushBayerSyncFrame(bayerFrame);
                if (ret != NO_ERROR) {
                    CFLOGE(bayerFrame, "Failed to pushSyncBayerFrame. ret %d", ret);
                    retry = true;
                }
            }
#endif

            if (retry == true
                && bayerBuffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(bayerBuffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for Pipe(%d)",
                            frame->getFrameCount(), bayerBuffer.index, m_getBayerPipeId());
                    /* Continue */
                }
                bayerBuffer.index = -2;

#ifdef SUPPORT_DEPTH_MAP
                if (m_flagUseInternalDepthMap && depthMapBuffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(depthMapBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[B%d]Failed to putBuffer. ret %d", depthMapBuffer.index, ret);
                    }
                    depthMapBuffer.index = -2;
                }
#endif

#ifdef USE_DUAL_BAYER_SYNC
                if (frame->isSlaveFrame() == false
                    && frame->getDualOperationMode() == DUAL_OPERATION_MODE_SYNC
                    && bayerFrame != NULL) {
                    components.captureSelector->releasePairFrameBuffer(bayerFrame);
                }
#endif
            }
        } while(retry == true);
    }
    if (ret != NO_ERROR | bayerBuffer.index < 0) {
        CLOGE("[F%d B%d]Failed to getBayerBuffer. ret %d",
                frame->getFrameCount(), bayerBuffer.index, ret);
        goto CLEAN;
    }

    if (checkLastFrameForMultiFrameCapture(frame) == true) {
#ifdef USE_DUAL_BAYER_SYNC
        if (frame->isSlaveFrame() == true
            && frame->getDualOperationMode() == DUAL_OPERATION_MODE_SYNC) {
            m_syncBayerFrameDoneQ->release();
        }
#endif

        switch (reprocessingBayerMode) {
        case REPROCESSING_BAYER_MODE_PURE_ALWAYS_ON:
        case REPROCESSING_BAYER_MODE_DIRTY_ALWAYS_ON:
            if (m_configurations->getMode(CONFIGURATION_REMOSAIC_CAPTURE_MODE)) {
                m_configurations->setMode(CONFIGURATION_REMOSAIC_CAPTURE_MODE, false);
            }
#ifdef SUPPORT_SENSOR_MODE_CHANGE
            m_stopSensorModeTransition();
#endif //SUPPORT_SENSOR_MODE_CHANGE
            break;
        case REPROCESSING_BAYER_MODE_PURE_DYNAMIC:
        case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC:
            m_needDynamicBayerCountLock.lock();
            m_configurations->setModeValue(CONFIGURATION_NEED_DYNAMIC_BAYER_COUNT, 0);
            m_needDynamicBayerCountLock.unlock();
#ifdef SUPPORT_SENSOR_MODE_CHANGE
            m_stopSensorModeTransition();
#endif //SUPPORT_SENSOR_MODE_CHANGE
            break;
        default:
            break;
        }

#ifdef OIS_CAPTURE
        ////////////////////////////////////////////////
        // disable OIS related sequence.
        if (components.activityControl->getOISCaptureMode() == true) {
            if (frame->getMode(FRAME_MODE_DUAL_BOKEH_ANCHOR) == true) {
                if (frame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE) {
                    components.activityControl->setOISCaptureMode(false);
                } else {
                    CLOGV("[F%d]skip disable OIS", frame->getFrameCount());
                }
            } else {
                CLOGD("[F%d]Disable OIS, after this", frame->getFrameCount());
                components.activityControl->setOISCaptureMode(false);
            }
        }
#endif

        if (components.captureSelector->getBayerFrameLock() == true
            && frame->getMode(FRAME_MODE_DUAL_BOKEH_ANCHOR) == false) {
            ret = components.captureSelector->initLockFrameHoldCount(m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE));
            if (ret != NO_ERROR) {
                CLOGE("initLockFrameHoldCount is fail. ret = %d", ret);
                return ret;
            }
            components.parameters->setBayerFrameLockCount(0, 0);

            if (m_configurations->getMode(CONFIGURATION_SUPER_NIGHT_SHOT_BAYER_MODE) == true) {
                if (m_camIdInfo.numOfSensors > 1) {

                    frame_handle_components_t slaveComponents;
                    m_getFrameHandleComponentsWrapper(FRAME_TYPE_INTERNAL_SLAVE, &slaveComponents);
                    ret = slaveComponents.captureSelector->initLockFrameHoldCount(m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE));
                    if (ret != NO_ERROR) {
                        CLOGE("initLockFrameHoldCount is fail. ret = %d", ret);
                        return ret;
                    }
                    slaveComponents.parameters->setBayerFrameLockCount(0, 0);
                }
            }
        }
    }

    shot_ext = (struct camera2_shot_ext *) bayerBuffer.addr[bayerBuffer.getMetaPlaneIndex()];
    if (shot_ext == NULL) {
        CLOGE("[F%d B%d]shot_ext is NULL", frame->getFrameCount(), bayerBuffer.index);
        goto CLEAN;
    }

    /* Sync-up metadata in frame and buffer */
    if (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) {
        ret = frame->getDynamicMeta(&shot_ext->shot.dm);
        if (ret != NO_ERROR) {
            CLOGE("[F%d(%d) B%d]Failed to getDynamicMetadata. ret %d",
                    frame->getFrameCount(),
                    shot_ext->shot.dm.request.frameCount,
                    bayerBuffer.index, ret);
            goto CLEAN;
        }

        ret = frame->getUserDynamicMeta(&shot_ext->shot.udm);
        if (ret != NO_ERROR) {
            CLOGE("[F%d(%d) B%d]Failed to getUserDynamicMetadata. ret %d",
                    frame->getFrameCount(),
                    shot_ext->shot.dm.request.frameCount,
                    bayerBuffer.index, ret);
            goto CLEAN;
        }
    } else {
        ret = frame->storeDynamicMeta(shot_ext);
        if (ret < 0) {
            CLOGE("[F%d(%d) B%d]Failed to storeDynamicMeta. ret %d",
                    frame->getFrameCount(),
                    shot_ext->shot.dm.request.frameCount,
                    bayerBuffer.index, ret);
            goto CLEAN;
        }

        ret = frame->storeUserDynamicMeta(shot_ext);
        if (ret < 0) {
            CLOGE("[F%d(%d) B%d]Failed to storeUserDynamicMeta. ret %d",
                    frame->getFrameCount(),
                    shot_ext->shot.dm.request.frameCount,
                    bayerBuffer.index, ret);
            goto CLEAN;
        }
    }

    // shot_ext->shot.udm.ae.vendorSpecific[398], 1 : main-flash fired
    // When captureExposureTime is greater than CAMERA_PREVIEW_EXPOSURE_TIME_LIMIT(100msec)
    // and is less than PERFRAME_CONTROL_CAMERA_EXPOSURE_TIME_MAX(300msec)
    // and flash is on,
    // RTA can't save captureExposureTime to shot_ext->shot.dm.sensor.exposureTime.
    // So HAL will skip the checking the exposureTime.
    if (!frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT)) {
        if (m_configurations->getCaptureExposureTime() != 0
            && m_longExposureRemainCount > 0
            && m_configurations->getLongExposureShotCount() > 1) {
            ExynosRect srcRect, dstRect;
            ExynosCameraBuffer *srcBuffer = NULL;
            ExynosCameraBuffer *dstBuffer = NULL;
            bool isPacked = false;

            CLOGD("m_longExposureRemainCount(%d) getLongExposureShotCount()(%d)",
                m_longExposureRemainCount, m_configurations->getLongExposureShotCount());

            if (m_longExposureRemainCount == m_configurations->getLongExposureShotCount()) {
                /* First Bayer Buffer */
                m_newLongExposureCaptureBuffer = bayerBuffer;
                m_longExposureRemainCount--;
                goto CLEAN_FRAME;
            }

#ifdef USE_3AA_CROP_AFTER_BDS
            if (components.parameters->getUsePureBayerReprocessing() == true) {
                components.parameters->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&srcRect.w, (uint32_t *)&srcRect.h);
                dstRect = srcRect;
            } else
#endif
            {
                components.parameters->getPictureBayerCropSize(&srcRect, &dstRect);
            }

            srcRect.colorFormat = components.parameters->getBayerFormat(m_getBayerPipeId());
            dstRect.colorFormat = srcRect.colorFormat;

            if (components.parameters->getBayerFormat(m_getBayerPipeId()) == V4L2_PIX_FMT_SBGGR16) {
                if (m_longExposureRemainCount > 1) {
                    srcBuffer = &bayerBuffer;
                    dstBuffer = &m_newLongExposureCaptureBuffer;
                } else {
                    srcBuffer = &m_newLongExposureCaptureBuffer;
                    dstBuffer = &bayerBuffer;
                }
            } else {
                if (m_longExposureRemainCount > 1) {
                    srcBuffer = &bayerBuffer;
                    dstBuffer = &m_newLongExposureCaptureBuffer;
                    isPacked = true;
                } else {
                    srcBuffer = &m_newLongExposureCaptureBuffer;
                    dstBuffer = &bayerBuffer;
                    isPacked = true;
                }
            }
#ifdef USES_CAMERA_EXYNOS_LEC
#ifdef USE_3AA_CROP_AFTER_BDS
            if (components.parameters->getUsePureBayerReprocessing() == true) {
                srcRect.fullW = srcRect.w;
                srcRect.fullH = srcRect.h;
                dstRect.fullW = dstRect.w;
                dstRect.fullH = dstRect.h;
            }
#endif
            ret = frame->setSrcRect(lecPipeId, dstRect);
            if (ret < 0){
                CLOGE("[F%d]Failed to setSrcRect. ret %d", frame->getFrameCount(), ret);
            }

            ret = frame->setDstRect(lecPipeId, dstRect);
            if (ret < 0){
                CLOGE("[F%d]Failed to setdstRect. ret %d", frame->getFrameCount(), ret);
            }

            ret = frame->setSrcBuffer(lecPipeId, *srcBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                     frame->getFrameCount(), lecPipeId, ret);
            }

            ret = frame->setDstBuffer(lecPipeId, *dstBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to setDstBuffer. pipeId %d ret %d",
                     frame->getFrameCount(), lecPipeId, ret);
            }

            components.reprocessingFactory->setOutputFrameQToPipe(m_pipeFrameLecDoneQ, lecPipeId);
            components.reprocessingFactory->pushFrameToPipe(frame, lecPipeId);

            int waitCount = 0;
            do {
                ret = m_pipeFrameLecDoneQ->waitAndPopProcessQ(&frame);
                waitCount++;
                if (waitCount%5 == 0) {
                    CLOGD("[F%d]waitAndPopProcessQ ret(%d) waitCount(%d)", frame->getFrameCount(), ret, waitCount);
                }
            } while (ret == TIMED_OUT && waitCount < 20);
#else
            ret = addBayerBuffer(srcBuffer, dstBuffer, &dstRect, isPacked);
            if (ret < 0) {
                CLOGE("addBayerBufferPacked() fail");
            }

            if (m_ionClient >= 0)
                exynos_ion_sync_fd(m_ionClient, dstBuffer->fd[0]);
#endif

            CLOGD("Selected frame(%d, %d msec) m_longExposureRemainCount(%d)",
                    frame->getFrameCount(),
                    (int) shot_ext->shot.dm.sensor.exposureTime, m_longExposureRemainCount);

            if (m_longExposureRemainCount-- > 1) {
                goto CLEAN;
            }

            ret = m_bufferSupplier->putBuffer(m_newLongExposureCaptureBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for Pipe(%d)",
                    frame->getFrameCount(), m_newLongExposureCaptureBuffer.index, m_getBayerPipeId()) ;
            }
        }
    }

#ifdef FAST_SHUTTER_NOTIFY
    if (frame->getFrameSpecialCaptureStep() == SCAPTURE_STEP_COUNT_1) {
        if (isBackCamera(m_cameraId)) {
            m_configurations->setMode(CONFIGURATION_FAST_SHUTTER_MODE, true);
            CLOGD("set fast shutter mode on");
        }
#ifdef FRONT_FAST_SHUTTER_NOTIFY_BV_VALUE
        } else if (isFrontCamera(m_cameraId)) {
            int Bv = shot_ext->shot.udm.internal.vendorSpecific[2];
            CLOGD("Bv %d %f", Bv, (double)Bv/256.f);

            if ((double)Bv/256.f > FRONT_FAST_SHUTTER_NOTIFY_BV_VALUE) {
                m_configurations->setMode(CONFIGURATION_FAST_SHUTTER_MODE, true);
                CLOGD("set fast shutter mode on");
            }
        }
#endif
    }
#endif

    if ((frame->getFrameType() != FRAME_TYPE_INTERNAL
#ifdef SUPPORT_REMOSAIC_CAPTURE
        && frame->getFrameType() != FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION
#endif
#ifdef USE_DUAL_CAMERA
        && frame->getFrameType() != FRAME_TYPE_INTERNAL_SLAVE
#endif
#ifdef FAST_SHUTTER_NOTIFY
        ) || (m_configurations->getMode(CONFIGURATION_FAST_SHUTTER_MODE) == true
            && frame->getFrameSpecialCaptureStep() == SCAPTURE_STEP_COUNT_1)
#else
    )
#endif
        ) {
        if (request->getNumOfInputBuffer() > 0
            && request->getCallbackDone(EXYNOS_REQUEST_RESULT::CALLBACK_NOTIFY_ONLY) == false) {
            ret = m_updateTimestamp(request, frame, &bayerBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d(%d) B%d]Failed to updateTimestamp. ret %d",
                        request->getKey(),
                        frame->getFrameCount(),
                        shot_ext->shot.dm.request.frameCount,
                        bayerBuffer.index,
                        ret);
                goto CLEAN;
            }

            ret = m_updateResultShot(frame, request, shot_ext, PARTIAL_3AA);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d(%d) B%d]Failed to updateResultShot. ret %d",
                        request->getKey(),
                        frame->getFrameCount(),
                        shot_ext->shot.dm.request.frameCount,
                        bayerBuffer.index,
                        ret);
                goto CLEAN;
            }

            m_sendNotifyShutter(request);
        }
    }

#ifdef SUPPORT_DEPTH_MAP
    if (frame->getStreamRequested(STREAM_TYPE_DEPTH_STALL)) {
        buffer_manager_tag_t bufTag;
        ExynosCameraBuffer serviceBuffer;
        const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();
        int32_t index = -1;

        serviceBuffer.index = -2;
        index = request->getBufferIndex(HAL_STREAM_ID_DEPTHMAP_STALL);

        if (index >= 0) {
            const camera3_stream_buffer_t *streamBuffer = &(bufferList[index]);
            buffer_handle_t *handle = streamBuffer->buffer;

            bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;
            bufTag.pipeId[0] = PIPE_VC1;
            serviceBuffer.handle[0] = handle;
            serviceBuffer.acquireFence[0] = streamBuffer->acquire_fence;
            serviceBuffer.releaseFence[0] = streamBuffer->release_fence;

            ret = m_bufferSupplier->getBuffer(bufTag, &serviceBuffer);
            if (ret != NO_ERROR || serviceBuffer.index < 0) {
                CLOGE("[R%d F%d B%d]Failed to getBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), serviceBuffer.index, ret);
            }

            ret = request->setAcquireFenceDone(handle, (serviceBuffer.acquireFence[0] == -1) ? true : false);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d]Failed to setAcquireFenceDone. ret %d",
                        request->getKey(), frame->getFrameCount(), serviceBuffer.index, ret);
            }

            if (depthMapBuffer.index >= 0) {
                timer.start();
                memcpy(serviceBuffer.addr[0], depthMapBuffer.addr[0], depthMapBuffer.size[0]);
                if (m_ionClient >= 0)
                    exynos_ion_sync_fd(m_ionClient, serviceBuffer.fd[0]);
                timer.stop();
                CLOGV("memcpy time:(%5d msec)", (int)timer.durationMsecs());
            } else {
                serviceBuffer.index = -2;
            }

            ret = m_sendDepthStreamResult(request, &serviceBuffer, HAL_STREAM_ID_DEPTHMAP_STALL);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to sendRawStreamResult. ret %d",
                        frame->getFrameCount(), serviceBuffer.index, ret);
            }
        }
    }

    if (m_flagUseInternalDepthMap && depthMapBuffer.index >= 0) {
        ret = m_bufferSupplier->putBuffer(depthMapBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[B%d]Failed to putBuffer. ret %d",
                    depthMapBuffer.index, ret);
        }
        depthMapBuffer.index = -2;
    }
#endif

#ifdef DEBUG_RAWDUMP
    if (m_configurations->checkBayerDumpEnable()
        && m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true) {
        m_dumpRawBuffer(&bayerBuffer, bayerFrame, frame);

    }
#endif /* DEBUG_RAWDUMP */

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
    ////////////////////////////////////////////////
    // about factory led calibration.
    if (m_configurations->getLedCalibrationEnable() == true) {
        ret = m_dumpLedCalibrationFile(frame, bayerBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[MotFactory] m_dumpLedCalibrationFile() fail.");
        }
    }
    ////////////////////////////////////////////////
#endif

    pipeID = frame->getFirstEntity()->getPipeId();
    CFLOGD(frame, "[B%d]Setup bayerBuffer(frame:%d) for %d",
            bayerBuffer.index,
            (bayerFrame != NULL) ? bayerFrame->getFrameCount() : -1,
            pipeID);

    if (frame->getFrameType() == FRAME_TYPE_INTERNAL
#ifdef USE_DUAL_CAMERA
        || frame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE
#endif
#ifdef SUPPORT_REMOSAIC_CAPTURE
        || frame->getFrameType() == FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION
#endif
        ) {
        goto SKIP_INTERNAL;
    }

    if (pipeID == PIPE_3AA_REPROCESSING
        && components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
        dstPipeId = PIPE_3AP_REPROCESSING;
    } else if (components.parameters->getHwConnectionMode(PIPE_ISP_REPROCESSING, PIPE_MCSC_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
        dstPipeId = PIPE_ISPC_REPROCESSING;
    } else {
        if (components.parameters->isUseHWFC() == true) {
            ret = m_setHWFCBuffer(pipeID, frame, PIPE_MCSC_JPEG_REPROCESSING, PIPE_HWFC_JPEG_SRC_REPROCESSING);
            if (ret != NO_ERROR) {
                CLOGE("Set HWFC Buffer fail, pipeID(%d), srcPipe(%d), dstPipe(%d), ret(%d)",
                        pipeID, PIPE_MCSC_JPEG_REPROCESSING, PIPE_HWFC_JPEG_SRC_REPROCESSING, ret);
                goto CLEAN;
            }

            ret = m_setHWFCBuffer(pipeID, frame, PIPE_MCSC_THUMB_REPROCESSING, PIPE_HWFC_THUMB_SRC_REPROCESSING);
            if (ret != NO_ERROR) {
                CLOGE("Set HWFC Buffer fail, pipeID(%d), srcPipe(%d), dstPipe(%d), ret(%d)",
                        pipeID, PIPE_MCSC_THUMB_REPROCESSING, PIPE_HWFC_THUMB_SRC_REPROCESSING, ret);
                goto CLEAN;
            }
        }

        dstPipeId = PIPE_MCSC_JPEG_REPROCESSING;
    }

    if (components.parameters->isUseHWFC() == false
        || dstPipeId != PIPE_MCSC_JPEG_REPROCESSING) {
        if (frame->getRequest(dstPipeId) == true) {
            int managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
            switch (frame->getFrameType()) {
            case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
            case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
                managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
                break;
            default:
                break;
            }
#endif
            /* Check available buffer */
            ret = m_checkBufferAvailable(dstPipeId, managerType);
            if (ret != NO_ERROR) {
                CLOGE("Waiting buffer for Pipe(%d) timeout. ret %d", dstPipeId, ret);
                goto CLEAN;
            }
        }
    }

    ret = m_setupCaptureFactoryInternalBuffers(frame);
    if (ret != NO_ERROR) {
        CFLOGE(frame, "get internal buffers fail. ret %d", dstPipeId, ret);
        goto CLEAN;
    }

SKIP_INTERNAL:
    ret = m_selectBayerHandler(pipeID, frame, &bayerBuffer, bayerFrame, factory);
    if (ret < 0) {
        CLOGE("Failed to m_selectBayerHandler. frameCount %d ret %d",
                frame->getFrameCount(), ret);
        goto CLEAN;
    }

    if (m_captureThread->isRunning() == false) {
        m_captureThread->run(PRIORITY_DEFAULT);
    }

    /* Thread can exit only if timeout or error occured from inputQ (at CLEAN: label) */
    return true;

CLEAN:
    if (bayerBuffer.index >= 0 && !frame->getStreamRequested(STREAM_TYPE_RAW)) {
        ret = m_releaseSelectorTagBuffers(bayerFrame);
        if (ret < 0)
            CLOGE("Failed to releaseSelectorTagBuffers. frameCount %d ret %d",
                    bayerFrame->getFrameCount(), ret);
    }

CLEAN_FRAME:
    if (m_flagUseInternalDepthMap && depthMapBuffer.index >= 0) {
        ret = m_bufferSupplier->putBuffer(depthMapBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[B%d]Failed to putBuffer. ret %d",
                    depthMapBuffer.index, ret);
        }
    }

    if (frame != NULL && m_getState() != EXYNOS_CAMERA_STATE_FLUSH) {
        ret = m_removeFrameFromList(&m_captureProcessList, &m_captureProcessLock, frame);
        if (ret != NO_ERROR)
            CLOGE("Failed to remove frame from m_captureProcessList. frameCount %d ret %d",
                     frame->getFrameCount(), ret);

        frame->printEntity();
        CLOGD("[F%d]Delete frame from m_captureProcessList.", frame->getFrameCount());
        frame = NULL;
    }

    return false;
}

bool ExynosCamera::m_bayerStreamThreadFunc(void)
{
    status_t ret = 0;
    ExynosCameraFrameSP_sptr_t frame = NULL;
    ExynosCameraFrameEntity *entity = NULL;
    ExynosCameraBuffer srcBuffer;
    ExynosCameraBuffer dstBuffer;
    ExynosCameraBuffer buffer;
    ExynosCameraFrameFactory *factory;
    ExynosCameraRequestSP_sprt_t request = NULL;
    entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_INVALID;
    int32_t scenario = -1;
    int pipeId = -1;
    int nextPipeId = -1;

    ExynosCameraRequestManager* requestMgr = NULL;

    ret = m_bayerStreamQ->waitAndPopProcessQ(&frame);
    if (ret != NO_ERROR) {
        /* TODO: We need to make timeout duration depends on FPS */
        if (ret == TIMED_OUT) {
            CLOGW("wait timeout");
        } else {
            CLOGE("Failed to wait&pop m_bayerStreamQ, ret(%d)", ret);
            /* TODO: doing exception handling */
        }
        goto FUNC_EXIT;
    }

    if (frame == NULL) {
        CLOGE("frame is NULL");
        goto FUNC_EXIT;
    } else if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGD("[F%d]Flush is in progress.", frame->getFrameCount());
        goto FUNC_EXIT;
    }

    requestMgr = m_getRequestManager(frame);

    if (frame->getFrameType() != FRAME_TYPE_INTERNAL
#ifdef USE_DUAL_CAMERA
        && frame->getFrameType() != FRAME_TYPE_INTERNAL_SLAVE
#endif
#ifdef SUPPORT_REMOSAIC_CAPTURE
        && frame->getFrameType() != FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION
#endif
        ) {
        factory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING];

#ifdef SUPPORT_REMOSAIC_CAPTURE
        if (frame->getFrameType() == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION)
            factory = m_frameFactory[FRAME_FACTORY_TYPE_REMOSAIC_REPROCESSING];
#endif

        request = (frame->isCompleteForResultUpdate() == false)
                    ? requestMgr->getRunningRequest(frame->getFrameCount()) : NULL;
    }

    entity = frame->getFrameDoneEntity();
    if (entity == NULL) {
        CLOGE("Current entity is NULL");
        /* TODO: doing exception handling */
        goto FUNC_EXIT;
    }

    pipeId = entity->getPipeId();
    CLOG_PERFRAME(PATH, m_cameraId, m_name, frame.get(), nullptr, frame->getRequestKey(), "pipeId(%d)", pipeId);

    CLOGD("[F%d T%d]Bayer Processing done. entityID %d",
            frame->getFrameCount(), frame->getFrameType(), pipeId);

    switch (pipeId) {
        case PIPE_REMOSAIC_REPROCESSING:
        case PIPE_LLS_REPROCESSING:
            /* get source buffer */
            ret = frame->getSrcBuffer(entity->getPipeId(), &srcBuffer);
            if (ret != NO_ERROR || srcBuffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                        frame->getFrameCount(), srcBuffer.index, entity->getPipeId(), ret);
                ret = INVALID_OPERATION;
                goto FUNC_EXIT;
            }

            ret = frame->getSrcBufferState(entity->getPipeId(), &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)",
                        entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        srcBuffer.index, frame->getFrameCount(), entity->getPipeId());
                if (pipeId == PIPE_REMOSAIC_REPROCESSING) {

                    CLOGW("If remosaic is faied to processed," \
                            "remosaic capture continues to run with src buffer instead of remosaic processed dst buffer");

                    m_bufferSupplier->putBuffer(buffer);

                    buffer = srcBuffer;
                } else {
                    ret = INVALID_OPERATION;
                    goto FUNC_EXIT;
                }
            }

            /*
             * if the frame is not internal frame, move the dst buffer
             * to source position for reprocessing
             */
            if (frame->getFrameType() != FRAME_TYPE_INTERNAL) {
                /* get dst buffer */
                ret = frame->getDstBuffer(entity->getPipeId(), &buffer);
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("[F%d B%d]Failed to getDstBuffer. pipeId %d, ret %d",
                            frame->getFrameCount(), buffer.index, entity->getPipeId(), ret);
                    ret = INVALID_OPERATION;
                    goto FUNC_EXIT;
                }

                ret = frame->getDstBufferState(entity->getPipeId(), &bufferState);
                if (ret < 0) {
                    CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), entity->getPipeId());
                    ret = INVALID_OPERATION;
                    goto FUNC_EXIT;
                }

                /* memcpy meta data to dst buf from src buf */
                memcpy((struct camera2_shot_ext *)srcBuffer.addr[srcBuffer.getMetaPlaneIndex()],
                        (struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()],
                        sizeof(struct camera2_shot_ext));

                /* cache clean */
                if (m_ionClient >= 0) {
                    for (int i = 0; i < buffer.getMetaPlaneIndex(); i++)
                        exynos_ion_sync_fd(m_ionClient, buffer.fd[i]);
                }

                uint32_t reprocessingPipeId = 0;
                (m_checkPureBayerReprocessingFrom(frame) == true)? \
                    (reprocessingPipeId = PIPE_3AA_REPROCESSING):(reprocessingPipeId = PIPE_ISP_REPROCESSING);
                CLOGD("%s bayer reprocessing pipeId(%d)",
                        (reprocessingPipeId==PIPE_3AA_REPROCESSING)?"PURE":"PROCESSED", reprocessingPipeId);

                m_setSrcBuffer(reprocessingPipeId, frame, &buffer);
                if (ret < 0) {
                    CLOGE("[F%d B%d]Failed to setSrcBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index,
                            PIPE_ISP_REPROCESSING, ret);
                    goto FUNC_EXIT;
                }
            }

            /* release source buffer */
            if (srcBuffer.index >= 0) {
                ret = m_releaseSelectorTagBuffers(frame);
                if (ret < 0) {
                    CLOGE("Failed to releaseSelectorTagBuffers. frameCount %d ret %d",
                            frame->getFrameCount(), ret);
                    goto FUNC_EXIT;
                }
            }

            /* frame complete for internal frame */
            if (frame->getFrameType() == FRAME_TYPE_INTERNAL) {
                frame->setFrameState(FRAME_STATE_COMPLETE);
                goto FUNC_EXIT;
            }
            break;
        case PIPE_PLUGIN_PRE1_REPROCESSING:
            scenario = frame->getPPScenario(pipeId);
            switch(scenario) {
            case PLUGIN_SCENARIO_HIFI_REPROCESSING:
            {
                /* get source buffer */
                ret = frame->getSrcBuffer(entity->getPipeId(), &srcBuffer);
                if (ret != NO_ERROR || srcBuffer.index < 0) {
                    CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                            frame->getFrameCount(), srcBuffer.index, entity->getPipeId(), ret);
                    ret = INVALID_OPERATION;
                    goto FUNC_EXIT;
                }

                ret = frame->getSrcBufferState(entity->getPipeId(), &bufferState);
                if (ret < 0) {
                    CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)",
                            entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }

                if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                    CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                            srcBuffer.index, frame->getFrameCount(), entity->getPipeId());
                    ret = INVALID_OPERATION;
                    goto FUNC_EXIT;
                }

                /*
                 * if the frame is not internal frame, move the dst buffer
                 * to source position for reprocessing
                 */
                if (frame->getFrameType() != FRAME_TYPE_INTERNAL) {
                    /* get dst buffer */
                    ret = frame->getDstBuffer(entity->getPipeId(), &buffer);
                    if (ret != NO_ERROR || buffer.index < 0) {
                        CLOGE("[F%d B%d]Failed to getDstBuffer. pipeId %d, ret %d",
                                frame->getFrameCount(), buffer.index, entity->getPipeId(), ret);
                        ret = INVALID_OPERATION;
                        goto FUNC_EXIT;
                    }

                    ret = frame->getDstBufferState(entity->getPipeId(), &bufferState);
                    if (ret < 0) {
                        CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", entity->getPipeId(), ret);
                        goto FUNC_EXIT;
                    }

                    if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                        CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                                buffer.index, frame->getFrameCount(), entity->getPipeId());
                        ret = INVALID_OPERATION;
                        goto FUNC_EXIT;
                    }

                    /* memcpy meta data to dst buf from src buf */
                    memcpy((struct camera2_shot_ext *)srcBuffer.addr[srcBuffer.getMetaPlaneIndex()],
                            (struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()],
                            sizeof(struct camera2_shot_ext));

                    /* cache clean */
                    if (m_ionClient >= 0) {
                        for (int i = 0; i < buffer.getMetaPlaneIndex(); i++)
                            exynos_ion_sync_fd(m_ionClient, buffer.fd[i]);
                    }

                    nextPipeId = frame->getNextEntity()->getPipeId();
                    m_setSrcBuffer(nextPipeId, frame, &buffer);
                    if (ret < 0) {
                        CLOGE("[F%d B%d]Failed to setSrcBuffer. pipeId %d ret %d",
                                frame->getFrameCount(), buffer.index,
                                PIPE_ISP_REPROCESSING, ret);
                        goto FUNC_EXIT;
                    }
                }

                /* release source buffer */
                if (srcBuffer.index >= 0) {
                    ret = m_releaseSelectorTagBuffers(frame);
                    if (ret < 0) {
                        CLOGE("Failed to releaseSelectorTagBuffers. frameCount %d ret %d",
                                frame->getFrameCount(), ret);
                        goto FUNC_EXIT;
                    }
                }

                /* frame complete for internal frame */
                if (frame->getFrameType() == FRAME_TYPE_INTERNAL) {
                    frame->setFrameState(FRAME_STATE_COMPLETE);
                    goto FUNC_EXIT;
                }
                break;
            }
            case PLUGIN_SCENARIO_COMBINE_REPROCESSING:
            {
#if 0
                /*
                 * release src buffer when all multi bayer processing done
                 * in COMBINE reprocessing plugin cause for keep to bayer buffer
                 */
                ret = m_putSrcBuffer(frame, pipeId);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]m_putSrcBuffer(pipeId(%d)) fail", frame->getFrameCount(), pipeId);
                }
#endif
                ////////////////////////////////////////////////
                // about dst buffer
                ret = frame->getDstBuffer(pipeId, &dstBuffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to getDstBuffer. pipeId %d ret %d",
                        frame->getFrameCount(), pipeId, ret);
                    goto FUNC_EXIT;
                }

                ////////////////////////////////////////////////
                // get nextPipeId
                nextPipeId = frame->getNextEntity()->getPipeId();

#ifdef USE_DUAL_CAMERA
                if (frame->getMode(FRAME_MODE_DUAL_BOKEH_ANCHOR) == true) {
                    ret = frame->setSrcBufferState(nextPipeId, ENTITY_BUFFER_STATE_REQUESTED);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]setDstBufferState(nextPipeId : %d, ENTITY_BUFFER_STATE_REQUESTED) fail",
                            frame->getFrameCount(), nextPipeId);
                        goto FUNC_EXIT;
                    }

                    /* cache clean */
                    if (dstBuffer.index < 0) {
                        CLOGE("Invalid dstBuffer index %d", dstBuffer.index);
                    } else {
                        if (m_ionClient >= 0) {
                            for (int i = 0; i < dstBuffer.getMetaPlaneIndex(); i++) {
                                CLOGI("exynos_ion_sync_fd for buffer index(%d), fd(%d)", dstBuffer.index, dstBuffer.fd[i]);
                                exynos_ion_sync_fd(m_ionClient, dstBuffer.fd[i]);
                            }
                        }
                    }

                    ret = frame->setSrcBuffer(nextPipeId, dstBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to setSrcBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), dstBuffer.index, nextPipeId, ret);
                        goto FUNC_EXIT;
                    }

                    m_prepareBokehAnchorCaptureQ->pushProcessQ(&frame);

                    goto FUNC_EXIT;
                } else
#endif
                if ((checkLastFrameForMultiFrameCapture(frame) == false)
#ifdef USE_DUAL_CAMERA
                    && (frame->getFrameType() != FRAME_TYPE_REPROCESSING_DUAL_MASTER
                        && frame->getFrameType() != FRAME_TYPE_REPROCESSING_DUAL_SLAVE)
#endif
                    ) {
                    /* set null buffer for preventing "putBuffer" */
                    ret = frame->setDstBufferState(pipeId, ENTITY_BUFFER_STATE_REQUESTED);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]setDstBufferState(pipeId : %d, ENTITY_BUFFER_STATE_REQUESTED) fail",
                            frame->getFrameCount(), pipeId);
                        goto FUNC_EXIT;
                    }

                    ExynosCameraBuffer nullBuf;
                    frame->setDstBuffer(pipeId, nullBuf);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]setDstBuffer(pipeId : %d, nullBuf) fail",
                            frame->getFrameCount(), pipeId);
                        goto FUNC_EXIT;
                    }

                    /* set src buffer of next pipe, with error */
                    frame->setSrcBufferState(nextPipeId, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]setDstBufferState(nextPipeId : %d, ENTITY_BUFFER_STATE_ERROR) fail",
                            frame->getFrameCount(), nextPipeId, ENTITY_BUFFER_STATE_ERROR);
                        goto FUNC_EXIT;
                    }

                    /* frame complete for internal frame */
                    frame->setFrameState(FRAME_STATE_COMPLETE);
                    goto FUNC_EXIT;
                } else {
                    /* forward dst buffer */
                    ret = frame->setSrcBufferState(nextPipeId, ENTITY_BUFFER_STATE_REQUESTED);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]setDstBufferState(nextPipeId : %d, ENTITY_BUFFER_STATE_REQUESTED) fail",
                            frame->getFrameCount(), nextPipeId);
                        goto FUNC_EXIT;
                    }

                    /* cache clean */
                    if (dstBuffer.index < 0) {
                        CLOGE("Invalid dstBuffer index %d", dstBuffer.index);
                    } else {
                        if (m_ionClient >= 0) {
                            for (int i = 0; i < dstBuffer.getMetaPlaneIndex(); i++) {
                                CLOGI("exynos_ion_sync_fd for buffer index(%d), fd(%d)", dstBuffer.index, dstBuffer.fd[i]);
                                exynos_ion_sync_fd(m_ionClient, dstBuffer.fd[i]);
                            }
                        }
                    }

                    ret = frame->setSrcBuffer(nextPipeId, dstBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to setSrcBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), dstBuffer.index, nextPipeId, ret);
                        goto FUNC_EXIT;
                    }
                }
                break;
            }
            default:
                break;
            }
            break;
#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
        case PIPE_SW_MCSC_REPEOCESSING:
            break;
#endif
        default:
            CLOGE("Invalid pipeId %d", entity->getPipeId());
            break;
    }

    ret = frame->setEntityState(pipeId, ENTITY_STATE_COMPLETE);
    if (ret < 0) {
        CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
                entity->getPipeId(), ENTITY_STATE_COMPLETE, ret);
        return ret;
    }

    m_captureQ->pushProcessQ(&frame);

FUNC_EXIT:
    if (frame != NULL && frame->isComplete() == true && m_getState() != EXYNOS_CAMERA_STATE_FLUSH) {
        /* error case */
        if (frame->getFrameType() != FRAME_TYPE_INTERNAL && ret < 0) {
            ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d] sendNotifyError fail. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
            }
        }
        if (frame->getPipeIdForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == pipeId
                && (frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == true)) {
            struct camera2_shot_ext resultShot;
            ExynosCameraRequestSP_sprt_t request = NULL;

            ret = frame->getMetaData(&resultShot);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to getMetaData. ret %d", frame->getFrameCount(), ret);
            }

            request = requestMgr->getRunningRequest(frame->getFrameCount());
            if (request == NULL) {
                CLOGE("getRequest failed ");
                return INVALID_OPERATION;
            }

            ret = m_updateResultShot(frame, request, &resultShot);
            if (ret != NO_ERROR) {
                CLOGE("[F%d(%d)]Failed to m_updateResultShot. ret %d",
                        frame->getFrameCount(), resultShot.shot.dm.request.frameCount, ret);
            }
            ret = m_sendMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_ALL_RESULT);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to sendMeta. ret %d", frame->getFrameCount(), ret);
            }
        }

        List<ExynosCameraFrameSP_sptr_t> *list = NULL;
        Mutex *listLock = NULL;
        list = &m_captureProcessList;
        listLock = &m_captureProcessLock;
        // TODO:decide proper position
        CLOGD("frame complete. framecount %d", frame->getFrameCount());
        ret = m_removeFrameFromList(list, listLock, frame);
        if (ret < 0) {
            CLOGE("remove frame from processList fail, ret(%d)", ret);
        }

        frame = NULL;
    }
    {
        Mutex::Autolock l(m_captureProcessLock);
        if (m_captureProcessList.size() > 0)
            return true;
        else
            return false;
    }
}

status_t ExynosCamera::m_handleYuvCaptureFrame(ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer srcBuffer;
    ExynosCameraBuffer dstBuffer;
    int pipeId_src = -1;
    int pipeId_gsc = -1;
    int pipeId_jpeg = -1;
    int pipe_mcsc_jpeg = -1;
    int pipe_mcsc_thumb = -1;
    int pipe_clahe_jpeg = -1;
    ExynosCameraRequestSP_sprt_t request = NULL;
    frame_handle_components_t components;
    ExynosCameraFrameFactory *factory = NULL;
    ExynosCameraBuffer gscBuffer;
    int rotation = 0;

    float zoomRatio = 0.0F;
    struct camera2_stream *shot_stream = NULL;
    int pictureW = 0, pictureH = 0, pictureFormat = 0;
    ExynosRect srcRect, dstRect;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(frame);

    request = requestMgr->getRunningRequest(frame->getFrameCount());
    m_getFrameHandleComponentsWrapper(frame, &components);

    if (components.parameters->isReprocessing() == true) {
#ifdef USE_CLAHE_REPROCESSING
        pipe_clahe_jpeg = PIPE_CLAHEC_REPROCESSING;
#endif
        pipeId_src = m_getMcscLeaderPipeId(&components);
        pipeId_jpeg = PIPE_JPEG_REPROCESSING;
        pipe_mcsc_jpeg = PIPE_MCSC_JPEG_REPROCESSING;
        pipe_mcsc_thumb = PIPE_MCSC_THUMB_REPROCESSING;
        factory = components.reprocessingFactory;
    } else {
        pipeId_src = PIPE_ISP;
        pipeId_jpeg = PIPE_JPEG;
        pipe_mcsc_jpeg = PIPE_MCSC_JPEG;
        pipe_mcsc_thumb = PIPE_MCSC_THUMB;
        factory = components.previewFactory;
    }

#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
    if (frame->getMode(FRAME_MODE_SWMCSC) == true) {
        pipeId_src = PIPE_SW_MCSC_REPEOCESSING;
    }
#endif

    if (components.parameters->isUseHWFC() == true
        ) {
        ret = frame->getDstBuffer(pipeId_src, &dstBuffer, factory->getNodeType(pipe_mcsc_jpeg));
        if (ret != NO_ERROR) {
            CLOGE("Failed to getDstBuffer. pipeId %d node %d ret %d",
                    pipeId_src, pipe_mcsc_jpeg, ret);
            return INVALID_OPERATION;
        }

        ret = m_bufferSupplier->putBuffer(dstBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to putBuffer for MCSC_JPEG_REP. ret %d",
                    frame->getFrameCount(), dstBuffer.index, ret);
            return INVALID_OPERATION;
        }

        if (frame->getRequest(pipe_mcsc_thumb) == true) {
            ret = frame->getDstBuffer(pipeId_src, &dstBuffer, factory->getNodeType(pipe_mcsc_thumb));
            if (ret != NO_ERROR) {
                if (request == NULL) {
                    CLOGE("[F%d]Failed to getDstBuffer. pipeId %d node %d ret %d",
                        frame->getFrameCount(),
                        pipeId_src, pipe_mcsc_thumb, ret);
                } else {
                    CLOGE("[R%d F%d]Failed to getDstBuffer. pipeId %d node %d ret %d",
                        request->getKey(), frame->getFrameCount(),
                        pipeId_src, pipe_mcsc_thumb, ret);
                }
                return INVALID_OPERATION;
            }

            ret = m_bufferSupplier->putBuffer(dstBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for MCSC_THUMB_REP. ret %d",
                        frame->getFrameCount(), dstBuffer.index, ret);
                return INVALID_OPERATION;
            }
        }
    } else {
        zoomRatio = components.configuration->getZoomRatio();

        if (frame->getRequest(pipe_mcsc_thumb) == true) {
            // Thumbnail image is currently not used
            ret = frame->getDstBuffer(pipeId_src, &dstBuffer, factory->getNodeType(pipe_mcsc_thumb));
            if (ret != NO_ERROR) {
                CLOGE("Failed to getDstBuffer. pipeId %d node %d ret %d",
                        pipeId_src, pipe_mcsc_thumb, ret);
            } else {
                ret = m_bufferSupplier->putBuffer(dstBuffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for MCSC_THUMB_REP. ret %d",
                            frame->getFrameCount(), dstBuffer.index, ret);
                }
                CLOGI("[F%d B%d]Thumbnail image disposed at pipeId %d node %d",
                        frame->getFrameCount(), dstBuffer.index,
                        pipeId_src, pipe_mcsc_thumb);
            }
        }

        if (components.parameters->needGSCForCapture(getCameraId()) == true
#ifdef SUPPORT_REMOSAIC_ROTATION
            || (frame->getFrameType() == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION)
#endif // SUPPORT_REMOSAIC_ROTATION
        ) {
#ifdef SUPPORT_REMOSAIC_ROTATION
            if (frame->getFrameType() == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION) {
                pipeId_gsc = PIPE_GSC_REPROCESSING;

                rotation = 360 - REMOSAIC_ROTATION;

                const buffer_manager_tag_t initBufTag;
                buffer_manager_tag_t bufTag;

                bufTag = initBufTag;
                bufTag.pipeId[0] = pipe_mcsc_jpeg;
                bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
                switch (frame->getFrameType()) {
                case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
                case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
                    bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
                    break;
                default:
                    break;
                }
#endif
                ret = m_bufferSupplier->getBuffer(bufTag, &gscBuffer);
                if (ret < 0)
                    CLOGE("getBuffer fail, pipeId(%d), ret(%d)", pipe_mcsc_jpeg, ret);

                ret = frame->getDstBuffer(pipeId_src, &srcBuffer, factory->getNodeType(pipe_mcsc_jpeg));
            } else
#endif //SUPPORT_REMOSAIC_ROTATION
            {
                ret = frame->getDstBuffer(pipeId_src, &srcBuffer);
            }
            if (ret < 0)
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", pipeId_src, ret);

            shot_stream = (struct camera2_stream *)(srcBuffer.addr[srcBuffer.getMetaPlaneIndex()]);
            if (shot_stream != NULL) {
                CLOGD("(%d %d %d %d)",
                        shot_stream->fcount,
                        shot_stream->rcount,
                        shot_stream->findex,
                        shot_stream->fvalid);
                CLOGD("(%d %d %d %d)(%d %d %d %d)",
                        shot_stream->input_crop_region[0],
                        shot_stream->input_crop_region[1],
                        shot_stream->input_crop_region[2],
                        shot_stream->input_crop_region[3],
                        shot_stream->output_crop_region[0],
                        shot_stream->output_crop_region[1],
                        shot_stream->output_crop_region[2],
                        shot_stream->output_crop_region[3]);
            } else {
                CLOGE("shot_stream is NULL");
                return INVALID_OPERATION;
            }

            /* should change size calculation code in pure bayer */
            components.configuration->getSize(CONFIGURATION_PICTURE_SIZE, (uint32_t *)&pictureW, (uint32_t *)&pictureH);
            pictureFormat = components.parameters->getHwPictureFormat();

            srcRect.x = shot_stream->output_crop_region[0];
            srcRect.y = shot_stream->output_crop_region[1];
            srcRect.w = shot_stream->output_crop_region[2];
            srcRect.h = shot_stream->output_crop_region[3];
            srcRect.fullW = shot_stream->output_crop_region[2];
            srcRect.fullH = shot_stream->output_crop_region[3];
            srcRect.colorFormat = pictureFormat;

#ifdef SUPPORT_REMOSAIC_ROTATION
            if (frame->getFrameType() == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION) {
                /* 16 pixel align for REMOSAIC_ROTATION stride */
                srcRect.fullW = ALIGN_UP(srcRect.fullW, CAMERA_16PX_ALIGN);
            }
#endif

            dstRect.x = 0;
            dstRect.y = 0;
            dstRect.w = pictureW;
            dstRect.h = pictureH;
            dstRect.fullW = pictureW;
            dstRect.fullH = pictureH;
            dstRect.colorFormat = JPEG_INPUT_COLOR_FMT;
            frame->setRotation(pipeId_gsc, rotation);

#ifdef SUPPORT_REMOSAIC_ROTATION
            if (frame->getFrameType() == FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION) {
                ret = getCropRectAlign(srcRect.h,  srcRect.w,
                        pictureW,   pictureH,
                        &srcRect.y, &srcRect.x,
                        &srcRect.h, &srcRect.w,
                        2, 2, zoomRatio);

            } else
#endif //SUPPORT_REMOSAIC_ROTATION
            {
                ret = getCropRectAlign(srcRect.w,  srcRect.h,
                        pictureW,   pictureH,
                        &srcRect.x, &srcRect.y,
                        &srcRect.w, &srcRect.h,
                        2, 2, zoomRatio);
            }
            ret = frame->setSrcRect(pipeId_gsc, &srcRect);
            ret = frame->setDstRect(pipeId_gsc, &dstRect);

            CLOGD("size (%d, %d, %d, %d %d %d)",
                    srcRect.x, srcRect.y, srcRect.w, srcRect.h, srcRect.fullW, srcRect.fullH);
            CLOGD("size (%d, %d, %d, %d %d %d)",
                    dstRect.x, dstRect.y, dstRect.w, dstRect.h, dstRect.fullW, dstRect.fullH);

            ret = m_setupEntity(pipeId_gsc, frame, &srcBuffer, &gscBuffer);
            if (ret < 0) {
                CLOGE("setupEntity fail, pipeId(%d), ret(%d)",
                         pipeId_jpeg, ret);
            }

            factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_gsc);
            factory->pushFrameToPipe(frame, pipeId_gsc);
        }

#ifdef USE_CLAHE_REPROCESSING
        else if (frame->getRequest(pipe_clahe_jpeg) == true) {
            pipeId_src = PIPE_CLAHE_REPROCESSING;
            ret = frame->getDstBuffer(pipeId_src, &srcBuffer, factory->getNodeType(pipe_clahe_jpeg));
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to getDstBuffer. pipeId %d ret %d",
                        frame->getFrameCount(), pipeId_src, ret);
                return ret;
            }

            ret = frame->setSrcBuffer(pipeId_jpeg, srcBuffer);
            if (ret != NO_ERROR) {
                if (request == NULL) {
                    CLOGE("[F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), pipeId_jpeg, ret);
                } else {
                    CLOGE("[R%d F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                            request->getKey(), frame->getFrameCount(), pipeId_jpeg, ret);
                }
            }

            factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_jpeg);
            factory->pushFrameToPipe(frame, pipeId_jpeg);
        }
#endif

        else { /* m_parameters[m_cameraId]->needGSCForCapture(getCameraId()) == false */
            ret = frame->getDstBuffer(pipeId_src, &srcBuffer, factory->getNodeType(pipe_mcsc_jpeg));
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to getDstBuffer. pipeId %d ret %d",
                        frame->getFrameCount(), pipeId_src, ret);
                return ret;
            }

            ret = frame->setSrcBuffer(pipeId_jpeg, srcBuffer);
            if (ret != NO_ERROR) {
                if (request == NULL) {
                    CLOGE("[F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                        frame->getFrameCount(), pipeId_jpeg, ret);
                } else {
                    CLOGE("[R%d F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                        request->getKey(), frame->getFrameCount(), pipeId_jpeg, ret);
                }
            }

            factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_jpeg);
            factory->pushFrameToPipe(frame, pipeId_jpeg);
        }
    }

    return ret;
}

status_t ExynosCamera::m_handleJpegFrame(ExynosCameraFrameSP_sptr_t frame, int leaderPipeId)
{
    status_t ret = NO_ERROR;
    int pipeId_jpeg = -1;
    ExynosCameraRequestSP_sprt_t request = NULL;
    ExynosCameraBuffer buffer;
    int jpegOutputSize = -1;
    exif_attribute_t exifInfo;
    ExynosRect pictureRect;
    ExynosRect thumbnailRect;
    struct camera2_shot_ext *jpeg_meta_shot;
    frame_handle_components_t components;
    uint32_t jpegDstNode = 0;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);
    components.parameters->getFixedExifInfo(&exifInfo);
    pictureRect.colorFormat = components.parameters->getHwPictureFormat();
    components.configuration->getSize(CONFIGURATION_PICTURE_SIZE, (uint32_t *)&pictureRect.w, (uint32_t *)&pictureRect.h);

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(frame);

    request = requestMgr->getRunningRequest(frame->getFrameCount());
    if (request == NULL) {
#ifdef USES_OFFLINE_CAPTURE
        if (m_offlineCapture->isOfflineCaptureFrame(frame)) {
            request = m_offlineCapture->getRequest();
        }
#endif
        if (request == NULL) {
            CLOGE("[F%d] request is NULL.", frame->getFrameCount());
            ret = INVALID_OPERATION;
            return ret;
        }
    }

    if (leaderPipeId == PIPE_VRA_REPROCESSING) {
        leaderPipeId = m_getMcscLeaderPipeId(&components);
    }

    /* We are using only PIPE_ISP_REPROCESSING */
    if (components.parameters->isReprocessing() == true
            && components.parameters->isUseVideoHQISP() == false) {
        pipeId_jpeg = PIPE_JPEG_REPROCESSING;
    } else {
        pipeId_jpeg = PIPE_JPEG;
    }

    if (components.parameters->isUseHWFC() == true && leaderPipeId != PIPE_JPEG_REPROCESSING) {
        entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_NOREQ;
        ret = frame->getDstBufferState(leaderPipeId, &bufferState, components.reprocessingFactory->getNodeType(PIPE_HWFC_JPEG_DST_REPROCESSING));
        if (ret != NO_ERROR) {
            CLOGE("Failed to getDstBufferState. frameCount %d pipeId %d node %d",
                    frame->getFrameCount(),
                    leaderPipeId, PIPE_HWFC_JPEG_DST_REPROCESSING);
            return INVALID_OPERATION;
        } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            request->setStreamBufferStatus(HAL_STREAM_ID_JPEG, CAMERA3_BUFFER_STATUS_ERROR);
            CLOGE("Invalid JPEG buffer state. frameCount %d bufferState %d",
                    frame->getFrameCount(), bufferState);
        }

        ret = frame->getDstBuffer(leaderPipeId, &buffer, components.reprocessingFactory->getNodeType(PIPE_HWFC_JPEG_DST_REPROCESSING));
        if (ret != NO_ERROR) {
            CLOGE("Failed to getDstBuffer. frameCount %d pipeId %d node %d",
                    frame->getFrameCount(),
                    leaderPipeId, PIPE_HWFC_JPEG_DST_REPROCESSING);
            return INVALID_OPERATION;
        }

        /* get dynamic meters for make exif info */
        jpeg_meta_shot = new struct camera2_shot_ext;
        memset(jpeg_meta_shot, 0x00, sizeof(struct camera2_shot_ext));
        frame->getMetaData(jpeg_meta_shot);

        thumbnailRect.w = jpeg_meta_shot->shot.ctl.jpeg.thumbnailSize[0];
        thumbnailRect.h = jpeg_meta_shot->shot.ctl.jpeg.thumbnailSize[1];
        components.parameters->setExifChangedAttribute(&exifInfo, &pictureRect, &thumbnailRect, jpeg_meta_shot, true);

        /*In case of HWFC, overwrite buffer's size to compression's size in ExynosCameraNodeJpeg file.*/
        jpegOutputSize = buffer.size[0];

        /* in case OTF until JPEG, we should overwrite debugData info to Jpeg data. */
        if (buffer.size[0] != 0) {
            /* APP1 Marker - EXIF */
            UpdateExif(buffer.addr[0], buffer.size[0], &exifInfo);
            /* APP4 Marker - DebugInfo */
            UpdateDebugData(buffer.addr[0], buffer.size[0], components.parameters->getDebug2Attribute());
        }

        delete jpeg_meta_shot;
    } else {
        ret = frame->setEntityState(pipeId_jpeg, ENTITY_STATE_FRAME_DONE);
        if (ret < 0) {
            CLOGE("Failed to setEntityState, frameCoutn %d ret %d",
                    frame->getFrameCount(), ret);
            return INVALID_OPERATION;
        }

        m_thumbnailCbThread->join();

        ret = frame->getSrcBuffer(pipeId_jpeg, &buffer);
        if (ret < 0) {
            CLOGE("getSrcBuffer fail, pipeId(%d), ret(%d)", pipeId_jpeg, ret);
        }

        ret = m_bufferSupplier->putBuffer(buffer);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d]Failed to putBuffer for JPEG_SRC. ret %d",
                request->getKey(), frame->getFrameCount(), buffer.index, ret);
        }

        int jpegPipeId = PIPE_JPEG0_REPROCESSING;
        jpegDstNode = components.reprocessingFactory->getNodeType(jpegPipeId);
        entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_NOREQ;
        ret = frame->getDstBufferState(pipeId_jpeg, &bufferState, jpegDstNode);
        if (ret != NO_ERROR) {
            CLOGE("ERR(%s[%d]):Failed to getDstBufferState. frameCount %d pipeId %d",
                    __FUNCTION__, __LINE__,
                    frame->getFrameCount(),
                    pipeId_jpeg);
        } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            request->setStreamBufferStatus(HAL_STREAM_ID_JPEG, CAMERA3_BUFFER_STATUS_ERROR);
            CLOGE("ERR(%s[%d]):Invalid JPEG buffer state. frameCount %d bufferState %d",
                    __FUNCTION__, __LINE__,
                    frame->getFrameCount(),
                    bufferState);
        }

#ifdef USE_DUAL_CAMERA
        if (components.configuration->getMode(CONFIGURATION_DUAL_BOKEH_REFOCUS_MODE) == true) {
            int refocusDepthPipeId = PIPE_PLUGIN_POST1_REPROCESSING;
            ret = frame->getSrcBuffer(pipeId_jpeg, &buffer, OUTPUT_NODE_2);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]getSrcBuffer fail, pipeId(%d), ret(%d)",
                        frame->getFrameCount(), pipeId_jpeg, ret);
                return ret;
            }

            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]getSrcBuffer fail, pipeId(%d), ret(%d)",
                        frame->getFrameCount(), pipeId_jpeg, ret);
                return ret;
            }

            ret = m_composeBokehRefocusJpegBuffer(frame, jpegPipeId, refocusDepthPipeId, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d P%d]Failed to m_compositionRefocusJpegBuffer. ret = %d",
                        frame->getFrameCount(), pipeId_jpeg, ret);
            }
        } else
#endif
        {
            ret = frame->getDstBuffer(pipeId_jpeg, &buffer, jpegDstNode);
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", pipeId_jpeg, ret);
            }
        }
        jpegOutputSize = frame->getJpegEncodeSize(PIPE_JPEG0_REPROCESSING);
    }

    CLOGI("Jpeg output done, jpeg size(%d)", jpegOutputSize);

#ifdef USES_OFFLINE_CAPTURE
    if (m_offlineCapture->isOfflineCaptureFrame(frame)) {
        CLOGD("[OFFLINE] Skip to send jpeg stream result");
        close(buffer.fd[0]);

        int cameraSessionForOffline = m_offlineCapture->getCameraSessionId(frame);
        if (m_offlineCapture->callbackHandler(frame, ((ret==NO_ERROR)?1:0)) == true) {

            CLOGD("current session(%d), offline camera session(%d)",
                    m_cameraSessionId, cameraSessionForOffline);

            if (m_cameraSessionId != cameraSessionForOffline) {
                ret = m_deinitReprocessingFrameFactory(cameraSessionForOffline);
                if (ret != NO_ERROR) {
                    CLOGE("[S(%d)] m_deinitReprocessingFrameFactory() is failed", cameraSessionForOffline);
                }

                ExynosCameraResourceManager::resources_t* resources = m_resourceManager->getResource(cameraSessionForOffline);
                m_resourceManager->deInitBufferSupplier(&resources->bufferProperty.bufferSupplier, &resources->bufferProperty.ionAllocator);
            } else {
                CLOGI("current session(%d) and capture session(%d) is same!!",
                        m_cameraSessionId, cameraSessionForOffline);
            }
        }
    } else
#endif
    {
        m_sendJpegStreamResult(request, &buffer, jpegOutputSize);
    }

    return ret;
}

bool ExynosCamera::m_captureStreamThreadFunc(void)
{
    status_t ret = 0;
    ExynosCameraFrameSP_sptr_t frame = NULL;
    ExynosCameraFrameEntity *entity = NULL;
    ExynosCameraBuffer buffer;
    ExynosCameraBuffer serviceBuffer;
    ExynosCameraRequestSP_sprt_t request = NULL;
    struct camera2_shot_ext resultShot;
    struct camera2_shot_ext *shot_ext = NULL;
    entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_INVALID;
    frame_handle_components_t components;
    int pipeId = -1;
    int dstPipeId = -1;
    int dstPos = -1;
    bool flag3aaVraOTF;
    bool flagMcscVraOTF = false;
    bool needNV21CallbackHandle = false;

    ExynosCameraRequestManager* requestMgr = NULL;

    ret = m_yuvCaptureDoneQ->waitAndPopProcessQ(&frame);
    if (ret != NO_ERROR) {
        /* TODO: We need to make timeout duration depends on FPS */
        if (ret == TIMED_OUT) {
            CLOGW("wait timeout");
        } else {
            CLOGE("Failed to wait&pop m_yuvCaptureDoneQ, ret(%d)", ret);
            /* TODO: doing exception handling */
        }
        goto FUNC_EXIT;
    }

    if (frame == NULL) {
        CLOGE("frame is NULL");
        goto FUNC_EXIT;
    } else if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
        CLOGD("[F%d]Flush is in progress.", frame->getFrameCount());
        goto FUNC_EXIT;
    }

    requestMgr = m_getRequestManager(frame);

    m_getFrameHandleComponentsWrapper(frame, &components, m_getCameraSessionId(frame));
    flag3aaVraOTF = (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_VRA_REPROCESSING)
                    == HW_CONNECTION_MODE_M2M);
    if (!flag3aaVraOTF) {
        flagMcscVraOTF = (components.parameters->getHwConnectionMode(PIPE_MCSC_REPROCESSING, PIPE_VRA_REPROCESSING)
                    == HW_CONNECTION_MODE_M2M);
    }
    entity = frame->getFrameDoneEntity();
    if (entity == NULL) {
        CLOGE("Current entity is NULL");
        /* TODO: doing exception handling */
        goto FUNC_EXIT;
    }

    pipeId = entity->getPipeId();
    CLOG_PERFRAME(PATH, m_cameraId, m_name, frame.get(), nullptr, frame->getRequestKey(), "pipeId(%d)", pipeId);

    if ((frame->getFrameType() != FRAME_TYPE_INTERNAL
#ifdef USE_DUAL_CAMERA
        && frame->getFrameType() != FRAME_TYPE_INTERNAL_SLAVE
#endif
        ) && frame->isCompleteForResultUpdate() == false) {
        request = requestMgr->getRunningRequest(frame->getFrameCount());
        if (request == NULL) {
#ifdef USES_OFFLINE_CAPTURE
            if (m_offlineCapture->isOfflineCaptureFrame(frame)) {
                request = m_offlineCapture->getRequest();
            }
#endif
            if (request == NULL) {
                CLOGE("[F%d]Failed to get request.", frame->getFrameCount());
                goto FUNC_EXIT2;
            }
        }
    }

    CFLOGD(frame, "[%d/%d] YUV capture done. entityID %d [%d,%d,%d]",
            frame->getFrameIndex(), frame->getMaxFrameIndex(),
            entity->getPipeId(), PIPE_ISP_REPROCESSING, PIPE_SYNC_REPROCESSING, PIPE_PLUGIN_POST1_REPROCESSING);

    switch (entity->getPipeId()) {
#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
    case PIPE_SW_MCSC_REPEOCESSING:
#endif
    case PIPE_3AA_REPROCESSING:
    case PIPE_ISP_REPROCESSING:

#ifdef SUPPORT_SENSOR_MODE_CHANGE
        if (entity->getPipeId() == PIPE_3AA_REPROCESSING) {
            switch(frame->getFrameType()) {
            case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
                m_switchSensorMode(NULL, false, false);
                break;
            default:
                break;
            }
        }
#endif

#ifdef USE_HW_RAW_REVERSE_PROCESSING
        /* To let the 3AA reprocessing pipe processing the frame twice */
        if (components.parameters->isUseRawReverseReprocessing() == true &&
            frame->getStreamRequested(STREAM_TYPE_RAW) == true &&
            pipeId == PIPE_3AA_REPROCESSING &&
            frame->getBackupRequest(REQUEST_BACKUP_MODE_DNG, PIPE_3AC_REPROCESSING) == true) {

            /*
             * Maybe just already another processing except for raw have been finished.
             * Try to check if it is true, push the frame to this pipe again for jpeg
             */
            if (frame->getRequest(PIPE_3AC_REPROCESSING) == true) {
                /* only set the jpeg request to true */
                frame->reverseExceptForSpecificReq(REQUEST_BACKUP_MODE_DNG, PIPE_3AC_REPROCESSING, false);

                ret = frame->setEntityState(pipeId, ENTITY_STATE_REWORK);
                if (ret != NO_ERROR) {
                    CLOGE("Set entity state fail, ret(%d)", ret);
                }

                /* for raw capture setfile index */
                if (m_oldSetfile != ISS_SUB_END) {
                    frame->setSetfile(m_oldSetfile);
                }

                CLOGD("[F%d] This frame will be processed again for jpeg", frame->getFrameCount());

                components.reprocessingFactory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId);
                components.reprocessingFactory->pushFrameToPipe(frame, pipeId);

                /* loop this thread again for processing remained request */
                return true;
            } else {
                CLOGD("[F%d] This frame's processing in this pipe was finished",
                        frame->getFrameCount());
            }

            frame->restoreRequest(REQUEST_BACKUP_MODE_DNG);
        }
#endif

        ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                    frame->getFrameCount(), buffer.index, entity->getPipeId(), ret);
            goto FUNC_EXIT;
        }

        ret = frame->getSrcBufferState(entity->getPipeId(), &bufferState);
        if (ret < 0) {
            CLOGE("[F%d B%d]getSrcBufferState fail. pipeId %d ret %d",
                    frame->getFrameCount(), buffer.index, entity->getPipeId(), ret);
            goto FUNC_EXIT;
        }

        if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            CLOGE("[F%d B%d]Src buffer state is error. pipeId %d",
                    frame->getFrameCount(), buffer.index, entity->getPipeId());

            if (request != NULL) {
                ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d B%d] sendNotifyError fail. ret %d",
                            request->getKey(),
                            frame->getFrameCount(),
                            buffer.index, ret);
                    goto FUNC_EXIT;
                }
            }
        }

        if (entity->getPipeId() == PIPE_ISP_REPROCESSING && buffer.hasDebugInfoPlane == true ) {
#ifdef USE_DUAL_CAMERA
            if ((enum FRAME_TYPE) frame->getFrameType() != FRAME_TYPE_REPROCESSING_DUAL_SLAVE)
#endif
            {
                if (frame->getMode(FRAME_MODE_MF_STILL) == false || \
                    checkFirstFrameForMultiFrameCapture(frame) ) {
                    m_parameters[m_cameraId]->setThumbNailInfo((char *)buffer.addr[buffer.getDebugInfoPlaneIndex()]);
                }
            }
        }

#ifdef USE_DUAL_CAMERA
        if (components.configuration->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW
            && (
#ifdef USES_COMBINE_PLUGIN
                // single slave frame should go to combine plugIn with dst buffer
                frame->getDualOperationMode() != DUAL_OPERATION_MODE_SLAVE &&
#endif
                (frame->getFrameType() == FRAME_TYPE_REPROCESSING_DUAL_SLAVE
                || frame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE))) {
            if (components.configuration->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
                int yuvStallPort = components.configuration->getModeValue(CONFIGURATION_YUV_STALL_PORT);
                dstPipeId = yuvStallPort + PIPE_MCSC0_REPROCESSING;
            }

            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for bayerBuffer. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
            }

            buffer.index = -2;
            ret = frame->getDstBuffer(pipeId, &buffer, components.reprocessingFactory->getNodeType(dstPipeId));
            if (ret != NO_ERROR) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", PIPE_ISP, ret);
            }

            if (buffer.index >= 0) {
                ret = frame->setSrcBuffer(PIPE_SYNC_REPROCESSING, buffer);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                            PIPE_SYNC_REPROCESSING, ret);
                }

                shot_ext = (camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()];
                if (shot_ext == NULL) {
                    CLOGE("[F%d B%d]shot_ext is NULL. pipeId %d",
                            frame->getFrameCount(), buffer.index, entity->getPipeId());
                    goto FUNC_EXIT;
                }
                components.parameters->getFaceDetectMeta(shot_ext);

#ifdef DEBUG_FUSION_CAPTURE_DUMP
                {
                    bool bRet;
                    char filePath[70];

                    memset(filePath, 0, sizeof(filePath));
                    snprintf(filePath, sizeof(filePath), "/data/camera/Tele%d_F%07d.nv21",
                            frame->getFrameType(), captureNum);

                    bRet = dumpToFile((char *)filePath, buffer.addr[0], buffer.size[0]);
                    if (bRet != true)
                        CLOGE("couldn't make a raw file");
                }
#endif

                ret = frame->storeDynamicMeta(shot_ext);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d(%d) B%d]Failed to storeUserDynamicMeta. ret %d",
                            frame->getFrameCount(),
                            shot_ext->shot.dm.request.frameCount,
                            buffer.index,
                            ret);
                    goto FUNC_EXIT;
                }
            } else {
                CLOGE("[F%d B%d] Buffer is invalid. pipeId %d",
                        frame->getFrameCount(), buffer.index, entity->getPipeId());
            }

            dstPipeId = PIPE_HWFC_JPEG_DST_REPROCESSING;
            if (frame->getRequest(dstPipeId) == true) {
                buffer.index = -2;
                ret = frame->getDstBuffer(PIPE_ISP_REPROCESSING, &buffer, components.reprocessingFactory->getNodeType(dstPipeId));
                if (ret != NO_ERROR) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", PIPE_ISP, ret);
                }

                if (buffer.index >= 0) {
                    ret = frame->setSrcBuffer(PIPE_SYNC_REPROCESSING, buffer, OUTPUT_NODE_2);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                                PIPE_SYNC_REPROCESSING, ret);
                    }
                }
            }

            m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING]->pushFrameToPipe(frame, PIPE_SYNC_REPROCESSING);
            break;
        } else
#endif
        {
            shot_ext = (camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()];
            if (shot_ext == NULL) {
                CLOGE("[F%d B%d]shot_ext is NULL. pipeId %d",
                        frame->getFrameCount(), buffer.index, entity->getPipeId());
                goto FUNC_EXIT;
            }

            ret = frame->storeDynamicMeta(shot_ext);
            if (ret != NO_ERROR) {
                CLOGE("[F%d(%d) B%d]Failed to storeUserDynamicMeta. ret %d",
                        frame->getFrameCount(),
                        shot_ext->shot.dm.request.frameCount,
                        buffer.index,
                        ret);
                goto FUNC_EXIT;
            }

            ret = frame->storeUserDynamicMeta(shot_ext);
            if (ret != NO_ERROR) {
                CLOGE("[F%d(%d) B%d]Failed to storeUserDynamicMeta. ret %d",
                        frame->getFrameCount(),
                        shot_ext->shot.dm.request.frameCount,
                        buffer.index,
                        ret);
                goto FUNC_EXIT;
            }

            if ((frame->getFrameType() != FRAME_TYPE_INTERNAL
#ifdef USE_DUAL_CAMERA
                && frame->getFrameType() != FRAME_TYPE_INTERNAL_SLAVE
#endif
                ) && entity->getPipeId() == PIPE_3AA_REPROCESSING
                && ((frame->getRequest(PIPE_3AC_REPROCESSING) == true)
                || (frame->getRequest(PIPE_3AG_REPROCESSING) == true))) {

#if defined(USE_RAW_REVERSE_PROCESSING) && defined(USE_SW_RAW_REVERSE_PROCESSING)
                if (components.parameters->isUseRawReverseReprocessing() == true) {
                    /* reverse the raw buffer */
                    m_reverseProcessingBayerQ->pushProcessQ(&frame);
                } else
#endif
                {
                    if (components.parameters->isUse3aaDNG()) {
                        dstPos = components.reprocessingFactory->getNodeType(PIPE_3AG_REPROCESSING);
                    } else {
                        dstPos = components.reprocessingFactory->getNodeType(PIPE_3AC_REPROCESSING);
                    }

                    ret = frame->getDstBuffer(entity->getPipeId(), &serviceBuffer, dstPos);
                    if (ret != NO_ERROR || serviceBuffer.index < 0) {
                        CLOGE("[F%d B%d]Failed to getDstBuffer. pos %d. ret %d",
                                frame->getFrameCount(), serviceBuffer.index, dstPos, ret);
                        goto FUNC_EXIT;
                    }

                    ret = frame->getDstBufferState(entity->getPipeId(), &bufferState, dstPos);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to getDstBufferState. pos %d. ret %d",
                                frame->getFrameCount(), buffer.index, dstPos, ret);
                        goto FUNC_EXIT;
                    }

                    if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                        CLOGE("[R%d F%d B%d]Invalid RAW buffer state. bufferState %d",
                                request->getKey(), frame->getFrameCount(), serviceBuffer.index, bufferState);
                        request->setStreamBufferStatus(HAL_STREAM_ID_RAW, CAMERA3_BUFFER_STATUS_ERROR);
                    }

                    ret = m_sendRawStreamResult(request, &serviceBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to sendRawStreamResult. ret %d",
                                frame->getFrameCount(), serviceBuffer.index, ret);
                    }
                }
            }

            if ((frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT) == false)
#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
                || (frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT) == true
                    && entity->getPipeId() == PIPE_SW_MCSC_REPEOCESSING)
#endif
                || (components.parameters->getUsePureBayerReprocessing() == true
                    && components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M
                    && entity->getPipeId() == PIPE_ISP_REPROCESSING)
                ) {
                if (frame->getMode(FRAME_MODE_DUAL_BOKEH_ANCHOR) == false) {
                    m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for bayerBuffer. ret %d",
                                frame->getFrameCount(), buffer.index, ret);
                    }
                }
            }

            CLOGD("[F%d(%d) B%d]3AA_REPROCESSING Done.",
                    frame->getFrameCount(),
                    shot_ext->shot.dm.request.frameCount,
                    buffer.index);

#ifdef USE_DUAL_CAMERA
            if (components.configuration->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW
                && (
#ifdef USES_COMBINE_PLUGIN
                    // single frame should go to combine plugIn
                    (frame->getDualOperationMode() == DUAL_OPERATION_MODE_MASTER
                    || frame->getDualOperationMode() == DUAL_OPERATION_MODE_SLAVE) ||
#endif
                    (frame->getFrameType() == FRAME_TYPE_REPROCESSING_DUAL_MASTER
                    || frame->getFrameType() == FRAME_TYPE_INTERNAL))) {
#ifdef USE_SLSI_PLUGIN
                int pipeId_next = -1, nodePipeId = -1;
                /* Set fusion dst buffer */
                ret = m_handleCaptureFramePlugin(frame, entity->getPipeId(), pipeId_next, nodePipeId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_handleCaptureFramePlugin. pipeId %d ret %d",
                            entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }

                ExynosCameraFrameFactory *factory;
                /* Push frame to sync pipe */
                switch (pipeId_next) {
                case PIPE_SYNC_REPROCESSING:
                    if (frame->isSlaveFrame())
                        factory = m_frameFactory[FRAME_FACTORY_TYPE_REPROCESSING];
                    else
                        factory = components.reprocessingFactory;
                    break;
                default:
                    factory = components.reprocessingFactory;
                    break;
                }

                factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_next);
                factory->pushFrameToPipe(frame, pipeId_next);

                if (factory->checkPipeThreadRunning(pipeId_next) == false) {
                    factory->startThread(pipeId_next);
                }
#else
                /* This is master NV21 src buffer */
                int yuvStallPort = components.configuration->getModeValue(CONFIGURATION_YUV_STALL_PORT);

                dstPipeId = yuvStallPort + PIPE_MCSC0_REPROCESSING;

                ret = frame->getDstBuffer(pipeId, &buffer, components.reprocessingFactory->getNodeType(dstPipeId));
                if (ret != NO_ERROR) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);
                }

                shot_ext = (camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()];
                if (shot_ext == NULL) {
                    CLOGE("[F%d B%d]shot_ext is NULL. pipeId %d",
                            frame->getFrameCount(), buffer.index, entity->getPipeId());
                    goto FUNC_EXIT;
                }
                components.parameters->getFaceDetectMeta(shot_ext);

#ifdef DEBUG_FUSION_CAPTURE_DUMP
                {
                    bool bRet;
                    char filePath[70];

                    memset(filePath, 0, sizeof(filePath));
                    snprintf(filePath, sizeof(filePath), "/data/camera/Wide%d_F%07d.nv21",
                        frame->getFrameType(), captureNum);

                    bRet = dumpToFile((char *)filePath, buffer.addr[0], buffer.size[0]);
                    if (bRet != true)
                        CLOGE("couldn't make a raw file");
                }
#endif

                ret = frame->storeDynamicMeta(shot_ext);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d(%d) B%d]Failed to storeUserDynamicMeta. ret %d",
                            frame->getFrameCount(),
                            shot_ext->shot.dm.request.frameCount,
                            buffer.index,
                            ret);
                    goto FUNC_EXIT;
                }

                ExynosRect rect = convertingBufferDst2Rect(&buffer, V4L2_PIX_FMT_NV21);
                frame->setSrcRect(PIPE_FUSION_REPROCESSING, rect);
                if(ret != NO_ERROR) {
                    CLOGE("setSrcRect fail, pipeId(%d), ret(%d)", PIPE_FUSION_REPROCESSING, ret);
                }

                frame->setDstRect(PIPE_FUSION_REPROCESSING, rect);
                if(ret != NO_ERROR) {
                    CLOGE("setSrcRect fail, pipeId(%d), ret(%d)", PIPE_FUSION_REPROCESSING, ret);
                }

                ret = m_setupEntity(PIPE_FUSION_REPROCESSING, frame, &buffer, &buffer);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                            PIPE_FUSION_REPROCESSING, ret);
                }

                components.reprocessingFactory->pushFrameToPipe(frame, PIPE_SYNC_REPROCESSING);
#endif
                break;
            }
#endif
        }

#if defined(USES_CAMERA_EXYNOS_VPL) && defined(USE_EARLY_FD_REPROCES)
        if (pipeId == PIPE_3AA_REPROCESSING
                && components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_VRA_REPROCESSING) == HW_CONNECTION_MODE_M2M) {

            dstPipeId = PIPE_3AF_REPROCESSING;
            if (frame->getRequest(PIPE_3AF_REPROCESSING) == true && frame->getRequest(PIPE_NFD_REPROCESSING) == true) {
                CLOGV("[F%d B%d] srcPipeId(%d) -> dstPipeId(PIPE_NFD_REPROCESSING) ", frame->getFrameCount(), buffer.index, pipeId);

                dstPos = components.reprocessingFactory->getNodeType(dstPipeId);
                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);

                if (ret != NO_ERROR) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", dstPipeId, ret);
                }

                if (buffer.index < 0) {
                    ret = frame->setSrcBufferState(PIPE_NFD_REPROCESSING, ENTITY_BUFFER_STATE_ERROR);
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), PIPE_NFD_REPROCESSING);
                } else {
                    ret = m_setupEntity(PIPE_NFD_REPROCESSING, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                PIPE_NFD_REPROCESSING, ret);
                    }

                    camera2_stream *shot_stream = NULL;
                    ExynosRect cropRect;

                    // NFD src cropRect setting
                    shot_stream = (camera2_stream *)buffer.addr[buffer.getMetaPlaneIndex()];
                    cropRect.x = shot_stream->output_crop_region[0];
                    cropRect.y = shot_stream->output_crop_region[1];
                    cropRect.w = shot_stream->output_crop_region[2];
                    cropRect.h = shot_stream->output_crop_region[3];
                    cropRect.fullW = MAX_VRA_INPUT_WIDTH;
                    cropRect.fullH = MAX_VRA_INPUT_HEIGHT;
                    cropRect.colorFormat = m_parameters[m_cameraId]->getHW3AFdFormat();

                    CLOGV("[F%d] NFD src size: %d, %d, %d x %d",
                            frame->getFrameCount(), cropRect.x, cropRect.y, cropRect.w, cropRect.h);
                    ret = frame->setSrcRect(PIPE_NFD_REPROCESSING, cropRect);
                    if (ret < 0){
                        CLOGE("[F%d]Failed to setSrcRect. ret %d", frame->getFrameCount(), ret);
                    }
                }
                if (components.reprocessingFactory->checkPipeThreadRunning(PIPE_NFD_REPROCESSING) == false) {
                    components.reprocessingFactory->startThread(PIPE_NFD_REPROCESSING);
                }

                components.reprocessingFactory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, PIPE_NFD_REPROCESSING);
                components.reprocessingFactory->pushFrameToPipe(frame, PIPE_NFD_REPROCESSING);
            }
        }
#endif

        if (entity->getPipeId() == PIPE_3AA_REPROCESSING
            && components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M) {

            dstPipeId = PIPE_3AP_REPROCESSING;
            if (frame->getRequest(dstPipeId) == true) {
                dstPos = components.reprocessingFactory->getNodeType(dstPipeId);
                ret = frame->getDstBuffer(pipeId, &buffer, dstPos);
                if (ret != NO_ERROR) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", pipeId, ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), pipeId);

                    ret = frame->setSrcBufferState(PIPE_ISP_REPROCESSING, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                frame->getFrameCount(), PIPE_VRA, ret);
                    }
                } else {
                    ret = m_setupEntity(PIPE_ISP_REPROCESSING, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                PIPE_MCSC_REPROCESSING, ret);
                    }
                }
            }

            components.reprocessingFactory->pushFrameToPipe(frame, PIPE_ISP_REPROCESSING);

            break;
        } else if (entity->getPipeId() == PIPE_ISP_REPROCESSING
                   && components.parameters->getHwConnectionMode(PIPE_ISP_REPROCESSING, PIPE_MCSC_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
            dstPipeId = PIPE_ISPC_REPROCESSING;
            if (frame->getRequest(dstPipeId) == true) {
                dstPos = components.reprocessingFactory->getNodeType(dstPipeId);
                ret = frame->getDstBuffer(entity->getPipeId(), &buffer, dstPos);
                if (ret != NO_ERROR) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            entity->getPipeId(), ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), entity->getPipeId());

                    ret = frame->setSrcBufferState(PIPE_MCSC_REPROCESSING, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                frame->getFrameCount(), PIPE_VRA, ret);
                    }
                } else {
                    ret = m_setupEntity(PIPE_MCSC_REPROCESSING, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                PIPE_MCSC_REPROCESSING, ret);
                    }
                }

                if (components.parameters->isUseHWFC() == true) {
                    ret = m_setHWFCBuffer(PIPE_MCSC_REPROCESSING, frame, PIPE_MCSC_JPEG_REPROCESSING, PIPE_HWFC_JPEG_SRC_REPROCESSING);
                    if (ret != NO_ERROR) {
                        CLOGE("Set HWFC Buffer fail, pipeId(%d), srcPipe(%d), dstPipe(%d), ret(%d)",
                                PIPE_MCSC_REPROCESSING, PIPE_MCSC_JPEG_REPROCESSING, PIPE_HWFC_JPEG_SRC_REPROCESSING, ret);
                    }

                    ret = m_setHWFCBuffer(PIPE_MCSC_REPROCESSING, frame, PIPE_MCSC_THUMB_REPROCESSING, PIPE_HWFC_THUMB_SRC_REPROCESSING);
                    if (ret != NO_ERROR) {
                        CLOGE("Set HWFC Buffer fail, pipeId(%d), srcPipe(%d), dstPipe(%d), ret(%d)",
                                PIPE_MCSC_REPROCESSING, PIPE_MCSC_THUMB_REPROCESSING, PIPE_HWFC_THUMB_SRC_REPROCESSING, ret);
                    }
                }
            }

            components.reprocessingFactory->pushFrameToPipe(frame, PIPE_MCSC_REPROCESSING);
            break;
        }

    case PIPE_MCSC_REPROCESSING:
        if (entity->getPipeId() == PIPE_MCSC_REPROCESSING) {
            ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                        frame->getFrameCount(), buffer.index, entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }

            ret = frame->getSrcBufferState(entity->getPipeId(), &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)",
                        entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                CLOGE("ERR(%s[%d]):Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        __FUNCTION__, __LINE__,
                        buffer.index, frame->getFrameCount(), entity->getPipeId());
                if (request != NULL) {
                    ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                    if (ret != NO_ERROR) {
                        CLOGE("[R%d F%d B%d] sendNotifyError fail. ret %d",
                                request->getKey(),
                                frame->getFrameCount(),
                                buffer.index, ret);
                        goto FUNC_EXIT;
                    }
                }
            }

            m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for bayerBuffer. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
            }
        }
        {
            needNV21CallbackHandle = true;
        }

#ifdef USE_CLAHE_REPROCESSING
        if (frame->getRequest(PIPE_CLAHEC_REPROCESSING) == false){
            /* Handle yuv capture buffer */
            if (frame->getRequest(PIPE_MCSC_JPEG_REPROCESSING) == true) {
                ret = m_handleYuvCaptureFrame(frame);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to handleYuvCaptureFrame. pipeId %d ret %d",
                            entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }
            }
        }
#else
        /* Handle yuv capture buffer */
        if (frame->getRequest(PIPE_MCSC_JPEG_REPROCESSING) == true) {
            ret = m_handleYuvCaptureFrame(frame);
            if (ret != NO_ERROR) {
                CLOGE("Failed to handleYuvCaptureFrame. pipeId %d ret %d",
                         entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }
        }
#endif

#ifdef USE_DUAL_CAMERA
        /* HACK: Slave preview has no VRA */
        if (components.configuration->getDualOperationMode() != DUAL_OPERATION_MODE_SLAVE && flagMcscVraOTF)
#else
        if (flagMcscVraOTF)
#endif
        {
            if (frame->getRequest(PIPE_VRA_REPROCESSING) == true) {
                /* Send the Yuv buffer to VRA Pipe */
                dstPos = components.reprocessingFactory->getNodeType(PIPE_MCSC5_REPROCESSING);

                ret = frame->getDstBuffer(entity->getPipeId(), &buffer, dstPos);
                if (ret < 0) {
                    CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                            entity->getPipeId(), ret);
                }

                if (buffer.index < 0) {
                    CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                            buffer.index, frame->getFrameCount(), entity->getPipeId());

                    ret = frame->setSrcBufferState(PIPE_VRA_REPROCESSING, ENTITY_BUFFER_STATE_ERROR);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                                frame->getFrameCount(), PIPE_VRA, ret);
                    }
                } else {
                    ret = m_setupEntity(PIPE_VRA_REPROCESSING, frame, &buffer, NULL);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                                PIPE_VRA_REPROCESSING, ret);
                    }
                }

                components.reprocessingFactory->pushFrameToPipe(frame, PIPE_VRA_REPROCESSING);
                break;
            }
        }

#ifdef USE_CLAHE_REPROCESSING
        if (frame->getRequest(PIPE_CLAHEC_REPROCESSING) == true) {
            /* Send the Yuv buffer to CLAHE Pipe */
            if (frame->getRequest(PIPE_MCSC_JPEG_REPROCESSING) == true) {
                dstPos = components.reprocessingFactory->getNodeType(PIPE_MCSC_JPEG_REPROCESSING);
            } else {
                dstPos = components.reprocessingFactory->getNodeType(PIPE_MCSC_PP_REPROCESSING);
            }

            ret = frame->getDstBuffer(entity->getPipeId(), &buffer, dstPos);
            if (ret < 0) {
                CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)",
                        entity->getPipeId(), ret);
            }

            if (buffer.index < 0) {
                CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), entity->getPipeId());

                ret = frame->setSrcBufferState(PIPE_CLAHE_REPROCESSING, ENTITY_BUFFER_STATE_ERROR);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                            frame->getFrameCount(), PIPE_CLAHE_REPROCESSING, ret);
                }
            } else {
                ret = m_setupEntity(PIPE_CLAHE_REPROCESSING, frame, &buffer, NULL);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer failed, pipeId(%d), ret(%d)",
                            PIPE_CLAHE_REPROCESSING, ret);
                }
            }

            components.reprocessingFactory->pushFrameToPipe(frame, PIPE_CLAHE_REPROCESSING);
            break;
        }

    case PIPE_CLAHE_REPROCESSING:
        if (entity->getPipeId() == PIPE_CLAHE_REPROCESSING) {
            ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                        frame->getFrameCount(), buffer.index, entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }

            ret = frame->getSrcBufferState(entity->getPipeId(), &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)",
                        entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                CLOGE("ERR(%s[%d]):Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        __FUNCTION__, __LINE__,
                        buffer.index, frame->getFrameCount(), entity->getPipeId());
                if (request != NULL) {
                    ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_REQUEST);
                    if (ret != NO_ERROR) {
                        CLOGE("[R%d F%d B%d] sendNotifyError fail. ret %d",
                                request->getKey(),
                                frame->getFrameCount(),
                                buffer.index, ret);
                        goto FUNC_EXIT;
                    }
                }
            }

            m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for bayerBuffer. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
            }

            if ((frame->getFrameYuvStallPortUsage() == YUV_STALL_USAGE_PICTURE) ||
                    needNV21CallbackHandle) {
                /* Handle NV21 capture callback buffer */
                if (frame->getRequest(PIPE_MCSC0_REPROCESSING) == true
                        || frame->getRequest(PIPE_MCSC1_REPROCESSING) == true
                        || frame->getRequest(PIPE_MCSC2_REPROCESSING) == true
#ifdef USE_RESERVED_NODE_PPJPEG_MCSCPORT
                        || frame->getRequest(PIPE_MCSC_PP_REPROCESSING) == true
#endif
                   ) {
                    ret = m_handleNV21CaptureFrame(frame, entity->getPipeId());
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to m_handleNV21CaptureFrame. pipeId %d ret %d",
                                entity->getPipeId(), ret);
                        goto FUNC_EXIT;
                    }
                }
            } else {
                /* Handle yuv capture buffer */
                if (frame->getRequest(PIPE_CLAHEC_REPROCESSING) == true) {
                    ret = m_handleYuvCaptureFrame(frame);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to handleYuvCaptureFrame. pipeId %d ret %d",
                                entity->getPipeId(), ret);
                        goto FUNC_EXIT;
                    }
                }
            }
            break;
        }
#endif

    case PIPE_VRA_REPROCESSING:
        if (entity->getPipeId() == PIPE_VRA_REPROCESSING) {
            ret = frame->getSrcBuffer(entity->getPipeId(), &buffer);
            if (ret != NO_ERROR) {
                CLOGE("Failed to getSrcBuffer. pipeId %d ret %d",
                        entity->getPipeId(), ret);
                return ret;
            }

            ret = frame->getSrcBufferState(entity->getPipeId(), &bufferState);
            if (ret < 0) {
                CLOGE("getSrcBufferState fail, pipeId(%d), ret(%d)", entity->getPipeId(), ret);
                return ret;
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]Failed to putBuffer for VRA. ret %d",
                            frame->getFrameCount(), buffer.index, ret);
                    break;
                }
            }
            break;
        }

        if ((frame->getFrameYuvStallPortUsage() == YUV_STALL_USAGE_PICTURE) ||
            needNV21CallbackHandle) {
            /* Handle NV21 capture callback buffer */
            if (frame->getRequest(PIPE_MCSC0_REPROCESSING) == true
                || frame->getRequest(PIPE_MCSC1_REPROCESSING) == true
                || frame->getRequest(PIPE_MCSC2_REPROCESSING) == true
#ifdef USE_RESERVED_NODE_PPJPEG_MCSCPORT
                || frame->getRequest(PIPE_MCSC_PP_REPROCESSING) == true
#endif
                ) {
                ret = m_handleNV21CaptureFrame(frame, entity->getPipeId());
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_handleNV21CaptureFrame. pipeId %d ret %d",
                            entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }
            }
        }

        /* Continue to JPEG processing stage in HWFC mode */
        if (components.parameters->isUseHWFC() == false
            || frame->getRequest(PIPE_MCSC_JPEG_REPROCESSING) == false) {
            break;
        }
#ifdef REMOSAIC_ROTATION
    case PIPE_GSC_REPROCESSING:
        if (pipeId == PIPE_GSC_REPROCESSING) {
            m_handleRemosaicCaptureFrame(frame, pipeId);
        }
        break;
#endif //REMOSAIC_ROTATION
    case PIPE_GSC_REPROCESSING2:
    case PIPE_JPEG_REPROCESSING:
        /* Handle JPEG buffer */
        if (entity->getSrcBufState() != ENTITY_BUFFER_STATE_ERROR
            && (pipeId == PIPE_JPEG_REPROCESSING || frame->getRequest(PIPE_MCSC_JPEG_REPROCESSING) == true)) {
            ret = m_handleJpegFrame(frame, entity->getPipeId());
            if (ret != NO_ERROR) {
                CLOGE("Failed to handleJpegFrame. pipeId %d ret %d",
                         entity->getPipeId(), ret);
                goto FUNC_EXIT;
            }
        }
        break;
#if defined(USES_CAMERA_EXYNOS_VPL) && defined(USE_EARLY_FD_REPROCES)
    case PIPE_NFD_REPROCESSING:
        /* handle the buffer of NFDPipe */
        if (frame->getRequest(PIPE_NFD_REPROCESSING) == true) {
            ret = frame->getSrcBuffer(pipeId, &buffer);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                        frame->getFrameCount(), buffer.index, pipeId, ret);
                goto FUNC_EXIT;
            }

            ret = frame->getSrcBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("[F%d B%d]getSrcBufferState fail. pipeId %d ret %d",
                        frame->getFrameCount(), buffer.index, pipeId, ret);
                goto FUNC_EXIT;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                CLOGE("Src buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to putBuffer for NFD. ret %d",
                        frame->getFrameCount(), buffer.index, ret);
                break;
            }

            CLOGV("Return NFD Buffer. driver->framecount %d hal->framecount %d",
                    getMetaDmRequestFrameCount((struct camera2_shot_ext *)buffer.addr[buffer.getMetaPlaneIndex()]),
                    frame->getFrameCount());

            entity_state_t entityState = ENTITY_STATE_FRAME_DONE;
            ret = frame->getEntityState(pipeId, &entityState);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to getEntityState. pipeId %d",
                        frame->getFrameCount(), pipeId);
                break;
            }

            if (entityState == ENTITY_STATE_FRAME_DONE) {
#if 0 /* TODO: If needed. */
                ret = m_updateNFDInfo(frame);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to updateNFDInfo. ret %d", frame->getFrameCount(), ret);
                }
#endif
                ret = m_updateFaceDetectMeta(frame);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to m_updateFaceDetectMeta. ret %d", frame->getFrameCount(), ret);
                }
            }
        }
        break;
#endif

    case PIPE_JPEG:
        /* Handle JPEG buffer */
        ret = m_handleJpegFrame(frame, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("Failed to handleJpegFrame. pipeId %d ret %d", pipeId, ret);
            goto FUNC_EXIT;
        }
        break;

#ifdef USE_SLSI_PLUGIN
    case PIPE_PLUGIN_POST1_REPROCESSING:
        if (entity->getPipeId() == PIPE_PLUGIN_POST1_REPROCESSING) {
            m_handleNV21CaptureFrame(frame, entity->getPipeId());
            if (frame->getFrameType() == FRAME_TYPE_REPROCESSING_DUAL_SLAVE
                || frame->getFrameType() == FRAME_TYPE_INTERNAL
                || frame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE) {
                /* my life is over anymore in dual slave frame */
                frame->setFrameState(FRAME_STATE_COMPLETE);
                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                        ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_BUFFER,
                        ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                        ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
            }
        }
        break;
#endif
#ifdef USE_DUAL_CAMERA
    case PIPE_SYNC_REPROCESSING:
        if (components.configuration->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
            if (
#ifdef USES_COMBINE_PLUGIN
                // single frame should go to combine plugIn
                (frame->getDualOperationMode() == DUAL_OPERATION_MODE_MASTER
                || frame->getDualOperationMode() == DUAL_OPERATION_MODE_SLAVE) ||
#endif
                (frame->getFrameType() == FRAME_TYPE_REPROCESSING_DUAL_MASTER
                || frame->getFrameType() == FRAME_TYPE_INTERNAL)) {
#ifdef USE_SLSI_PLUGIN
                int pipeId_next = -1, nodePipeId = -1;
                /* Set fusion src buffer */
                ret = m_handleCaptureFramePlugin(frame, entity->getPipeId(), pipeId_next, nodePipeId);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_handleCaptureFramePlugin. pipeId %d ret %d",
                            entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }

                /* Push frame to fusion plugin */
                components.reprocessingFactory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_next);
                components.reprocessingFactory->pushFrameToPipe(frame, pipeId_next);

                if (components.reprocessingFactory->checkPipeThreadRunning(pipeId_next) == false) {
                    components.reprocessingFactory->startThread(pipeId_next);
                }
#else
                if (frame->getFrameState() != FRAME_STATE_SKIPPED) {
                    ret = frame->getDstBuffer(pipeId, &buffer);
                    if (buffer.index < 0) {
                        CLOGE("Invalid buffer index(%d), framecount(%d), pipeId(%d)",
                                buffer.index, frame->getFrameCount(), pipeId);
                    } else {
                        ExynosRect rect = convertingBufferDst2Rect(&buffer, V4L2_PIX_FMT_NV21);
                        frame->setSrcRect(PIPE_FUSION_REPROCESSING, rect, OUTPUT_NODE_2);

                        ret = frame->setSrcBuffer(PIPE_FUSION_REPROCESSING, buffer, OUTPUT_NODE_2);
                        if (ret != NO_ERROR) {
                            CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                                    PIPE_FUSION_REPROCESSING, ret);
                        }
                    }
                } else if (frame->getFrameState() == FRAME_STATE_SKIPPED) {
                    ret = frame->getDstBuffer(pipeId, &buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                                pipeId, ret);
                    }

                    if (buffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret != NO_ERROR) {
                            CLOGE("[F%d T%d B%d]Failed to putBuffer for PIPE_SYNC_REPROCESSING. ret %d",
                                    frame->getFrameCount(), frame->getFrameType(), buffer.index, ret);
                        }
                    }
                }
#endif
            } else if (frame->getFrameType() == FRAME_TYPE_REPROCESSING_DUAL_SLAVE
                || frame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE) {
                if (frame->getFrameState() == FRAME_STATE_SKIPPED) {
                    ret = frame->getSrcBuffer(pipeId, &buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                                pipeId, ret);
                    }

                    if (buffer.index >= 0) {
                        ret = m_bufferSupplier->putBuffer(buffer);
                        if (ret != NO_ERROR) {
                            CLOGE("[F%d T%d B%d]Failed to putBuffer for PIPE_SYNC_REPROCESSING. ret %d",
                                    frame->getFrameCount(), frame->getFrameType(), buffer.index, ret);
                        }
                    }
                } else {
                    /* my life is over anymore in dual slave frame */
                    frame->setFrameState(FRAME_STATE_COMPLETE);
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                            ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_BUFFER,
                            ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                    frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                            ExynosCameraFrame::RESULT_UPDATE_STATUS_NONE);
                }
            }
        }
        break;
    case PIPE_FUSION_REPROCESSING:
        if (pipeId == PIPE_FUSION_REPROCESSING) {
            if (components.configuration->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW
                && (frame->getFrameType() == FRAME_TYPE_REPROCESSING_DUAL_MASTER
                    || frame->getFrameType() == FRAME_TYPE_INTERNAL)) {
#ifndef USE_SLSI_PLUGIN
                ret = frame->getSrcBuffer(entity->getPipeId(), &buffer, OUTPUT_NODE_2);
                if (ret != NO_ERROR) {
                    CLOGE("setSrcBuffer fail, pipeId(%d), ret(%d)",
                            entity->getPipeId(), ret);
                }

                if (buffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d T%d B%d]Failed to putBuffer for PIPE_FUSION_REPROCESSING. ret %d",
                                frame->getFrameCount(), frame->getFrameType(), buffer.index, ret);
                    }
                }
#endif
                ret = m_handleNV21CaptureFrame(frame, entity->getPipeId());
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_handleNV21CaptureFrame. pipeId %d ret %d",
                            entity->getPipeId(), ret);
                    goto FUNC_EXIT;
                }
            }
        }
        break;
#endif //USE_DUAL_CAMERA

    default:
        CLOGE("Invalid pipeId %d", entity->getPipeId());
        break;
    }

    ret = frame->setEntityState(entity->getPipeId(), ENTITY_STATE_COMPLETE);
    if (ret < 0) {
        CLOGE("setEntityState fail, pipeId(%d), state(%d), ret(%d)",
             entity->getPipeId(), ENTITY_STATE_COMPLETE, ret);
        return ret;
    }

FUNC_EXIT:
    if (frame != NULL && m_getState() != EXYNOS_CAMERA_STATE_FLUSH) {
        if (frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL) == true
            && frame->getFrameType() != FRAME_TYPE_INTERNAL
#ifdef SUPPORT_REMOSAIC_CAPTURE
            && frame->getFrameType() != FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION
#endif
#ifdef USE_DUAL_CAMERA
            && frame->getFrameType() != FRAME_TYPE_INTERNAL_SLAVE
            && frame->getFrameType() != FRAME_TYPE_REPROCESSING_DUAL_SLAVE
#endif
           ) {
            if (request->getCallbackDone(EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_3AA) == false
                && request->getNumOfInputBuffer() > 0) {
                ret = frame->getMetaData(&resultShot);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]Failed to getMetaData. ret %d", frame->getFrameCount(), ret);
                }

                ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_3AA);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d(%d)]Failed to pushResult. ret %d",
                            request->getKey(),
                            frame->getFrameCount(),
                            resultShot.shot.dm.request.frameCount,
                            ret);
                }

                m_sendPartialMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_PARTIAL_3AA);
            }

            frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_PARTIAL,
                                            ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
        }

        if (frame->isReadyForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL) == true) {
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
            switch (frame->getFrameType()) {
            case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
            case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
                CFLOGD(frame, "start to release remosaic buffer");
                m_releaseRemosaicBufferThread->run();
                break;
            default:
                break;
            }
#endif
            ret = frame->getMetaData(&resultShot);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to getMetaData. ret %d", frame->getFrameCount(), ret);
            }

            ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_NONE, (frame_type_t)frame->getFrameType());
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d(%d)]Failed to m_updateResultShot. ret %d",
                        request->getKey(),
                        frame->getFrameCount(),
                        resultShot.shot.dm.request.frameCount,
                        ret);
            }

#ifdef USE_DUAL_CAMERA
            /* update result state for physical cameras */
            {
                int numOfPhysCam = request->getNumOfPhysCamSettings();
                int32_t *physIDs;
                int32_t masterCameraId, slaveCameraId;

                if (numOfPhysCam > 0) {
                    masterCameraId = m_camIdInfo.cameraId[MAIN_CAM];
                    slaveCameraId = m_camIdInfo.cameraId[SUB_CAM];
                    physIDs = request->getAllPhysCamInternalIDs();

                    for (int i = 0; i < numOfPhysCam; i++) {
                        int physCamID = -1;
                        /*
                         * Usually Logical camera meta & master camera meta is same.
                         * Can't we use the logical camera meta for Physical Camera (master).
                         */
                        if (physIDs[i] == masterCameraId) {
                            physCamID = masterCameraId;
                        } else if (physIDs[i] == slaveCameraId) {
                            physCamID = slaveCameraId;
                        } else {
                            continue;
                        }

                        ret = m_updateResultShot(frame, request, &resultShot, PARTIAL_NONE, (frame_type_t)frame->getFrameType(), physCamID);
                        if (ret != NO_ERROR) {
                            CLOGE("[R%d F%d(%d)]Failed to m_updateResultShot. ret %d",
                                    request->getKey(),
                                    frame->getFrameCount(),
                                    resultShot.shot.dm.request.frameCount,
                                    ret);
                        }
                    }
                }
            }
#endif
            ret = m_sendMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_ALL_RESULT);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d]Failed to sendMeta. ret %d",
                        request->getKey(),
                        frame->getFrameCount(),
                        ret);
            }

            frame->setStatusForResultUpdate(ExynosCameraFrame::RESULT_UPDATE_TYPE_ALL,
                                            ExynosCameraFrame::RESULT_UPDATE_STATUS_DONE);
        }

        if (frame->isComplete() == true) {
#ifdef SUPPORT_SENSOR_MODE_CHANGE
            components.configuration->setMode(CONFIGURATION_REMOSAIC_CAPTURE_MODE, false);
#endif //SUPPORT_SENSOR_MODE_CHANGE

#ifdef USE_DUAL_CAMERA
            if (components.configuration->getMode(CONFIGURATION_DUAL_MODE)) {
                if ((frame->isSlaveFrame() == true) && (android_atomic_or(0, &m_needSlaveDynamicBayerCount) > 0))
                    android_atomic_and(0, &m_needSlaveDynamicBayerCount);
            }
#endif
            List<ExynosCameraFrameSP_sptr_t> *list = NULL;
            Mutex *listLock = NULL;
            list = &m_captureProcessList;
            listLock = &m_captureProcessLock;
            // TODO:decide proper position
            CLOGD("frame complete. framecount %d", frame->getFrameCount());
            ret = m_removeFrameFromList(list, listLock, frame);
            if (ret < 0) {
                CLOGE("remove frame from processList fail, ret(%d)", ret);
            }

            frame = NULL;
        }
    }

FUNC_EXIT2:
    {
        Mutex::Autolock l(m_captureProcessLock);
        if (m_captureProcessList.size() > 0)
            return true;
        else {
            return false;
        }
    }
}

status_t ExynosCamera::m_handleNV21CaptureFrame(ExynosCameraFrameSP_sptr_t frame, int leaderPipeId)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer dstBuffer;
    frame_handle_components_t components;

    int nodePipeId = -1;
    int streamId = -1;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components, m_getCameraSessionId(frame));

    if (leaderPipeId == PIPE_VRA_REPROCESSING) {
        leaderPipeId = m_getMcscLeaderPipeId(&components);
    }

#ifdef USE_CLAHE_REPROCESSING
    if (leaderPipeId == PIPE_CLAHE_REPROCESSING) {
        nodePipeId = PIPE_CLAHEC_REPROCESSING;
    }
#endif

    if (leaderPipeId == PIPE_FUSION_REPROCESSING) {
        nodePipeId = leaderPipeId;
    } else
    {
        nodePipeId = components.streamMgr->getOutputPortId(HAL_STREAM_ID_CALLBACK_STALL) % ExynosCameraParameters::YUV_MAX + PIPE_MCSC0_REPROCESSING;
    }

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(frame);

    if (frame->getStreamRequested(STREAM_TYPE_YUVCB_STALL)
        && ((frame->getNumRemainPipe() == 1) || (frame->getMode(FRAME_MODE_SWMCSC) && frame->getNumRemainPipe() == 2))) {
        ExynosCameraRequestSP_sprt_t request = requestMgr->getRunningRequest(frame->getFrameCount());
        if (request == NULL) {
            CLOGE("[F%d]request is NULL.", frame->getFrameCount());
        }

        if (frame->getMode(FRAME_MODE_VENDOR_YUV_STALL)) {
            if (components.parameters->getUsePureBayerReprocessing() == true) {
                if (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
                    leaderPipeId = PIPE_ISP_REPROCESSING;
                } else {
                    leaderPipeId = PIPE_3AA_REPROCESSING;
                }
            }
        }

        if (frame->getStreamRequested(STREAM_TYPE_THUMBNAIL_CB)) {
            m_resizeToDScaledYuvStall(frame, leaderPipeId, nodePipeId);

            if (m_thumbnailCbThread->isRunning()) {
                m_thumbnailCbThread->join();
                CLOGD("m_thumbnailCbThread join");
            }

            m_thumbnailCbThread->run();
            m_thumbnailCbQ->pushProcessQ(&frame);

            m_thumbnailCbThread->join();

            ExynosCameraBuffer srcBuffer;
            ret = frame->getDstBuffer(PIPE_GSC_REPROCESSING3, &srcBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]getDstBuffer fail. ret(%d)",
                        frame->getFrameCount(), srcBuffer.index, ret);
            }

            ret = m_bufferSupplier->putBuffer(srcBuffer);
            if (ret < 0) {
                CLOGE("[F%d B%d]Failed to putBuffer. ret %d",
                        frame->getFrameCount(), srcBuffer.index, ret);
            }
        }

#ifdef ENABLE_YUV_STALL_FOR_SECOND_YUV
        // TODO: need more condition for specific vendor tag
        if (frame->getStreamRequested(STREAM_TYPE_YUVCB_STALL)) {
            ret = frame->getDstBuffer(leaderPipeId, &dstBuffer, frame->getServiceBufferPosition(HAL_STREAM_ID_CALLBACK_STALL));
            if (ret != NO_ERROR) {
                CFLOGE(frame, "Failed to getDstBuffer, pipeId %d pos %d ret %d",
                        leaderPipeId, frame->getServiceBufferPosition(HAL_STREAM_ID_CALLBACK_STALL), ret);
                return ret;
            }

            if (request != NULL) {
                ret = m_sendYuvStreamStallResult(request, &dstBuffer, HAL_STREAM_ID_CALLBACK_STALL);
                if (ret != NO_ERROR) {
                    CFLOGE(frame, "Failed to sendYuvStreamStallResult. buf(%d,%s) pipeId %d ret %d",
                            dstBuffer.index, dstBuffer.bufMgrNm,
                            nodePipeId, ret);
                    return ret;
                }
            }

            return ret;
        }
#endif
        /* PIPE_MCSC 0, 1, 2 */
        for (int i = 0; i < m_streamManager->getTotalYuvStreamCount(); i++) {
            streamId = m_streamManager->getYuvStreamId(ExynosCameraParameters::YUV_STALL_0 + i);
            nodePipeId = i + PIPE_MCSC0_REPROCESSING;

            if (frame->getRequest(nodePipeId) == false) {
                continue;
            }

            entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_NOREQ;
            ret = frame->getDstBufferState(leaderPipeId, &bufferState, components.reprocessingFactory->getNodeType(nodePipeId));
            if (ret != NO_ERROR) {
                CLOGE("ERR(%s[%d]):Failed to getDstBufferState. frameCount %d pipeId %d",
                        __FUNCTION__, __LINE__,
                        frame->getFrameCount(),
                        nodePipeId);
                return ret;
            } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                if (request != NULL) {
                    request->setStreamBufferStatus(streamId, CAMERA3_BUFFER_STATUS_ERROR);
                    CLOGE("ERR(%s[%d]):Invalid JPEG buffer state. frameCount %d bufferState %d",
                            __FUNCTION__, __LINE__,
                            frame->getFrameCount(),
                            bufferState);
                }
            }

            ret = frame->getDstBuffer(leaderPipeId, &dstBuffer, components.reprocessingFactory->getNodeType(nodePipeId));
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to getDstBuffer."
                        " pipeId %d streamId %d ret %d",
                        frame->getFrameCount(),
                        dstBuffer.index,
                        nodePipeId, streamId, ret);
                return ret;
            }

            if (request != NULL) {
                struct camera2_shot_ext *shot_ext = (struct camera2_shot_ext *) dstBuffer.addr[dstBuffer.getMetaPlaneIndex()];

                ret = m_updateJpegPartialResultShot(request, shot_ext, components.parameters);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to m_updateJpegPartialResultShot");
                }

                {
                    ret = m_sendYuvStreamStallResult(request, &dstBuffer, streamId);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to sendYuvStreamStallResult."
                                " pipeId %d streamId %d ret %d",
                                frame->getFrameCount(),
                                dstBuffer.index,
                                nodePipeId, streamId, ret);
                        return ret;
                    }
                }
            } else {
                if (dstBuffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(dstBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for MCSC. ret %d",
                                frame->getFrameCount(), dstBuffer.index, ret);
                        break;
                    }
                }
            }
        }
    } else {
        if (m_getState() != EXYNOS_CAMERA_STATE_FLUSH) {
            int pipeId_next = -1;

#ifdef USE_SLSI_PLUGIN
            ret = m_handleCaptureFramePlugin(frame, leaderPipeId, pipeId_next, nodePipeId);
#endif

            if (frame->getStreamRequested(STREAM_TYPE_THUMBNAIL_CB)
                && pipeId_next == PIPE_JPEG_REPROCESSING) {
                m_resizeToDScaledYuvStall(frame, leaderPipeId, nodePipeId);

                if (m_thumbnailCbThread->isRunning()) {
                    m_thumbnailCbThread->join();
                    CLOGD("m_thumbnailCbThread join");
                }

                m_thumbnailCbThread->run();
                m_thumbnailCbQ->pushProcessQ(&frame);

                m_thumbnailCbThread->join();

                ExynosCameraBuffer srcBuffer;
                ret = frame->getDstBuffer(PIPE_GSC_REPROCESSING3, &srcBuffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]getDstBuffer fail. ret(%d)",
                            frame->getFrameCount(), srcBuffer.index, ret);
                }

                ret = m_bufferSupplier->putBuffer(srcBuffer);
                if (ret < 0) {
                    CLOGE("[F%d B%d]Failed to putBuffer. ret %d",
                            frame->getFrameCount(), srcBuffer.index, ret);
                }
            }

            components.reprocessingFactory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_next);
            components.reprocessingFactory->pushFrameToPipe(frame, pipeId_next);
            if (components.reprocessingFactory->checkPipeThreadRunning(pipeId_next) == false) {
                components.reprocessingFactory->startThread(pipeId_next);
            }
        }
    }

    return ret;
}

status_t ExynosCamera::m_resizeToDScaledYuvStall(ExynosCameraFrameSP_sptr_t frame, int leaderPipeId, int nodePipeId)
{
    status_t ret = NO_ERROR;
    int outputSizeW = 0, outputSizeH = 0;
    ExynosRect srcRect, dstRect;
    int gscPipeId = PIPE_GSC_REPROCESSING3;
    ExynosCameraBuffer srcBuffer;
    ExynosCameraBuffer dstBuffer;
    int waitCount = 0;
    frame_handle_components_t components;
    struct camera2_stream *shot_stream = NULL;
    ExynosCameraBuffer buffer;
    buffer_manager_tag_t bufTag;

    srcBuffer.index = -2;
    dstBuffer.index = -2;

    CLOGD("[F%d]-- IN --", frame->getFrameCount());

    m_getFrameHandleComponentsWrapper(frame, &components, m_getCameraSessionId(frame));

    m_configurations->getSize(CONFIGURATION_DS_YUV_STALL_SIZE, (uint32_t *)&outputSizeW, (uint32_t *)&outputSizeH);

    ret = frame->getDstBuffer(leaderPipeId, &srcBuffer, components.reprocessingFactory->getNodeType(nodePipeId));
    if (ret != NO_ERROR) {
        CLOGE("[F%d]getDstBuffer fail. pipeId (%d) ret(%d)",
                frame->getFrameCount(), nodePipeId, ret);
        goto CLEAN;
    }

    shot_stream = (struct camera2_stream *)(srcBuffer.addr[srcBuffer.getMetaPlaneIndex()]);
    if (shot_stream != NULL) {
        CLOGV("(%d %d %d %d)",
                shot_stream->fcount,
                shot_stream->rcount,
                shot_stream->findex,
                shot_stream->fvalid);
        CLOGV("(%d %d %d %d)(%d %d %d %d)",
                shot_stream->input_crop_region[0],
                shot_stream->input_crop_region[1],
                shot_stream->input_crop_region[2],
                shot_stream->input_crop_region[3],
                shot_stream->output_crop_region[0],
                shot_stream->output_crop_region[1],
                shot_stream->output_crop_region[2],
                shot_stream->output_crop_region[3]);
    } else {
        CLOGE("shot_stream is NULL");
        return INVALID_OPERATION;
    }

    bufTag.pipeId[0] = gscPipeId;
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    switch (frame->getFrameType()) {
    case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
    case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
        break;
    default:
        break;
    }
#endif

    ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
    if (ret != NO_ERROR || dstBuffer.index < 0) {
        CLOGE("[F%d B%d]Failed to get InternalNV21Buffer. ret %d",
                frame->getFrameCount(), dstBuffer.index, ret);
    }

    {
        srcRect.x = shot_stream->output_crop_region[0];
        srcRect.y = shot_stream->output_crop_region[1];
        srcRect.w = shot_stream->output_crop_region[2];
        srcRect.h = shot_stream->output_crop_region[3];
        srcRect.fullW = shot_stream->output_crop_region[2];
        srcRect.fullH = shot_stream->output_crop_region[3];
        srcRect.colorFormat = V4L2_PIX_FMT_NV21;
    }

    dstRect.x = 0;
    dstRect.y = 0;
    dstRect.w = outputSizeW;
    dstRect.h = outputSizeH;
    dstRect.fullW = outputSizeW;
    dstRect.fullH = outputSizeH;
    dstRect.colorFormat = V4L2_PIX_FMT_NV21;

    CLOGV("srcBuf(%d) dstBuf(%d) (%d, %d, %d, %d) format(%d) actual(%x) -> (%d, %d, %d, %d) format(%d)  actual(%x)",
            srcBuffer.index, dstBuffer.index,
            srcRect.x, srcRect.y, srcRect.w, srcRect.h, srcRect.colorFormat, V4L2_PIX_2_HAL_PIXEL_FORMAT(srcRect.colorFormat),
            dstRect.x, dstRect.y, dstRect.w, dstRect.h, dstRect.colorFormat, V4L2_PIX_2_HAL_PIXEL_FORMAT(dstRect.colorFormat));

    frame->setSrcRect(gscPipeId, srcRect);
    frame->setDstRect(gscPipeId, dstRect);

    ret = m_setupEntity(gscPipeId, frame, &srcBuffer, &dstBuffer);
    if (ret < 0) {
        CLOGE("setupEntity fail, pipeId(%d), ret(%d)", gscPipeId, ret);
    }

    components.reprocessingFactory->setOutputFrameQToPipe(m_resizeDoneQ, gscPipeId);
    components.reprocessingFactory->pushFrameToPipe(frame, gscPipeId);

    /* wait PIPE_GSC_REPROCESSING3 done */
    CLOGV("wait PIPE_GSC_REPROCESSING3 output");
    waitCount = 0;
    frame = NULL;
    dstBuffer.index = -2;
    do {
        ret = m_resizeDoneQ->waitAndPopProcessQ(&frame);
        waitCount++;
    } while (ret == TIMED_OUT && waitCount < 100);

    if (ret < 0) {
        CLOGW("Failed to waitAndPopProcessQ. ret %d waitCount %d", ret, waitCount);
    }

    if (frame == NULL) {
        CLOGE("frame is NULL");
        goto CLEAN;
    }

CLEAN:
    if (frame != NULL) {
        CLOGD("frame delete. framecount %d", frame->getFrameCount());
        frame = NULL;
    }

    CLOGD("--OUT--");

    return ret;
}

status_t ExynosCamera::m_resizeToScaledYuv(ExynosCameraFrameSP_sptr_t frame, int leaderPipeId)
{
    status_t ret = NO_ERROR;
    int outputSizeW = 0, outputSizeH = 0;
    ExynosRect srcRect, dstRect;
    int gscPipeId = PIPE_GSC_REPROCESSING3;
    ExynosCameraBuffer srcBuffer;
    ExynosCameraBuffer dstBuffer;
    int waitCount = 0;
    frame_handle_components_t components;
    struct camera2_stream *shot_stream = NULL;
    ExynosCameraBuffer buffer;
    buffer_manager_tag_t bufTag;

    srcBuffer.index = -2;
    dstBuffer.index = -2;

    CLOGD("[F%d]-- IN --", frame->getFrameCount());

    m_getFrameHandleComponentsWrapper(frame, &components);

    components.parameters->getSize(HW_INFO_HW_PICTURE_SIZE, (uint32_t *)&outputSizeW, (uint32_t *)&outputSizeH);

    ret = frame->getDstBuffer(leaderPipeId, &srcBuffer);
    if (ret != NO_ERROR) {
        CLOGE("[F%d]getDstBuffer fail. pipeId (%d) ret(%d)",
                frame->getFrameCount(),leaderPipeId,ret);
        goto CLEAN;
    }

    shot_stream = (struct camera2_stream *)(srcBuffer.addr[srcBuffer.getMetaPlaneIndex()]);
    if (shot_stream != NULL) {
        CLOGV("(%d %d %d %d)",
                shot_stream->fcount,
                shot_stream->rcount,
                shot_stream->findex,
                shot_stream->fvalid);
        CLOGV("(%d %d %d %d)(%d %d %d %d)",
                shot_stream->input_crop_region[0],
                shot_stream->input_crop_region[1],
                shot_stream->input_crop_region[2],
                shot_stream->input_crop_region[3],
                shot_stream->output_crop_region[0],
                shot_stream->output_crop_region[1],
                shot_stream->output_crop_region[2],
                shot_stream->output_crop_region[3]);
    } else {
        CLOGE("shot_stream is NULL");
        return INVALID_OPERATION;
    }

    bufTag.pipeId[0] = gscPipeId;
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    switch (frame->getFrameType()) {
    case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
    case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
        break;
    default:
        break;
    }
#endif

    ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
    if (ret != NO_ERROR || dstBuffer.index < 0) {
        CLOGE("[F%d B%d]Failed to get InternalNV21Buffer. ret %d",
                frame->getFrameCount(), dstBuffer.index, ret);
    }

    srcRect.x = shot_stream->output_crop_region[0];
    srcRect.y = shot_stream->output_crop_region[1];
    srcRect.w = shot_stream->output_crop_region[2];
    srcRect.h = shot_stream->output_crop_region[3];
    srcRect.fullW = shot_stream->output_crop_region[2];
    srcRect.fullH = shot_stream->output_crop_region[3];
    srcRect.colorFormat = V4L2_PIX_FMT_NV21;

    dstRect.x = 0;
    dstRect.y = 0;
    dstRect.w = outputSizeW;
    dstRect.h = outputSizeH;
    dstRect.fullW = outputSizeW;
    dstRect.fullH = outputSizeH;
    dstRect.colorFormat = V4L2_PIX_FMT_NV21;

    CLOGD("srcBuf(%d) dstBuf(%d) (%d, %d, %d, %d) format(%d) actual(%x) -> (%d, %d, %d, %d) format(%d)  actual(%x)",
            srcBuffer.index, dstBuffer.index,
            srcRect.x, srcRect.y, srcRect.w, srcRect.h, srcRect.colorFormat, V4L2_PIX_2_HAL_PIXEL_FORMAT(srcRect.colorFormat),
            dstRect.x, dstRect.y, dstRect.w, dstRect.h, dstRect.colorFormat, V4L2_PIX_2_HAL_PIXEL_FORMAT(dstRect.colorFormat));

    frame->setSrcRect(gscPipeId, srcRect);
    frame->setDstRect(gscPipeId, dstRect);

    ret = m_setupEntity(gscPipeId, frame, &srcBuffer, &dstBuffer);
    if (ret < 0) {
        CLOGE("setupEntity fail, pipeId(%d), ret(%d)", gscPipeId, ret);
    }

    components.reprocessingFactory->setOutputFrameQToPipe(m_resizeYuvDoneQ, gscPipeId);
    components.reprocessingFactory->pushFrameToPipe(frame, gscPipeId);

    /* wait PIPE_GSC_REPROCESSING3 done */
    CLOGV("wait PIPE_GSC_REPROCESSING3 output");
    waitCount = 0;
    frame = NULL;
    dstBuffer.index = -2;
    do {
        ret = m_resizeYuvDoneQ->waitAndPopProcessQ(&frame);
        waitCount++;
    } while (ret == TIMED_OUT && waitCount < 100);

    if (ret < 0) {
        CLOGW("Failed to waitAndPopProcessQ. ret %d waitCount %d", ret, waitCount);
    }

    if (frame == NULL) {
        CLOGE("frame is NULL");
        goto CLEAN;
    }
    ret = frame->getDstBuffer(PIPE_GSC_REPROCESSING3, &srcBuffer);
    if (ret != NO_ERROR) {
        CLOGE("[F%d B%d]getDstBuffer fail. ret(%d)",
                frame->getFrameCount(), srcBuffer.index, ret);
    }

    ret = m_bufferSupplier->putBuffer(srcBuffer);
    if (ret < 0) {
        CLOGE("[F%d B%d]Failed to putBuffer. ret %d",
                frame->getFrameCount(), srcBuffer.index, ret);
    }

CLEAN:
    if (frame != NULL) {
        CLOGD("frame delete. framecount %d", frame->getFrameCount());
        frame = NULL;
    }

    CLOGD("--OUT--");

    return ret;
}


status_t ExynosCamera::m_setFliteBuffers(bool isRemosaic, int maxSensorW, int maxSensorH)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    CLOGD("[%s] %dx%d",
            isRemosaic ? "Remosaic" : "Normal", maxSensorW, maxSensorH);

    status_t ret = NO_ERROR;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;
    int maxBufferCount = 1;
    int minBufferCount = 1;
    int bayerFormat = 0;
    int pipeId = -1;
    bool flagFlite3aaM2M = (m_parameters[m_cameraId]->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);
    bool flagUsePostVC0 = false;
    int32_t reprocessingBayerMode = m_parameters[m_cameraId]->getReprocessingBayerMode();

    /* FLITE */
    if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true
        || flagFlite3aaM2M == true) {
        pipeId = PIPE_VC0;
    } else {
        pipeId = PIPE_3AC;
    }

#ifdef DEBUG_RAWDUMP
    /* For RAW_DUMP with pure bayer,
    * another buffer manager is required on processed bayer reprocessing mode.
    */
    /**/
    if (bufTag.pipeId[0] != PIPE_VC0) {
        /* VC0 for RAW_DUMP */
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_VC0;
        if (isRemosaic)
            bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
        else
            bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("RAW_DUMP_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create RAW_DUMP_BUF. ret %d", ret);
        }

        bayerFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_VC0);

        bufConfig = initBufConfig;
        bufConfig.planeCount = 2;
        bufConfig.bytesPerLine[0] = getBayerLineSize(maxSensorW, bayerFormat);
        bufConfig.size[0] = bufConfig.bytesPerLine[0] * maxSensorH;
        bufConfig.reqBufCount = maxBufferCount;
        bufConfig.allowedMaxBufCount = maxBufferCount;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = true;
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
        bufConfig.debugInfo = {maxSensorW, maxSensorH, bayerFormat};

        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc RAW_DUMP_BUF. ret %d", ret);
            return ret;
        }
    }
#endif

    int indexPipeId = 0;
    bufTag = initBufTag;
    bufTag.pipeId[indexPipeId++] = pipeId;
#ifdef SUPPORT_REMOSAIC_CAPTURE
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC)) {
        bufTag.pipeId[indexPipeId++] = PIPE_VC0;
    }
#endif //SUPPORT_REMOSAIC_CAPTURE
    if (isRemosaic)
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
    else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
    if (flagFlite3aaM2M == true) {
        bufTag.pipeId[indexPipeId++] = PIPE_3AA;
    }
#ifdef USES_COMBINE_PLUGIN
    bufTag.pipeId[indexPipeId++] = PIPE_PLUGIN_PRE1_REPROCESSING;
#endif

    ret = m_bufferSupplier->createBufferManager("FLITE_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create FLITE_BUF. ret %d", ret);
    }

    maxBufferCount = m_configurations->maxNumOfSensorBuffer(isRemosaic);
    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;

    switch (reprocessingBayerMode) {
    case REPROCESSING_BAYER_MODE_PURE_DYNAMIC :
    case REPROCESSING_BAYER_MODE_DIRTY_DYNAMIC :
        if ((m_streamManager->findStream(HAL_STREAM_ID_YUV_INPUT) == true)
            || (m_streamManager->findStream(HAL_STREAM_ID_ZSL_INPUT) == true)
            || ((m_streamManager->findStream(HAL_STREAM_ID_JPEG) == false)
                 && (m_streamManager->findStream(HAL_STREAM_ID_CALLBACK_STALL) == false)
                 && (m_streamManager->findStream(HAL_STREAM_ID_RAW) == false))) {
            minBufferCount = 1;
        } else {
            minBufferCount = maxBufferCount;
        }
        break;
    default :
        minBufferCount = maxBufferCount;
        break;
    }
    CLOGD("minBufferCount = %d, maxBufferCount = %d", minBufferCount, maxBufferCount);
#ifdef CAMERA_PACKED_BAYER_ENABLE
    if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true
        || flagUsePostVC0 ) {
        bayerFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_VC0);
        bufConfig.bytesPerLine[0] = getBayerLineSize(maxSensorW, bayerFormat);
    } else {
        if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_SUPER_NIGHT_SHOT_BAYER)) {
            camera_pixel_size pixelSize = CAMERA_PIXEL_SIZE_8BIT;
            m_parameters[m_cameraId]->getSuperNightBayerFormatIsp(&bayerFormat, &pixelSize);
        } else {
            bayerFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_3AC);
        }
#ifdef SUPPORT_REMOSAIC_CAPTURE
        bayerFormat = MAX(getBayerLineSize(maxSensorW, m_parameters[m_cameraId]->getBayerFormat(PIPE_VC0)),
                            getBayerLineSize(maxSensorW, bayerFormat));

#endif
        bufConfig.bytesPerLine[0] = getBayerLineSize(maxSensorW, bayerFormat);
    }

    bufConfig.size[0] = bufConfig.bytesPerLine[0] * maxSensorH;
#else
    bufConfig.bytesPerLine[0] = maxSensorW * 2;
    bufConfig.size[0] = bufConfig.bytesPerLine[0] * maxSensorH;
#endif
    bufConfig.reqBufCount = minBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.allocMode = (minBufferCount == maxBufferCount) ? BUFFER_MANAGER_ALLOCATION_ATONCE : BUFFER_MANAGER_ALLOCATION_ONDEMAND;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
#ifdef DEBUG_RAWDUMP
    bufConfig.needMmap = true;
#else
    if (flagUsePostVC0) {
        bufConfig.needMmap = true;
    } else {
        bufConfig.needMmap = false;
    }
#endif

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
    // TODO : we need to set on run-time.
    bufConfig.needMmap = true;
#endif

#ifdef RESERVED_MEMORY_ENABLE
    if (isBackCamera(getCameraId())) {
        bufConfig.reservedMemoryCount = RESERVED_NUM_BAYER_BUFFERS;
        if (m_rawStreamExist || flagUsePostVC0)
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_RESERVED_TYPE;
        else
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_RESERVED_TYPE;
    } else if (isFrontCamera(getCameraId())
                && m_configurations->getMode(CONFIGURATION_PIP_MODE) == false) {
        bufConfig.reservedMemoryCount = FRONT_RESERVED_NUM_BAYER_BUFFERS;
        if (m_rawStreamExist || flagUsePostVC0)
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_RESERVED_TYPE;
        else
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_RESERVED_TYPE;
    } else
#endif
    {
        bool useCombinePlugin = false;
#ifdef USES_COMBINE_PLUGIN
        useCombinePlugin = true;
#endif
        if (m_rawStreamExist || flagUsePostVC0 || useCombinePlugin)
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
        else
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    }

    bufConfig.debugInfo = {maxSensorW, maxSensorH, bayerFormat};

#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_FLITE, BUF_TYPE_NORMAL);
    if (ret != NO_ERROR) {
        CLOGE("Failed to add FLITE_BUF. ret %d", ret);
        return ret;
    }
#else
    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc FLITE_BUF. ret %d", ret);
        return ret;
    }
#endif

    return ret;
}

status_t ExynosCamera::m_setBuffers(void)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;
    int maxBufferCount = 1;
    int minBufferCount = 1;
    int maxSensorW  = 0, maxSensorH  = 0;
    int bayerFormat = 0;
    int maxPreviewW  = 0, maxPreviewH  = 0;
    int dsWidth  = 0, dsHeight  = 0;
    int pipeId = -1;
    ExynosRect bdsRect;
    bool flagFlite3aaM2M = (m_parameters[m_cameraId]->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M);
    bool flagUsePostVC0 = false;
    int32_t reprocessingBayerMode = m_parameters[m_cameraId]->getReprocessingBayerMode();

    int indexPipeId = 0;

    if (m_ionAllocator == NULL || m_bufferSupplier == NULL) {
        CLOGE("Allocator %p, BufferSupplier %p is NULL",
                m_ionAllocator, m_bufferSupplier);
        return INVALID_OPERATION;
    }

    CLOGI("alloc buffer - camera ID: %d", m_cameraId);

#ifdef SUPPORT_VENDOR_DYNAMIC_SENSORMODE
    if (m_configurations->getMode(CONFIGURATION_FULL_SIZE_SENSOR_LUT_MODE)) {
        m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&maxSensorW, (uint32_t *)&maxSensorH);
    } else
#endif
    {
        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&maxSensorW, (uint32_t *)&maxSensorH);
    }
    m_parameters[m_cameraId]->getPreviewBdsSize(&bdsRect, false);

    for (int i = 1; i < m_camIdInfo.numOfSensors; i++) {
        int slaveMaxSensorW  = 0, slaveMaxSensorH  = 0;
        ExynosRect slaveBdsRect;

#ifdef SUPPORT_VENDOR_DYNAMIC_SENSORMODE
        if (m_configurations->getMode(CONFIGURATION_FULL_SIZE_SENSOR_LUT_MODE)) {
            m_parameters[m_camIdInfo.cameraId[i]]->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&slaveMaxSensorW, (uint32_t *)&slaveMaxSensorH);
        } else
#endif
        {
            m_parameters[m_camIdInfo.cameraId[i]]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&slaveMaxSensorW, (uint32_t *)&slaveMaxSensorH);
        }

        if (maxSensorW * maxSensorH < slaveMaxSensorW * slaveMaxSensorH) {
            maxSensorW = slaveMaxSensorW;
            maxSensorH = slaveMaxSensorH;
        }

        m_parameters[m_camIdInfo.cameraId[i]]->getPreviewBdsSize(&slaveBdsRect, false);
        if (bdsRect.w * bdsRect.h < slaveBdsRect.w * slaveBdsRect.h) {
            bdsRect.w = slaveBdsRect.w;
            bdsRect.h = slaveBdsRect.h;
        }
    }

#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    // remosaic capture will be available in this configureStream
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC) == true) {
        m_configurations->getSize(CONFIGURATION_MAX_NOT_REMOSAIC_SENSOR_SIZE, (uint32_t *)&maxSensorW, (uint32_t *)&maxSensorH);
        CLOGI("Session Remosaic Enable");
    }
#endif

    CLOGI("HW Sensor MAX width x height = %dx%d", maxSensorW, maxSensorH);
    CLOGI("Preview BDS width x height = %dx%d", bdsRect.w, bdsRect.h);

    ret = m_setFliteBuffers(false, maxSensorW, maxSensorH);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create RAW_DUMP_BUF. ret %d", ret);
        return ret;
    }

    if (m_configurations->getDynamicMode(DYNAMIC_HIGHSPEED_RECORDING_MODE) == true) {
        m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&maxPreviewW, (uint32_t *)&maxPreviewH);
        CLOGI("PreviewSize(HW - Highspeed) width x height = %dx%d",
                maxPreviewW, maxPreviewH);
        maxSensorW = maxPreviewW;
        maxSensorH = maxPreviewH;
    } else {
        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_PREVIEW_SIZE, (uint32_t *)&maxPreviewW, (uint32_t *)&maxPreviewH);

        for (int i = 1; i < m_camIdInfo.numOfSensors; i++) {
            int slaveMaxPreviewW  = 0, slaveMaxPreviewH  = 0;
            m_parameters[m_camIdInfo.cameraId[i]]->getSize(HW_INFO_MAX_PREVIEW_SIZE, (uint32_t *)&slaveMaxPreviewW, (uint32_t *)&slaveMaxPreviewH);
            if (maxPreviewW * maxPreviewH < slaveMaxPreviewW * slaveMaxPreviewH) {
                maxPreviewW = slaveMaxPreviewW;
                maxPreviewH = slaveMaxPreviewH;
            }
        }
        CLOGI("PreviewSize(Max) width x height = %dx%d",
                maxPreviewW, maxPreviewH);
    }

    dsWidth = MAX_VRA_INPUT_WIDTH;
    dsHeight = MAX_VRA_INPUT_HEIGHT;
    CLOGI("DS width x height = %dx%d", dsWidth, dsHeight);

    ////////////////////////////////////////////////
    // alloc sensor gyro buf
    if (m_configurations->getMode(CONFIGURATION_SENSOR_GYRO_MODE) == true) {
        ret = m_setSensorGyroBuffers(maxBufferCount);
        if (ret != NO_ERROR) {
            CLOGE("m_setSensorGyroBuffers(%d) fail", maxBufferCount);
        }
    }

    ////////////////////////////////////////////////


    /* 3AA */
    bufTag = initBufTag;
    if (flagFlite3aaM2M == true) {
        bufTag.pipeId[0] = PIPE_FLITE;
    } else {
        bufTag.pipeId[0] = PIPE_3AA;
    }
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("3AA_IN_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create 3AA_IN_BUF. ret %d", ret);
    }

    maxBufferCount = m_exynosconfig->current->bufInfo.num_3aa_buffers;
    if (m_parameters[m_cameraId]->getSensorControlDelay() == 0) {
#ifdef USE_DUAL_CAMERA
        if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true) {
            maxBufferCount -= (SENSOR_REQUEST_DELAY * 2);
        } else
#endif
        {
            maxBufferCount -= SENSOR_REQUEST_DELAY;
        }
    }

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.size[0] = 32 * 64 * 2;
    bufConfig.reqBufCount = maxBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane =isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = false;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.debugInfo = {32, 64, 0};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc 3AA_BUF. ret %d", ret);
        return ret;
    }

#ifdef SUPPORT_ME
    if ( (m_configurations->getMode(CONFIGURATION_GMV_MODE) == true)
            || (m_parameters[m_cameraId]->getLLSOn() == true)
#ifdef USES_SW_VDIS
            || (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE) == true)
#endif
    ){
        int meWidth = 0, meHeight = 0;

        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_ME;
        bufTag.pipeId[1] = PIPE_GMV;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("ME_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create ME_BUF. ret %d", ret);
        }

        bufConfig = initBufConfig;
        bufConfig.planeCount = 2;
        m_parameters[m_cameraId]->getMeSize(&meWidth, &meHeight);
        if (m_parameters[m_cameraId]->getMeFormat() == V4L2_PIX_FMT_Y12)
            bufConfig.size[0] = meWidth * meHeight * 2;
        else
            bufConfig.size[0] = meWidth * meHeight;
        bufConfig.reqBufCount = maxBufferCount;
        bufConfig.allowedMaxBufCount = maxBufferCount;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = true;
        bufConfig.reservedMemoryCount = 0;
        bufConfig.debugInfo = {meWidth, meHeight, 0};

        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc ME_BUF. ret %d", ret);
            return ret;
        }
    }
#endif

#ifdef SUPPORT_PD_IMAGE
    m_setPDimageInternalBuffer();
#endif

    /* ISP */
    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_3AP;
    bufTag.pipeId[1] = PIPE_ISP;
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("ISP_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create ISP_BUF. ret %d", ret);
    }

    int ispW = 0, ispH = 0;

#if defined (USE_ISP_BUFFER_SIZE_TO_BDS)
    ispW = bdsRect.w;
    ispH = bdsRect.h;
#else
    ispW = maxPreviewW;
    ispH = maxPreviewH;
#endif

    bayerFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_ISP);

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.bytesPerLine[0] = getBayerLineSize(ispW, bayerFormat);
    if (m_parameters[m_cameraId]->isUseBayerCompression() == true) {
        float bytePerPixel = getBayerBytesPerPixel(bayerFormat);
        int bufSize = ((ispH + ((ispW / 24) * 4 * ispH + ispW - 1) / ispW) * ispW * bytePerPixel) + 0.5;
        bufConfig.size[0] = ALIGN_UP(bufSize, 4096);
        CLOGD("Bayer compression buffer size(%d), original(%d), bytePerPixel(%f)", bufConfig.size[0],
                bufConfig.bytesPerLine[0] * ispH, bytePerPixel);
    } else if (m_parameters[m_cameraId]->getPixelCompInfo(PIPE_3AP)) {
        float bytePerPixel = getBayerBytesPerPixel(bayerFormat);
        uint32_t bitsPerPixel = (uint32_t) (bytePerPixel * 8);
        bitsPerPixel = ((bitsPerPixel + 1) >> 1) << 1;  //multiples of 2.
        uint32_t payloadSize = getSBWCPayloadSize(ispW, ispH, bitsPerPixel);
        uint32_t headerSize = getSBWCHeaderSize(ispW, ispH);

        uint32_t bufSize = payloadSize + headerSize;
        bufConfig.size[0] = ALIGN_UP(bufSize, 4096);
        CLOGD("ISP: SWBC buffer size(%d), payloadSize(%d), headerSize(%d) ispW = %d ispH = %d bitsPerPixel = %d normal_buf_size = %d", bufConfig.size[0],
                payloadSize, headerSize, ispW, ispH, bitsPerPixel, bufConfig.bytesPerLine[0] * ispH);

        bufConfig.size[0] = MAX(bufConfig.size[0], bufConfig.bytesPerLine[0] * ispH);
    } else {
        bufConfig.size[0] = bufConfig.bytesPerLine[0] * ispH;
    }
    bufConfig.reqBufCount = maxBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = false;
#if defined(RESERVED_MEMORY_ENABLE) && defined(USE_ISP_BUFFER_SIZE_TO_BDS)
    if (isBackCamera(getCameraId())) {
        if (m_configurations->getDynamicMode(DYNAMIC_UHD_RECORDING_MODE) == true) {
            bufConfig.reservedMemoryCount = RESERVED_NUM_ISP_BUFFERS_ON_UHD;
        } else {
            bufConfig.reservedMemoryCount = RESERVED_NUM_ISP_BUFFERS;
        }
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_RESERVED_TYPE;
    } else if (isFrontCamera(getCameraId())
            && m_configurations->getMode(CONFIGURATION_PIP_MODE) == false) {
        bufConfig.reservedMemoryCount = FRONT_RESERVED_NUM_ISP_BUFFERS;
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_RESERVED_TYPE;
    } else
#endif
    {
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    }
    bufConfig.debugInfo = {ispW, ispH, bayerFormat};


#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_ISP, BUF_TYPE_NORMAL);
    if (ret != NO_ERROR) {
     CLOGE("Failed to add ISP_BUF. ret %d", ret);
     return ret;
    }
#else
    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc ISP_BUF. ret %d", ret);
        return ret;
    }
#endif

#if 0
    /* ISPC */
    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_ISPC;
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("ISPC_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create ISPC_BUF. ret %d", ret);
    }

    bayerFormat = m_parameters[m_cameraId]->getBayerFormat(PIPE_ISP);
    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
#if defined (USE_ISP_BUFFER_SIZE_TO_BDS)
    bufConfig.bytesPerLine[0] = getBayerLineSize(bdsRect.w, bayerFormat);
    bufConfig.size[0] = bufConfig.bytesPerLine[0] * bdsRect.h;
#else
    bufConfig.bytesPerLine[0] = getBayerLineSize(maxPreviewW, bayerFormat);
    bufConfig.size[0] = bufConfig.bytesPerLine[0] * maxPreviewH;
#endif
    bufConfig.reqBufCount = maxBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    bufConfig.debugInfo = {bdsRect.h, bdsRect.w, bayerFormat};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc ISP_BUF. ret %d", ret);
        return ret;
    }
#endif

#ifdef SUPPORT_HW_GDC
    /* GDC */
    int videoOutputPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO);
    if (videoOutputPortId > -1
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == 1)
            && m_configurations->getSecondPortId() > -1
            && m_configurations->getOnePortId() != videoOutputPortId
#endif
        ) {
        ExynosRect videoRect;
        int videoFormat = m_configurations->getYuvFormat(videoOutputPortId);
        camera_pixel_size videoPixelSize = m_configurations->getYuvPixelSize(videoOutputPortId);
        m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&videoRect.w, (uint32_t *)&videoRect.h, videoOutputPortId);

        bufTag = initBufTag;
        bufTag.pipeId[0] = (videoOutputPortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
        bufTag.pipeId[1] = PIPE_GDC;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("GDC_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create GDC_BUF. ret %d", ret);
        }

        bufConfig = initBufConfig;
        bufConfig.planeCount = getYuvPlaneCount(videoFormat) + 1;
        getYuvPlaneSize(videoFormat, bufConfig.size, videoRect.w, videoRect.h, videoPixelSize);
        bufConfig.reqBufCount = 5;
        bufConfig.allowedMaxBufCount = 5;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = false;
        bufConfig.reservedMemoryCount = 0;
        bufConfig.debugInfo = {videoRect.h, videoRect.w, videoFormat};

        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc GDC_BUF. ret %d", ret);
            return ret;
        }
    }
#endif

    if ((m_parameters[m_cameraId]->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M) ||
        (m_parameters[m_cameraId]->getHwConnectionMode(PIPE_3AA, PIPE_VRA) == HW_CONNECTION_MODE_M2M)
#if defined(BOARD_CAMERA_EARLY_FD) && defined(USE_ALWAYS_FD_OFF)
        || (true)
#endif
       ) {
        /* VRA */
        bufTag = initBufTag;
        if (m_parameters[m_cameraId]->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M) {
            bufTag.pipeId[0] = PIPE_MCSC5;
            maxBufferCount = m_exynosconfig->current->bufInfo.num_vra_buffers;
        } else {
            //maxBufferCount; /* same as 3AA buf count */
            bufTag.pipeId[0] = PIPE_3AF;
        }

        if (m_parameters[m_cameraId]->getHwConnectionMode(PIPE_MCSC_REPROCESSING, PIPE_VRA_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
            bufTag.pipeId[1] = PIPE_MCSC5_REPROCESSING;
        } else {
            bufTag.pipeId[1] = PIPE_3AF_REPROCESSING;
        }

#if !defined(USE_ALWAYS_FD_OFF)
#ifdef USE_VRA_FD
        bufTag.pipeId[2] = PIPE_VRA;
        bufTag.pipeId[3] = PIPE_VRA_REPROCESSING;
#else
        bufTag.pipeId[2] = PIPE_NFD;
        bufTag.pipeId[3] = PIPE_NFD_REPROCESSING;
#endif
#endif
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("VRA_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create VRA_BUF. ret %d", ret);
        }

        bufConfig = initBufConfig;
        switch (m_parameters[m_cameraId]->getHW3AFdFormat()) {
            case V4L2_PIX_FMT_NV16M:
            case V4L2_PIX_FMT_NV61M:
                bufConfig.planeCount = 3;
                bufConfig.bytesPerLine[0] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN);
                bufConfig.bytesPerLine[1] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN);
                bufConfig.size[0] = bufConfig.bytesPerLine[0] * dsHeight;
                bufConfig.size[1] = bufConfig.bytesPerLine[1] * dsHeight;

                break;
            case V4L2_PIX_FMT_NV16:
            case V4L2_PIX_FMT_NV61:
                bufConfig.planeCount = 2;
                bufConfig.bytesPerLine[0] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN);
                bufConfig.size[0] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN) * dsHeight * 2;
                break;
            case V4L2_PIX_FMT_RGB24:
            case V4L2_PIX_FMT_BGR24:
                bufConfig.planeCount = 2;
                bufConfig.bytesPerLine[0] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN);
                bufConfig.size[0] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN) * dsHeight * 3;
                break;
            default:
                bufConfig.planeCount = 2;
                bufConfig.size[0] = ALIGN_UP(dsWidth, CAMERA_16PX_ALIGN) * dsHeight * 2;
                break;
        }
        bufConfig.reqBufCount = maxBufferCount - 2;
        bufConfig.allowedMaxBufCount = maxBufferCount;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = true;
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
        bufConfig.debugInfo = {dsWidth, dsHeight, m_parameters[m_cameraId]->getHW3AFdFormat()};

#ifdef ADAPTIVE_RESERVED_MEMORY
        ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_VRA, BUF_TYPE_NORMAL);
        if (ret != NO_ERROR) {
            CLOGE("Failed to add VRA_BUF. ret %d", ret);
            return ret;
        }
#else
        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc VRA_BUF. ret %d", ret);
            return ret;
        }
#endif
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
        int onePortId = m_streamManager->getOutputPortIdForDualScenario();
        if (onePortId > -1) {
            ExynosRect previewRect;
            int previewFormat = m_configurations->getYuvFormat(onePortId);
            camera_pixel_size pixelSize = m_configurations->getYuvPixelSize(onePortId);

            // get the MCSC output size
            m_getMcscOutputBufferSize(&previewRect.w, &previewRect.h);

#ifdef USE_DUAL_CAMERA
            if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
                ExynosRect fusionSrcRect;
                ExynosRect fusionDstRect;

                // TODO: need to adjust preview size
                m_parameters[m_cameraId]->getFusionSize(previewRect.w, previewRect.h,
                        &fusionSrcRect, &fusionDstRect,
                        DUAL_SOLUTION_MARGIN_VALUE_NONE);
                previewRect.w = fusionSrcRect.w;
                previewRect.h = fusionSrcRect.h;
            }
#endif
            CLOGD("FUSION_BUF width x height = %d x %d", previewRect.w, previewRect.h);

            bufTag = initBufTag;
            int pipeIdx = 0;
            int streamId;
            //bufTag.maxpipes = 5
            for (int port = 0; (port < ExynosCameraParameters::YUV_MAX) &&  pipeIdx < 5; port++) {
                // It is intended for using one of the YUV port for the Fusion
                streamId = m_streamManager->getYuvStreamId(port);
                if (streamId > -1) {
                    switch(streamId % HAL_STREAM_ID_MAX) {
                    case HAL_STREAM_ID_PREVIEW:
                    case HAL_STREAM_ID_VIDEO:
                    case HAL_STREAM_ID_CALLBACK:
                    case HAL_STREAM_ID_CALLBACK_PHYSICAL:
                        bufTag.pipeId[pipeIdx++] = port + PIPE_MCSC0;
                        break;
                    default:
                        break;
                    }
                }
            }
            bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

            ret = m_bufferSupplier->createBufferManager("FUSION_BUF", m_ionAllocator, bufTag);
            if (ret != NO_ERROR) {
                CLOGE("Failed to create FUSION_BUF. ret %d", ret);
            }

            maxBufferCount = m_exynosconfig->current->bufInfo.dual_num_fusion_buffers;

#ifdef USES_DUAL_CAMERA_SOLUTION_FAKE
            maxBufferCount = m_exynosconfig->current->bufInfo.dual_num_fusion_buffers + 4;
#endif

            bufConfig = initBufConfig;
            bufConfig.planeCount = getYuvPlaneCount(previewFormat) + 1;
            getYuvPlaneSize(previewFormat, bufConfig.size, previewRect.w, previewRect.h, pixelSize);
            bufConfig.reqBufCount = maxBufferCount;
            bufConfig.allowedMaxBufCount = maxBufferCount;
            bufConfig.startBufIndex = 0;
            bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
            bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
            bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
            bufConfig.createMetaPlane = true;
            bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
            bufConfig.needMmap = true;
            bufConfig.reservedMemoryCount = 0;
            bufConfig.debugInfo = {previewRect.w, previewRect.h, previewFormat};

#ifdef ADAPTIVE_RESERVED_MEMORY
            ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_FUSION, BUF_TYPE_NORMAL);
            if (ret != NO_ERROR) {
                CLOGE("Failed to add FUSION_BUF. ret %d", ret);
                return ret;
            }
#else
            ret = m_allocBuffers(bufTag, bufConfig);
            if (ret != NO_ERROR) {
                CLOGE("Failed to alloc FUSION_BUF. ret %d", ret);
                return ret;
            }
#endif
#ifdef USE_LCAM
            //LCAM: Alloc dummy Fusion buffers for handling Only Physical stream requests
            if (m_isLogicalCam) {
                bufTag = initBufTag;

                bufTag.pipeId[0] = PIPE_LCAM_FUSION;
                bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

                ret = m_bufferSupplier->createBufferManager("LCAM_FUSION_BUF", m_ionAllocator, bufTag);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to create LCAM_FUSION_BUF. ret %d", ret);
                }

                maxBufferCount = m_exynosconfig->current->bufInfo.dual_num_fusion_buffers;

                bufConfig = initBufConfig;
                bufConfig.planeCount = getYuvPlaneCount(previewFormat) + 1;
                getYuvPlaneSize(previewFormat, bufConfig.size, previewRect.w, previewRect.h, pixelSize);
                bufConfig.reqBufCount = maxBufferCount;
                bufConfig.allowedMaxBufCount = maxBufferCount;
                bufConfig.startBufIndex = 0;
                bufConfig.batchSize = 1;
                bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
                bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
                bufConfig.createMetaPlane = true;  //is it required?
                bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
                bufConfig.needMmap = true;
                bufConfig.reservedMemoryCount = 0;
                bufConfig.debugInfo = {previewRect.w, previewRect.h, previewFormat};

                ret = m_allocBuffers(bufTag, bufConfig);
                if (ret != NO_ERROR) {
                    CLOGE("Failed to alloc LCAM_FUSION_BUF. ret %d", ret);
                    return ret;
                }
            }
#endif
        }
    }
#endif

#ifdef DEBUG_DUMP_IMAGE
    //Alloc buffers for Image Dump

    int32_t dumpImagePropertyConfig;
    int32_t dumpImageConfigrationVal;
    int imageW = maxSensorW;
    int imageH = maxSensorH;

    dumpImagePropertyConfig = getDumpImagePropertyConfig();
    dumpImageConfigrationVal = m_configurations->getModeValue(CONFIGURATION_DUMP_IMAGE_VALUE);

    if (m_configurations->getModeMultiValue(CONFIGURATION_MULTI_SESSION_MODE_VALUE, EXYNOS_SESSION_MODE_REMOSAIC)) {
        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&imageW, (uint32_t *)&imageH);
        CLOGI("session mode remosaic, IMAGE_DUMP buffer wxh(%dx%d)", imageW, imageH);
    }

    if ((dumpImagePropertyConfig > 0) || (dumpImageConfigrationVal > 0)) {
        bufTag = initBufTag;

        bufTag.pipeId[0] = PIPE_DUMP_IMAGE;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("DUMP_IMAGE_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create DUMP_IMAGE_BUF. ret %d", ret);
        }

        bufConfig = initBufConfig;
        bufConfig.bytesPerLine[0] = ROUND_UP(imageW * 2, CAMERA_16PX_ALIGN);
        bufConfig.size[0] = bufConfig.bytesPerLine[0] * imageH;
#ifdef DEBUG_DUMP_YUV_REQUIRED
        bufConfig.planeCount = 3;
        bufConfig.size[1] = bufConfig.size[0];
#else
        bufConfig.planeCount = 2;
#endif
        bufConfig.reqBufCount = 2;
        bufConfig.allowedMaxBufCount = DEBUG_DUMP_ALLOC_BUF_CNT;
        bufConfig.startBufIndex = 0;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
        bufConfig.createMetaPlane = true;  //is it required?
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = true;
        bufConfig.reservedMemoryCount = 0;
        bufConfig.debugInfo = {imageW, imageH, 0};

        CLOGD("[DUMP_IMAGE_BUF]  planeCount = %d size[0] = %d, size[1] = %d", bufConfig.planeCount,
                bufConfig.size[0], bufConfig.size[1]);
        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc LCAM_FUSION_BUF. ret %d", ret);
            return ret;
        }
    }
#endif

#ifdef USE_CLAHE_PREVIEW
    /* CLAHE */
    int recordingW = 0, recordingH = 0;

    if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_CLAHEC;
        bufTag.pipeId[1] = PIPE_VDIS;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("CLAHE_OUT_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create CLAHE_OUT_BUF. ret %d", ret);
        }

        bufConfig = initBufConfig;
        bufConfig.planeCount = 3;
        m_configurations->getSize(CONFIGURATION_VIDEO_SIZE, (uint32_t *)&recordingW, (uint32_t *)&recordingH);
        bufConfig.size[0] = recordingW * recordingH;
        bufConfig.size[1] = recordingW * recordingH / 2;
        bufConfig.reqBufCount = m_exynosconfig->current->bufInfo.num_request_video_buffers;
        bufConfig.allowedMaxBufCount = m_exynosconfig->current->bufInfo.num_request_video_buffers;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = false;
        bufConfig.reservedMemoryCount = 0;

        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc CLAHE_OUT_BUF. ret %d", ret);
            return ret;
        }
    }
#endif

    ret = m_setVendorBuffers();
    if (ret != NO_ERROR) {
        CLOGE("Failed to m_setVendorBuffers. ret %d", ret);
        return ret;
    }

    CLOGI("alloc buffer done - camera ID: %d", m_cameraId);
    return ret;
}

status_t ExynosCamera::m_setVisionBuffers(void)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;
    int maxBufferCount = 1;
    int maxSensorW  = 0, maxSensorH  = 0;
    int maxPreviewW  = 0, maxPreviewH  = 0;
    ExynosRect bdsRect;

    if (m_ionAllocator == NULL || m_bufferSupplier == NULL) {
        CLOGE("Allocator %p, BufferSupplier %p is NULL",
                m_ionAllocator, m_bufferSupplier);
        return INVALID_OPERATION;
    }

    CLOGI("alloc buffer - camera ID: %d", m_cameraId);

    m_parameters[m_cameraId]->getSize(HW_INFO_MAX_SENSOR_SIZE, (uint32_t *)&maxSensorW, (uint32_t *)&maxSensorH);
    CLOGI("HW Sensor MAX width x height = %dx%d",
            maxSensorW, maxSensorH);
    m_parameters[m_cameraId]->getPreviewBdsSize(&bdsRect);
    CLOGI("Preview BDS width x height = %dx%d",
            bdsRect.w, bdsRect.h);

    if (m_configurations->getDynamicMode(DYNAMIC_HIGHSPEED_RECORDING_MODE) == true) {
        m_parameters[m_cameraId]->getSize(HW_INFO_HW_PREVIEW_SIZE, (uint32_t *)&maxPreviewW, (uint32_t *)&maxPreviewH);
        CLOGI("PreviewSize(HW - Highspeed) width x height = %dx%d",
                maxPreviewW, maxPreviewH);
    } else {
        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_PREVIEW_SIZE, (uint32_t *)&maxPreviewW, (uint32_t *)&maxPreviewH);
        CLOGI("PreviewSize(Max) width x height = %dx%d",
                maxPreviewW, maxPreviewH);
    }

    /* 3AA */
    bufTag = initBufTag;
    if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true
        || m_parameters[m_cameraId]->getHwConnectionMode(PIPE_FLITE, PIPE_3AA) == HW_CONNECTION_MODE_M2M) {
        bufTag.pipeId[0] = PIPE_FLITE;
    } else {
        bufTag.pipeId[0] = PIPE_3AA;
    }
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("3AA_IN_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create 3AA_IN_BUF. ret %d", ret);
    }

    maxBufferCount = m_exynosconfig->current->bufInfo.num_3aa_buffers;
    if (m_parameters[m_cameraId]->getSensorControlDelay() == 0) {
        maxBufferCount -= SENSOR_REQUEST_DELAY;
    }

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.size[0] = 32 * 64 * 2;
    bufConfig.reqBufCount = maxBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = false;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.debugInfo = {32, 64, 0};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc 3AA_BUF. ret %d", ret);
        return ret;
    }

    CLOGI("alloc buffer done - camera ID: %d", m_cameraId);

    return NO_ERROR;
}

status_t ExynosCamera::m_setupBatchFactoryBuffers(ExynosCameraRequestSP_sprt_t request,
                                                  ExynosCameraFrameSP_sptr_t frame,
                                                  ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    int streamId = -1;
    uint32_t leaderPipeId = 0;
    uint32_t nodeType = 0;
    frame_handle_components_t components;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    if (factory == NULL) {
        CLOGE("frame Factory is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);

    enum pipeline controlPipeId = (enum pipeline) components.parameters->getPerFrameControlPipe();
    int batchSize = components.parameters->getBatchSize(controlPipeId);

    bool flag3aaIspM2M = (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M);
    bool flagIspMcscM2M = (components.parameters->getHwConnectionMode(PIPE_ISP, PIPE_MCSC) == HW_CONNECTION_MODE_M2M);

    for (int batchIndex = 0; batchIndex < batchSize; batchIndex++) {
        if (batchIndex > 0
            && m_getSizeFromRequestList(&m_requestPreviewWaitingList, &m_requestPreviewWaitingLock) > 0) {
            /* Use next request to get stream buffers */
            Mutex::Autolock l(m_requestPreviewWaitingLock);
            List<ExynosCameraRequestSP_sprt_t>::iterator r = m_requestPreviewWaitingList.begin();
            request = *r;
            m_requestPreviewWaitingList.erase(r);

            ExynosCameraRequestSP_sprt_t serviceRequest = NULL;
            m_popServiceRequest(serviceRequest);
            serviceRequest = NULL;
        } else if (batchIndex > 0) {
            request = NULL;
        }

        if (request == NULL) {
            CLOGW("[R%d F%d]Not enough request for batch buffer. batchIndex %d batchSize %d",
                    request->getKey(), frame->getFrameCount(), batchIndex, batchSize);
            /* Skip to set stream buffer for this batch index. This is Frame Drop */
            return INVALID_OPERATION;
        }

        m_frameCountLock.lock();
        if (request->getFrameCount() == 0) {
           m_requestMgr->setFrameCount(m_internalFrameCount++, request->getKey());
        }
        m_frameCountLock.unlock();

        const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();
        for (uint32_t bufferIndex = 0; bufferIndex < request->getNumOfOutputBuffer(); bufferIndex++) {
            const camera3_stream_buffer_t *streamBuffer = &(bufferList[bufferIndex]);
            streamId = request->getStreamIdwithBufferIdx(bufferIndex);
            buffer_handle_t *handle = streamBuffer->buffer;
            buffer_manager_tag_t bufTag;
            bufTag.reserved.i32 = streamId;
            bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

            switch (streamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_ZSL_OUTPUT:
                leaderPipeId = PIPE_3AA;
                bufTag.pipeId[0] = PIPE_VC0;
                break;
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
                leaderPipeId = PIPE_3AA;
                bufTag.pipeId[0] = PIPE_VC1;
                break;
#endif
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_CALLBACK:
                if (flagIspMcscM2M == true
                    && IS_OUTPUT_NODE(factory, PIPE_MCSC) == true) {
                    leaderPipeId = PIPE_MCSC;
                } else if (flag3aaIspM2M == true
                           && IS_OUTPUT_NODE(factory, PIPE_ISP) == true) {
                    leaderPipeId = PIPE_ISP;
                } else {
                    leaderPipeId = PIPE_3AA;
                }
                bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                    % ExynosCameraParameters::YUV_MAX)
                                    + PIPE_MCSC0;
                break;
            case HAL_STREAM_ID_RAW:
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                /* Do nothing */
                break;
            default:
                CLOGE("Invalid stream ID %d", streamId);
                break;
            }

            if (bufTag.pipeId[0] < 0) {
                CLOGW("[R%d F%d]Invalid pipe ID. batchIndex %d batchSize %d",
                        request->getKey(), frame->getFrameCount(), batchIndex, batchSize);
                /* Skip to set stream buffer for this batch index. This is Frame Drop */
                continue;
            }

            nodeType = (uint32_t) factory->getNodeType(bufTag.pipeId[0]);

            ret = frame->getDstBuffer(leaderPipeId, &buffer, nodeType);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to getDstBuffer. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

            buffer.handle[batchIndex] = handle;
            buffer.acquireFence[batchIndex] = streamBuffer->acquire_fence;
            buffer.releaseFence[batchIndex] = streamBuffer->release_fence;

            ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, nodeType);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to setDstBufferState. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

            frame->setServiceBufferPipeId(streamId, leaderPipeId);
            frame->setServiceBufferPosition(streamId, nodeType);
            ret = frame->setDstBuffer(leaderPipeId, buffer, nodeType, INDEX(bufTag.pipeId[0]));
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to setDstBuffer. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

            frame->setRequest(bufTag.pipeId[0], true);
        }
    }

    List<int> keylist;
    List<int>::iterator iter;
    ExynosCameraStream *stream = NULL;
    keylist.clear();
    m_streamManager->getStreamKeys(&keylist);
    for (iter = keylist.begin(); iter != keylist.end(); iter++) {
        buffer_manager_tag_t bufTag;
        bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

        m_streamManager->getStream(*iter, &stream);
        stream->getID(&streamId);
        bufTag.reserved.i32 = streamId;

        switch (streamId % HAL_STREAM_ID_MAX) {
        case HAL_STREAM_ID_ZSL_OUTPUT:
            leaderPipeId = PIPE_3AA;
            bufTag.pipeId[0] = PIPE_VC0;
            break;
#ifdef SUPPORT_DEPTH_MAP
        case HAL_STREAM_ID_DEPTHMAP:
            leaderPipeId = PIPE_3AA;
            bufTag.pipeId[0] = PIPE_VC1;
            break;
#endif
        case HAL_STREAM_ID_PREVIEW:
        case HAL_STREAM_ID_CALLBACK:
        case HAL_STREAM_ID_VIDEO:
            if (flagIspMcscM2M == true
                    && IS_OUTPUT_NODE(factory, PIPE_MCSC) == true) {
                leaderPipeId = PIPE_MCSC;
            } else if (flag3aaIspM2M == true
                    && IS_OUTPUT_NODE(factory, PIPE_ISP) == true) {
                leaderPipeId = PIPE_ISP;
            } else {
                leaderPipeId = PIPE_3AA;
            }
            bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                        % ExynosCameraParameters::YUV_MAX)
                                + PIPE_MCSC0;
            break;
        case HAL_STREAM_ID_RAW:
        case HAL_STREAM_ID_JPEG:
        case HAL_STREAM_ID_CALLBACK_STALL:
        case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
        case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
            /* Do nothing */
            break;
        default:
            CLOGE("Invalid stream ID %d", streamId);
            break;
        }

        if (bufTag.pipeId[0] < 0
            || frame->getRequest(bufTag.pipeId[0]) == false) {
            continue;
        }

        nodeType = (uint32_t) factory->getNodeType(bufTag.pipeId[0]);

        ret = frame->getDstBuffer(leaderPipeId, &buffer, nodeType);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to getDstBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[R%d F%d B%d S%d]Failed to getBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }

        for (int batchIndex = 0; batchIndex < buffer.batchSize; batchIndex++) {
            ret = request->setAcquireFenceDone(buffer.handle[batchIndex],
                                            (buffer.acquireFence[batchIndex] == -1) ? true : false);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to setAcquireFenceDone. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }
        }

        ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, nodeType);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to setDstBufferState. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }

        ret = frame->setDstBuffer(leaderPipeId, buffer, nodeType);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to setDstBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }
    }

    return ret;
}

status_t ExynosCamera::m_setupPreviewFactoryBuffers(const ExynosCameraRequestSP_sprt_t request,
                                                    ExynosCameraFrameSP_sptr_t frame,
                                                    ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    uint32_t leaderPipeId = 0;
    uint32_t nodeType = 0;
    frame_handle_components_t components;
#ifdef USE_DUAL_CAMERA
    enum DUAL_PREVIEW_MODE dualPreviewMode = m_configurations->getDualPreviewMode();
#endif

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    if (factory == NULL) {
        CLOGE("frame Factory is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);

    bool flag3aaIspM2M = (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M);
    bool flagIspMcscM2M = (components.parameters->getHwConnectionMode(PIPE_ISP, PIPE_MCSC) == HW_CONNECTION_MODE_M2M);
    int alternativePreviewPortId = components.parameters->getAlternativePreviewPortId();
    const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();

    for (uint32_t index = 0; index < request->getNumOfOutputBuffer(); index++) {
        const camera3_stream_buffer_t *streamBuffer = &(bufferList[index]);
        int streamId = request->getStreamIdwithBufferIdx(index);
        buffer_handle_t *handle = streamBuffer->buffer;
        buffer_manager_tag_t bufTag;

        // It should be not processed when SW_MCSC scenario. preview should be service buffer.
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
#else
        /* Set Internal Buffer */
        if ((m_flagVideoStreamPriority && request->hasStream(HAL_STREAM_ID_VIDEO) == false)
            ) {
            if ((streamId % HAL_STREAM_ID_MAX) == HAL_STREAM_ID_PREVIEW) {
                ExynosCameraBuffer internalBuffer;
                bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

#ifdef USE_DUAL_CAMERA
                if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                    if (frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                        if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                            leaderPipeId = PIPE_ISP;
                        } else {
                            leaderPipeId = PIPE_3AA;
                        }

                        if (alternativePreviewPortId >= 0) {
                            bufTag.pipeId[0] = alternativePreviewPortId + PIPE_MCSC0;
                        } else {
                            bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                                % ExynosCameraParameters::YUV_MAX)
                                                + PIPE_MCSC0;
                        }
                    } else {
                        leaderPipeId = PIPE_FUSION;
                        bufTag.pipeId[0] = PIPE_FUSION;
                    }
                } else
#endif
                {
                    if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                        leaderPipeId = PIPE_ISP;
                    } else {
                        leaderPipeId = PIPE_3AA;
                    }
                    bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                        % ExynosCameraParameters::YUV_MAX)
                                        + PIPE_MCSC0;
                }

                frame->storeInternalBufTagPipeId(bufTag.pipeId[0]);

                ret = m_bufferSupplier->getBuffer(bufTag, &internalBuffer);
                if (ret != NO_ERROR || internalBuffer.index < 0) {
                    CLOGE("[R%d F%d T%d]Set Internal Buffers: Failed to getBuffer(%d). ret %d",
                            request->getKey(), frame->getFrameCount(), frame->getFrameType(), internalBuffer.index, ret);
#ifdef USE_DUAL_CAMERA
                    if (leaderPipeId == PIPE_FUSION) {
                        frame->setRequest(PIPE_FUSION, false);
                        frame->storeInternalBufTagPipeId(-1);
                    }
#endif
                } else {
                    nodeType = (uint32_t) factory->getNodeType(bufTag.pipeId[0]);
                    ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, nodeType);
                    if (ret != NO_ERROR) {
                        CLOGE("Set Internal Buffers: Failed to setDstBufferState. ret %d", ret);
                        continue;
                    }

                    ret = frame->setDstBuffer(leaderPipeId, internalBuffer, nodeType);
                    if (ret != NO_ERROR) {
                        CLOGE("Set Internal Buffers: Failed to setDstBuffer. ret %d", ret);
                        continue;
                    }
                }
            }
        }
#endif
        bufTag.reserved.i32 = streamId;
        bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;
#ifdef USE_LCAM
        if (m_isLogicalCam) {
            if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                if ((streamId % HAL_STREAM_ID_MAX) == HAL_STREAM_ID_CALLBACK_PHYSICAL) {
                    int32_t onePortId = -1;
                    m_getOnePortId(request, NULL, &onePortId);
                    if (onePortId == m_streamManager->getOutputPortId(streamId)) {
                        //Only Physical Stream case
                        leaderPipeId = PIPE_LCAM_FUSION;
                        bufTag.reserved.i32 = -1;
                        bufTag.pipeId[0] = PIPE_LCAM_FUSION;
                        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
                        goto SETUP_BUF;    //stream is handled here
                    } else {
                        continue;   // nothing to do
                    }
                }
            }
        }
#endif

        switch (streamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_ZSL_OUTPUT:
                leaderPipeId = PIPE_3AA;
                if (components.parameters->getUsePureBayerReprocessing() == true) {
                    bufTag.pipeId[0] = PIPE_VC0;
                } else {
                    bufTag.pipeId[0] = PIPE_3AC;
                }
                break;
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
                leaderPipeId = PIPE_3AA;
                bufTag.pipeId[0] = PIPE_VC1;
                break;
#endif
            case HAL_STREAM_ID_PREVIEW_VIDEO:
            case HAL_STREAM_ID_VIDEO:
                if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_GDC) == true
                        && frame->getRequest(PIPE_GDC) == true) {
                    leaderPipeId = PIPE_GDC;
                    bufTag.pipeId[0] = PIPE_GDC;
                    break;
                } else {
#ifdef USE_DUAL_CAMERA
                    if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION
#ifdef USES_SW_VDIS
                            && (frame->getRequest(PIPE_VDIS) == false)
#endif
                       ) {
                        /*
                         * Pipe Tag Rule for Dual in recording w/o VDIS
                         * 1. Fusion case w/ videoStreamPriority
                         *    [MCSC] -> FusionBuf -> [Fusion] -> VideoBuf -> [GSC] -> Preview Buf
                         * 2. Fusion case
                         *    [MCSC] -> FusionBuf -> [Fusion] -> PreviewBuf -> [GSC] -> VideoBuf
                         * 3. Not fusion case
                         *    [MCSC] -> VideoBuf
                         */
                        if (m_flagVideoStreamPriority == true) {
                            // 1. Fusion case w/ videoStreamPriority
                            leaderPipeId = PIPE_FUSION;
                            bufTag.pipeId[0] = PIPE_FUSION;
                        } else {
                        if (frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                            // 3. Not fusion case
                            int previewPortId = components.parameters->getPreviewPortId();

                            if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                                leaderPipeId = PIPE_ISP;
                            } else {
                                leaderPipeId = PIPE_3AA;
                            }

                            if (alternativePreviewPortId >= 0) {
                                bufTag.pipeId[0] = (alternativePreviewPortId % ExynosCameraParameters::YUV_MAX)
                                                    + PIPE_MCSC0;
                            } else {
                                bufTag.pipeId[0] = (previewPortId % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
                            }
                        } else {
                            // 2. Fusion case
                            leaderPipeId = PIPE_GSC;
                            bufTag.pipeId[0] = PIPE_GSC;
                        }
                        }
                        break;
                    }
#endif
                }

#ifdef USES_COMBINE_PLUGIN
                if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0 &&
                        (frame->getRequest(PIPE_VDIS) == false)) {
                    leaderPipeId = PIPE_PLUGIN1;
                    bufTag.pipeId[0] = PIPE_PLUGIN_RECORDING;
                    break;
                }
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
                /*
                 * if video stream is output of MCSC,
                 *     [MCSC] -> video -> [SWMCSC] -> preview/preview cb
                 * else
                 *     [MCSC] -> preview/preview cb -> [SWMCSC] -> video
                 */
                if (m_configurations->getSecondPortId() > -1){
                    int onePortStreamId =  m_streamManager->getYuvStreamId(m_configurations->getOnePortId());
                    if (onePortStreamId == streamId) {
                        if (flagIspMcscM2M == true && IS_OUTPUT_NODE(factory, PIPE_MCSC) == true) {
                            leaderPipeId = PIPE_MCSC;
                        } else if (flag3aaIspM2M == true && IS_OUTPUT_NODE(factory, PIPE_ISP) == true) {
                            leaderPipeId = PIPE_ISP;
                        } else {
                            leaderPipeId = PIPE_3AA;
                        }
                    } else {
                        leaderPipeId = PIPE_SW_MCSC;
                    }
                    bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                        % ExynosCameraParameters::YUV_MAX)
                                        + PIPE_MCSC0;
                    break;
                }
#endif
                // pass through
            case HAL_STREAM_ID_PREVIEW:
#ifndef USES_COMBINE_PLUGIN
#ifndef USE_SW_MCSC
                /*
                 * COMBINE_PLUGIN does not yet support video streaming.
                 * The Vidoe stream is output directly from the MCSC.
                 */
                if (m_flagVideoStreamPriority == true) {
                    leaderPipeId = PIPE_GSC;
                    bufTag.pipeId[0] = PIPE_GSC;
                    break;
                } else
#endif
#endif
                {
#ifdef USE_DUAL_CAMERA
                    if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION
#ifdef USES_SW_VDIS
                            && (frame->getRequest(PIPE_VDIS) == false)
#endif
                       ) {
                        /*
                         * Pipe Tag Rule for Dual for preview w/o VDIS
                         * 1. Fusion case w/ videoStreamPriority in recording
                         *    [MCSC] -> FusionBuf -> [Fusion] -> VideoBuf -> [GSC] -> Preview Buf
                         * 2. Fusion case
                         *    [MCSC] -> FusionBuf -> [Fusion] -> PreviewBuf -> [GSC] -> VideoBuf
                         * 3. Not fusion case
                         *    [MCSC] -> PreviewBuf
                         */
                        if (request->hasStream(HAL_STREAM_ID_VIDEO) == true &&
                                m_flagVideoStreamPriority == true) {
                            // 1. Fusion case w/ videoStreamPriority in recording
                            leaderPipeId = PIPE_GSC;
                            bufTag.pipeId[0] = PIPE_GSC;
                        } else {
                            if (frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                                // 3. Not fusion case
                                if (alternativePreviewPortId >= 0) {
                                    int previewPortId = components.parameters->getPreviewPortId();

                                    if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                                        leaderPipeId = PIPE_ISP;
                                    } else {
                                        leaderPipeId = PIPE_3AA;
                                    }

                                    bufTag.pipeId[0] = (alternativePreviewPortId % ExynosCameraParameters::YUV_MAX)
                                                        + PIPE_MCSC0;
                                } else {
                                    leaderPipeId = PIPE_GSC;
                                    bufTag.pipeId[0] = PIPE_GSC;
                                }
                            } else {
                                // 2. Fusion case
                                leaderPipeId = PIPE_FUSION;
                                bufTag.pipeId[0] = PIPE_FUSION;
                            }
                        }
                        break;
                    }
#endif
#ifdef USES_COMBINE_PLUGIN
                    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0 &&
                            frame->getRequest(PIPE_VDIS) == false) {
                        if (request->hasStream(HAL_STREAM_ID_VIDEO) == false) {
                            leaderPipeId = PIPE_PLUGIN1;
                            bufTag.pipeId[0] = PIPE_PLUGIN1;
                        } else {
                            leaderPipeId = PIPE_PLUGIN1;
                            bufTag.pipeId[0] = PIPE_PLUGIN_PREVIEW;
                        }
                        break;
                    }
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
                    /*
                     * if preview stream is output of MCSC
                     *    [MCSC] -> preview -> [SWMCSC] -> video/preview cb
                     * else
                     *    [MCSC] -> video/preview cb -> [SWMCSC] -> preview
                     *                                                                                                          */
                    if (m_configurations->getSecondPortId() > -1) {
                        int onePortStreamId =  m_streamManager->getYuvStreamId(m_configurations->getOnePortId());
                        if (onePortStreamId == streamId) {
                            if (flagIspMcscM2M == true && IS_OUTPUT_NODE(factory, PIPE_MCSC) == true) {
                                leaderPipeId = PIPE_MCSC;
                            } else if (flag3aaIspM2M == true && IS_OUTPUT_NODE(factory, PIPE_ISP) == true) {
                                leaderPipeId = PIPE_ISP;
                            } else {
                                leaderPipeId = PIPE_3AA;
                            }
                        } else {
                            leaderPipeId = PIPE_SW_MCSC;
                        }
                        bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                % ExynosCameraParameters::YUV_MAX)
                            + PIPE_MCSC0;
                        break;
                    }
#endif
                }
                // pass through
            case HAL_STREAM_ID_CALLBACK:
#ifdef USES_SW_VDIS
                if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0
                        && (frame->getRequest(PIPE_VDIS) == true)) {
                    /*
                     * Pipe Tag Rule for Dual in recording w/ VDIS
                     * 1. Multiple Camera
                     *    [MCSC] -> FusionBuf -> [Fusion] -> MCS_OUT Buf -> [VDIS] -> Preview Buf / Video Buf
                     * 2. Single Camera w/o PlugIn
                     *    [MCSC] -> MCS_OUT buf -> [VDIS] -> Preview Buf / Video Buf
                     * 3. Single Camera w/  PlugIn (TODO)
                     *    [MCSC] -> MCS_OUT buf -> [PLUGIN] -> MCS_OUT buf -> [VDIS] -> Preview Buf / Video Buf
                     */
                    leaderPipeId = m_exCameraSolutionSWVdis->getPipeId();
                    switch (streamId % HAL_STREAM_ID_MAX) {
                    case HAL_STREAM_ID_PREVIEW_VIDEO:
                    case HAL_STREAM_ID_VIDEO:
                        bufTag.pipeId[0] = leaderPipeId;
                        break;
                    case HAL_STREAM_ID_PREVIEW:
                        bufTag.pipeId[0] = PIPE_VDIS_PREVIEW;
                        break;
                    case HAL_STREAM_ID_CALLBACK:
                        bufTag.pipeId[0] = PIPE_VDIS_PREVIEW;
                        break;
                    }
                    break;
                }
#endif

#ifdef USE_DUAL_CAMERA
                if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
                    if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
                        continue;
                    } else {
                        if (frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                            leaderPipeId = PIPE_GSC_CLONE;
                            bufTag.pipeId[0] = PIPE_GSC_CLONE;
                        } else {
                            leaderPipeId = PIPE_FUSION_CLONE;
                            bufTag.pipeId[0] = PIPE_FUSION_CLONE;
                        }
                    }
                } else
#endif
#ifdef SUPPORT_PREVIEW_PLUGIN_YUV_STREAM
                if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
                    if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
                        continue;
                    } else {
                        leaderPipeId = PIPE_PLUGIN_CALLBACK;
                        bufTag.pipeId[0] = PIPE_PLUGIN_CALLBACK;
                    }
                } else
#endif
#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
                    /*
                     * if preview callback stream is output of MCSC,
                     *    [MCSC] -> preview cb -> [SWMCSC] -> preview/video
                     * else
                     *    [MCSC] -> preview/video -> [SWMCSC] -> preview cb
                     */
                    if (m_configurations->getSecondPortId() > -1) {
                        int onePortStreamId =  m_streamManager->getYuvStreamId(m_configurations->getOnePortId());
                        if (onePortStreamId == streamId) {
                            if (flagIspMcscM2M == true && IS_OUTPUT_NODE(factory, PIPE_MCSC) == true) {
                                leaderPipeId = PIPE_MCSC;
                            } else if (flag3aaIspM2M == true && IS_OUTPUT_NODE(factory, PIPE_ISP) == true) {
                                leaderPipeId = PIPE_ISP;
                            } else {
                                leaderPipeId = PIPE_3AA;
                            }
                        } else {
                            leaderPipeId = PIPE_SW_MCSC;
                        }
                        bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                % ExynosCameraParameters::YUV_MAX)
                            + PIPE_MCSC0;
                    }else
#endif
                {
                    if (flagIspMcscM2M == true
                        && IS_OUTPUT_NODE(factory, PIPE_MCSC) == true) {
                        leaderPipeId = PIPE_MCSC;
                    } else if (flag3aaIspM2M == true
                            && IS_OUTPUT_NODE(factory, PIPE_ISP) == true) {
                        leaderPipeId = PIPE_ISP;
                    } else {
                        leaderPipeId = PIPE_3AA;
                    }

                    bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                        % ExynosCameraParameters::YUV_MAX)
                                        + PIPE_MCSC0;
                }
                break;
            case HAL_STREAM_ID_RAW:
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                /* Do nothing */
                break;
            case HAL_STREAM_ID_VISION:
                leaderPipeId = PIPE_FLITE;
                bufTag.pipeId[0] = PIPE_VC0;
                break;
            default:
                CLOGE("Invalid stream ID %d", streamId);
                break;
        }

SETUP_BUF:

        if (bufTag.pipeId[0] < 0) {
            CLOGV("Invalid pipe ID %d", bufTag.pipeId[0]);
            continue;
        }

        request->setParentStreamPipeId(streamId, leaderPipeId);
        request->setStreamPipeId(streamId, bufTag.pipeId[0]);
        if ((leaderPipeId == PIPE_FUSION_CLONE)
#ifdef USE_LCAM
            || (leaderPipeId == PIPE_LCAM_FUSION)
#endif
            ) {
            request->setParentStreamPipeId(streamId, PIPE_FUSION);
            request->setStreamPipeId(streamId, PIPE_FUSION);
            leaderPipeId = PIPE_FUSION;
        } else if (leaderPipeId == PIPE_GSC_CLONE) {
            request->setParentStreamPipeId(streamId, PIPE_GSC);
            request->setStreamPipeId(streamId, PIPE_GSC);
            leaderPipeId = PIPE_GSC;
        } else if (leaderPipeId == PIPE_PLUGIN_CALLBACK) {
            request->setParentStreamPipeId(streamId, PIPE_PLUGIN1);
            request->setStreamPipeId(streamId, PIPE_PLUGIN1);
            leaderPipeId = PIPE_PLUGIN1;
            CLOGD("[R%d F%d T%d] skip to set Preview Callback buuffer",
                    request->getKey(), frame->getFrameCount(), frame->getFrameType());
            return ret;
        } else {
            request->setParentStreamPipeId(streamId, leaderPipeId);
            request->setStreamPipeId(streamId, bufTag.pipeId[0]);
        }

        buffer.handle[0] = handle;
        buffer.acquireFence[0] = streamBuffer->acquire_fence;
        buffer.releaseFence[0] = streamBuffer->release_fence;
        nodeType = (uint32_t) factory->getNodeType(bufTag.pipeId[0]);

        CLOGV("[R%d F%d T%d] set service buffer, leaderPipeId %d, nodePipeid %d",
                request->getKey(), frame->getFrameCount(), frame->getFrameType(),
                leaderPipeId, bufTag.pipeId[0]);

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[R%d F%d B%d S%d T%d]Failed to getBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, frame->getFrameType(), ret);
#ifdef SUPPORT_DEPTH_MAP
            if (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_DEPTHMAP) {
                frame->setRequest(PIPE_VC1, false);
            }
#endif
            continue;
        }

        ret = request->setAcquireFenceDone(handle, (buffer.acquireFence[0] == -1) ? true : false);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[R%d F%d B%d S%d T%d]Failed to setAcquireFenceDone. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, frame->getFrameType(), ret);
#ifdef SUPPORT_DEPTH_MAP
            if (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_DEPTHMAP) {
                frame->setRequest(PIPE_VC1, false);
            }
#endif
            continue;
        }

        ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, nodeType);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to setDstBufferState. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
#ifdef SUPPORT_DEPTH_MAP
            if (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_DEPTHMAP) {
                frame->setRequest(PIPE_VC1, false);
            }
#endif
            continue;
        }

        frame->setServiceBufferPipeId(streamId, leaderPipeId);
        frame->setServiceBufferPosition(streamId, nodeType);
        ret = frame->setDstBuffer(leaderPipeId, buffer, nodeType, INDEX(bufTag.pipeId[0]));
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to setDstBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
#ifdef SUPPORT_DEPTH_MAP
            if (streamId % HAL_STREAM_ID_MAX == HAL_STREAM_ID_DEPTHMAP) {
                frame->setRequest(PIPE_VC1, false);
            }
#endif
            continue;
        }
    }

    return ret;
}

status_t ExynosCamera::m_setupVisionFactoryBuffers(const ExynosCameraRequestSP_sprt_t request,
                                                   ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_VISION];
    uint32_t leaderPipeId = 0;
    uint32_t nodeType = 0;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        return BAD_VALUE;
    }

    const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();

    for (uint32_t index = 0; index < request->getNumOfOutputBuffer(); index++) {
        const camera3_stream_buffer_t *streamBuffer = &(bufferList[index]);
        int streamId = request->getStreamIdwithBufferIdx(index);
        buffer_handle_t *handle = streamBuffer->buffer;
        buffer_manager_tag_t bufTag;
        bufTag.reserved.i32 = streamId;
        bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

        switch (streamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_ZSL_OUTPUT:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
#endif
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_PREVIEW_VIDEO:
            case HAL_STREAM_ID_RAW:
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
            case HAL_STREAM_ID_CALLBACK_PHYSICAL:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                /* Do nothing */
                break;
            case HAL_STREAM_ID_VISION:
                leaderPipeId = PIPE_FLITE;
                bufTag.pipeId[0] = PIPE_VC0;
                break;
            default:
                CLOGE("Invalid stream ID %d", streamId);
                break;
        }

SETUP_BUF:

        if (bufTag.pipeId[0] < 0) {
            CLOGV("Invalid pipe ID %d", bufTag.pipeId[0]);
            continue;
        }

        request->setParentStreamPipeId(streamId, leaderPipeId);
        request->setStreamPipeId(streamId, bufTag.pipeId[0]);

        buffer.handle[0] = handle;
        buffer.acquireFence[0] = streamBuffer->acquire_fence;
        buffer.releaseFence[0] = streamBuffer->release_fence;
        nodeType = (uint32_t) factory->getNodeType(bufTag.pipeId[0]);

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[R%d F%d B%d S%d]Failed to getBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }

        ret = request->setAcquireFenceDone(handle, (buffer.acquireFence[0] == -1) ? true : false);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("[R%d F%d B%d S%d]Failed to setAcquireFenceDone. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }

        ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, nodeType);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to setDstBufferState. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }

        frame->setServiceBufferPipeId(streamId, leaderPipeId);
        frame->setServiceBufferPosition(streamId, nodeType);
        ret = frame->setDstBuffer(leaderPipeId, buffer, nodeType, INDEX(bufTag.pipeId[0]));
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d S%d]Failed to setDstBuffer. ret %d",
                    request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
            continue;
        }
    }

    return ret;
}

status_t ExynosCamera::m_setupCaptureFactoryInternalBuffers(ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    uint32_t leaderPipeId = 0;
    uint32_t nodeType = 0;
    buffer_manager_tag_t bufTag;
    const buffer_manager_tag_t initBufTag;
    int yuvStallPipeId = m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT) + PIPE_MCSC0_REPROCESSING;
    frame_handle_components_t components;
    ExynosCameraFrameFactory *factory = NULL;

    m_getFrameHandleComponentsWrapper(frame, &components);

    if (components.parameters->isUseVideoHQISP() == true) {
        factory = components.previewFactory;
    } else {
        factory = components.reprocessingFactory;
    }

    if (frame == NULL) {
        CLOGE("frame is NULL");
        return BAD_VALUE;
    }

    /* Set Internal Buffers */
    if ((frame->getRequest(yuvStallPipeId) == true)
        && (frame->getStreamRequested(STREAM_TYPE_YUVCB_STALL) == false
        || m_flagUseInternalyuvStall == true
#ifdef USE_DUAL_CAMERA
        || m_configurations->getMode(CONFIGURATION_FUSION_CAPTURE_MODE) == true
#endif
        )) {
#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
        if (frame->getMode(FRAME_MODE_SWMCSC) == true) {
            leaderPipeId = PIPE_SW_MCSC_REPEOCESSING;
        } else
#endif
        {
            if (components.parameters->getUsePureBayerReprocessing() == true) {
                if (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
                    leaderPipeId = PIPE_ISP_REPROCESSING;
                } else {
                    leaderPipeId = PIPE_3AA_REPROCESSING;
                }
            } else {
                leaderPipeId = PIPE_ISP_REPROCESSING;
            }
        }
        bufTag.pipeId[0] = yuvStallPipeId;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
        switch (frame->getFrameType()) {
        case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
        case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
            bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
            break;
        default:
            break;
        }
#endif

        ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CFLOGE(frame, "[B%d]Failed to getBuffer. ret %d", buffer.index, ret);
            return BAD_VALUE;
        }

        nodeType = (uint32_t)factory->getNodeType(bufTag.pipeId[0]);

        ret = frame->setDstBufferState(leaderPipeId,
                                       ENTITY_BUFFER_STATE_REQUESTED,
                                       nodeType);
        if (ret != NO_ERROR) {
            CFLOGE(frame, "[B%d]Failed to getDstBufferState. ret %d", buffer.index, ret);
            return BAD_VALUE;
        }

        ret = frame->setDstBuffer(leaderPipeId, buffer, nodeType, INDEX(bufTag.pipeId[0]));
        if (ret != NO_ERROR) {
            CFLOGE(frame, "[B%d]Failed to getDstBuffer. ret %d", buffer.index, ret);
            return BAD_VALUE;
        }
    }

    return ret;
}

status_t ExynosCamera::m_setupCaptureFactoryBuffers(const ExynosCameraRequestSP_sprt_t request,
                                                    ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    uint32_t leaderPipeId = 0;
    uint32_t nodeType = 0;
    uint32_t frameType = 0;
    buffer_manager_tag_t bufTag;
    const buffer_manager_tag_t initBufTag;
    int yuvStallPipeId = m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT) + PIPE_MCSC0_REPROCESSING;
    frame_handle_components_t components;
    ExynosCameraFrameFactory *factory = NULL;
    camera2_shot_ext shotExt;
    ExynosRect jpegRect;

    m_getFrameHandleComponentsWrapper(frame, &components);

    if (components.parameters->isUseVideoHQISP() == true) {
        factory = components.previewFactory;
    } else {
        factory = components.reprocessingFactory;
    }

    bool flagRawOutput = false;
    bool flag3aaIspM2M = (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M);
    bool flagIspMcscM2M = (components.parameters->getHwConnectionMode(PIPE_ISP_REPROCESSING, PIPE_MCSC_REPROCESSING) == HW_CONNECTION_MODE_M2M);

    if (frame == NULL) {
        CLOGE("frame is NULL");
        return BAD_VALUE;
    }

    if (request == NULL) {
        CLOGE("request is NULL");
        return BAD_VALUE;
    }

    const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();
    frameType = frame->getFrameType();
    frame->getMetaData(&shotExt);

    /* Set Service Buffers */
    if (frameType != FRAME_TYPE_INTERNAL
#ifdef SUPPORT_REMOSAIC_CAPTURE
        && frameType != FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION
#endif
#ifdef USE_DUAL_CAMERA
        && frameType != FRAME_TYPE_INTERNAL_SLAVE
#endif
        ) {
        for (uint32_t index = 0; index < request->getNumOfOutputBuffer(); index++) {
            const camera3_stream_buffer_t *streamBuffer = &(bufferList[index]);
            int streamId = request->getStreamIdwithBufferIdx(index);
            int id = streamId % HAL_STREAM_ID_MAX;
            bufTag = initBufTag;
            buffer_handle_t *handle = streamBuffer->buffer;
            bufTag.reserved.i32 = streamId;
            bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;
            flagRawOutput = false;

            cameraId_Info physicalCamIdInfo;
            int phyCamID = atoi(streamBuffer->stream->physical_camera_id);

            physicalCamIdInfo.serviceCameraId = phyCamID;
            getCameraIdInfo(&physicalCamIdInfo);

            CLOGD("[I%d R%d F%d T%d], streamId(%d/%d), phyCamID(%d), InternalID(%d)",
                    index, request->getKey(), frame->getFrameCount(), frameType,
                    streamId, streamId % HAL_STREAM_ID_MAX, phyCamID, physicalCamIdInfo.cameraId[MAIN_CAM]);
            switch (id) {
                case HAL_STREAM_ID_JPEG:
                    if (m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT_USAGE) == YUV_STALL_USAGE_PICTURE) {
#ifdef USE_DUAL_CAMERA
                        if (frameType == FRAME_TYPE_REPROCESSING_DUAL_SLAVE) {
                            leaderPipeId = -1;
                            bufTag.pipeId[0] = -1;
                        } else
#endif
                        {
                            leaderPipeId = PIPE_JPEG_REPROCESSING;
                            bufTag.pipeId[0] = PIPE_JPEG0_REPROCESSING;
                        }
                    } else if (components.parameters->isReprocessing() == true) {
                        if (components.parameters->isUseHWFC() == true) {
                            if (flagIspMcscM2M == true
                                && IS_OUTPUT_NODE(factory, PIPE_MCSC_REPROCESSING) == true) {
                                leaderPipeId = PIPE_MCSC_REPROCESSING;
                            } else if (flag3aaIspM2M == true
                                     && IS_OUTPUT_NODE(factory, PIPE_ISP_REPROCESSING) == true) {
                                leaderPipeId = PIPE_ISP_REPROCESSING;
                            } else {
                                if (components.parameters->getUsePureBayerReprocessing() == true) {
                                    leaderPipeId = PIPE_3AA_REPROCESSING;
                                } else {
                                    leaderPipeId = PIPE_ISP_REPROCESSING;
                                }
                            }
                            bufTag.pipeId[0] = PIPE_HWFC_JPEG_DST_REPROCESSING;
                        } else {
                            leaderPipeId = PIPE_JPEG_REPROCESSING;
                            bufTag.pipeId[0] = PIPE_JPEG0_REPROCESSING;
                        }
                    } else {
                        leaderPipeId = PIPE_JPEG;
                        bufTag.pipeId[0] = PIPE_JPEG;
                    }

#ifdef USE_DUAL_CAMERA
                    if (frameType != FRAME_TYPE_REPROCESSING_DUAL_SLAVE)
#endif
                    {
                        if (components.parameters->supportJpegYuvRotation() == true) {
                            frame->setRotation(bufTag.pipeId[0], request->getRotation(streamId));
                        }

                        m_configurations->getSize(CONFIGURATION_PICTURE_SIZE, (uint32_t *)&jpegRect.w, (uint32_t *)&jpegRect.h);
#ifdef SUPPORT_MULTI_STREAM_CAPTURE
                        if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
                            const camera3_stream_buffer_t *streamBuffer = request->getOutputBuffer(HAL_STREAM_ID_JPEG, false);
                            if (streamBuffer != nullptr) {
                                jpegRect.w = streamBuffer->stream->width;
                                jpegRect.h = streamBuffer->stream->height;
                                CFLOGD(frame, "jpeg streamBufferSize(%dx%d)", jpegRect.w, jpegRect.h);
                            }
                        }
#endif
                        frame->setJpegPipeInfo(bufTag.pipeId[0], jpegRect, &shotExt.shot);
                    }
                    break;
                case HAL_STREAM_ID_CALLBACK:
                    if ((frame->getStreamRequested(STREAM_TYPE_ZSL_INPUT) == false)
#ifdef SUPPORT_VENDOR_YUV_STALL
                        && (frame->getMode(FRAME_MODE_VENDOR_YUV_STALL) == false)
#endif
                        ) {
                        /* If there is no ZSL_INPUT stream buffer,
                         * It will be processed through preview stream.
                         */
                        break;
                    }
                case HAL_STREAM_ID_CALLBACK_STALL:
#ifdef USE_DUAL_CAMERA
                    if (frameType == FRAME_TYPE_REPROCESSING_DUAL_MASTER) {
                        leaderPipeId = PIPE_FUSION_REPROCESSING;
                        bufTag.pipeId[0] = PIPE_FUSION_REPROCESSING;
                    } else
#endif
                    {
                        if (m_flagUseInternalyuvStall == true) {
                            continue;
                        }

#if defined(USE_SW_MCSC_REPROCESSING) && (USE_SW_MCSC_REPROCESSING == true)
                        if (frame->getMode(FRAME_MODE_SWMCSC) == true) {
                            leaderPipeId = PIPE_SW_MCSC_REPEOCESSING;
                        } else
#endif
                        {
                            if (components.parameters->getUsePureBayerReprocessing() == true) {
                                if (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
                                    leaderPipeId = PIPE_ISP_REPROCESSING;
                                } else {
                                    leaderPipeId = PIPE_3AA_REPROCESSING;
                                }
                            } else {
                                leaderPipeId = PIPE_ISP_REPROCESSING;
                            }
                        }
#ifdef ENABLE_YUV_STALL_FOR_SECOND_YUV
                        // TODO: need to handle multi yuv stall..
                        if (frame->getRequest(PIPE_PLUGIN_POST1_REPROCESSING)) {
                            leaderPipeId = PIPE_PLUGIN_POST1_REPROCESSING;
                        }
#endif
                        bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamId)
                                % ExynosCameraParameters::YUV_MAX)
                            + PIPE_MCSC0_REPROCESSING;
                    }
                    break;
                case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef USE_DUAL_CAMERA
                    if (frameType == FRAME_TYPE_REPROCESSING_DUAL_SLAVE) {
                        leaderPipeId = -1;
                        bufTag.pipeId[0] = -1;
                    } else
#endif
                    {
                        leaderPipeId = PIPE_GSC_REPROCESSING2;
                        bufTag.pipeId[0] = PIPE_GSC_REPROCESSING2;
                    }
                    break;
                case HAL_STREAM_ID_RAW:
                    flagRawOutput = true;
                    leaderPipeId = PIPE_3AA_REPROCESSING;
                    if (components.parameters->isUse3aaDNG())
                        bufTag.pipeId[0] = PIPE_3AG_REPROCESSING;
                    else
                        bufTag.pipeId[0] = PIPE_3AC_REPROCESSING;

                    break;
                case HAL_STREAM_ID_ZSL_OUTPUT:
                case HAL_STREAM_ID_PREVIEW:
                case HAL_STREAM_ID_VIDEO:
                case HAL_STREAM_ID_PREVIEW_VIDEO:
#ifdef SUPPORT_DEPTH_MAP
                case HAL_STREAM_ID_DEPTHMAP:
                case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                case HAL_STREAM_ID_VISION:
                    /* Do nothing */
                    bufTag.pipeId[0] = -1;
                    break;
                default:
                    bufTag.pipeId[0] = -1;
                    CLOGE("Invalid stream ID %d", streamId);
                    break;
            }

            if (bufTag.pipeId[0] < 0) {
                CLOGV("Invalid pipe ID %d", bufTag.pipeId[0]);
                continue;
            }

            request->setParentStreamPipeId(streamId, leaderPipeId);
            request->setStreamPipeId(streamId, bufTag.pipeId[0]);

            buffer.handle[0] = handle;
            buffer.acquireFence[0] = streamBuffer->acquire_fence;
            buffer.releaseFence[0] = streamBuffer->release_fence;

            ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[R%d F%d B%d S%d]Failed to getBuffer. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

            ret = request->setAcquireFenceDone(handle, (buffer.acquireFence[0] == -1) ? true : false);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("[R%d F%d B%d S%d]Failed to setAcquireFenceDone. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

#ifdef SUPPORT_VENDOR_YUV_STALL
            // Only for yuv domain
            if (frame->getMode(FRAME_MODE_VENDOR_YUV_STALL) &&
                    (id == HAL_STREAM_ID_CALLBACK ||
                     id == HAL_STREAM_ID_CALLBACK_STALL)) {
                /* set dst buffer for YUV_stall.
                   app use the yuv multistream. do not mapping buffer yuv buffer manager.
                   each yuv stream have different size. we don't identify the stall yuv stream.
                */
                bufTag.pipeId[0] = m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT) + PIPE_MCSC0_REPROCESSING;
            }
#endif

            nodeType = (uint32_t)factory->getNodeType(bufTag.pipeId[0]);

            ret = frame->setDstBufferState(leaderPipeId,
                                           ENTITY_BUFFER_STATE_REQUESTED,
                                           nodeType);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to setDstBufferState. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

#if defined(USE_RAW_REVERSE_PROCESSING) && defined(USE_SW_RAW_REVERSE_PROCESSING)
            /* change the 3AC buffer to internal from service */
            if (components.parameters->isUseRawReverseReprocessing() == true && flagRawOutput) {
                ret = frame->setDstBufferState(leaderPipeId, ENTITY_BUFFER_STATE_REQUESTED, OUTPUT_NODE_1);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d B%d S%d]Failed to setDstBufferState. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                    continue;
                }

                /* HACK: backup the service buffer to the frame by output node index */
                frame->setServiceBufferPipeId(streamId, leaderPipeId);
                frame->setServiceBufferPosition(streamId, OUTPUT_NODE_1);
                ret = frame->setDstBuffer(leaderPipeId, buffer, OUTPUT_NODE_1);
                if (ret != NO_ERROR) {
                    CLOGE("[R%d F%d B%d S%d]Failed to setDstBuffer. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                }

                bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
                switch (frame->getFrameType()) {
                case FRAME_TYPE_REPROCESSING_SENSOR_TRANSITION:
                case FRAME_TYPE_REPROCESSING_INTERNAL_SENSOR_TRANSITION:
                    bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
                    break;
                default:
                    break;
                }
#endif
                ret = m_bufferSupplier->getBuffer(bufTag, &buffer);
                if (ret != NO_ERROR || buffer.index < 0) {
                    CLOGE("[R%d F%d B%d S%d]Failed to getBuffer. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                    continue;
                }

                /* ion sync before qbuf to driver */
                for (int plane = 0; plane < buffer.getMetaPlaneIndex(); plane++)
                    if (m_ionClient >= 0)
                        exynos_ion_sync_fd(m_ionClient, buffer.fd[plane]);
            }
#endif
            frame->setServiceBufferPipeId(streamId, leaderPipeId);
            frame->setServiceBufferPosition(streamId, nodeType);
            ret = frame->setDstBuffer(leaderPipeId, buffer, nodeType);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to setDstBuffer. ret %d",
                        request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                continue;
            }

#ifdef USE_RESERVED_NODE_PPJPEG_MCSCPORT
            /* set flip value from pipe_jpeg to sub_pipe. it use remained MCSC. */
            int flipPipeId = bufTag.pipeId[0];

            frame->setFlipHorizontal(flipPipeId, request->getFlipHorizontal(streamId));
            frame->setFlipVertical  (flipPipeId, request->getFlipVertical(streamId));
#endif
        }
    }

    return ret;
}

status_t ExynosCamera::m_setReprocessingBuffer(bool isRemosaic)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;
    int minBufferCount = 0;
    int maxBufferCount = 0;

    int maxPictureW = 0, maxPictureH = 0;
    int hwSensorW = 0, hwSensorH = 0;
    int maxThumbnailW = 0, maxThumbnailH = 0;
    int pixWidth = 0, pixHeight = 0;

    int pictureFormat = 0;
    ExynosRect srcRect;

    if (m_ionAllocator == NULL || m_bufferSupplier == NULL) {
        CLOGE("Allocator %p, BufferSupplier %p is NULL",
                m_ionAllocator, m_bufferSupplier);

        return INVALID_OPERATION;
    }

    CLOGI("alloc buffer - camera ID: %d", m_cameraId);

    if (m_configurations->getDynamicMode(DYNAMIC_HIGHSPEED_RECORDING_MODE) == true) {
        m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&hwSensorW, (uint32_t *)&hwSensorH);
        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_PICTURE_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);
    } else {
        m_configurations->getSize(CONFIGURATION_MAX_SENSOR_SIZE, (uint32_t *)&hwSensorW, (uint32_t *)&hwSensorH);
        m_configurations->getSize(CONFIGURATION_MAX_PICTURE_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);
    }

#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    // remosaic capture will be available in this configureStream
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC) == true) {
        if (isRemosaic) {
            m_configurations->getSize(CONFIGURATION_MAX_REMOSAIC_SENSOR_SIZE, (uint32_t *)&hwSensorW, (uint32_t *)&hwSensorH);
            m_configurations->getSize(CONFIGURATION_MAX_REMOSAIC_SENSOR_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);
        } else {
            m_configurations->getSize(CONFIGURATION_MAX_NOT_REMOSAIC_SENSOR_SIZE, (uint32_t *)&hwSensorW, (uint32_t *)&hwSensorH);
            // Only in case that application should guarantee to give not-remosaic size buufer.
            // eg. bayer(12M) => 3AA1(12M) -> ISPHQ(12M) -> MCSC(48M) : Not support
            //     bayer(12M) => 3AA1(12M) -> ISPHQ(12M) -> MCSC(12M) : Support
            m_configurations->getSize(CONFIGURATION_MAX_NOT_REMOSAIC_SENSOR_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);

            int curPictureW = 0, curPictureH = 0;
            m_configurations->getSize(CONFIGURATION_PICTURE_SIZE, (uint32_t *)&curPictureW, (uint32_t *)&curPictureH);
            if (curPictureW > maxPictureW || curPictureH > maxPictureH)
            {
                CLOGI("Get remosaic max szie (%dx%d vs %dx%d)", curPictureW, curPictureH, maxPictureW, maxPictureH);
                m_configurations->getSize(CONFIGURATION_MAX_REMOSAIC_SENSOR_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);
            }
        }
    }
#endif
    m_parameters[m_cameraId]->getSize(HW_INFO_MAX_THUMBNAIL_SIZE, (uint32_t *)&maxThumbnailW, (uint32_t *)&maxThumbnailH);
    pictureFormat = m_parameters[m_cameraId]->getHwPictureFormat();

    CLOGI("[%s] Max Picture %ssize %dx%d format %x",
            isRemosaic ? "Remosaic" : "Normal",
            (m_configurations->getDynamicMode(DYNAMIC_HIGHSPEED_RECORDING_MODE) == true) ?
            "on HighSpeedRecording ":"",
            maxPictureW, maxPictureH, pictureFormat);
    CLOGI("hwSensor %dx%d MAX Thumbnail size %dx%d",
            hwSensorW, hwSensorH,
            maxThumbnailW, maxThumbnailH);

#ifdef USES_COMBINE_PLUGIN
	/* combined plugin do not need addtional buffer */
#else
#ifdef SUPPORT_REMOSAIC_CAPTURE
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC)) {
        m_setRemosaicBuffer();
    }
#endif //SUPPORT_DYNAMIC_REMOSAIC_ALLOCATION
#endif //SUPPORT_REMOSAIC_CAPTURE
#endif // USES_COMBINE_PLUGIN

    /* Reprocessing buffer from 3AA to ISP */
    if ((m_parameters[m_cameraId]->isReprocessing() == true
        && m_parameters[m_cameraId]->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M
        && m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true)
#ifdef SUPPORT_REMOSAIC_CAPTURE
        || (m_parameters[m_cameraId]->isReprocessing() == true && m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC))
#endif //SUPPORT_REMOSAIC_CAPTURE
        ) {
        /* ISP_RE */
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_3AP_REPROCESSING;
        bufTag.pipeId[1] = PIPE_ISP_REPROCESSING;
        if (isRemosaic)
            bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
        else
            bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("ISP_RE_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create MCSC_BUF. ret %d", ret);
        }

        minBufferCount = 1;
        maxBufferCount = m_exynosconfig->current->bufInfo.num_reprocessing_buffers;
        bufConfig = initBufConfig;
        bufConfig.planeCount = 2;

        if (m_configurations->getDynamicMode(DYNAMIC_HIGHSPEED_RECORDING_MODE)) {
            pixWidth   = hwSensorW;
            pixHeight  = hwSensorH;
        } else {
            pixWidth   = maxPictureW;
            pixHeight  = maxPictureH;
        }

#ifdef USE_REMOSAIC_SENSOR
        if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_REMOSAIC)) {
            /* For stripe processing, each region requires additional processing margin. */
            const int stipeProcessingMargin = 512;
            const int stipeProcessingRegionNum = 2;

            /* Pixel margin for each stripe region */
            pixWidth += (stipeProcessingMargin * stipeProcessingRegionNum);
        }
#endif

#ifdef CAMERA_PACKED_BAYER_ENABLE
#ifdef DEBUG_RAWDUMP
        if (m_configurations->checkBayerDumpEnable()) {
            bufConfig.bytesPerLine[0] = pixWidth * 2;
        } else
#endif /* DEBUG_RAWDUMP */
        {
            //Old: bytesPerLine[0] = ROUND_UP((pixWidth * 3 / 2), 16);
            bufConfig.bytesPerLine[0] = getBayerLineSize(pixWidth, m_parameters[m_cameraId]->getBayerFormat(PIPE_ISP_REPROCESSING));
        }
#else
        bufConfig.bytesPerLine[0] = pixWidth * 2;
#endif

        bufConfig.size[0] = bufConfig.bytesPerLine[0] * pixHeight;
        bufConfig.reqBufCount = minBufferCount;
        bufConfig.allowedMaxBufCount = maxBufferCount;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[1], &bufConfig.planeCount);
        bufConfig.needMmap = false;
        bufConfig.reservedMemoryCount = 0;
        bufConfig.debugInfo = {pixWidth, pixHeight, 0};

#ifdef ADAPTIVE_RESERVED_MEMORY
        ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_ISP_RE, BUF_TYPE_REPROCESSING);
        if (ret != NO_ERROR) {
            CLOGE("Failed to add ISP_REP_BUF. ret %d", ret);
            return ret;
        }
#else
        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc ISP_REP_BUF. ret %d", ret);
            return ret;
        }
#endif
    }

    /* CAPTURE_CB */
    unsigned int bufferMargin[EXYNOS_CAMERA_BUFFER_MAX_PLANES] = {0};
#ifdef USE_M2M_SCLAER_BUFFER_MARGIN
    /*
    This code is HACK for additional buffer allocation for the S / W M2M scaler.
    S/W M2M scaler need to allocation addtional buffer each planes.
    plane[0] = 512, other plane[1~N] = 512/2
    */
    srcRect.x = 0;
    srcRect.y = 0;

    srcRect.fullW = srcRect.w = hwSensorW;
    srcRect.fullH = srcRect.h = hwSensorH;
    if (checkNeedYUVMaxDownscaling(&srcRect, m_configurations)) {
        for(int i = 0 ; i < EXYNOS_CAMERA_BUFFER_MAX_PLANES ; i++) {
            bufferMargin[i] = (i == 0)? M2M_SCALER_BUFFER_MARGIN : M2M_SCALER_BUFFER_MARGIN / 2;
        }
    }
#endif
    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_MCSC0_REPROCESSING;
    bufTag.pipeId[1] = PIPE_MCSC1_REPROCESSING;
    bufTag.pipeId[2] = PIPE_MCSC2_REPROCESSING;
#ifdef USE_RESERVED_NODE_PPJPEG_MCSCPORT
    bufTag.pipeId[3] = PIPE_MCSC_PP_REPROCESSING;
#endif
    bufTag.pipeId[4] = PIPE_PLUGIN_POST1_REPROCESSING;
    if (isRemosaic)
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
    else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("CAPTURE_CB_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create CAPTURE_CB_BUF. ret %d", ret);
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true
        && m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
        minBufferCount = 2;
    } else
#endif
    {
        minBufferCount = 1;
    }
    maxBufferCount = m_exynosconfig->current->bufInfo.num_nv21_picture_buffers;

#ifdef USES_COMBINE_PLUGIN
    /* increase buffer until HDR usage. */
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_HDR_YUV) == true) {
        const int hdrYuvDstBufferNum = 1;
        int hdrMergeNum = getHdrYuvMergeNum() + hdrYuvDstBufferNum;

#ifdef USE_DUAL_CAMERA
        if (m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
            hdrMergeNum *= 2;

            if (m_configurations->getMode(CONFIGURATION_DUAL_BOKEH_REFOCUS_MODE) == true) {
                hdrMergeNum += m_exynosconfig->current->bufInfo.num_nv21_picture_buffers;
            }
        }
#endif

        if (maxBufferCount < hdrMergeNum) {
            CLOGD("Allocate hdrMergeNum(%d), instread of maxBufferCount(%d) on CAPTURE_CB(NV21)_BUF, for HDR_YUV",
                hdrMergeNum, maxBufferCount);
            maxBufferCount = hdrMergeNum;
        }
    }

    /* increase buffer until OIS usage */
    if (m_configurations->isSupportedFunction(SUPPORTED_FUNCTION_OIS_DENOISE_YUV) == true) {
        const int oisDenoiseYuvDstBufferNum = 1;
        int oisDenoiseYuvMergeNum = getOisDenoiseYuvMergeNum() + oisDenoiseYuvDstBufferNum;
        if (maxBufferCount < oisDenoiseYuvMergeNum) {
            CLOGD("Allocate oisDenoiseYuvMergeNum(%d), instread of maxBufferCount(%d) on CAPTURE_CB(NV21)_BUF, for OIS_DENOISE_YUV",
                    oisDenoiseYuvMergeNum, maxBufferCount);
            maxBufferCount = oisDenoiseYuvMergeNum;
        }
    }
#endif

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
        minBufferCount = MIN(minBufferCount, (m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE) * 2));
        maxBufferCount += (m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE) * 2);
    } else
#endif
    {
        minBufferCount = MIN(minBufferCount, (m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE)));
        maxBufferCount += m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE);
    }

    if (minBufferCount <= 0) {
        CLOGE("minBufferCount can't be set less than 0");
        minBufferCount = 1;
    }

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 3 / 2 + bufferMargin[0];
    bufConfig.reqBufCount = minBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
#if defined(RESERVED_MEMORY_ENABLE)
    if (isBackCamera(getCameraId()) {
        bufConfig.reservedMemoryCount = RESERVED_NUM_INTERNAL_NV21_BUFFERS;
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_RESERVED_TYPE;
    } else if (m_configurations->getMode(CONFIGURATION_PIP_MODE) == false) {
        bufConfig.reservedMemoryCount = FRONT_RESERVED_NUM_INTERNAL_NV21_BUFFERS;
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_RESERVED_TYPE;
    } else
#endif
    {
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
    }
    bufConfig.debugInfo = {maxPictureW, maxPictureH, 0};

    CLOGD("Allocate CAPTURE_CB(NV21)_BUF (minBufferCount=%d, maxBufferCount=%d)",
                minBufferCount, maxBufferCount);

#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_CAPTURE_CB, BUF_TYPE_REPROCESSING);
    if (ret != NO_ERROR) {
        CLOGE("Failed to add CAPTURE_CB_BUF. ret %d", ret);
        return ret;
    }
#else
    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret < 0) {
        CLOGE("Failed to alloc CAPTURE_CB_BUF. ret %d", ret);
        return ret;
    }
#endif

    /* Reprocessing YUV buffer */
    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_MCSC_JPEG_REPROCESSING;
    bufTag.pipeId[1] = PIPE_JPEG0_REPROCESSING;
    bufTag.pipeId[2] = PIPE_HWFC_JPEG_SRC_REPROCESSING;
    bufTag.pipeId[3] = PIPE_MCSC_JPEG;
#ifdef USE_CLAHE_REPROCESSING
    bufTag.pipeId[4] = PIPE_CLAHE_REPROCESSING;
#else
    bufTag.pipeId[4] = PIPE_JPEG;
#endif
    if (isRemosaic)
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
    else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("YUV_CAP_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create YUV_CAP_BUF. ret %d", ret);
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true
        && m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
        minBufferCount = 2;
    } else
#endif
    {
        minBufferCount = 1;
    }
    maxBufferCount = m_exynosconfig->current->bufInfo.num_reprocessing_buffers;

    bufConfig = initBufConfig;
    switch (pictureFormat) {
        case V4L2_PIX_FMT_NV21M:
            bufConfig.planeCount = 3;
            bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN);
            bufConfig.size[1] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) / 2;
            break;
        case V4L2_PIX_FMT_NV21:
            bufConfig.planeCount = 2;
            bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 3 / 2;
            break;
        default:
            bufConfig.planeCount = 2;
            bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 2;
            break;
    }
    bufConfig.reqBufCount = minBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_TYPE;
    if (m_parameters[m_cameraId]->isUseHWFC() == true)
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    else
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.reservedMemoryCount = 0;
    bufConfig.debugInfo = {maxPictureW, maxPictureH, pictureFormat};

#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_YUV_CAP, BUF_TYPE_REPROCESSING);
    if (ret != NO_ERROR) {
        CLOGE("Failed to add YUV_CAP_BUF. ret %d", ret);
        return ret;
    }
#else
    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc YUV_CAP_BUF. ret %d", ret);
        return ret;
    }
#endif

    if (m_parameters[m_cameraId]->supportJpegYuvRotation() == true) {
        /* ROTATION YUV buffer */
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_MCSC_JPEG_REPROCESSING;
        bufTag.pipeId[1] = PIPE_JPEG0_REPROCESSING;
        bufTag.pipeId[2] = PIPE_JPEG1_REPROCESSING;
        bufTag.pipeId[3] = PIPE_MCSC_JPEG;
        bufTag.pipeId[4] = PIPE_JPEG;
        if (isRemosaic)
            bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ONLY_HAL_USE_ION_TYPE;
        else
            bufTag.managerType = BUFFER_MANAGER_ONLY_HAL_USE_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("YUV_ROT_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create YUV_CAP_BUF. ret %d", ret);
        }

#ifdef USE_DUAL_CAMERA
        if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true
                && m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
            minBufferCount = 2;
        } else
#endif
        {
            minBufferCount = 1;
        }
        maxBufferCount = m_exynosconfig->current->bufInfo.num_reprocessing_buffers;

        /* bufConfig is same as YUV_CAP_BUF */
        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc YUV_CAP_BUF. ret %d", ret);
            return ret;
        }
    }

#ifdef USE_CLAHE_REPROCESSING
    /* Reprocessing buffer from CLAHE to JPEG */
    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_CLAHEC_REPROCESSING;
    bufTag.pipeId[1] = PIPE_JPEG;
    if (isRemosaic)
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
    else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("CLAHE_CAP_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create CLAHE_CAP_BUF. ret %d", ret);
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true
        && m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
        minBufferCount = 2;
    } else
#endif
    {
        minBufferCount = 1;
    }
    maxBufferCount = m_exynosconfig->current->bufInfo.num_reprocessing_buffers;

    bufConfig = initBufConfig;
    switch (pictureFormat) {
        case V4L2_PIX_FMT_NV21M:
            bufConfig.planeCount = 3;
            bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN);
            bufConfig.size[1] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) / 2;
            break;
        case V4L2_PIX_FMT_NV21:
            bufConfig.planeCount = 2;
            bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 3 / 2;
            break;
        default:
            bufConfig.planeCount = 2;
            bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 2;
            break;
    }
    bufConfig.reqBufCount = minBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_TYPE;
    if (m_parameters[m_cameraId]->isUseHWFC() == true)
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    else
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.reservedMemoryCount = 0;

#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_YUV_CAP, BUF_TYPE_REPROCESSING);
    if (ret != NO_ERROR) {
        CLOGE("Failed to add CLAHE_CAP_BUF. ret %d", ret);
        return ret;
    }
#else
    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc CLAHE_CAP_BUF. ret %d", ret);
        return ret;
    }
#endif
#endif

    if (m_parameters[m_cameraId]->getHwConnectionMode(PIPE_ISP_REPROCESSING, PIPE_MCSC_REPROCESSING) == HW_CONNECTION_MODE_M2M) {
        /* Reprocessing buffer from ISPC to MCSC */
        bufTag = initBufTag;
        bufTag.pipeId[0] = PIPE_ISPC_REPROCESSING;
        bufTag.pipeId[1] = PIPE_MCSC_REPROCESSING;
        if (isRemosaic)
            bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
        else
            bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("ISPC_CAP_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create ISPC_CAP_BUF. ret %d", ret);
        }

#ifdef USE_DUAL_CAMERA
        if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true
                && m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
            minBufferCount = 2;
        } else
#endif
        {
            minBufferCount = 1;
        }
        maxBufferCount = m_exynosconfig->current->bufInfo.num_reprocessing_buffers;

        bufConfig = initBufConfig;
        switch (pictureFormat) {
            case V4L2_PIX_FMT_NV21M:
                bufConfig.planeCount = 3;
                bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN);
                bufConfig.size[1] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) / 2;
                break;
            case V4L2_PIX_FMT_NV21:
                bufConfig.planeCount = 2;
                bufConfig.size[0] = ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) * ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 3 / 2;
                break;
            default:
                bufConfig.planeCount = 2;
                bufConfig.size[0] = (ALIGN_UP(maxPictureW, GSCALER_IMG_ALIGN) + ALIGN_UP(STRIPE_MARGIN_WIDTH, GSCALER_IMG_ALIGN) * 2)* ALIGN_UP(maxPictureH, GSCALER_IMG_ALIGN) * 2;
                break;
        }
        bufConfig.reqBufCount = minBufferCount;
        bufConfig.allowedMaxBufCount = maxBufferCount;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_TYPE;
        if (m_parameters[m_cameraId]->isUseHWFC() == true)
            bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
        else
            bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = true;
        bufConfig.reservedMemoryCount = 0;

#ifdef ADAPTIVE_RESERVED_MEMORY
        ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_YUV_CAP, BUF_TYPE_REPROCESSING);
        if (ret != NO_ERROR) {
            CLOGE("Failed to add ISPC_CAP_BUF. ret %d", ret);
            return ret;
        }
#else
        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc ISPC_CAP_BUF. ret %d", ret);
            return ret;
        }
#endif
    }

    /* Reprocessing Thumbanil buffer */
    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_MCSC_THUMB_REPROCESSING;
    bufTag.pipeId[1] = PIPE_HWFC_THUMB_SRC_REPROCESSING;
    bufTag.pipeId[2] = PIPE_HWFC_THUMB_DST_REPROCESSING;
    bufTag.pipeId[3] = PIPE_MCSC_THUMB;
    if (isRemosaic)
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
    else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("THUMB_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create THUMB_BUF. ret %d", ret);
    }

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_MODE) == true
        && m_configurations->getDualReprocessingMode() == DUAL_REPROCESSING_MODE_SW) {
        minBufferCount = 2;
    } else
#endif
    {
        minBufferCount = 1;
    }
    maxBufferCount = m_exynosconfig->current->bufInfo.num_reprocessing_buffers;

    bufConfig = initBufConfig;
    switch (pictureFormat) {
        case V4L2_PIX_FMT_NV21M:
            bufConfig.planeCount = 3;
            bufConfig.size[0] = maxThumbnailW * maxThumbnailH;
            bufConfig.size[1] = maxThumbnailW * maxThumbnailH / 2;
            break;
        case V4L2_PIX_FMT_NV21:
        default:
            bufConfig.planeCount = 2;
            bufConfig.size[0] = FRAME_SIZE(V4L2_PIX_2_HAL_PIXEL_FORMAT(pictureFormat), maxThumbnailW, maxThumbnailH);
            break;
    }

    bufConfig.reqBufCount = minBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
    if (m_parameters[m_cameraId]->isUseHWFC() == true)
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    else
        bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = false;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.debugInfo = {maxThumbnailW, maxThumbnailH, pictureFormat};

#ifdef ADAPTIVE_RESERVED_MEMORY
    ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_THUMB, BUF_TYPE_REPROCESSING);
    if (ret != NO_ERROR) {
        CLOGE("Failed to add THUMB_BUF. ret %d", ret);
        return ret;
    }
#else
    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc THUMB_BUF. ret %d", ret);
        return ret;
    }
#endif

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getMode(CONFIGURATION_DUAL_BOKEH_REFOCUS_MODE) == true) {
        ret = m_setBokehRefocusBuffer(isRemosaic);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc m_setBokehRefocusBuffer. ret %d", ret);
            return ret;
        }
    }
#endif

    m_setVendorReprocessingBuffer(isRemosaic);

    return NO_ERROR;
}

status_t ExynosCamera::m_setVendorReprocessingBuffer(bool isRemosaic)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;

    int maxBufferCount = 0;
    int minBufferCount = 0;

#ifdef USE_GSC_FOR_CAPTURE_YUV_RESCALE
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;

    /* GSC Internal buffer */
    int outputSizeW,outputSizeH;
    m_parameters[m_cameraId]->getSize(HW_INFO_HW_PICTURE_SIZE, (uint32_t *)&outputSizeW, (uint32_t *)&outputSizeH);

    maxBufferCount = m_exynosconfig->current->bufInfo.num_nv21_picture_buffers;

    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_GSC_REPROCESSING3;
    if (isRemosaic)
        bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
    else
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("SCALEYUV_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create SCALEYUV_BUF. ret %d", ret);
    }

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.size[0] = (outputSizeW * outputSizeH * 3) / 2;
    bufConfig.reqBufCount = 1;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc PRE_THUMBNAIL_BUF. ret %d", ret);
        return ret;
    }
#endif

    return ret;
}

status_t ExynosCamera::m_sendForceStallStreamResult(ExynosCameraRequestSP_sprt_t request)
{
    status_t ret = NO_ERROR;
    camera3_stream_buffer_t *streamBuffer = NULL;
    const camera3_stream_buffer_t *outputBuffer = NULL;
    camera3_capture_result_t *requestResult = NULL;
    ExynosCameraStream *stream = NULL;
    ResultRequest resultRequest = NULL;
    int streamId = 0;
    int bufferCnt = 0;
    int frameCount = request->getFrameCount();

    request->setSkipCaptureResult(true);
    bufferCnt = request->getNumOfOutputBuffer();
    outputBuffer = request->getOutputBuffers();

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(request);

    m_frameCountLock.lock();
    if (request->getFrameCount() == 0) {
        requestMgr->setFrameCount(m_internalFrameCount++, request->getKey());
    }
    m_frameCountLock.unlock();

    /* timestamp issue for burst capture */
    ret = m_sendNotifyError(request, EXYNOS_REQUEST_RESULT::ERROR_RESULT);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d]Failed to sendNotifyError. ret %d",
                request->getKey(), request->getFrameCount(), ret);
    }

    for (int i = 0; i < bufferCnt; i++) {
        streamBuffer = NULL;
        requestResult = NULL;
        stream = NULL;

        stream = static_cast<ExynosCameraStream*>(outputBuffer[i].stream->priv);
        if (stream == NULL) {
            CLOGE("[R%d F%d]Failed to getStream.", request->getKey(), frameCount);
            return INVALID_OPERATION;
        }

        stream->getID(&streamId);

        switch (streamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_RAW:
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                break;
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_PREVIEW_VIDEO:
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_ZSL_OUTPUT:
                continue;
            default:
                CLOGE("Inavlid stream Id %d", streamId);
                return BAD_VALUE;
        }

        resultRequest = requestMgr->createResultRequest(request->getKey(), frameCount,
                EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
        if (resultRequest == NULL) {
            CLOGE("[R%d F%d S%d] createResultRequest fail.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        requestResult = resultRequest->getCaptureResult();
        if (requestResult == NULL) {
            CLOGE("[R%d F%d S%d] getCaptureResult fail.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        streamBuffer = resultRequest->getStreamBuffer();
        if (streamBuffer == NULL) {
            CLOGE("[R%d F%d S%d] getStreamBuffer fail.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        ret = stream->getStream(&(streamBuffer->stream));
        if (ret != NO_ERROR) {
            CLOGE("Failed to getStream. frameCount %d requestKey %d",
                    frameCount, request->getKey());
            continue;
        }

        streamBuffer->buffer = outputBuffer[i].buffer;

        ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status, true);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d S%d]Failed to checkStreamBufferStatus.",
                    request->getKey(), frameCount, streamId);
            return ret;
        }

        streamBuffer->acquire_fence = -1;
        streamBuffer->release_fence = -1;

        /* construct result for service */
        requestResult->frame_number = request->getKey();
        requestResult->result = NULL;
        requestResult->num_output_buffers = 1;
        requestResult->output_buffers = streamBuffer;
        requestResult->input_buffer = request->getInputBuffer();
        requestResult->partial_result = 0;

        CLOGV("[R%d F%d S%d]checkStreamBufferStatus.",
                request->getKey(), frameCount, streamId);

        requestMgr->pushResultRequest(resultRequest);
    }

    ret = m_sendMeta(request, EXYNOS_REQUEST_RESULT::CALLBACK_ALL_RESULT);
    if (ret != NO_ERROR) {
        CLOGE("[R%d]Failed to sendMeta. ret %d", request->getKey(), ret);
    }

    return NO_ERROR;
}

status_t ExynosCamera::m_sendForceYuvStreamResult(ExynosCameraRequestSP_sprt_t request,
                                                   ExynosCameraFrameSP_sptr_t frame,
                                                   ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    camera3_stream_buffer_t *streamBuffer = NULL;
    camera3_capture_result_t *requestResult = NULL;
    ExynosCameraBuffer buffer;
    ExynosCameraStream *stream = NULL;
    ResultRequest resultRequest = NULL;
    List<int> *outputStreamId;
    int frameCount = 0;
    int streamId = 0;

    if (frame == NULL) {
        CLOGE("frame is NULL.");
        ret = INVALID_OPERATION;
        return ret;
    }

    frameCount = frame->getFrameCount();

    request->getAllRequestOutputStreams(&outputStreamId);
    for (List<int>::iterator iter = outputStreamId->begin(); iter != outputStreamId->end(); iter++) {
        streamBuffer = NULL;
        requestResult = NULL;

        m_streamManager->getStream(*iter, &stream);
        if (stream == NULL) {
            CLOGE("[R%d F%d]Failed to getStream.", request->getKey(), frameCount);
            continue;
        }

        stream->getID(&streamId);
        switch (streamId % HAL_STREAM_ID_MAX) {
            case HAL_STREAM_ID_RAW:
            case HAL_STREAM_ID_ZSL_OUTPUT:
            case HAL_STREAM_ID_JPEG:
            case HAL_STREAM_ID_CALLBACK_STALL:
            case HAL_STREAM_ID_THUMBNAIL_CALLBACK:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP_STALL:
#endif
                continue;
            case HAL_STREAM_ID_PREVIEW:
            case HAL_STREAM_ID_VIDEO:
            case HAL_STREAM_ID_CALLBACK:
            case HAL_STREAM_ID_CALLBACK_PHYSICAL:
#ifdef SUPPORT_DEPTH_MAP
            case HAL_STREAM_ID_DEPTHMAP:
#endif
            case HAL_STREAM_ID_PREVIEW_VIDEO:
                break;
            default:
                CLOGE("[R%d F%d]Inavlid stream Id %d",
                        request->getKey(), frameCount, streamId);
                continue;
        }

        resultRequest = m_requestMgr->createResultRequest(request->getKey(), frameCount,
                EXYNOS_REQUEST_RESULT::CALLBACK_BUFFER_ONLY);
        if (resultRequest == NULL) {
            CLOGE("[R%d F%d S%d] createResultRequest fail.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        requestResult = resultRequest->getCaptureResult();
        if (requestResult == NULL) {
            CLOGE("[R%d F%d S%d] getCaptureResult fail.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        streamBuffer = resultRequest->getStreamBuffer();
        if (streamBuffer == NULL) {
            CLOGE("[R%d F%d S%d] getStreamBuffer fail.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        ret = stream->getStream(&(streamBuffer->stream));
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d S%d]Failed to getStream.",
                    request->getKey(), frameCount, streamId);
            continue;
        }

        ret = m_checkStreamBuffer(frame, stream, &buffer, request, factory);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d S%d B%d]Failed to checkStreamBuffer.",
                    request->getKey(),
                    frame->getFrameCount(),
                    streamId,
                    buffer.index);
            /* Continue to handle other streams */
            continue;
        }

        streamBuffer->buffer = buffer.handle[0];

        ret = m_checkStreamBufferStatus(request, stream, &streamBuffer->status, true);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d S%d B%d]Failed to checkStreamBufferStatus.",
                    request->getKey(), frame->getFrameCount(), streamId, buffer.index);
            /* Continue to handle other streams */
            continue;
        }

        streamBuffer->acquire_fence = -1;
        streamBuffer->release_fence = -1;

        /* construct result for service */
        requestResult->frame_number = request->getKey();
        requestResult->result = NULL;
        requestResult->input_buffer = request->getInputBuffer();
        requestResult->num_output_buffers = 1;
        requestResult->output_buffers = streamBuffer;
        requestResult->partial_result = 0;

        m_requestMgr->pushResultRequest(resultRequest);

        if (buffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(buffer);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d S%d B%d]Failed to putBuffer. ret %d",
                        request->getKey(), frameCount, streamId, buffer.index, ret);
            }
        }
    }

    return NO_ERROR;
}

bool ExynosCamera::m_thumbnailCbThreadFunc(void)
{
    int loop = false;
    status_t ret = NO_ERROR;
    ExynosCameraFrameSP_sptr_t frame = NULL;
    ExynosRect srcRect, dstRect;
    int srcPipeId = -1;
    int nodePipeId = m_configurations->getModeValue(CONFIGURATION_YUV_STALL_PORT) + PIPE_MCSC0_REPROCESSING;
    int gscPipeId = PIPE_GSC_REPROCESSING2;
    ExynosCameraBuffer srcBuffer;
    ExynosCameraBuffer dstBuffer;
    entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_NOREQ;
    int thumbnailH = 0, thumbnailW = 0;
    int inputSizeH = 0, inputSizeW = 0;
    int waitCount = 0;
    frame_handle_components_t components;
    int streamId = HAL_STREAM_ID_THUMBNAIL_CALLBACK;
    ExynosCameraRequestSP_sprt_t request = NULL;
    ExynosCameraStream *stream = NULL;
    bool flag3aaIspM2M = false;
    bool flagIspMcscM2M = false;

    ExynosCameraRequestManager* requestMgr = NULL;

    srcBuffer.index = -2;
    dstBuffer.index = -2;

    CLOGD("-- IN --");

    CLOGV("wait m_postProcessingQ");
    ret = m_thumbnailCbQ->waitAndPopProcessQ(&frame);
    if (ret < 0) {
        CLOGW("wait and pop fail, ret(%d)", ret);
        /* TODO: doing exception handling */
        goto CLEAN;
    } else if (frame == NULL) {
        CLOGE("frame is NULL!!");
        goto CLEAN;
    }

    m_getFrameHandleComponentsWrapper(frame, &components, m_getCameraSessionId(frame));

    flag3aaIspM2M = (components.parameters->getHwConnectionMode(PIPE_3AA_REPROCESSING, PIPE_ISP_REPROCESSING) == HW_CONNECTION_MODE_M2M);
    flagIspMcscM2M = (components.parameters->getHwConnectionMode(PIPE_ISP_REPROCESSING, PIPE_MCSC_REPROCESSING) == HW_CONNECTION_MODE_M2M);

    requestMgr = m_getRequestManager(frame);

    request = requestMgr->getRunningRequest(frame->getFrameCount());
    if (request == NULL) {
        CLOGE("getRequest failed ");
        return INVALID_OPERATION;
    }

    if (flagIspMcscM2M == true
        && IS_OUTPUT_NODE(components.reprocessingFactory, PIPE_MCSC_REPROCESSING) == true) {
        srcPipeId = PIPE_MCSC_REPROCESSING;
    } else if (flag3aaIspM2M == true
            && IS_OUTPUT_NODE(components.reprocessingFactory, PIPE_ISP_REPROCESSING) == true) {
        srcPipeId = PIPE_ISP_REPROCESSING;
    } else {
        srcPipeId = PIPE_3AA_REPROCESSING;
    }

    ret = m_streamManager->getStream(streamId, &stream);
    if (ret != NO_ERROR)
        CLOGE("Failed to getStream from streamMgr. HAL_STREAM_ID_THUMBNAIL_CALLBACK");

    if (frame->getFrameYuvStallPortUsage() == YUV_STALL_USAGE_PICTURE) {
        ret = frame->getDstBuffer(PIPE_GSC_REPROCESSING3, &srcBuffer);
    } else {
        ret = frame->getDstBuffer(srcPipeId, &srcBuffer, components.reprocessingFactory->getNodeType(nodePipeId));
    }
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d]getDstBuffer fail. pipeId (%d) ret(%d)",
                request->getKey(), frame->getFrameCount(), nodePipeId, ret);
        goto CLEAN;
    }

    ret = frame->getDstBuffer(gscPipeId, &dstBuffer);
    if (ret != NO_ERROR) {
        CLOGE("[R%d F%d]getDstBuffer fail. pipeId(%d) ret(%d)",
                request->getKey(), frame->getFrameCount(), gscPipeId, ret);
        goto CLEAN;
    }

    srcRect.x = 0;
    srcRect.y = 0;
    srcRect.w = inputSizeW;
    srcRect.h = inputSizeH;
    srcRect.fullW = inputSizeW;
    srcRect.fullH = inputSizeH;
    srcRect.colorFormat = V4L2_PIX_FMT_NV21;

    dstRect.x = 0;
    dstRect.y = 0;
    dstRect.w = thumbnailW;
    dstRect.h = thumbnailH;
    dstRect.fullW = thumbnailW;
    dstRect.fullH = thumbnailH;
    dstRect.colorFormat = V4L2_PIX_FMT_NV21;

    CLOGD("srcBuf(%d) dstBuf(%d) (%d, %d, %d, %d) format(%d) actual(%x) -> (%d, %d, %d, %d) format(%d)  actual(%x)",
            srcBuffer.index, dstBuffer.index,
            srcRect.x, srcRect.y, srcRect.w, srcRect.h, srcRect.colorFormat, V4L2_PIX_2_HAL_PIXEL_FORMAT(srcRect.colorFormat),
            dstRect.x, dstRect.y, dstRect.w, dstRect.h, dstRect.colorFormat, V4L2_PIX_2_HAL_PIXEL_FORMAT(dstRect.colorFormat));

    ret = frame->setSrcRect(gscPipeId, srcRect);
    ret = frame->setDstRect(gscPipeId, dstRect);

    ret = m_setupEntity(gscPipeId, frame, &srcBuffer, &dstBuffer);
    if (ret < 0) {
        CLOGE("setupEntity fail, pipeId(%d), ret(%d)", gscPipeId, ret);
    }

    components.reprocessingFactory->setOutputFrameQToPipe(m_thumbnailPostCbQ, gscPipeId);
    components.reprocessingFactory->pushFrameToPipe(frame, gscPipeId);

    /* wait GSC done */
    CLOGV("wait GSC output");
    waitCount = 0;
    frame = NULL;
    dstBuffer.index = -2;
    do {
        ret = m_thumbnailPostCbQ->waitAndPopProcessQ(&frame);
        waitCount++;
    } while (ret == TIMED_OUT && waitCount < 100);

    if (ret < 0) {
        CLOGW("Failed to waitAndPopProcessQ. ret %d waitCount %d", ret, waitCount);
    }
    if (frame == NULL) {
        CLOGE("frame is NULL");
        goto CLEAN;
    }

    ret = frame->getDstBuffer(gscPipeId, &dstBuffer);
    if (ret < 0) {
        CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", gscPipeId, ret);
        goto CLEAN;
    }

    ret = frame->getDstBufferState(gscPipeId, &bufferState);
    if (ret != NO_ERROR) {
        CLOGE("ERR(%s[%d]):Failed to getDstBufferState. frameCount %d pipeId %d",
                __FUNCTION__, __LINE__,
                frame->getFrameCount(),
                gscPipeId);
        goto CLEAN;
    } else if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
        request->setStreamBufferStatus(streamId, CAMERA3_BUFFER_STATUS_ERROR);
        CLOGE("ERR(%s[%d]):Invalid thumnail stream buffer state. frameCount %d bufferState %d",
                __FUNCTION__, __LINE__,
                frame->getFrameCount(),
                bufferState);
    }

    ret = m_sendThumbnailStreamResult(request, &dstBuffer, streamId);
    if (ret != NO_ERROR) {
        CLOGE("[F%d B%d]Failed to sendYuvStreamStallResult."
                " pipeId %d streamId %d ret %d",
                frame->getFrameCount(),
                dstBuffer.index,
                gscPipeId, streamId, ret);
        goto CLEAN;
    }

CLEAN:
    if (frame != NULL) {
        CLOGV("frame delete. framecount %d", frame->getFrameCount());
        frame = NULL;
    }

    CLOGD("--OUT--");

    return loop;
}

#ifdef SUPPORT_PD_IMAGE
status_t ExynosCamera::m_setPDimageInternalBuffer()
{
    status_t ret = NO_ERROR;
    int bayerFormat = PD_IMAGE_FORMAT;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_configuration_t bufConfig;
    buffer_manager_tag_t bufTag;
    int pdImageW = 0, pdImageH = 0;
    int pdInternalBufferCount = NUM_PD_IMAGE_BUFFERS;

    /* TODO: is it required to consider Multi camera? */
    if (m_parameters[m_cameraId]->isPDImageSupported() == false) {
        return NO_ERROR;
    }

    m_parameters[m_cameraId]->getPDImageSize(pdImageW, pdImageH);

    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_VC1;
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("PD_IMAGE_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create PD_IMAGE_BUF. ret %d", ret);
    }

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.bytesPerLine[0] = getBayerLineSize(pdImageW, bayerFormat);
    bufConfig.size[0] = getBayerPlaneSize(pdImageW, pdImageH, bayerFormat);
    bufConfig.reqBufCount = pdInternalBufferCount;
    bufConfig.allowedMaxBufCount = pdInternalBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
    bufConfig.debugInfo = {pdImageW, pdImageH, bayerFormat};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc PD_IMAGE_BUF. ret %d", ret);
        return ret;
    }

    CLOGI("m_allocBuffers(PD_IMAGE_BUF) %d x %d,\
        planeSize(%d), planeCount(%d), maxBufferCount(%d)",
        pdImageW, pdImageH,
        bufConfig.size[0], bufConfig.planeCount, pdInternalBufferCount);

    return ret;
}
#endif


#ifdef SUPPORT_DEPTH_MAP
status_t ExynosCamera::m_setDepthInternalBuffer()
{
    status_t ret = NO_ERROR;
    int bayerFormat = DEPTH_MAP_FORMAT;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_configuration_t bufConfig;
    buffer_manager_tag_t bufTag;
    int depthW = 0, depthH = 0;
    int depthInternalBufferCount = NUM_DEPTHMAP_BUFFERS;

    m_flagUseInternalDepthMap = true;
    m_parameters[m_cameraId]->getDepthMapSize(&depthW, &depthH);
    m_configurations->setMode(CONFIGURATION_DEPTH_MAP_MODE, true);

    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_VC1;
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("DEPTH_MAP_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create DEPTH_MAP_BUF. ret %d", ret);
    }

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
    bufConfig.bytesPerLine[0] = getBayerLineSize(depthW, bayerFormat);
    bufConfig.size[0] = getBayerPlaneSize(depthW, depthH, bayerFormat);
    bufConfig.reqBufCount = depthInternalBufferCount;
    bufConfig.allowedMaxBufCount = depthInternalBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
    bufConfig.debugInfo = {depthW, depthH, bayerFormat};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc DEPTH_MAP_BUF. ret %d", ret);
        return ret;
    }

    CLOGI("m_allocBuffers(DepthMap Buffer) %d x %d,\
        planeSize(%d), planeCount(%d), maxBufferCount(%d)",
        depthW, depthH,
        bufConfig.size[0], bufConfig.planeCount, depthInternalBufferCount);

    return ret;
}
#endif

#ifdef ADAPTIVE_RESERVED_MEMORY
status_t ExynosCamera::m_setupAdaptiveBuffer()
{
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    status_t ret = NO_ERROR;

    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    for (int i = 0; i < BUF_PRIORITY_MAX; i++) {
        m_adaptiveBufferInfos[i].bufTag = initBufTag;
        m_adaptiveBufferInfos[i].bufConfig = initBufConfig;
        m_adaptiveBufferInfos[i].minReservedNum = 0;
        m_adaptiveBufferInfos[i].totalPlaneSize = 0;
        m_adaptiveBufferInfos[i].bufType = BUF_TYPE_UNDEFINED;
    }

    if (m_configurations->getMode(CONFIGURATION_VISION_MODE) == false) {
        ret = m_setBuffers();
        if (ret != NO_ERROR) {
            CLOGE("Failed to m_setAdaptiveBuffers. ret %d", ret);
            return ret;
        }
    }
    if (m_captureStreamExist && m_parameters[m_cameraId]->isReprocessing() == true) {
        ret = m_setReprocessingBuffer();
        if (ret != NO_ERROR) {
            CLOGE("Failed to m_setAdaptiveBuffers. ret %d", ret);
            return ret;
        }
    }
    ret = m_setAdaptiveReservedBuffers();
    if (ret != NO_ERROR) {
        CLOGE("Failed to m_setAdaptiveBuffers. ret %d", ret);
        return ret;
    }

    return ret;
}

status_t ExynosCamera::m_addAdaptiveBufferInfos(const buffer_manager_tag_t bufTag,
                                         const buffer_manager_configuration_t bufConfig,
                                         enum BUF_PRIORITY bufPrior,
                                         enum BUF_TYPE bufType)
{
    status_t ret = NO_ERROR;
    int i;
    int bufferPlaneCount;

    if (bufPrior >= BUF_PRIORITY_MAX) {
        ret = BAD_INDEX;
        return ret;
    }

    bufferPlaneCount = bufConfig.planeCount;

    if (bufConfig.createDebugInfoPlane == true && bufferPlaneCount > 1) {
        bufferPlaneCount--;
    }

    if (bufConfig.createMetaPlane == true && bufferPlaneCount > 1) {
        bufferPlaneCount--;
    }

    m_adaptiveBufferInfos[bufPrior].totalPlaneSize = 0;
    for (i = 0; i < bufferPlaneCount; i++) {
        m_adaptiveBufferInfos[bufPrior].totalPlaneSize
            += ((ALIGN_UP(bufConfig.size[i], 0x1000)) * bufConfig.batchSize);
    }

    m_adaptiveBufferInfos[bufPrior].bufTag = bufTag;
    m_adaptiveBufferInfos[bufPrior].bufConfig = bufConfig;
    m_adaptiveBufferInfos[bufPrior].bufConfig.reservedMemoryCount = 0;
    m_adaptiveBufferInfos[bufPrior].bufType = bufType;

    if (m_adaptiveBufferInfos[bufPrior].bufConfig.type == EXYNOS_CAMERA_BUFFER_ION_CACHED_RESERVED_TYPE)
        m_adaptiveBufferInfos[bufPrior].bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
    else if (m_adaptiveBufferInfos[bufPrior].bufConfig.type == EXYNOS_CAMERA_BUFFER_ION_NONCACHED_RESERVED_TYPE)
        m_adaptiveBufferInfos[bufPrior].bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    else if (m_adaptiveBufferInfos[bufPrior].bufConfig.type == EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_RESERVED_TYPE)
        m_adaptiveBufferInfos[bufPrior].bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_TYPE;

#ifdef MIN_RESERVED_NUM_CAPTURE_CB
    if (bufPrior == BUF_PRIORITY_CAPTURE_CB) {
        m_adaptiveBufferInfos[bufPrior].minReservedNum = MIN_RESERVED_NUM_CAPTURE_CB;
    }
#endif

#ifdef MIN_RESERVED_NUM_YUV_CAP
    if (bufPrior == BUF_PRIORITY_YUV_CAP) {
        m_adaptiveBufferInfos[bufPrior].minReservedNum = MIN_RESERVED_NUM_YUV_CAP;
    }
#endif

#ifdef DEBUG_ADAPTIVE_RESERVED
    CLOGI("bufPrior(%d)", bufPrior);
#endif
    return ret;
}

status_t ExynosCamera::m_allocAdaptiveNormalBuffers()
{
    status_t ret = NO_ERROR;
#ifdef DEBUG_ADAPTIVE_RESERVED
    ExynosCameraDurationTimer m_timer;
    long long durationTime[BUF_PRIORITY_MAX] = {0};
    int totalDurationTime = 0;

    CLOGI("==IN==");
#endif

    for (int i = 0; i < BUF_PRIORITY_MAX; i++) {
        if (m_adaptiveBufferInfos[i].bufType == BUF_TYPE_UNDEFINED
            || m_adaptiveBufferInfos[i].totalPlaneSize == 0) {
            continue;
        }

        if (m_adaptiveBufferInfos[i].bufType == BUF_TYPE_NORMAL
            || m_adaptiveBufferInfos[i].bufType == BUF_TYPE_VENDOR) {
#ifdef DEBUG_ADAPTIVE_RESERVED
            m_timer.start();
#endif
            ret = m_allocBuffers(m_adaptiveBufferInfos[i].bufTag, m_adaptiveBufferInfos[i].bufConfig);
#ifdef DEBUG_ADAPTIVE_RESERVED
            m_timer.stop();
            durationTime[i] = m_timer.durationMsecs();
#endif
            if (ret < 0) {
                CLOGE("Failed to alloc i(%d). ret %d", i, ret);
                /* android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Failed to alloc. so, assert!!!!",
                        __FUNCTION__, __LINE__); */
                return ret;
            }

#ifdef DEBUG_ADAPTIVE_RESERVED
            CLOGI("buf(%d), size(%d KB), reserved(%d), req(%d), reprocessing(%d), time(%5d msec)", i,
                m_adaptiveBufferInfos[i].totalPlaneSize/1024,
                m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount,
                m_adaptiveBufferInfos[i].bufConfig.reqBufCount,
                ((m_adaptiveBufferInfos[i].bufType == BUF_TYPE_REPROCESSING) ? 1 : 0),
                (int)durationTime[i]);
            totalDurationTime += (int)durationTime[i];
#endif
        }
    }

#ifdef DEBUG_ADAPTIVE_RESERVED
    CLOGI("total duration time(%5d msec)", totalDurationTime);
    CLOGI("==OUT==");
#endif
    return ret;
}

status_t ExynosCamera::m_allocAdaptiveReprocessingBuffers()
{
    status_t ret = NO_ERROR;
#ifdef DEBUG_ADAPTIVE_RESERVED
    ExynosCameraDurationTimer m_timer;
    long long durationTime[BUF_PRIORITY_MAX] = {0};
    int totalDurationTime = 0;

    CLOGI("==IN==");
#endif

    for (int i = 0; i < BUF_PRIORITY_MAX; i++) {
        if (m_adaptiveBufferInfos[i].bufType == BUF_TYPE_UNDEFINED
            || m_adaptiveBufferInfos[i].totalPlaneSize == 0) {
            continue;
        }

        if (m_adaptiveBufferInfos[i].bufType == BUF_TYPE_REPROCESSING) {
#ifdef DEBUG_ADAPTIVE_RESERVED
            m_timer.start();
#endif
            ret = m_allocBuffers(m_adaptiveBufferInfos[i].bufTag, m_adaptiveBufferInfos[i].bufConfig);
#ifdef DEBUG_ADAPTIVE_RESERVED
            m_timer.stop();
            durationTime[i] = m_timer.durationMsecs();
#endif
            if (ret < 0) {
                CLOGE("Failed to alloc i(%d). ret %d", i, ret);
                /* android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Failed to alloc. so, assert!!!!",
                        __FUNCTION__, __LINE__); */
                return ret;
            }
#ifdef DEBUG_ADAPTIVE_RESERVED
            CLOGI("buf(%d), size(%d KB), reserved(%d), req(%d), duration time(%5d msec)", i,
                m_adaptiveBufferInfos[i].totalPlaneSize/1024,
                m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount,
                m_adaptiveBufferInfos[i].bufConfig.reqBufCount,
                (int)durationTime[i]);
            totalDurationTime += (int)durationTime[i];
#endif
        }
    }

#ifdef DEBUG_ADAPTIVE_RESERVED
    CLOGI("total duration time(%5d msec)", totalDurationTime);
    CLOGI("==OUT==");
#endif
    return ret;
}

status_t ExynosCamera::m_setAdaptiveReservedBuffers()
{
    status_t ret = NO_ERROR;
    int clearance = TOTAL_RESERVED_BUFFER_SIZE;
#ifdef DEBUG_ADAPTIVE_RESERVED
    ExynosCameraDurationTimer m_timer;
    long long durationTime[BUF_PRIORITY_MAX] = {0};
    int totalAllocReservedBuf = 0;

    CLOGI("==IN==");
#endif

    for (int i = 0; i < BUF_PRIORITY_MAX; i++) {
        int minBuf = m_adaptiveBufferInfos[i].minReservedNum;
        int size = m_adaptiveBufferInfos[i].totalPlaneSize;

        if (m_adaptiveBufferInfos[i].bufConfig.reqBufCount < minBuf) {
            minBuf = m_adaptiveBufferInfos[i].bufConfig.reqBufCount;
            m_adaptiveBufferInfos[i].minReservedNum = minBuf;
        }

        if (minBuf > 0 && size > LOW_LIMIT_RESERVED_BUFFER_SIZE) {
            if (clearance >= size * minBuf) {
                clearance -= (size * minBuf);
                m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount = minBuf;
            }
        }
    }

    for (int i = 0; i < BUF_PRIORITY_MAX; i++) {
        int size = m_adaptiveBufferInfos[i].totalPlaneSize;
        int reqBuf = m_adaptiveBufferInfos[i].bufConfig.reqBufCount;
        int minBuf = m_adaptiveBufferInfos[i].minReservedNum;

        if (size > LOW_LIMIT_RESERVED_BUFFER_SIZE) {
            if (reqBuf >= minBuf) {
                reqBuf -= minBuf;
            }
            if (reqBuf > 0) {
                if (clearance >= size * reqBuf) {
                    clearance -= (size * reqBuf);
                    if (minBuf > 0)
                        m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount += reqBuf;
                    else
                        m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount = reqBuf;
                } else {
                    if (clearance >= size) {
                        int tempReqBuf = (clearance / size);
                        if (tempReqBuf >= minBuf) {
                            tempReqBuf -= minBuf;
                        }
                        clearance -= (size * tempReqBuf);
                        if (minBuf > 0)
                            m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount += tempReqBuf;
                        else
                            m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount = tempReqBuf;
                    }
                }
            }

            if (m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount > 0) {
                if (m_adaptiveBufferInfos[i].bufConfig.type == EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE)
                    m_adaptiveBufferInfos[i].bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_RESERVED_TYPE;
                else if (m_adaptiveBufferInfos[i].bufConfig.type == EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE)
                    m_adaptiveBufferInfos[i].bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_RESERVED_TYPE;
                else if (m_adaptiveBufferInfos[i].bufConfig.type == EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_TYPE)
                    m_adaptiveBufferInfos[i].bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_SYNC_FORCE_RESERVED_TYPE;
            }
        }

#ifdef DEBUG_ADAPTIVE_RESERVED
        CLOGI("buf(%d) / req(%d) / minBuf(%d) / reserved(%d) / size(%d KB) / allocReservedBuf(%d KB) / totalReservedBuf(%d KB)",
            i,
            m_adaptiveBufferInfos[i].bufConfig.reqBufCount,
            minBuf,
            m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount,
            size/1024,
            m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount * size/1024,
            totalAllocReservedBuf += m_adaptiveBufferInfos[i].bufConfig.reservedMemoryCount * size/1024);
#endif
    }

#ifdef DEBUG_ADAPTIVE_RESERVED
    CLOGI("================================================================================");
    CLOGI("remaining reserved memory (%d KB)", clearance/1024);
    CLOGI("================================================================================");
    CLOGI("==OUT==");
#endif
    return ret;
}
#endif

status_t ExynosCamera::m_copyOnePortBuf2PhysStreamBuf(ExynosCameraRequestSP_sprt_t request,
                                                            ExynosCameraFrameSP_sptr_t frame,
                                                            ExynosCameraBuffer *srcBuf,
                                                            int32_t streamID,
                                                            camera3_buffer_status_t streamBufferState)
{
    int32_t index = -1;
    ExynosCameraBuffer dstBuf;
    const camera3_stream_buffer_t *bufferList;
    buffer_manager_tag_t bufTag;
    bool skipFlag = false;
    int32_t numOfPlanesDst;
    int32_t numOfPlanesSrc;
    ExynosCameraStream *dstStream;
    bool flagMemcpy = false;
    status_t ret = NO_ERROR;

    CLOGV("streamID = %d", streamID);
    ret = m_streamManager->getStream(streamID, &dstStream);
    if ((ret != NO_ERROR) || (dstStream == NULL)) {
        CLOGE("Failed to getStream from StreamMgr. streamId srcStreamId(%d)", streamID);
        return ret;
    }

    dstStream->getPlaneCount(&numOfPlanesDst);
    bufferList = request->getOutputBuffers();
    index = request->getBufferIndex(streamID);
    CLOGV("buf_index = %d", index);
    if (index >= 0) {
        const camera3_stream_buffer_t *streamBuffer = &(bufferList[index]);
        buffer_handle_t *handle = streamBuffer->buffer;
        int streamId = request->getStreamIdwithBufferIdx(index);

        bufTag.reserved.i32 = streamId;
        bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

#ifdef USE_LCAM
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
            bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamID)
                            % ExynosCameraParameters::YUV_MAX)
                            + PIPE_LCAM_MCSC;
        } else
#endif
        {
            bufTag.pipeId[0] = (m_streamManager->getOutputPortId(streamID)
                            % ExynosCameraParameters::YUV_MAX)
                            + PIPE_MCSC0;
        }
        dstBuf.handle[0] = handle;
        dstBuf.acquireFence[0] = streamBuffer->acquire_fence;
        dstBuf.releaseFence[0] = streamBuffer->release_fence;

        ret = m_bufferSupplier->getBuffer(bufTag, &dstBuf);
        if (ret != NO_ERROR || dstBuf.index < 0) {
            CLOGE("[R%d F%d B%d]Failed to getBuffer. ret %d",
                request->getKey(), frame->getFrameCount(), dstBuf.index, ret);
            return ret;
        }

        ret = request->setAcquireFenceDone(handle, (dstBuf.acquireFence[0] == -1) ? true : false);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d]Failed to setAcquireFenceDone. ret %d",
                    request->getKey(), frame->getFrameCount(), dstBuf.index, ret);
        }
        CLOGV("src_buf_index = %d", srcBuf->index);
        if (srcBuf->index >= 0) {
            int srcFormat = m_configurations->getYuvFormat(frame->getOnePortId());
            ExynosRect srcRect = convertingBufferDst2Rect(srcBuf, srcFormat);
            ExynosRect dstRect;

            numOfPlanesSrc = getYuvPlaneCount(srcFormat);

            int physStreamOutputPortId = m_streamManager->getOutputPortId(streamID);
            int dstFormat = m_configurations->getYuvFormat(physStreamOutputPortId);
            int dstWidth = 0;
            int dstHeight = 0;
            m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&dstWidth, (uint32_t *)&dstHeight, physStreamOutputPortId);

            dstRect.w = dstWidth;
            dstRect.h = dstHeight;
            dstRect.fullW = dstWidth;
            dstRect.fullH = dstHeight;
            dstRect.colorFormat = dstFormat;

            //TODO: need to consider color format
            if (srcRect.w == dstRect.w &&
                srcRect.h == dstRect.h) {
                flagMemcpy = true;
            } else {
                flagMemcpy = false;
            }
            CLOGV("flagMemcpy = %d numOfPlanesSrc = %d numOfPlanesDst = %d", flagMemcpy, numOfPlanesSrc, numOfPlanesDst);
            ret = m_copySrcBuf2DstBuf(frame, srcBuf, &dstBuf, &srcRect, &dstRect, flagMemcpy, numOfPlanesSrc, numOfPlanesDst);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d]m_copySrcBuf2DstBuf() fail",
                    request->getKey(), frame->getFrameCount(), dstBuf.index);
                dstBuf.index = -2;
                skipFlag = true;
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
            }
        } else {
            CLOGE("streamID = %d : CAMERA3_BUFFER_STATUS_ERROR", streamID);
            dstBuf.index = -2;
            skipFlag = true;
            streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
        }

        request->setStreamBufferStatus(streamID, streamBufferState);
        CLOGD("streamID = %d : m_sendYuvStreamResult", streamID);
        ret = m_sendYuvStreamResult(frame, request, &dstBuf, streamID,
                                    skipFlag, frame->getStreamTimestamp(),
                                    frame->getParameters());
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to send CALLBACK_PHYSICAL StreamResult. ret %d",
                    frame->getFrameCount(), dstBuf.index, ret);
            return ret;
        }
    }

    return ret;
}

status_t ExynosCamera::m_copyStreamBuf(ExynosCameraFrameSP_sptr_t frame,
                                       int32_t srcStreamId,
                                       int32_t dstStreamId)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer srcBuf, dstBuf;
    ExynosRect srcRect, dstRect;
    ExynosCameraStream *srcStream, *dstStream;
    camera_pixel_size pixelSize;
    int pipeId;
    int bufPos;

    CFLOGV(frame, "copy from %d to %d", srcStreamId, dstStreamId);
    // get stream info (src)
    ret = m_streamManager->getStream(srcStreamId, &srcStream);
    if ((ret != NO_ERROR) || (srcStream == NULL)) {
        CFLOGE(frame, "Failed to getStream(%d) from StreamMgr", srcStreamId);
        return ret;
    }

    ret = srcStream->getSize((uint32_t *)&srcRect.w, (uint32_t *)&srcRect.h);
    if (ret != NO_ERROR) {
        CFLOGE(frame, "Failed to getSize(%d)", srcStreamId);
        return ret;
    }

    ret = srcStream->getFormat(&srcRect.colorFormat, &pixelSize);
    if (ret != NO_ERROR) {
        CFLOGE(frame, "Failed to getFormat(%d)", srcStreamId);
        return ret;
    }

    srcRect.fullW = srcRect.w;
    srcRect.fullH = srcRect.h;
    srcRect.colorFormat = HAL_PIXEL_FORMAT_2_V4L2_PIX(srcRect.colorFormat);

    // get stream info (dst)
    ret = m_streamManager->getStream(dstStreamId, &dstStream);
    if ((ret != NO_ERROR) || (dstStream == NULL)) {
        CFLOGE(frame, "Failed to getStream(%d) from StreamMgr", dstStreamId);
        return ret;
    }

    ret = dstStream->getSize((uint32_t *)&srcRect.w, (uint32_t *)&dstRect.h);
    if (ret != NO_ERROR) {
        CFLOGE(frame, "Failed to getSize(%d)", dstStreamId);
        return ret;
    }

    ret = dstStream->getFormat(&dstRect.colorFormat, &pixelSize);
    if (ret != NO_ERROR) {
        CFLOGE(frame, "Failed to getFormat(%d)", dstStreamId);
        return ret;
    }

    dstRect.fullW = dstRect.w;
    dstRect.fullH = dstRect.h;
    dstRect.colorFormat = HAL_PIXEL_FORMAT_2_V4L2_PIX(dstRect.colorFormat);

    // get stream buffer (src)
    pipeId = frame->getServiceBufferPipeId(srcStreamId);
    bufPos = frame->getServiceBufferPosition(srcStreamId);
    ret = frame->getDstBuffer(pipeId, &srcBuf, bufPos);
    if (ret != NO_ERROR || srcBuf.index < 0) {
        CFLOGE(frame, "Failed to getDstBuf(stream%d, pipe%d, pos:%d)",
                srcStreamId, pipeId, bufPos);
        return ret;
    }

    // get stream buffer (dst)
    pipeId = frame->getServiceBufferPipeId(dstStreamId);
    bufPos = frame->getServiceBufferPosition(dstStreamId);
    ret = frame->getDstBuffer(pipeId, &dstBuf, bufPos);
    if (ret != NO_ERROR || dstBuf.index < 0) {
        CFLOGE(frame, "Failed to getDstBuf(stream%d, pipe%d, pos:%d)",
                dstStreamId, pipeId, bufPos);
        return ret;
    }

    if (m_gscWrapper == NULL) {
        m_gscWrapper = new ExynosCameraGSCWrapper(PREVIEW_GSC_NODE_NUM);
        if (m_gscWrapper == nullptr) {
            android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Fail to new gscWrapper instance. so, assert!!!!",
                    __FUNCTION__, __LINE__);
        }

        if (m_gscWrapper->create() != NO_ERROR) {
            android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Fail to create gscWrapper so, assert!!!!",
                    __FUNCTION__, __LINE__);
        }
    }

    ret = m_gscWrapper->convertWithRotation(srcRect, dstRect, srcBuf, dstBuf);
    if (ret != NO_ERROR) {
        CFLOGE(frame, "convert fail src:fd(%d, %d) size(%d, %d, %d, %d) format:%x, dst:fd(%d, %d) size(%d, %d, %d, %d) format:%x",
                srcBuf.fd[0],
                srcBuf.fd[1],
                srcRect.w,
                srcRect.h,
                srcRect.fullW,
                srcRect.fullH,
                srcRect.colorFormat,
                dstBuf.fd[0],
                dstBuf.fd[1],
                dstRect.w,
                dstRect.h,
                dstRect.fullW,
                dstRect.fullH,
                dstRect.colorFormat);
        return ret;
    }

    return ret;
}

void ExynosCamera::m_copyPreviewCbThreadFunc(ExynosCameraRequestSP_sprt_t request,
                                                            ExynosCameraFrameSP_sptr_t frame,
                                                            ExynosCameraBuffer *buffer)
{
    buffer_manager_tag_t bufTag;
    ExynosCameraBuffer serviceBuffer;
    const camera3_stream_buffer_t *bufferList = request->getOutputBuffers();
    int32_t index = -1;
    int ret = 0;
    bool skipFlag = false;
    int streamId = 0;

    serviceBuffer.index = -2;

    if (request->hasStream(HAL_STREAM_ID_CALLBACK_CPY) == true) {
        index = request->getBufferIndex(HAL_STREAM_ID_CALLBACK_CPY);
        streamId = HAL_STREAM_ID_CALLBACK_CPY;
    } else {
        index = request->getBufferIndex(HAL_STREAM_ID_CALLBACK);
        streamId = HAL_STREAM_ID_CALLBACK;
    }

    if (index >= 0) {
        const camera3_stream_buffer_t *streamBuffer = &(bufferList[index]);
        buffer_handle_t *handle = streamBuffer->buffer;
        int streamId = request->getStreamIdwithBufferIdx(index);

        bufTag.reserved.i32 = streamId;
        bufTag.managerType = BUFFER_MANAGER_SERVICE_GRALLOC_TYPE;

        if (request->hasStream(HAL_STREAM_ID_CALLBACK_CPY) == true) {
            bufTag.pipeId[0] = PIPE_GSC_CLONE;
        } else
#ifdef USE_DUAL_CAMERA
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
            bufTag.pipeId[0] = PIPE_FUSION_CLONE;
        } else
#endif
#ifdef SUPPORT_PREVIEW_PLUGIN_YUV_STREAM
        if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
            bufTag.pipeId[0] = PIPE_PLUGIN_CALLBACK;
        } else
#endif
        {
            bufTag.pipeId[0] = (m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK)
                            % ExynosCameraParameters::YUV_MAX)
                            + PIPE_MCSC0;
        }
        serviceBuffer.handle[0] = handle;
        serviceBuffer.acquireFence[0] = streamBuffer->acquire_fence;
        serviceBuffer.releaseFence[0] = streamBuffer->release_fence;

        //const private_handle_t *privateHandle = reinterpret_cast<const private_handle_t *> (*handle);

        ret = m_bufferSupplier->getBuffer(bufTag, &serviceBuffer);
        if (ret != NO_ERROR || serviceBuffer.index < 0) {
            CLOGE("[R%d F%d B%d]Failed to getBuffer. ret %d",
                request->getKey(), frame->getFrameCount(), serviceBuffer.index, ret);
        }

        ret = request->setAcquireFenceDone(handle, (serviceBuffer.acquireFence[0] == -1) ? true : false);
        if (ret != NO_ERROR) {
            CLOGE("[R%d F%d B%d]Failed to setAcquireFenceDone. ret %d",
                request->getKey(), frame->getFrameCount(), serviceBuffer.index, ret);
        }

        if (buffer->index >= 0) {
            ret = m_copyPreview2Callback(frame, buffer, &serviceBuffer);
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d]m_copyPreview2Callback->create() fail",
                    request->getKey(), frame->getFrameCount(), serviceBuffer.index);
            }
        } else {
            serviceBuffer.index = -2;
            skipFlag = true;
        }

        ret = m_sendYuvStreamResult(frame, request, &serviceBuffer, HAL_STREAM_ID_CALLBACK,
                                    skipFlag, frame->getStreamTimestamp(),
                                    frame->getParameters());
        if (ret != NO_ERROR) {
            CLOGE("[F%d B%d]Failed to sendRawStreamResult. ret %d",
                    frame->getFrameCount(), serviceBuffer.index, ret);
        }
    }
}

status_t ExynosCamera::m_copySrcBuf2DstBuf(ExynosCameraFrameSP_sptr_t frame,
                                           ExynosCameraBuffer *srcBuffer,
                                           ExynosCameraBuffer *dstBuffer,
                                           ExynosRect *srcRect,
                                           ExynosRect *dstRect,
                                           bool flagMemcpy,
                                           int32_t numOfPlanesSrc,
                                           int32_t numOfPlanesDst)
{
    status_t ret = NO_ERROR;
    ExynosCameraImage srcImage[ExynosCameraImageCapacity::MAX_NUM_OF_IMAGE_MAX];
    ExynosCameraImage dstImage[ExynosCameraImageCapacity::MAX_NUM_OF_IMAGE_MAX];

    if (flagMemcpy == true) {
        if ((numOfPlanesSrc == 2) && (numOfPlanesDst == 1)) {
            memcpy(dstBuffer->addr[0],                      srcBuffer->addr[0], srcBuffer->size[0]);
            memcpy(dstBuffer->addr[0] + srcBuffer->size[0], srcBuffer->addr[1], srcBuffer->size[1]);
            if(m_ionClient >= 0) {
               exynos_ion_sync_fd(m_ionClient, dstBuffer->fd[0]);
            }
        } else if (numOfPlanesSrc == numOfPlanesDst) {
            for (int i = 0; i < numOfPlanesSrc; i++) {
                memcpy(dstBuffer->addr[i], srcBuffer->addr[i], srcBuffer->size[i]);
                if(m_ionClient >= 0) {
                   exynos_ion_sync_fd(m_ionClient, dstBuffer->fd[i]);
                }
            }
        } else {
            //TODO: need to support other cases.
            CLOGE("not supported formats (%d %d)", srcRect->colorFormat, dstRect->colorFormat);
            goto done;
        }
    } else {
        if (m_gscWrapper == NULL) {
            m_gscWrapper = new ExynosCameraGSCWrapper(PREVIEW_GSC_NODE_NUM);
            if (m_gscWrapper == nullptr) {
                android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Fail to new gscWrapper instance. so, assert!!!!",
                        __FUNCTION__, __LINE__);
            }

            if (m_gscWrapper->create() != NO_ERROR) {
                android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Fail to create gscWrapper so, assert!!!!",
                        __FUNCTION__, __LINE__);
            }
        }

        ret = m_gscWrapper->convertWithRotation(*srcRect, *dstRect, *srcBuffer, *dstBuffer);
        if (ret != NO_ERROR) {
            CLOGE("m_gscWrapper->convertWithRotation(src(fd(%d, %d) size(%d, %d, %d, %d)), dst(fd(%d, %d) size(%d, %d, %d, %d)) fail",
                srcBuffer->fd[0],
                srcBuffer->fd[1],
                srcRect->w,
                srcRect->h,
                srcRect->fullW,
                srcRect->fullH,
                dstBuffer->fd[0],
                dstBuffer->fd[1],
                dstRect->w,
                dstRect->h,
                dstRect->fullW,
                dstRect->fullH);
            return -1;
        }
    }
done:

    return NO_ERROR;
}

status_t ExynosCamera::m_copyPreview2Callback(ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer *srcBuffer, ExynosCameraBuffer *dstBuffer)
{
    status_t ret = NO_ERROR;

    ExynosCameraDurationTimer timer;

    int previewOutputPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_PREVIEW);
    int previewFormat = m_configurations->getYuvFormat(previewOutputPortId);
    ExynosRect rect = convertingBufferDst2Rect(srcBuffer, previewFormat);

    int callbbackOutputPortId = m_streamManager->getOutputPortId(HAL_STREAM_ID_CALLBACK);
    int callbackFormat = m_configurations->getYuvFormat(callbbackOutputPortId);

    ExynosCameraStream *stream;
    camera_pixel_size pixelSize;
    m_streamManager->getStream(HAL_STREAM_ID_CALLBACK, &stream);
    stream->getFormat(&callbackFormat, &pixelSize);

    int callbackWidth = 0;
    int callbackHeight = 0;
    m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&callbackWidth, (uint32_t *)&callbackHeight, callbbackOutputPortId);

    bool flagMemcpy = false;

    if (rect.w == callbackWidth &&
        rect.h == callbackHeight) {
        flagMemcpy = true;
    } else {
        flagMemcpy = false;
    }

    timer.start();

    if(flagMemcpy == true) {
        memcpy(dstBuffer->addr[0],                      srcBuffer->addr[0], srcBuffer->size[0]);
        memcpy(dstBuffer->addr[0] + srcBuffer->size[0], srcBuffer->addr[1], srcBuffer->size[1]);

        if(m_ionClient >= 0) {
            exynos_ion_sync_fd(m_ionClient, dstBuffer->fd[0]);
        }
    } else {
        if (m_gscWrapper == NULL) {
            m_gscWrapper = new ExynosCameraGSCWrapper(PREVIEW_GSC_NODE_NUM);
            if (m_gscWrapper == nullptr) {
                android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Fail to new gscWrapper instance. so, assert!!!!",
                        __FUNCTION__, __LINE__);
            }

            if (m_gscWrapper->create() != NO_ERROR) {
                android_printAssert(NULL, LOG_TAG, "ASSERT(%s[%d]):Fail to create gscWrapper so, assert!!!!",
                        __FUNCTION__, __LINE__);
            }
        }

        ExynosRect dstRect;
        dstRect.w     = callbackWidth;
        dstRect.fullW = callbackWidth;
        dstRect.h     = callbackHeight;
        dstRect.fullH = callbackHeight;
        dstRect.colorFormat = HAL_PIXEL_FORMAT_2_V4L2_PIX(callbackFormat);

        ret = m_gscWrapper->convertWithRotation(rect, dstRect, *srcBuffer, *dstBuffer);
        if (ret != NO_ERROR) {
            CLOGE("m_gscWrapper->convertWithRotation(src(fd(%d, %d) size(%d, %d, %d, %d)), dst(fd(%d, %d) size(%d, %d, %d, %d)) fail",
                srcBuffer->fd[0],
                srcBuffer->fd[1],
                rect.w,
                rect.h,
                rect.fullW,
                rect.fullH,
                dstBuffer->fd[0],
                dstBuffer->fd[1],
                dstRect.w,
                dstRect.h,
                dstRect.fullW,
                dstRect.fullH);

            goto done;
        }
    }

done:

    timer.stop();

    if(flagMemcpy == true) {
        CLOGV("memcpy for callback time:(%5d msec)", (int)timer.durationMsecs());
    } else {
        CLOGV("PP for callback time:(%5d msec)", (int)timer.durationMsecs());
    }

    return ret;
}

#if defined(USE_RAW_REVERSE_PROCESSING) && defined(USE_SW_RAW_REVERSE_PROCESSING)
/*
 * RGB gain Calculation
 * @param RGBgain, inverseRGBGain(from CFG), pedestal 10bit
 * @return void
 * @Constraint precesion is 14bit, The number of gains is 4.
 */
void ExynosCamera::m_reverseProcessingApplyCalcRGBgain(int32_t *inRGBgain, int32_t *invRGBgain, int32_t *pedestal)
{
    const int kPrecision = 14;
    const int kNumOfGains = 4;
    int iValue = 0;
    double dValue = 0.0;

    for (int i = 0; i < kNumOfGains; i++) {
        dValue = (double)16383.0 * (double)1024.0 / (((double)16383.0 - (double)(pedestal[i])) * (double)(inRGBgain[i])); // golden
        iValue = (int)(dValue * (1 << kPrecision) + (double)0.5);
        invRGBgain[i] = iValue;
    }
}

/*
 * Gamma Image Processing
 * @param PixelInput, GammaLutX, GammaLutY
 * @return Pixel as Integer.
 * @Constraint input/output pixel use 14bit
 */
int ExynosCamera::m_reverseProcessingApplyGammaProc(int pixelIn, int32_t *lutX, int32_t *lutY)
{
    const int kFirstIdx = 0;
    const int kLastIdx = 31;
    const int kInImgBitWidth = 14; // 0 ~ 16383
    const int kOutImgBitWidth = 14; // 0 ~ 16383
    int deltaX = 0;
    int deltaY = 0;
    int baseX = 0;
    int baseY = 0;
    int shiftX = 0;
    int step = 0;
    int pixelOut = 0;
    int curIdx = 0;
    bool sign = (pixelIn >= 0) ? false : true;

    if (pixelIn < 0)
        pixelIn = -pixelIn;

    if (pixelIn > ((1 << kInImgBitWidth) - 1))
        pixelIn = ((1 << kInImgBitWidth) - 1); // clip to input gamma max.

    for (curIdx = kFirstIdx; curIdx < kLastIdx; curIdx++)
        if (lutX[curIdx] > pixelIn)
            break;

    if (curIdx == kFirstIdx) {
        deltaX = lutX[0];
        deltaY = lutY[0];
        baseX = 0;
        baseY = 0;
    } else if (curIdx == kLastIdx) {
        // [LAST_IDX] is difference value between last two values [LAST_IDX - 1] and [LAST_IDX]. This is h/w concept.
        deltaX = lutX[kLastIdx];
        deltaY = lutY[kLastIdx];
        baseX = lutX[kLastIdx - 1];
        baseY = lutY[kLastIdx - 1];
    } else {
        deltaX = lutX[curIdx] - lutX[curIdx - 1];
        deltaY = lutY[curIdx] - lutY[curIdx - 1];
        baseX = lutX[curIdx - 1];
        baseY = lutY[curIdx - 1];
    }

    // shift = 0(1), 1(2~3), 2(4~7), 3(8~15), ... , 13(8192 ~ 16383)
    for (shiftX = 0; shiftX < kInImgBitWidth; shiftX++) {
        if (deltaX == (1 << shiftX)) {
            step = (deltaY * (pixelIn - baseX)) >> shiftX;
            pixelOut = baseY + step;
            break;
        }
    }

    // Exceptional case clipping
    if (pixelOut > ((1 << kOutImgBitWidth) - 1))
        pixelOut = pixelOut & ((1 << kOutImgBitWidth) - 1);

    if (sign == true)
        pixelOut = -pixelOut;

    return pixelOut;
}

status_t ExynosCamera::m_reverseProcessingBayer(ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer *inBuf, ExynosCameraBuffer *outBuf)
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);

    status_t ret = NO_ERROR;

#if 0
    directDumpToFile(inBuf, m_cameraId, frame->getMetaFrameCount());
    for (int i = 0; i < inBuf->getMetaPlaneIndex(); i++) {
        if (inBuf->fd[i] > 0)
            memcpy(outBuf->addr[i], inBuf->addr[i], ALIGN(inBuf->size[i] / 2, 16));
    }
    directDumpToFile(outBuf, m_cameraId, frame->getMetaFrameCount());
#else
    int i;
    char *inImg = inBuf->addr[0];
    char *outImg = outBuf->addr[0];
    struct camera2_shot_ext shot_ext;
    frame->getMetaData(&shot_ext);
    struct camera2_stream *shot_stream = (struct camera2_stream *)(inBuf->addr[inBuf->getMetaPlaneIndex()]);
    int row = shot_stream->output_crop_region[3];
    int col = shot_stream->output_crop_region[2];
    int inPackBitWidth = 16;
    int outPackBitWidth = 16;

    switch (m_parameters[m_cameraId]->getBayerFormat(PIPE_3AC_REPROCESSING)) {
    case V4L2_PIX_FMT_SBGGR10:
    case V4L2_PIX_FMT_SBGGR12:
        inPackBitWidth = 12;
        break;
    default:
        break;
    }

    int inByteSize = (col * inPackBitWidth + 7) >> 3;
    int inStride = ((inByteSize + 15) >> 4) << 4;
    int outByteSize = (col * outPackBitWidth + 7) >> 3;
    int outStride = ((outByteSize + 15) >> 4) << 4;

    /* apply Postgamma/invWB/pedestalRemove/Stretching */
    int mod2_x = 0;
    int mod2_y = 0;
    int gainIdx = 0;
    int pixelIn = 0;
    int postGamma = 0;
    int invWB = 0;
    int clipV = 0;
    int outV = 0;
    int in_line_addr = 0;
    int out_line_addr = 0;
    int x_idx = 0;
    int y_idx = 0;
    int inRemain = 0;
    int outRemain = 0;
    int pixelInPed = 0;
    unsigned int inBuffer = 0;
    unsigned int outBuffer = 0;

    /*
     * inverse RGB gain calculation with pedestal stretching
     * Bayerorder Gr first.
     */
    int32_t invRGBgain[4] = { 0, 0, 0, 0 }; // Gr R Gb B
#if 0
    /* just test */
    int32_t samplePedestal[4] = { 896, 896, 896, 896 };
    int32_t sampleRgbGain[4] = { 1024, 1731, 2394, 1024 };
    int32_t sampleGammaLutX[32] = {0    , 512  , 1024 , 2048 , 2560 ,
        3072 , 3584 , 4096 , 4608 , 5120 ,
        5632 , 6144 , 6656 , 7168 , 7680 ,
        8192 , 8704 , 9216 , 9728 , 10240,
        10752, 11264, 11776, 12288, 12800,
        13312, 13824, 14336, 14848, 15360,
        15488, 1024 };

    int32_t sampleGammaLutY[32] = {0    , 112  , 239  , 533  , 707  ,
        896  , 1109 , 1347 , 1611 , 1902 ,
        2224 , 2567 , 2936 , 3342 , 3785 ,
        4266 , 4788 , 5354 , 5967 , 6625 ,
        7325 , 8066 , 8854 , 9694 , 10592,
        11553, 12575, 13665, 14829, 16069,
        16383, 16384};

    int32_t *pedestal = samplePedestal;
    int32_t *rgbGain = sampleRgbGain;
    int32_t *gammaX = sampleGammaLutX;
    int32_t *gammaY = sampleGammaLutY;
#else
    /* Meta Information */
    int32_t pedestal[4] = {
        /* G, R, B, G */
        (int32_t)shot_ext.shot.udm.dng.pedestal[1], /* G */
        (int32_t)shot_ext.shot.udm.dng.pedestal[0], /* R */
        (int32_t)shot_ext.shot.udm.dng.pedestal[2], /* B */
        (int32_t)shot_ext.shot.udm.dng.pedestal[1]  /* G */
    };

    /* HACK : RTA Team */
    for (i = 0; i < 4; i++) {
        if (pedestal[i] < 896) {
            pedestal[i] = 896;
        }
    }
    int32_t *rgbGain = (int32_t *)shot_ext.shot.udm.dng.wbgain;
    int32_t *gammaX = (int32_t *)shot_ext.shot.udm.dng.gammaXpnt;
    int32_t *gammaY = (int32_t *)shot_ext.shot.udm.dng.gammaYpnt;
#endif

    CLOGI("[F%d M%d] inBuf(%d),outBuf(%d), (%dx%d inPackBit:%d, in(%d, %d), out(%d, %d))",
            frame->getFrameCount(), frame->getMetaFrameCount(), inBuf->index, outBuf->index,
            col, row, inPackBitWidth, outPackBitWidth, inByteSize, inStride, outByteSize, outStride);

    if (col % 2 != 0) {
        CLOGE("Image width should be even! current image(w:%d, h:%d)", col, row);
        ret = INVALID_OPERATION;
        goto p_err;
    }

    if (((inStride % 16) != 0) || ((outStride % 16) != 0)) {
        CLOGE("Stride is not 16times! (inStride:%d, outStride:%d)", inStride, outStride);
        ret = INVALID_OPERATION;
        goto p_err;
    }

#if 0
    for (i = 0; i < 4; i+=4) {
        CLOGD("pedestal[%d][ %d, %d, %d, %d ]", i, pedestal[i], pedestal[i+1], pedestal[i+2], pedestal[i+3]);
        CLOGD("rgbgain[%d][ %d, %d, %d, %d ]", i, rgbGain[i], rgbGain[i+1], rgbGain[i+2], rgbGain[i+3]);
    }

    for (i = 0; i < 32; i+=4)
        CLOGD("gammaX[%d][ %d, %d, %d, %d ]", i, gammaX[i], gammaX[i+1], gammaX[i+2], gammaX[i+3]);

    for (i = 0; i < 32; i+=4)
        CLOGD("gammaY[%d][ %d, %d, %d, %d ]", i, gammaY[i], gammaY[i+1], gammaY[i+2], gammaY[i+3]);
#endif
    m_reverseProcessingApplyCalcRGBgain(rgbGain, invRGBgain, pedestal);

    for (i = 0; i < row * col; i++) {
        x_idx = i % col;
        y_idx = i / col;
        mod2_x = (x_idx % 2);
        mod2_y = (y_idx % 2);
        // for pixel order calc
        gainIdx = 2 * mod2_y + mod2_x;

        //=========================================
        // 0) Unpack Proc.
        // line address & buffer value/size initialize
        if (x_idx == 0) {
            in_line_addr = y_idx * inStride;
            out_line_addr = y_idx * outStride;
            inRemain = 0;
            inBuffer = 0;
            outRemain = 0;
            outBuffer = 0;
        }

        // Unpack core
        while (inRemain < inPackBitWidth) {
            inBuffer = (inImg[in_line_addr] << inRemain) + inBuffer;
            inRemain += 8;
            in_line_addr++;
        }

        pixelIn = inBuffer & ((1 << inPackBitWidth) - 1);
        inBuffer = inBuffer >> inPackBitWidth;
        inRemain -= inPackBitWidth;

        //=========================================
        // 1) input 12bit to 14bit
        pixelIn = pixelIn << 2;
        // input 10bit to 14bit
        if (inPackBitWidth < 12) {
            pixelIn = pixelIn << (12 - inPackBitWidth);
        }

        // 2) Post-gamma proc
        pixelInPed = pixelIn - pedestal[gainIdx];
        postGamma = m_reverseProcessingApplyGammaProc(pixelInPed, gammaX, gammaY);
        clipV = CLIP3(postGamma, 0, 16383);

        // 3) inv WB gain proc & pedestal stretching
        invWB = (invRGBgain[gainIdx] * clipV + (1 << 17)) >> 18; //unpack 10bit output

        // 4) clipping
        outV = MIN(invWB, 1023); //unpack 10bit output

        // 5) Pack core
        // constraint : outPackBitWidth > 8
        outBuffer = (outV << outRemain) + outBuffer;
        outRemain += outPackBitWidth;

        while (outRemain >= 8) {
            outImg[out_line_addr] = outBuffer & ((1 << 8) - 1);
            outBuffer = outBuffer >> 8;
            out_line_addr++;
            outRemain -= 8;
        }
    }
#endif

p_err:

    return ret;
}
#endif

void ExynosCamera::m_setApertureControl(frame_handle_components_t *components, struct camera2_shot_ext *shot_ext)
{
    int ret = 0;
    int aperture_value = shot_ext->shot.ctl.lens.aperture;

    if (components->previewFactory != NULL) {
        ret = components->previewFactory->setControl(V4L2_CID_IS_FACTORY_APERTURE_CONTROL, aperture_value, PIPE_3AA);
        if (ret < 0) {
            CLOGE("setcontrol() failed!!");
        } else {
            CLOGV("setcontrol() V4L2_CID_IS_FACTORY_APERTURE_CONTROL:(%d)", aperture_value);
        }
    }
}

status_t ExynosCamera::m_updateYsumValue(ExynosCameraFrameSP_sptr_t frame, ExynosCameraRequestSP_sprt_t request)
{
    int ret = NO_ERROR;
    struct camera2_udm udm;

    if (frame == NULL) {
        CLOGE("Frame is NULL");
        return BAD_VALUE;
    }

    if (request == NULL) {
        CLOGE("Request is NULL");
        return BAD_VALUE;
    }

    ret = frame->getUserDynamicMeta(&udm);
    if (ret < 0) {
        CLOGE("getUserDynamicMeta fail, ret(%d)", ret);
        return ret;
    }
#ifdef USE_DUAL_CAMERA
    if (frame->getFrameType() != FRAME_TYPE_PREVIEW_DUAL_SLAVE)
        /* YSUM recoridng does not necessarily have to match the Y value of the recording buffer.
         * Because it looks at the trend between Y values. */
#endif
    {
        request->setYsumValue(&udm.scaler.ysumdata);
    }

    return ret;
}

//#define DEBUG_UPDATE_DISPLAY_REGION
status_t ExynosCamera::m_updateDisplayRegion(ExynosCameraFrameSP_sptr_t frame, ExynosCameraRequestSP_sprt_t request, int streamId)
{
    status_t ret = NO_ERROR;

    if (streamId != HAL_STREAM_ID_PREVIEW) {
        CLOGV("No effect. Skip updating displayRegion");
        return ret;
    }

    for (int i = 0; i < m_camIdInfo.numOfSensors; i++) {
        int32_t cameraId = frame->getCameraId(i);
        if (cameraId < 0) continue;

        ExynosRect srcRect, dstRect;
        m_configurations->getSize(CONFIGURATION_PREVIEW_SIZE, (uint32_t *)&dstRect.w, (uint32_t *)&dstRect.h);
        dstRect.fullW = dstRect.w;
        dstRect.fullH = dstRect.h;

#ifdef DEBUG_UPDATE_DISPLAY_REGION
        CFLOGD(frame, "[START] [%d,%d,%d,%d(%dx%d)]",
                streamId, dstRect.x, dstRect.y, dstRect.w, dstRect.h, dstRect.fullW, dstRect.fullH);
#endif

        std::vector<frame_size_scenario_t> scenarios;
        scenarios.push_back(FRAME_SIZE_VDIS_CROP    ); // VDIS trans
        scenarios.push_back(FRAME_SIZE_FUSION_SCALEUP); // Fusion scaleup
        scenarios.push_back(FRAME_SIZE_FUSION_CROP  ); // Fusion trans
        scenarios.push_back(FRAME_SIZE_MCP_OUT      ); // HW chain trans
        scenarios.push_back(FRAME_SIZE_MCP_CROP     ); // HW chain trans
        scenarios.push_back(FRAME_SIZE_MCS_CROP_IN  ); // HW chain trans
        scenarios.push_back(FRAME_SIZE_ISP_CROP_IN  ); // HW chain trans
        scenarios.push_back(FRAME_SIZE_BDS          ); // HW chain trans
        scenarios.push_back(FRAME_SIZE_BCROP_OUT    ); // HW chain trans

        frame_size_info_t info;
        for (auto scenario : scenarios) {
            if (frame->getSizeInfo(scenario, info, cameraId)) {
                srcRect = info.rect;
                dstRect = convertDstRectBySrcRect(srcRect, dstRect);
#ifdef DEBUG_UPDATE_DISPLAY_REGION
                CFLOGD(frame, "[%d][TRANS][CAM%d][S%d][P%d] src[%d,%d,%d,%d(%dx%d)] dst[%d,%d,%d,%d(%dx%d)]",
                        i, cameraId, scenario, info.pipeId,
                        srcRect.x, srcRect.y, srcRect.w, srcRect.h, srcRect.fullW, srcRect.fullH,
                        dstRect.x, dstRect.y, dstRect.w, dstRect.h, dstRect.fullW, dstRect.fullH);
#endif
            }
        }

        const auto &sizeMap = frame->getSizeInfoMap(cameraId);

        // TODO: need to support multiple camera
        ExynosCameraParameters *param = m_configurations->getParameters(cameraId);
        param->setDisplayStatRoi(cameraId, dstRect, sizeMap);
    }

    return ret;
}

#ifdef USES_SENSOR_LISTENER
bool ExynosCamera::m_sensorListenerUnloadThreadFunc(void)
{
    CLOGI("-IN-");

    if (m_gyroHandle != NULL) {
        if (ExynosCameraSensorListenerWrapper::disable_sensor(m_gyroHandle, ExynosCameraSensorListenerWrapper::ST_GYROSCOPE) < 0) {
            CLOGE("[GYRO]sensor_listener_disable_sensor failed!!");
        } else {
            ExynosCameraSensorListenerWrapper::unload(&m_gyroHandle);
            m_gyroHandle = NULL;
        }
    }

    if (m_accelerometerHandle != NULL) {
        if (ExynosCameraSensorListenerWrapper::disable_sensor(m_accelerometerHandle, ExynosCameraSensorListenerWrapper::ST_ACCELEROMETER) < 0) {
            CLOGE("[ACCELEROMETER]sensor_listener_disable_sensor failed!!");
        } else {
            ExynosCameraSensorListenerWrapper::unload(&m_accelerometerHandle);
            m_accelerometerHandle = NULL;
        }
    }

    if (m_rotationHandle != NULL) {
        if (ExynosCameraSensorListenerWrapper::disable_sensor(m_rotationHandle, ExynosCameraSensorListenerWrapper::ST_ROTATION) < 0) {
            CLOGE("[ROTATION]ExynosCameraSensorListenerWrapper::disable_sensor failed!!");
        } else {
            ExynosCameraSensorListenerWrapper::unload(&m_rotationHandle);
            m_rotationHandle = NULL;
        }
    }

    CLOGI("-OUT-");

    return false;
}

bool ExynosCamera::m_sensorListenerThreadFunc(void)
{
    CLOGI("");
    ExynosCameraDurationTimer m_timer;
    long long durationTime = 0;

    m_timer.start();

    if (isBackCamera(getCameraId())) {
        if (m_gyroHandle == NULL) {
            m_gyroHandle = ExynosCameraSensorListenerWrapper::load(getCameraId());
            if (m_gyroHandle != NULL) {
                if (ExynosCameraSensorListenerWrapper::enable_sensor(m_gyroHandle, ExynosCameraSensorListenerWrapper::ST_GYROSCOPE, 10) < 0) {
                    ExynosCameraSensorListenerWrapper::unload(&m_gyroHandle);
                } else {
                    m_configurations->setMode(CONFIGURATION_GYRO_MODE, true);
                }
            }
        } else {
            m_configurations->setMode(CONFIGURATION_GYRO_MODE, true);
        }
    }

    if (m_parameters[m_cameraId]->getAutoFocusSupported() == true) {
        if (m_accelerometerHandle == NULL) {
            m_accelerometerHandle = ExynosCameraSensorListenerWrapper::load(getCameraId());
            if (m_accelerometerHandle != NULL) {
                if (ExynosCameraSensorListenerWrapper::enable_sensor(m_accelerometerHandle, ExynosCameraSensorListenerWrapper::ST_ACCELEROMETER, 33) < 0) {
                    ExynosCameraSensorListenerWrapper::unload(&m_accelerometerHandle);
                } else {
                    m_configurations->setMode(CONFIGURATION_ACCELEROMETER_MODE, true);
                }
            }
        } else {
            m_configurations->setMode(CONFIGURATION_ACCELEROMETER_MODE, true);
        }
    }

    if (m_configurations->getModeValue(CONFIGURATION_VT_MODE) == 0) {
        if (m_rotationHandle == NULL) {
            m_rotationHandle = ExynosCameraSensorListenerWrapper::load(getCameraId());
            if (m_rotationHandle != NULL) {
                if (ExynosCameraSensorListenerWrapper::enable_sensor(m_rotationHandle, ExynosCameraSensorListenerWrapper::ST_ROTATION, 33) < 0) {
                    ExynosCameraSensorListenerWrapper::unload(&m_rotationHandle);
                } else {
                    m_configurations->setMode(CONFIGURATION_ROTATION_MODE, true);
                }
            }
        } else {
            m_configurations->setMode(CONFIGURATION_ROTATION_MODE, true);
        }
    }

    m_timer.stop();
    durationTime = m_timer.durationMsecs();
    CLOGD("duration time(%5d msec)", (int)durationTime);

    return false;
}

bool ExynosCamera::m_getSensorListenerData(frame_handle_components_t *components)
{
    int ret = 0;
    ExynosCameraParameters *parameters = components->parameters;

    static uint8_t gyro_error_cnt = 0;
    static uint8_t accelerometer_error_cnt = 0;
    static uint8_t rotation_error_cnt = 0;

    if (m_gyroHandle != NULL) {
        int numOfData = 1;
        ExynosCameraSensorListenerWrapper::EVENT_TYPE eventType = ExynosCameraSensorListenerWrapper::EVENT_TYPE_LATEST;

#ifdef USE_GYRO_HISTORY_FOR_TNR
        numOfData = ExynosCameraSensorListenerWrapper::get_numberOfdata(m_gyroHandle, ExynosCameraSensorListenerWrapper::ST_GYROSCOPE);
        eventType = ExynosCameraSensorListenerWrapper::EVENT_TYPE_OLDEST;
#endif
        for (int i = 0; i < numOfData; i++) {
            ret = ExynosCameraSensorListenerWrapper::get_data(m_gyroHandle, ExynosCameraSensorListenerWrapper::ST_GYROSCOPE, &m_gyroListenerData, false, eventType);
            if (ret < 0) {
                if ((gyro_error_cnt % 30) == 0) {
                    CLOGW("skip the Gyro data. ret %d", ret);
                    gyro_error_cnt = 1;
                } else {
                    gyro_error_cnt++;
                }
            } else {
                if (m_configurations->getMode(CONFIGURATION_GYRO_MODE)) {
                    parameters->setGyroData(m_gyroListenerData);
                }
            }
        }
    }

    if (m_accelerometerHandle != NULL) {
        ret = ExynosCameraSensorListenerWrapper::get_data(m_accelerometerHandle, ExynosCameraSensorListenerWrapper::ST_ACCELEROMETER, &m_accelerometerListenerData, false);
        if (ret < 0) {
            if ((accelerometer_error_cnt % 30) == 0) {
                CLOGW("skip the accelerometer_error_cnt data. ret %d", ret);
                accelerometer_error_cnt = 1;
            } else {
                accelerometer_error_cnt++;
            }
        } else {
            if (m_configurations->getMode(CONFIGURATION_ACCELEROMETER_MODE)) {
                parameters->setAccelerometerData(m_accelerometerListenerData);
            }
        }
    }

    if (m_rotationHandle != NULL) {
        ret = ExynosCameraSensorListenerWrapper::get_data(m_rotationHandle, ExynosCameraSensorListenerWrapper::ST_ROTATION, &m_rotationListenerData, false);
        if (ret < 0) {
            if ((rotation_error_cnt % 30) == 0) {
                CLOGW("skip the Rotation data. ret %d", ret);
                rotation_error_cnt = 1;
            } else {
                rotation_error_cnt++;
            }
        } else {
            if (m_configurations->getMode(CONFIGURATION_ROTATION_MODE)) {
                /* rotationListenerData : counterclockwise,index / DeviceOrientation : clockwise,degree  */
                int fdOrientation = 0;
                int currentCameraId = parameters->getCameraId();
                ExynosCameraActivityUCTL *uctlMgr = NULL;
                int orientation_Degrees = 0;

                switch (m_rotationListenerData.rotation.orientation) {
                    case ExynosCameraSensorListenerWrapper::SCREEN_DEGREES_0:
                        orientation_Degrees = 0;
                        break;
                    case ExynosCameraSensorListenerWrapper::SCREEN_DEGREES_270:
                        orientation_Degrees = 270;
                        break;
                    case ExynosCameraSensorListenerWrapper::SCREEN_DEGREES_180:
                        orientation_Degrees = 180;
                        break;
                    case ExynosCameraSensorListenerWrapper::SCREEN_DEGREES_90:
                        orientation_Degrees = 90;
                        break;
                    default:
                        CLOGW("unknown degree index. orientation %d", m_rotationListenerData.rotation.orientation);
                        orientation_Degrees = m_configurations->getModeValue(CONFIGURATION_DEVICE_ORIENTATION);
                        break;
                }

                /* Gets the FD orientation angle in degrees. Calibrate FRONT FD orientation */
                if (currentCameraId == CAMERA_ID_FRONT) {
                    fdOrientation = (orientation_Degrees + FRONT_ROTATION + 180) % 360;
                } else {
                    fdOrientation = (orientation_Degrees + BACK_ROTATION) % 360;
                }

                uctlMgr = components->activityControl->getUCTLMgr();
                if (uctlMgr != NULL) {
                    if (uctlMgr->getDeviceRotation() != fdOrientation
                            && m_configurations->getMode(CONFIGURATION_ROTATION_MODE)) {
                        m_configurations->setModeValue(CONFIGURATION_DEVICE_ORIENTATION, orientation_Degrees);
                        m_configurations->setModeValue(CONFIGURATION_FD_ORIENTATION, orientation_Degrees);

                        uctlMgr->setDeviceRotation(m_configurations->getModeValue(CONFIGURATION_FD_ORIENTATION));
                    }
                }
            }
        }
    }

    return true;
}
#endif

/********************************************************************************/
/**                          VENDOR                                            **/
/********************************************************************************/
void ExynosCamera::m_checkVendorDynamicBayerMode(bool &useDynamicBayer)
{
    if (m_configurations->getMode(CONFIGURATION_ZERO_CAMERA_MODE) == true) {
        useDynamicBayer = false;
    }

#ifdef SUPPORT_SESSION_PARAMETERS
    if (m_configurations->getModeMultiValue(CONFIGURATION_MULTI_SESSION_MODE_VALUE, EXYNOS_SESSION_MODE_PRO) == true) {
        useDynamicBayer = true;
    } else
#endif
#ifdef USES_COMBINE_PLUGIN
    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
        useDynamicBayer = false;
    } else
#endif
    {
        CLOGD("Don't change to useDynamicBayer(%d)", useDynamicBayer);
    }
}

void ExynosCamera::m_vendorSpecificPreConstructorInitalize(__unused int cameraId, __unused int scenario)
{
}
void ExynosCamera::m_vendorSpecificConstructorInitalize(void)
{
#ifdef USES_SENSOR_LISTENER
    m_gyroHandle = NULL;
    m_configurations->setMode(CONFIGURATION_GYRO_MODE, false);

    m_accelerometerHandle = NULL;
    m_configurations->setMode(CONFIGURATION_ACCELEROMETER_MODE, false);

    m_rotationHandle = NULL;
    m_configurations->setMode(CONFIGURATION_ROTATION_MODE, false);
#endif

#ifdef OIS_CAPTURE
    ExynosCameraActivitySpecialCapture *sCaptureMgr = m_activityControl[m_cameraId]->getSpecialCaptureMgr();
    sCaptureMgr->resetOISCaptureFcount();
#endif

#ifdef SUPPORT_DEPTH_MAP
    m_flagUseInternalDepthMap = false;
#endif

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
    m_flagSetLedCalibration = false;
#endif

#ifdef USES_SENSOR_GYRO_FACTORY_MODE
    m_sensorGyroTest = NULL;
    m_sensorGyroTestIndex = -1;
#endif

#ifdef USE_HW_RAW_REVERSE_PROCESSING
    m_oldSetfile = ISS_SUB_END;
#endif

    if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
#ifdef SUPPORT_MULTI_STREAM_CAPTURE
        int maxPictureW = 0, maxPictureH = 0;

        m_parameters[m_cameraId]->getSize(HW_INFO_MAX_PICTURE_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);
        for (int i = 1; i < m_camIdInfo.numOfSensors; i++) {
            int slaveMaxPictureW  = 0, slaveMaxPictureH  = 0;

            m_parameters[m_camIdInfo.cameraId[i]]->getSize(HW_INFO_MAX_PICTURE_SIZE, (uint32_t *)&slaveMaxPictureW, (uint32_t *)&slaveMaxPictureH);
            if (maxPictureW * maxPictureH < slaveMaxPictureW * slaveMaxPictureH) {
                maxPictureW = slaveMaxPictureW;
                maxPictureH = slaveMaxPictureH;
            }
        }
        m_configurations->setSize(CONFIGURATION_MAX_PICTURE_SIZE_OF_MULTISTREAM, maxPictureW, maxPictureH);

        CLOGD("Max Picture of Multi-Stream (%dx%d)", maxPictureW, maxPictureH);
#endif /* SUPPORT_MULTI_STREAM_CAPTURE */
    }
}
void ExynosCamera::m_vendorSpecificPreDestructorDeinitalize(void)
{
    __unused status_t ret = 0;

#ifdef USES_SENSOR_LISTENER
    if (m_sensorListenerThread != NULL) {
        m_sensorListenerThread->join();
    }

    if (m_sensorListenerUnloadThread != NULL) {
        m_sensorListenerUnloadThread->run();
    }
#endif
}

void ExynosCamera::m_vendorUpdateExposureTime(__unused struct camera2_shot_ext *shot_ext)
{
}

status_t ExynosCamera::m_checkStreamInfo_vendor(status_t &ret)
{
    return ret;

}

status_t ExynosCamera::setParameters_vendor(__unused const CameraParameters& params)
{
    status_t ret = NO_ERROR;

    return ret;
}

status_t ExynosCamera::m_checkMultiCaptureMode_vendor_update(__unused ExynosCameraRequestSP_sprt_t request)
{
    return NO_ERROR;
}

status_t ExynosCamera::processCaptureRequest_vendor_initDualSolutionZoom(__unused camera3_capture_request *request, status_t& ret)
{
    return ret;
}

status_t ExynosCamera::processCaptureRequest_vendor_initDualSolutionPortrait(__unused camera3_capture_request *request, status_t& ret)
{
    return ret;
}

status_t ExynosCamera::m_captureFrameHandler_vendor_updateConfigMode(__unused ExynosCameraRequestSP_sprt_t request, __unused ExynosCameraFrameFactory *targetfactory, __unused frame_type_t& frameType)
{
return NO_ERROR;
}

status_t ExynosCamera::m_captureFrameHandler_vendor_updateDualROI(__unused ExynosCameraRequestSP_sprt_t request, __unused frame_handle_components_t& components, __unused frame_type_t frameType)
{
    return NO_ERROR;
}

status_t ExynosCamera::m_captureFrameHandler_vendor_updateIntent(ExynosCameraRequestSP_sprt_t request,
                                                                 frame_handle_components_t& components)
{
    status_t ret = NO_ERROR;

    ////////////////////////////////////////////////
    // setCaptureIntent
    m_updateCaptureIntent(request, components);

    ////////////////////////////////////////////////
    // ois
    if (m_configurations->getMode(CONFIGURATION_OIS_CAPTURE_MODE) == true) {
#ifdef OIS_CAPTURE
        ////////////////////////////////////////////////
        // turn on OIS capture mode.
        components.activityControl->setOISCaptureMode(true);
#endif

        ////////////////////////////////////////////////
        // set multi capture.
        ExynosCameraActivitySpecialCapture *sCaptureMgr = components.activityControl->getSpecialCaptureMgr();
        sCaptureMgr->setMultiCaptureMode(true);

        ////////////////////////////////////////////////
        // start sCapture
        sCaptureMgr->setCaptureStep(ExynosCameraActivitySpecialCapture::SCAPTURE_STEP_START);
    }

    ////////////////////////////////////////////////

    return ret;
}

void ExynosCamera::m_updateCaptureIntent(ExynosCameraRequestSP_sprt_t request,
                                         frame_handle_components_t& components)
{
    bool flagUpdateIntent = true;
    enum aa_capture_intent captureIntent = AA_CAPTURE_INTENT_STILL_CAPTURE;
    int currentCameraId = components.currentCameraId;
    struct camera2_shot_ext *shot_ext = m_currentCaptureShot[currentCameraId];

    ////////////////////////////////////////////////
    // check whether to change captureIntent
    enum aa_capture_intent newCaptureIntent = (enum aa_capture_intent)m_configurations->getModeValue(CONFIGURATION_CAPTURE_INTENT);

    if (captureIntent != newCaptureIntent) {
        captureIntent = newCaptureIntent;
        flagUpdateIntent = true;
    }

    ////////////////////////////////////////////////
    // update captureIntent
    if (flagUpdateIntent == true) {
        int value;
        unsigned int mask = 0;
        int32_t dynamicShotCount = 0;
        int32_t oldBayerLockCount = 0;

        ////////////////////////////////////////////////
        // set mask
        dynamicShotCount = m_configurations->getModeValue(CONFIGURATION_CAPTURE_COUNT);

        oldBayerLockCount = components.parameters->getOldBayerFrameLockCount();
        CLOGW("Adjust captureCount : dynamicShotCount(%d) - oldBayerLockCount(%d) = %d",
                dynamicShotCount, oldBayerLockCount, (dynamicShotCount-oldBayerLockCount));

        dynamicShotCount -= oldBayerLockCount;

        mask = (((((unsigned int)captureIntent) << 16) & 0xFFFF0000) | ((dynamicShotCount << 0) & 0x0000FFFF));
        value = mask;

        ////////////////////////////////////////////////
        // set meta
        shot_ext->shot.ctl.aa.captureIntent = captureIntent;
        shot_ext->shot.ctl.aa.vendor_captureCount = dynamicShotCount;

        ExynosCameraActivitySpecialCapture *sCaptureMgr = NULL;
        sCaptureMgr = components.activityControl->getSpecialCaptureMgr();
        sCaptureMgr->setCaptureIntent(captureIntent);
        sCaptureMgr->setCaptureCount(dynamicShotCount);

        ////////////////////////////////////////////////
        // set ioctl
        if (components.previewFactory == NULL) {
            CLOGE("FrameFactory is NULL!!");
        } else {
            status_t ret = NO_ERROR;

            ret = components.previewFactory->setControl(V4L2_CID_IS_INTENT, value, PIPE_3AA);
            if (ret) {
                CLOGE("setcontrol() V4L2_CID_IS_INTENT:(%d) failed", value);
            } else {
                CLOGD("setcontrol() V4L2_CID_IS_INTENT:(%d)", value);
            }
        }

        ////////////////////////////////////////////////
        // log
        int requestKey = -1;
        if (request) {
            requestKey = request->getKey();
        }

        CLOGD("[R%d]start set multi mode captureIntent(%d) capturecount(%d)",
            requestKey, captureIntent, dynamicShotCount);
    }

    ////////////////////////////////////////////////
}

status_t ExynosCamera::m_previewFrameHandler_vendor_updateRequest(__unused ExynosCameraFrameFactory *targetfactory)
{
    return NO_ERROR;
}

status_t ExynosCamera::m_handlePreviewFrame_vendor_handleBuffer(ExynosCameraRequestSP_sprt_t request,
                                                                __unused ExynosCameraFrameSP_sptr_t frame,
                                                                __unused int pipeId,
                                                                __unused ExynosCameraFrameFactory *factory,
                                                                __unused frame_handle_components_t& components,
                                                                __unused status_t& ret)
{
#ifdef USE_DUAL_CAMERA
    if (frame->getRequest(PIPE_SYNC) == false)
#endif
    {
        if (frame->getInternalBufTagPipeId() >= 0) {
            ExynosCameraBuffer srcBuffer;
            int nodePipeId;

#ifdef USE_DUAL_CAMERA
            int alternativePreviewPortId = components.parameters->getAlternativePreviewPortId();

            if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
                && frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE && alternativePreviewPortId >= 0) {
                nodePipeId = PIPE_MCSC0 + (alternativePreviewPortId % ExynosCameraParameters::YUV_MAX);
            } else
#endif
            if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
                nodePipeId = PIPE_MCSC0 + (components.parameters->getPreviewPortId() % ExynosCameraParameters::YUV_MAX);
            } else {
                nodePipeId = PIPE_MCSC0 + (components.parameters->getPreviewCbPortId() % ExynosCameraParameters::YUV_MAX);
            }

            srcBuffer.index = -2;

            ret = frame->getDstBuffer(pipeId, &srcBuffer, factory->getNodeType(nodePipeId));
            if (ret != NO_ERROR) {
                CLOGE("Failed to getDst buffer, pipeId(%d), ret(%d)", pipeId, ret);
            } else {
                if (srcBuffer.index >= 0) {
                    ret = m_bufferSupplier->putBuffer(srcBuffer);
                    if (ret != NO_ERROR) {
                        CLOGE("Failed to putBuffer. pipeId(%d), ret(%d)", pipeId, ret);
                    }
                }
            }
        }
    }

    if (frame->getRequest(PIPE_GSC) == true) {
#ifdef USE_DUAL_CAMERA
        if (m_videoStreamExist == false
            && m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
            && frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
            ExynosCameraBuffer buffer;
            entity_buffer_state_t bufferState;
            camera3_buffer_status_t streamBufferState = CAMERA3_BUFFER_STATUS_OK;
            int nodePipeId;

            if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
                nodePipeId = PIPE_MCSC0 + (components.parameters->getPreviewPortId() % ExynosCameraParameters::YUV_MAX);
            } else {
                nodePipeId = PIPE_MCSC0 + (components.parameters->getPreviewCbPortId() % ExynosCameraParameters::YUV_MAX);
            }

            /* for skip frame when jump sequence */
            ret = frame->getDstBuffer(pipeId, &buffer, factory->getNodeType(nodePipeId));
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("Failed to get GSC buffer. pipeId %d/%d bufferIndex %d frameCount %d ret %d",
                    pipeId, nodePipeId, buffer.index, frame->getFrameCount(), ret);
            }

            ret = frame->getDstBufferState(pipeId, &bufferState);
            if (ret < 0) {
                CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", pipeId, ret);
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), pipeId);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index, pipeId, ret);
                }
            }
        }
#endif
    }

    return ret;
}

void ExynosCamera::m_vendorSpecificDestructorDeinitalize(void)
{
#ifdef USES_SENSOR_LISTENER
    if (m_sensorListenerUnloadThread != NULL) {
        m_sensorListenerUnloadThread->join();
    }
#endif
}

#ifdef USE_DUAL_CAMERA
status_t ExynosCamera::m_updateBeforeForceSwitchSolution(ExynosCameraFrameSP_sptr_t frame, __unused int pipeId)
{
    status_t ret = NO_ERROR;
    // Do something before switching
    return ret;
}

status_t ExynosCamera::m_updateAfterForceSwitchSolution(ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    // Do something after switching
    return ret;
}

status_t ExynosCamera::m_updateBeforeDualSolution(ExynosCameraFrameSP_sptr_t frame, __unused int pipeId)
{
    status_t ret = NO_ERROR;

    if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
        // Do something before transition
        // In case of VDIS scenario, get Internal Buffer
        if (frame->getRequest(PIPE_VDIS)) {
            ExynosCameraBuffer srcBuffer, dstBuffer;
            buffer_manager_tag_t bufTag;
            bufTag.pipeId[0] = pipeId;
            bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
            ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
            if (dstBuffer.index < 0) {
                CFLOGE(frame, "can't get dstBuffer! pipeId:%d", pipeId);
                return INVALID_OPERATION;
            }
            ret = frame->setDstBuffer(pipeId, dstBuffer);
            if (ret != NO_ERROR) {
                CFLOGE(frame, "Failed to setDstBuffer, pipeId:%d", pipeId);
                m_bufferSupplier->putBuffer(dstBuffer);
                return ret;
            }
        }
    }

    /* update faceDetection Info */
    const int masterNodeIndex = OUTPUT_NODE_1, slaveNodeIndex = OUTPUT_NODE_2;
    const int masterCameraId = frame->getCameraId(masterNodeIndex), slaveCameraId = frame->getCameraId(slaveNodeIndex);
    ExynosCameraParameters *masterParamater = (masterCameraId >= 0) ? m_parameters[masterCameraId] : NULL;
    ExynosCameraParameters *slaveParamater = (slaveCameraId >= 0) ? m_parameters[slaveCameraId] : NULL;

    if (masterParamater != NULL
        && (masterParamater->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M
            || masterParamater->getHwConnectionMode(PIPE_3AA, PIPE_VRA) == HW_CONNECTION_MODE_M2M)) {
        ExynosCameraBuffer srcBuffer;

        ret = frame->getSrcBuffer(pipeId, &srcBuffer, masterNodeIndex);
        if (ret != NO_ERROR || srcBuffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                        frame->getFrameCount(), srcBuffer.index, pipeId, ret);
        } else {
            camera2_shot_ext *shot_ext = (camera2_shot_ext *)srcBuffer.addr[srcBuffer.getMetaPlaneIndex()];
            frame->getMetaData(shot_ext, masterNodeIndex);
            if (shot_ext->shot.ctl.stats.faceDetectMode > FACEDETECT_MODE_OFF) {
                masterParamater->getFaceDetectMeta(shot_ext);
                frame->storeDynamicMeta(shot_ext, masterNodeIndex);

#if 0 /* Only debug */
                for (int i = 0; i < NUM_OF_DETECTED_FACES; i++) {
                    if (shot_ext->shot.dm.stats.faceIds[i] <= 0) {
                        continue;
                    }

                    CLOGD("Master: ID %d, faceScores %d, Rectangles %d, %d, %d, %d",
                            shot_ext->shot.dm.stats.faceIds[i],
                            shot_ext->shot.dm.stats.faceScores[i],
                            shot_ext->shot.dm.stats.faceRectangles[i][0],
                            shot_ext->shot.dm.stats.faceRectangles[i][1],
                            shot_ext->shot.dm.stats.faceRectangles[i][2],
                            shot_ext->shot.dm.stats.faceRectangles[i][3]);
                }
#endif
            }
        }
    }

    if (slaveParamater != NULL
        && (slaveParamater->getHwConnectionMode(PIPE_MCSC, PIPE_VRA) == HW_CONNECTION_MODE_M2M
            || slaveParamater->getHwConnectionMode(PIPE_3AA, PIPE_VRA) == HW_CONNECTION_MODE_M2M)) {
        ExynosCameraBuffer srcBuffer;

        ret = frame->getSrcBuffer(pipeId, &srcBuffer, slaveNodeIndex);
        if (ret != NO_ERROR || srcBuffer.index < 0) {
            CLOGE("[F%d B%d]Failed to getSrcBuffer. pipeId %d, ret %d",
                        frame->getFrameCount(), srcBuffer.index, pipeId, ret);
        } else {
            camera2_shot_ext *shot_ext = (camera2_shot_ext *)srcBuffer.addr[srcBuffer.getMetaPlaneIndex()];;
            frame->getMetaData(shot_ext, slaveNodeIndex);
            if (shot_ext->shot.ctl.stats.faceDetectMode > FACEDETECT_MODE_OFF) {
                slaveParamater->getFaceDetectMeta(shot_ext);
                frame->storeDynamicMeta(shot_ext, slaveNodeIndex);

#if 0 /* Only debug */
                for (int i = 0; i < NUM_OF_DETECTED_FACES; i++) {
                    if (shot_ext->shot.dm.stats.faceIds[i] <= 0) {
                        continue;
                    }

                    CLOGD("Slave: ID %d, faceScores %d, Rectangles %d, %d, %d, %d",
                            shot_ext->shot.dm.stats.faceIds[i],
                            shot_ext->shot.dm.stats.faceScores[i],
                            shot_ext->shot.dm.stats.faceRectangles[i][0],
                            shot_ext->shot.dm.stats.faceRectangles[i][1],
                            shot_ext->shot.dm.stats.faceRectangles[i][2],
                            shot_ext->shot.dm.stats.faceRectangles[i][3]);
                }
#endif
            }
        }
    }

    return NO_ERROR;
}

status_t ExynosCamera::m_updateAfterDualSolution(ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;

    /* set N-1 zoomRatio in Frame */
    if (m_configurations->getAppliedZoomRatio() < 1.0f) {
        frame->setAppliedZoomRatio(frame->getZoomRatio());
    } else {
        frame->setAppliedZoomRatio(m_configurations->getAppliedZoomRatio());
    }

    {
        m_configurations->setAppliedZoomRatio(frame->getZoomRatio());
    }

    if (m_configurations->getDualOperationMode()  == DUAL_OPERATION_MODE_SYNC
            && frame->getFrameType() == FRAME_TYPE_PREVIEW_DUAL_MASTER) {
        bool cond = true;
        bool fusionReady = false;

        // TODO: Check fusion capture condition like lux and focusdistance
        //       Or HAL can get the result of cond from plugIn
        // const struct camera2_shot_ext *shot_ext1 = frame->getConstMeta(OUTPUT_NODE_1);
        // const struct camera2_shot_ext *shot_ext2 = frame->getConstMeta(OUTPUT_NODE_2);

        // default always true
        if (cond) {
            fusionReady = true;
        }

        m_configurations->setModeValue(CONFIGURATION_FUSION_CAPTURE_READY, (int)fusionReady);
    }

    return ret;
}
#endif

void ExynosCamera::m_getMcscOutputBufferSize(int *width, int *height)
{
    m_configurations->getSize(CONFIGURATION_VIDEO_SIZE, (uint32_t *)width, (uint32_t *)height);

#ifdef USES_COMBINE_PLUGIN
    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
        int tWidth = 0, tHeight = 0;
        int port = m_parameters[m_cameraId]->getPreviewPortId();

        m_configurations->getSize(CONFIGURATION_MAX_HW_YUV_PORT_SIZE,
                (uint32_t *)&tWidth, (uint32_t *)&tHeight, port);

        if ((tWidth * tHeight) > ((*width) * (*height))) {
            *width = tWidth;
            *height = tHeight;
        }
    }
#endif

#ifdef USES_SW_VDIS
    if (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE) == true) {
        int tWidth = 0, tHeight = 0;
        m_exCameraSolutionSWVdis->getSize(tWidth, tHeight);
        if ((tWidth * tHeight) > ((*width) * (*height))) {
            *width = tWidth;
            *height = tHeight;
        }
    } else
#endif
    {
#ifdef USE_DUAL_CAMERA
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
                && m_flagVideoStreamPriority == true) {
            int tWidth = 0, tHeight = 0;
            m_configurations->getSize(CONFIGURATION_MAX_HW_YUV_PORT_SIZE,
                    (uint32_t *)&tWidth, (uint32_t *)&tHeight,
                    m_parameters[m_cameraId]->getPreviewPortId());
            if ((tWidth * tHeight) > ((*width) * (*height))) {
                *width = tWidth;
                *height = tHeight;
            }
        }
#endif
    }
}

status_t ExynosCamera::m_setVendorBuffers()
{
    status_t ret = NO_ERROR;

    int width = 0, height = 0;
    int planeCount = 0;
    int buffer_count = 0;
    bool needMmap = false;
    int format = 0;
    exynos_camera_buffer_type_t buffer_type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE;
    buffer_manager_allocation_mode_t allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;

#ifdef USES_SW_VDIS
    if (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE) == true) {
        m_exCameraSolutionSWVdis->setBuffer(m_bufferSupplier);
    }
#endif

    m_getMcscOutputBufferSize(&width, &height);

#ifdef USES_COMBINE_PLUGIN
    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
        buffer_count = m_exynosconfig->current->bufInfo.num_request_preview_buffers;
        planeCount = 3;
        needMmap = true;
    }
#endif

#ifdef USES_SW_VDIS
    if (m_configurations->getMode(CONFIGURATION_VIDEO_STABILIZATION_MODE) == true) {
        buffer_count = NUM_SW_VDIS_INTERNAL_BUFFERS;
        planeCount = 3;
        needMmap = true;
    } else
#endif
    {
#ifdef USE_DUAL_CAMERA
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
                && m_flagVideoStreamPriority == true) {
            planeCount = 3;
            buffer_count = m_exynosconfig->current->bufInfo.num_request_video_buffers;
            needMmap = true;
        }
#endif
    }

#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
    if (m_configurations->getSecondPortId() > -1) {
        int streamId =  m_streamManager->getYuvStreamId(m_configurations->getOnePortId());
        format = m_configurations->getYuvFormat(m_configurations->getOnePortId());
        planeCount =  getYuvPlaneCount(format) + 1;
        m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&width, (uint32_t *)&height, m_configurations->getOnePortId());
        if (streamId == HAL_STREAM_ID_PREVIEW) {
            buffer_count = m_exynosconfig->current->bufInfo.num_request_preview_buffers;
        } else if (streamId == HAL_STREAM_ID_VIDEO){
            buffer_count = m_exynosconfig->current->bufInfo.num_request_video_buffers;
        } else if (streamId == HAL_STREAM_ID_CALLBACK) {
            buffer_count = m_exynosconfig->current->bufInfo.num_request_callback_buffers;
        } else {
            planeCount = 0;
            buffer_count = 0;
            CLOGE("not supported streamId(%d) for MCSC_OUT_BUF", streamId);
        }
        needMmap = true;
    }
#endif

    CLOGD("MCSC_OUT_BUF width x height = %d x %d, buffer count: %d, planeCount: %d", width, height, buffer_count, planeCount);

    if (buffer_count > 0) {
        const buffer_manager_tag_t initBufTag;
        const buffer_manager_configuration_t initBufConfig;
        buffer_manager_configuration_t bufConfig;
        buffer_manager_tag_t bufTag;

        bufTag = initBufTag;
#ifdef USE_DUAL_CAMERA
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
            && m_configurations->getDynamicMode(DYNAMIC_DUAL_FORCE_SWITCHING) == false) {
            bufTag.pipeId[0] = PIPE_FUSION;
        } else
#endif

#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
        if (m_configurations->getSecondPortId() > -1) {
            bufTag.pipeId[0] = (m_configurations->getOnePortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
            bufTag.pipeId[1] = PIPE_SW_MCSC;
#ifdef SUPPORT_HW_GDC
            if (m_configurations->getOnePortId() == m_streamManager->getOutputPortId(HAL_STREAM_ID_VIDEO)) {
                bufTag.pipeId[2] = PIPE_GDC;
            }
#endif
        } else
#endif

        {
            bufTag.pipeId[0] = PIPE_MCSC0;
            bufTag.pipeId[1] = PIPE_MCSC1;
            bufTag.pipeId[2] = PIPE_MCSC2;
#ifdef USES_SW_VDIS
            bufTag.pipeId[3] = PIPE_VDIS;
#endif
#ifdef USE_CLAHE_PREVIEW
            bufTag.pipeId[4] = PIPE_CLAHE;
#endif
        }
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->createBufferManager("MCSC_OUT_BUF", m_ionAllocator, bufTag);
        if (ret != NO_ERROR) {
            CLOGE("Failed to create MCSC_OUT_BUF. ret %d", ret);
            return ret;
        }

        bufConfig = initBufConfig;
        bufConfig.planeCount = planeCount;
        /*
        bufConfig.size[0] = width * height;
        bufConfig.size[1] = width * height / 2;
        */
        switch (format) {
            case V4L2_PIX_FMT_NV21M:
                bufConfig.size[0] = width * height;
                bufConfig.size[1] = width * height / 2;
                break;
            case V4L2_PIX_FMT_NV21:
                bufConfig.size[0] = width * height * 3 / 2;
                break;
            default:
                bufConfig.size[0] = width * height;
                bufConfig.size[1] = width * height / 2;
                break;
        }
        bufConfig.reqBufCount = buffer_count;
        bufConfig.allowedMaxBufCount = buffer_count;
        bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
        bufConfig.type = buffer_type;
        bufConfig.allocMode = allocMode;
        bufConfig.createMetaPlane = true;
        bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
        bufConfig.needMmap = needMmap;
        bufConfig.reservedMemoryCount = 0;
        bufConfig.debugInfo = {width, height, 0};

#ifdef ADAPTIVE_RESERVED_MEMORY
        ret = m_addAdaptiveBufferInfos(bufTag, bufConfig, BUF_PRIORITY_MCSC_OUT, BUF_TYPE_VENDOR);
        if (ret != NO_ERROR) {
            CLOGE("Failed to add MCSC_OUT_BUF. ret %d", ret);
            return ret;
        }
#else
        ret = m_allocBuffers(bufTag, bufConfig);
        if (ret != NO_ERROR) {
            CLOGE("Failed to alloc MCSC_OUT_BUF. ret %d", ret);
            return ret;
        }
#endif

        CLOGI("m_allocBuffers(MCSC_OUT_BUF) %d x %d,\
            planeSize(%d), planeCount(%d), maxBufferCount(%d)",
            width, height,
            bufConfig.size[0], bufConfig.planeCount, buffer_count);
    }

    return ret;
}

status_t ExynosCamera::m_setSensorGyroBuffers(int numOfBuf)
{
    status_t ret = NO_ERROR;

    if (m_flagSensorGyroBuffersAlloc() == true) {
        CLOGV("SENSOR_GYRO_BUF is already allocated. so, skip");
        return ret;
    }

    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;

    int hwSensorGyroW = 0;
    int hwSensorGyroH = 0;

    ret = m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_GYRO_SIZE, (uint32_t *)&hwSensorGyroW, (uint32_t *)&hwSensorGyroH);
    if (ret != NO_ERROR) {
        CLOGE("getSize(HW_INFO_HW_SENSOR_GYRO_SIZE) fail");
        return ret;
    }

    bufTag.pipeId[0] = m_getSensorGyroPipeId();
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    ret = m_bufferSupplier->createBufferManager("SENSOR_GYRO_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("m_bufferSupplier->createBufferManager(SENSOR_GYRO_BUF, pipeId(%d)) fail", bufTag.pipeId[0]);
        return ret;
    }

    bufConfig.planeCount = 2;
    bufConfig.bytesPerLine[0] = getBayerLineSize(hwSensorGyroW, m_parameters[m_cameraId]->getSensorGyroFormat());
    bufConfig.size[0] = bufConfig.bytesPerLine[0] * hwSensorGyroH;
    bufConfig.reqBufCount = numOfBuf;
    bufConfig.allowedMaxBufCount = numOfBuf;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ATONCE;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_NONCACHED_TYPE;
    bufConfig.debugInfo = {hwSensorGyroW, hwSensorGyroH, m_parameters[m_cameraId]->getSensorGyroFormat()};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("m_allocBuffers(%s) fail", m_bufferSupplier->getName(bufTag));
        return ret;
    }

    CLOGI("m_allocBuffers(SENSOR_GYRO_BUF) %d x %d,\
                      planeSize(%d), planeCount(%d), maxBufferCount(%d)",
                      hwSensorGyroW, hwSensorGyroH,
                      bufConfig.size[0], bufConfig.planeCount, bufConfig.allowedMaxBufCount);

    return ret;
}

bool ExynosCamera::m_flagSensorGyroBuffersAlloc(void)
{
    bool ret = true;

    buffer_manager_tag_t bufTag;

    bufTag.pipeId[0] = m_getSensorGyroPipeId();
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

    char *name = m_bufferSupplier->getName(bufTag);
    if (name == NULL) {
        CLOGD("Gyro buffer is not alloced. so, alloc now.");
        ret = false;
    }

    return ret;
}

void ExynosCamera::m_checkUseOnePort()
{
    m_flagUseOnePort = false;

#ifdef USE_DUAL_CAMERA
    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
        m_flagUseOnePort = true;
    }
#endif

#ifdef USES_COMBINE_PLUGIN
    if (m_configurations->getModeValue(CONFIGURATION_COMBINE_PREVIEW_PLUGIN_VALUE) > 0) {
#ifdef SUPPORT_PREVIEW_PLUGIN_YUV_STREAM
        m_flagUseOnePort = true;
#else
        // use oneport in case of recording mode
        if (m_configurations->getMode(CONFIGURATION_RECORDING_MODE) == true) {
            m_flagUseOnePort = true;
        }
#endif
    }
#endif

#ifdef USES_SW_VDIS
    if (m_configurations->getModeValue(CONFIGURATION_VIDEO_STABILIZATION_ENABLE) > 0) {
        m_flagUseOnePort = true;
    }
#endif
#if defined(NUM_OF_MCSC_OUTPUT_PORTS) && (NUM_OF_MCSC_OUTPUT_PORTS == 1)
    {
        m_flagUseOnePort = true;
    }
#endif

}

void ExynosCamera::m_checkVideoStreamPriority()
{
    if (m_videoStreamExist == true && m_flagUseOnePort == true) {
        int previewW = 0, previewH = 0;
        int recordingW = 0, recordingH = 0;

        m_configurations->getSize(CONFIGURATION_VIDEO_SIZE, (uint32_t *)&recordingW, (uint32_t *)&recordingH);
        m_configurations->getSize(CONFIGURATION_PREVIEW_SIZE, (uint32_t *)&previewW, (uint32_t *)&previewH);

        if ((recordingW > previewW || recordingH > previewH)
            || m_configurations->getMode(CONFIGURATION_HDR_RECORDING_MODE) == true) {
            m_flagVideoStreamPriority = true;
        }
    }
}

bool ExynosCamera::m_compareStreamPriority(int srcStreamId, int dstStreamId)
{
    /* retune true when srcStreamId has a higher priority than dstStreamId */
    if (!m_streamManager->findStream(srcStreamId))
        return false;
    if (!m_streamManager->findStream(dstStreamId))
        return true;

    uint32_t srcWidth = 0, srcHeight = 0, dstWidth = 0, dstHeight = 0;

    ExynosCameraStream *srcStream, *dstStream;
    m_streamManager->getStream(srcStreamId, &srcStream);
    m_streamManager->getStream(dstStreamId, &dstStream);
    srcStream->getSize(&srcWidth, &srcHeight);
    dstStream->getSize(&dstWidth, &dstHeight);
    CLOGV("srcStreamId(%d), srcWidth(%d), srcHeight(%d), dstStreamId(%d), dstWidth(%d), dstHeight(%d)",
            srcStreamId, srcWidth, srcHeight, dstStreamId, dstWidth, dstHeight);

    if (srcWidth > dstWidth || srcHeight > dstHeight)
        return true;
    else
        return false;
}

void ExynosCamera::m_initLockFrameHoldCount()
{
    status_t ret = NO_ERROR;
    int oldBayerKeepCount = 0;

    CLOGD("");

    if (m_configurations->getMode(CONFIGURATION_DYNAMIC_BAYER_MODE) == true) {
        CLOGV("not supprot old bayer keep when dynamic bayer mode");
        return;
    }

    /*
     * need to Vendor condition
     * ex) oldBayerKeepCount = getMaxOldBayerKeepCountVendor();
     */

#ifdef MAX_OLD_BAYER_KEEP_COUNT
    oldBayerKeepCount = MAX_OLD_BAYER_KEEP_COUNT;
#endif

    m_configurations->setModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE, oldBayerKeepCount);

    for (int slave_idx = 0; slave_idx < m_camIdInfo.numOfSensors; slave_idx++) {
        ret = m_captureSelector[m_cameraIds[slave_idx]]->initLockFrameHoldCount(oldBayerKeepCount);
        if (ret != NO_ERROR) {
            CLOGE("initLockFrameHoldCount is fail. ret = %d", ret);
            return;
        }

        m_parameters[m_cameraIds[slave_idx]]->setBayerFrameLockCount(0, 0);
    }
}

status_t ExynosCamera::m_checkLockFrameHoldCount(frame_handle_components_t &components)
{
    status_t ret = NO_ERROR;

    components.captureSelector->setBayerFrameLock(components.parameters->getBayerFrameLock());

    int oldBayerMaxCount = m_configurations->getModeValue(CONFIGURATION_MAX_OLD_BAYER_KEEP_VALUE);
    int oldBayerCount = components.parameters->getOldBayerFrameLockCount();
    if (oldBayerMaxCount < oldBayerCount) {
        CLOGE("oldBayerCount(%d) cannot be larger than oldBayerMaxCount(%d).",
                oldBayerCount, oldBayerMaxCount);
        return BAD_VALUE;
    }

#ifdef MAX_OLD_BAYER_KEEP_COUNT
    if (components.captureSelector->getLockFrameHoldCount() == MAX_OLD_BAYER_KEEP_COUNT) {
        if ( oldBayerCount != MAX_OLD_BAYER_KEEP_COUNT ) {
            CLOGW("Can't change lockFrameHoldCount(%d) by setting as oldBayerCount(%d)",
                    MAX_OLD_BAYER_KEEP_COUNT, oldBayerCount);
        }
    } else
#endif
    {
        ret = components.captureSelector->setLockFrameHoldCount(oldBayerCount);
        if (ret != NO_ERROR) {
            CLOGE("setLockFrameHoldCount is fail. ret = %d", ret);
            return ret;
        }
    }

    if (oldBayerCount == 0) {
        ret = components.captureSelector->unlockFrameList();
        if (ret != NO_ERROR) {
            CLOGE("unlockFrameList is fail. ret = %d", ret);
            return ret;
        }
    }

    if (components.parameters->getNewBayerFrameLockCount() > 0) {
        ret = components.captureSelector->setFrameHoldCount(components.parameters->getNewBayerFrameLockCount());
        if (ret != NO_ERROR) {
            CLOGE("setsetFrameHoldCount is fail. ret = %d", ret);
            return ret;
        }
    }

    return ret;
}

status_t ExynosCamera::m_setupPreviewGSC(ExynosCameraFrameSP_sptr_t frame,
                                         ExynosCameraRequestSP_sprt_t request,
                                         int pipeId, int subPipeId, bool useDstBuffer,
                                         int pp_scenario)
{
    UNUSED_VARIABLE(pp_scenario);

    status_t ret = NO_ERROR;
    int gscPipeId = PIPE_GSC;
    struct camera2_stream *shot_stream = NULL;
    struct camera2_shot_ext *shot_ext = NULL;
    ExynosCameraBuffer dstBuffer;
    ExynosCameraBuffer srcBuffer;
    ExynosRect srcRect;
    ExynosRect dstRect;
    frame_handle_components_t components;

    if (frame == NULL) {
        CLOGE("frame is NULL");
        /* TODO: doing exception handling */
        return BAD_VALUE;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);
    ExynosCameraFrameFactory *factory = components.previewFactory;

    int colorFormat = V4L2_PIX_FMT_NV21M;
    int portId = components.parameters->getPreviewPortId();

    int inYuvSizeW = 0, inYuvSizeH = 0;
    int outYuvSizeW = 0, outYuvSizeH = 0;
    int dstSizeW = 0, dstSizeH = 0;
    int start_x = 0, start_y = 0;

    if (m_flagVideoStreamPriority == true || m_videoStreamExist == false) {
        m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&dstSizeW, (uint32_t *)&dstSizeH, portId);
    } else {
        m_configurations->getSize(CONFIGURATION_VIDEO_SIZE, (uint32_t *)&dstSizeW, (uint32_t *)&dstSizeH);
    }

    //set srcBuffer
    if (useDstBuffer) {
        ret = frame->getDstBuffer(pipeId, &srcBuffer, factory->getNodeType(subPipeId));
    } else {
        ret = frame->getSrcBuffer(pipeId, &srcBuffer, factory->getNodeType(subPipeId));
    }

    if (ret != NO_ERROR || srcBuffer.index < 0) {
        CLOGE("Failed to get SRC buffer or DST Buffer(%d). pipeId %d bufferIndex %d frameCount %d ret %d",
                useDstBuffer, subPipeId, srcBuffer.index, frame->getFrameCount(), ret);
        return ret;
    }

    shot_stream = (struct camera2_stream *)(srcBuffer.addr[srcBuffer.getMetaPlaneIndex()]);
    if (shot_stream != NULL) {
        CLOGV("(%d %d %d %d)",
                shot_stream->fcount,
                shot_stream->rcount,
                shot_stream->findex,
                shot_stream->fvalid);
        CLOGV("(%d %d %d %d)(%d %d %d %d)",
                shot_stream->input_crop_region[0],
                shot_stream->input_crop_region[1],
                shot_stream->input_crop_region[2],
                shot_stream->input_crop_region[3],
                shot_stream->output_crop_region[0],
                shot_stream->output_crop_region[1],
                shot_stream->output_crop_region[2],
                shot_stream->output_crop_region[3]);
    } else {
        CLOGE("shot_stream is NULL");
        return INVALID_OPERATION;
    }

    inYuvSizeW = outYuvSizeW = shot_stream->output_crop_region[2];
    inYuvSizeH = outYuvSizeH = shot_stream->output_crop_region[3];

    srcRect.x = start_x;
    srcRect.y = start_y;
    srcRect.w = outYuvSizeW;
    srcRect.h = outYuvSizeH;
    srcRect.fullW = inYuvSizeW;
    srcRect.fullH = inYuvSizeH;
    srcRect.colorFormat = colorFormat;

    ret = frame->setSrcRect(gscPipeId, srcRect);
    if (ret != NO_ERROR) {
        CLOGE("setSrcRect(Pipe:%d) failed, Fcount(%d), ret(%d)",
                gscPipeId, frame->getFrameCount(), ret);
    }

    //set dstBuffer
    ret = frame->getDstBuffer(PIPE_GSC, &dstBuffer);
    if (ret != NO_ERROR || dstBuffer.index < 0) {
        CLOGE("GSC Failed to get Output Buffer. ret %d", ret);
        ret = INVALID_OPERATION;
        return ret;
    }

    dstRect.x = 0;
    dstRect.y = 0;
    dstRect.w = dstSizeW;
    dstRect.h = dstSizeH;
    dstRect.fullW = dstSizeW;
    dstRect.fullH = dstSizeH;
    dstRect.colorFormat = colorFormat;
    if (dstBuffer.planeCount == 2) {
        dstRect.colorFormat = V4L2_PIX_FMT_NV21;
    } else {
        dstRect.colorFormat = colorFormat;
    }

    ret = frame->setDstRect(gscPipeId, dstRect);
    if (ret != NO_ERROR) {
        CLOGE("setDstRect(Pipe:%d) failed, Fcount(%d), ret(%d)",
                gscPipeId, frame->getFrameCount(), ret);
    }

    CLOGV("GSC input  buffer idx %d, addrY 0x%p fdY %d\n", srcBuffer.index, srcBuffer.addr[0], srcBuffer.fd[0]);
    CLOGV("GSC output buffer idx %d, addrY 0x%p fdY %d\n", dstBuffer.index, dstBuffer.addr[0], dstBuffer.fd[0]);

    ret = m_setupEntity(gscPipeId, frame, &srcBuffer, &dstBuffer);
    if (ret < 0) {
        CLOGE("setupEntity fail, pipeId(%d), ret(%d)", gscPipeId, ret);
    }

    shot_ext = (struct camera2_shot_ext *) srcBuffer.addr[srcBuffer.getMetaPlaneIndex()];
    if (request != NULL) {
        shot_ext->shot.udm.sensor.timeStampBoot = request->getSensorTimestamp();
    }

    return ret;
}
#ifdef USE_DUAL_CAMERA
bool ExynosCamera::m_gscPreviewCbThreadFunc(void)
{
    bool loop = true;

    int dstPipeId = -1;
    int srcStreamId = 0;   /* GSC SRC */
    int dstStreamId = 0;    /* GSC DST */
    int callbackId = 0;
    uint32_t nodeType = 0;

    status_t ret = NO_ERROR;
    ExynosCameraFrameSP_sptr_t frame = NULL;
    ExynosCameraBuffer buffer;

    ExynosCameraFrameFactory *factory = m_frameFactory[FRAME_FACTORY_TYPE_CAPTURE_PREVIEW];
    ExynosCameraRequestSP_sprt_t request = NULL;
    entity_buffer_state_t bufferState;
    camera3_buffer_status_t streamBufferState = CAMERA3_BUFFER_STATUS_OK;
    frame_handle_components_t components;
    enum DUAL_PREVIEW_MODE dualPreviewMode = m_configurations->getDualPreviewMode();

    buffer.index = -2;

    ret = m_pipeFrameDoneQ[PIPE_GSC]->waitAndPopProcessQ(&frame);
    if (ret == TIMED_OUT && m_pipeFrameDoneQ[PIPE_GSC]->getSizeOfProcessQ() > 0) {
        return true;
    } else if (ret < 0 || ret == TIMED_OUT) {
        CLOGW("GSC Failed to waitAndPopProcessQ. ret %d", ret);
        return false;
    }

    if (frame == NULL) {
        CLOGE("GSC frame is NULL");
        return false;
    }

    m_getFrameHandleComponentsWrapper(frame, &components);
    factory = components.previewFactory;

    request = m_requestMgr->getRunningRequest(frame->getFrameCount());
    if (request == NULL) {
        CLOGE("GSC getRequest failed ");
        goto CLEAN;
    }

    if (m_videoStreamExist == true) {
        if (m_flagVideoStreamPriority == true) {
            srcStreamId = HAL_STREAM_ID_VIDEO;
            dstStreamId = HAL_STREAM_ID_PREVIEW;
        } else {
            srcStreamId = HAL_STREAM_ID_PREVIEW;
            dstStreamId = HAL_STREAM_ID_VIDEO;
        }
    } else {
        if (request->hasStream(HAL_STREAM_ID_PREVIEW) == true) {
            dstStreamId = HAL_STREAM_ID_PREVIEW;
        } else if(request->hasStream(HAL_STREAM_ID_CALLBACK) == true) {
            dstStreamId = HAL_STREAM_ID_CALLBACK;
        }
    }

    if (request->hasStream(HAL_STREAM_ID_CALLBACK_CPY) == true) {
        callbackId = HAL_STREAM_ID_CALLBACK_CPY;
    } else if (request->hasStream(HAL_STREAM_ID_CALLBACK) == true) {
        callbackId = HAL_STREAM_ID_CALLBACK;
    }

    if (request->hasStream(dstStreamId) == true) {
        dstPipeId = PIPE_GSC;

        ret = frame->getDstBuffer(dstPipeId, &buffer);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("Failed to get GSC buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                dstPipeId, buffer.index, frame->getFrameCount(), ret);
            goto CLEAN;
        }

        ret = frame->getDstBufferState(dstPipeId, &bufferState);
        if (ret < 0) {
            CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", dstPipeId, ret);
            goto CLEAN;
        }

        if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
            CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                    buffer.index, frame->getFrameCount(), dstPipeId);
        }

        if (request != NULL && request->hasStream(dstStreamId) == true) {
            if (dstStreamId == HAL_STREAM_ID_PREVIEW && callbackId > 0) {
                if ((m_flagUseOnePort && m_videoStreamExist)
                    || m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION
                ) {
                    request->setStreamBufferStatus(callbackId, streamBufferState);
                    m_copyPreviewCbThreadFunc(request, frame, &buffer);
                }
            }

            request->setStreamBufferStatus(dstStreamId, streamBufferState);

            ret = m_sendYuvStreamResult(frame, request, &buffer, dstStreamId, frame->isSkipPreview(),
                                        frame->getStreamTimestamp(), frame->getParameters());
            if (ret != NO_ERROR) {
                CLOGE("Failed to resultCallback."
                        " pipeId %d bufferIndex %d frameCount %d streamId %d ret %d",
                        dstPipeId, buffer.index, frame->getFrameCount(), dstStreamId, ret);
                goto CLEAN;
            }
        } else {
            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index, dstPipeId, ret);
                }
            }
        }

        if (srcStreamId == 0
            && dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION
            && frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
            ret = frame->getSrcBuffer(PIPE_GSC, &buffer);
            if (ret != NO_ERROR || buffer.index < 0) {
                CLOGE("Failed to get GSC buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                    PIPE_GSC, buffer.index, frame->getFrameCount(), ret);
                goto CLEAN;
            }

            ret = frame->getSrcBufferState(PIPE_GSC, &bufferState);
            if (ret < 0) {
                CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", PIPE_GSC, ret);
                goto CLEAN;
            }

            if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
                streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                CLOGE("Dst buffer state is error index(%d), framecount(%d), pipeId(%d)",
                        buffer.index, frame->getFrameCount(), PIPE_GSC);
            }

            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index, PIPE_GSC, ret);
                }
            }
        }
    }

    if (request->hasStream(srcStreamId) == true) {
        if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
            if (frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                    dstPipeId = PIPE_ISP;
                } else {
                    dstPipeId = PIPE_3AA;
                }

                if (components.parameters->getAlternativePreviewPortId() >= 0) {
                    nodeType = factory->getNodeType(components.parameters->getAlternativePreviewPortId() + PIPE_MCSC0);
                } else {
                    nodeType = factory->getNodeType(components.parameters->getPreviewPortId() + PIPE_MCSC0);
                }
            } else {
                dstPipeId = PIPE_FUSION;
            }
        }

        streamBufferState = CAMERA3_BUFFER_STATUS_OK;

        buffer.index = -2;
        ret = frame->getDstBuffer(dstPipeId, &buffer, nodeType);
        if (ret != NO_ERROR || buffer.index < 0) {
            CLOGE("Failed to get DST buffer. pipeId %d bufferIndex %d frameCount %d ret %d",
                dstPipeId, buffer.index, frame->getFrameCount(), ret);
            goto CLEAN;
        }

        ret = frame->getDstBufferState(dstPipeId, &bufferState, nodeType);
        if (ret < 0) {
            CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", dstPipeId, ret);
            goto CLEAN;
        }

        if (bufferState == ENTITY_BUFFER_STATE_ERROR) {
            streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
        }

        if (request != NULL && request->hasStream(srcStreamId) == true) {
            if (srcStreamId == HAL_STREAM_ID_PREVIEW
                && callbackId > 0
                && dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION
                ) {
                request->setStreamBufferStatus(callbackId, streamBufferState);
                m_copyPreviewCbThreadFunc(request, frame, &buffer);
            }

            request->setStreamBufferStatus(srcStreamId, streamBufferState);

            ret = m_sendYuvStreamResult(frame, request, &buffer, srcStreamId, frame->isSkipPreview(),
                                        frame->getStreamTimestamp(), frame->getParameters());
            if (ret != NO_ERROR) {
                CLOGE("Failed to resultCallback."
                        " pipeId %d bufferIndex %d frameCount %d streamId %d ret %d",
                        dstPipeId, buffer.index, frame->getFrameCount(), srcStreamId, ret);
                goto CLEAN;
            }
        } else {
            if (buffer.index >= 0) {
                ret = m_bufferSupplier->putBuffer(buffer);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d B%d]PutBuffers failed. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index, dstPipeId, ret);
                }
            }
        }
    }

CLEAN:
    if (frame->getInternalBufTagPipeId() >= 0) {
        /* GSC input buffer */
        ExynosRect rect;
        int pipeId;
        int nodePipeId = PIPE_MCSC0 + components.parameters->getPreviewPortId();
        ExynosCameraBuffer inBuffer;

        if (dualPreviewMode == DUAL_PREVIEW_MODE_SW_FUSION) {
            if (frame->getMode(FRAME_MODE_DUAL_ZOOM_SOLUTION) == DISABLE) {
                if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                    pipeId = PIPE_ISP;
                } else {
                    pipeId = PIPE_3AA;
                }

                int alternativePreviewPortId = components.parameters->getAlternativePreviewPortId();

                if (alternativePreviewPortId >= 0) {
                    nodePipeId = alternativePreviewPortId + PIPE_MCSC0;
                } else if (dstStreamId == HAL_STREAM_ID_CALLBACK) {
                    nodePipeId = components.parameters->getPreviewCbPortId() + PIPE_MCSC0;
                }
            } else {
                pipeId = PIPE_FUSION;
                nodePipeId = PIPE_FUSION;
            }
        } else {
            if (components.parameters->getHwConnectionMode(PIPE_3AA, PIPE_ISP) == HW_CONNECTION_MODE_M2M) {
                pipeId = PIPE_ISP;
            } else {
                pipeId = PIPE_3AA;
            }
        }

        inBuffer.index = -2;
        ret = frame->getDstBuffer(pipeId, &inBuffer, factory->getNodeType(nodePipeId));
        if (ret != NO_ERROR) {
            CLOGE("Failed to get GSC input buffer");
        }

        if (inBuffer.index >= 0) {
            ret = m_bufferSupplier->putBuffer(inBuffer);
            if (ret != NO_ERROR) {
                CLOGE("Failed to putBuffer. ret %d", ret);
            }
        }
    }

    if (frame != NULL) {
        CLOGV("GSC frame delete. framecount %d", frame->getFrameCount());
        frame = NULL;
    }

    return loop;
}

status_t ExynosCamera::m_createBokehSuperNightShotBayerAnchorFrame(ExynosCameraRequestSP_sprt_t request,
                                                                                ExynosCameraFrameFactory *targetfactory,
                                                                                frame_type_t internalframeType,
                                                                                map<int, int> scenarioList,
                                                                                frame_handle_components_t components,
                                                                                frame_queue_t *selectBayerQ,
                                                                                sp<mainCameraThread> selectBayerThread,
                                                                                int captureCount)
{
    status_t ret = NO_ERROR;
    ExynosCameraFrameSP_sptr_t prepareAnchorFrame = NULL;
    const int prepareAnchorFrameNum = getBokehPrepareAnchorNum();
    bool masterCam = ((internalframeType == FRAME_TYPE_INTERNAL) ? true : false);

    if (masterCam == true) {
        m_prepareBokehAnchorMasterFrames.clear();
    } else {
        m_prepareBokehAnchorSlaveFrames.clear();
    }

    for (int i = 0; i < prepareAnchorFrameNum; i++) {
        ret = m_generateInternalFrame(targetfactory, &m_captureProcessList,
                &m_captureProcessLock, prepareAnchorFrame, internalframeType);
        if (ret != NO_ERROR) {
            CLOGE("m_generateInternalFrame fail");
            return ret;
        } else if (prepareAnchorFrame == NULL) {
            CLOGE("new faame is NULL");
            return INVALID_OPERATION;
        }

        prepareAnchorFrame->setStreamRequested(STREAM_TYPE_RAW, true);
        prepareAnchorFrame->setStreamRequested(STREAM_TYPE_YUVCB_STALL, false);
        prepareAnchorFrame->setStreamRequested(STREAM_TYPE_THUMBNAIL_CB, false);
        prepareAnchorFrame->setStreamRequested(STREAM_TYPE_CAPTURE, false);
        prepareAnchorFrame->setStreamRequested(STREAM_TYPE_ZSL_YUV_INPUT, false);

        prepareAnchorFrame->setFrameIndex(i);
        prepareAnchorFrame->setMaxFrameIndex(prepareAnchorFrameNum);
        prepareAnchorFrame->setMode(FRAME_MODE_DUAL_BOKEH_ANCHOR, true);
        prepareAnchorFrame->setMode(FRAME_MODE_MF_STILL, true);
        prepareAnchorFrame->setDualOperationMode(DUAL_OPERATION_MODE_SYNC);
        prepareAnchorFrame->setFallbackOn(m_configurations->isFallbackOn());

        ret = prepareAnchorFrame->setMetaData(m_currentCaptureShot[components.currentCameraId]);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Set metadata to frame fail, ret(%d)",
                    prepareAnchorFrame->getFrameCount(), ret);
        }

        ret = prepareAnchorFrame->setVendorMeta(request->getVendorMeta());
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Set vendor metadata to frame fail, ret(%d)",
                    prepareAnchorFrame->getFrameCount(), ret);
        }

        for (map<int, int>::iterator iter = scenarioList.begin() ; iter != scenarioList.end() ; iter++) {
            prepareAnchorFrame->setPPScenario(iter->first, iter->second);
        }

        CLOGD("[R%d F%d T%d]prepareAnchorFrame generate[%d/%d]",
                request->getKey(), prepareAnchorFrame->getFrameCount(), internalframeType,
                prepareAnchorFrame->getFrameIndex(), prepareAnchorFrame->getMaxFrameIndex());

        if (m_getState() == EXYNOS_CAMERA_STATE_FLUSH) {
            CLOGD("[R%d F%d]Flush is in progress.",
                    request->getKey(), prepareAnchorFrame->getFrameCount());
            /* Generated frame is going to be deleted at flush() */
            return ret;
        }

        selectBayerQ->pushProcessQ(&prepareAnchorFrame);
        if (selectBayerThread != NULL && selectBayerThread->isRunning() == false) {
            selectBayerThread->run();
            CLOGI("Initiate selectBayerThread (%d)", selectBayerThread->getTid());
        }
    }

    int anchorWaitCount = 0;
    const int anchorMaxWaitCount = 10;
    do {
        if (masterCam == true) {
            ret = m_prepareBokehAnchorMasterCaptureDoneQ->waitAndPopProcessQ(&prepareAnchorFrame);
        } else {
            ret = m_prepareBokehAnchorSlaveCaptureDoneQ->waitAndPopProcessQ(&prepareAnchorFrame);
        }
        if (ret != NO_ERROR) {
            if (ret == TIMED_OUT) {
                CLOGD("Wait timeout");
                continue;
            } else {
                CLOGE("Failed to waitAndPopProcessQ. ret %d", ret);
                return ret;
            }
        } else if (prepareAnchorFrame == NULL) {
            CLOGE("prepareAnchorFrame is NULL!!");
            return BAD_VALUE;
        }

        if (prepareAnchorFrame->getFrameIndex() == prepareAnchorFrame->getBokehAnchorFrameIndex()) {
            ExynosCameraFrameSP_sptr_t anchorFrame = NULL;
            const int anchorFrameMaxIndex = 2;
            int anchorFrameIndex = 0;

            ret = m_generateInternalFrame(targetfactory, &m_captureProcessList,
                            &m_captureProcessLock, anchorFrame, internalframeType);
            if (ret != NO_ERROR) {
                CLOGE("m_generateInternalFrame fail");
                return ret;
            } else if (anchorFrame == NULL) {
                CLOGE("new faame is NULL");
                return INVALID_OPERATION;
            }

            anchorFrame->setStreamRequested(STREAM_TYPE_RAW, true);
            anchorFrame->setStreamRequested(STREAM_TYPE_YUVCB_STALL, false);
            anchorFrame->setStreamRequested(STREAM_TYPE_THUMBNAIL_CB, false);
            anchorFrame->setStreamRequested(STREAM_TYPE_CAPTURE, false);
            anchorFrame->setStreamRequested(STREAM_TYPE_ZSL_YUV_INPUT, false);

            anchorFrame->setFrameIndex((masterCam == true) ? anchorFrameIndex + 1 : anchorFrameIndex);
            anchorFrame->setMaxFrameIndex(anchorFrameMaxIndex);
            anchorFrame->setMode(FRAME_MODE_MF_STILL, false);
            anchorFrame->setMode(FRAME_MODE_DUAL_BOKEH_ANCHOR, true);
            anchorFrame->setDualOperationMode(DUAL_OPERATION_MODE_SYNC);
            anchorFrame->setFallbackOn(m_configurations->isFallbackOn());

            ret = anchorFrame->setMetaData(m_currentCaptureShot[components.currentCameraId]);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Set metadata to frame fail, ret(%d)",
                        anchorFrame->getFrameCount(), ret);
            }

            ret = anchorFrame->setVendorMeta(request->getVendorMeta());
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Set vendor metadata to frame fail, ret(%d)",
                        anchorFrame->getFrameCount(), ret);
            }

            for (map<int, int>::iterator iter = scenarioList.begin() ; iter != scenarioList.end() ; iter++) {
                anchorFrame->setPPScenario(iter->first, iter->second);
            }

            ExynosCameraBuffer buffer;
            prepareAnchorFrame->getSrcBuffer(PIPE_ISP_REPROCESSING, &buffer);
            if (ret != NO_ERROR) {
                CLOGE("getSrcBuffer failed. PIPE_ISP_REPROCESSING, ret(%d)", ret);
            } else if (buffer.index >= 0) {
                ret = anchorFrame->setSrcBuffer(PIPE_ISP_REPROCESSING, buffer);
                if (ret != NO_ERROR || buffer.index <= -1) {
                    CLOGE("[F%d B%d]Failed to getDstBuffer. PIPE_ISP_REPROCESSING, ret %d",
                            anchorFrame->getFrameCount(), buffer.index, ret);
                    return ret;
                }
            }

            if (masterCam == true) {
                prepareAnchorFrame->getDstBuffer(PIPE_PLUGIN_PRE1_REPROCESSING, &buffer);
                if (ret != NO_ERROR) {
                    CLOGE("getDstBuffer failed. PIPE_PLUGIN_PRE1_REPROCESSINGG, ret(%d)", ret);
                } else if (buffer.index >= 0) {
                    m_bufferSupplier->putBuffer(buffer);
                    if (ret != NO_ERROR) {
                        CLOGE("[F%d B%d]Failed to putBuffer for JPEG_SRC. ret %d",
                                prepareAnchorFrame->getFrameCount(), buffer.index, ret);
                        return ret;
                    }
                }

                ret = anchorFrame->setEntityState(PIPE_PLUGIN_PRE1_REPROCESSING, ENTITY_STATE_COMPLETE);
                if (ret != NO_ERROR) {
                    CFLOGE(anchorFrame, "set entity state fail, ret(%d)", ret);
                    return ret;
                }
            }

            m_captureQ->pushProcessQ(&anchorFrame);

            CLOGD("[R%d F%d T%d]push to AnchorFrame from [F%d] [%d/%d]",
                    request->getKey(), anchorFrame->getFrameCount(), anchorFrame->getFrameType(),
                    prepareAnchorFrame->getFrameCount(),
                    anchorFrame->getFrameIndex(), anchorFrame->getMaxFrameIndex());
        }

        if (masterCam == true) {
            int pipeId = PIPE_PLUGIN_PRE1_REPROCESSING;

            prepareAnchorFrame->setMode(FRAME_MODE_DUAL_BOKEH_ANCHOR, false);
            prepareAnchorFrame->setDualOperationMode(DUAL_OPERATION_MODE_MASTER);
            prepareAnchorFrame->setFallbackOn(m_configurations->isFallbackOn());
            prepareAnchorFrame->setMaxFrameIndex(captureCount);

            ret = prepareAnchorFrame->setEntityState(pipeId, ENTITY_STATE_REWORK);
            if (ret != NO_ERROR) {
                CFLOGE(prepareAnchorFrame, "set entity state fail, ret(%d)", ret);
                return ret;
            }

            targetfactory->pushFrameToPipe(prepareAnchorFrame, pipeId);
            if (m_bayerStreamThread != NULL && m_bayerStreamThread->isRunning() == false) {
                m_bayerStreamThread->run();
            }

            CLOGD("[R%d F%d T%d]AnchorFrame Rework to normal internal frame[%d/%d]",
                request->getKey(), prepareAnchorFrame->getFrameCount(), prepareAnchorFrame->getFrameType(),
                prepareAnchorFrame->getFrameIndex(), prepareAnchorFrame->getMaxFrameIndex());
        } else {
            if (prepareAnchorFrame->getFrameIndex() != prepareAnchorFrame->getBokehAnchorFrameIndex()) {
                int pipeId = PIPE_ISP_REPROCESSING;

                ret = m_putSrcBuffer(prepareAnchorFrame, pipeId);
                if (ret != NO_ERROR) {
                    CLOGE("[F%d]m_putSrcBuffer(pipeId(%d)) fail", prepareAnchorFrame->getFrameCount(), pipeId);
                }
            }

            prepareAnchorFrame->setFrameState(FRAME_STATE_COMPLETE);

            ret = m_removeFrameFromList(&m_captureProcessList, &m_captureProcessLock, prepareAnchorFrame);
            if (ret != NO_ERROR) {
                CLOGE("[F%d]Failed to removeFrameFromList for captureProcessList. ret %d",
                    prepareAnchorFrame->getFrameCount(), ret);
            }
        }
    } while ((anchorWaitCount++ < anchorMaxWaitCount)
            && ((ret == TIMED_OUT) || (prepareAnchorFrame->getFrameIndex() < prepareAnchorFrameNum - 1)));

    return ret;
}

bool ExynosCamera::m_prepareBokehAnchorCaptureThreadFunc()
{
    ExynosCameraAutoTimer autoTimer(__FUNCTION__);
    ExynosCameraFrameSP_sptr_t prepareAnchorFrame = NULL;
    int anchorFrameMaxIndex = 0;

    status_t ret = NO_ERROR;
    ret = m_prepareBokehAnchorCaptureQ->waitAndPopProcessQ(&prepareAnchorFrame);
    if (ret != NO_ERROR) {
        /* TODO: We need to make timeout duration depends on FPS */
        if (ret == TIMED_OUT) {
            CLOGV("Wait timeout");
        } else {
            CLOGE("Failed to wait&pop captureQ, ret %d", ret);
            /* TODO: doing exception handling */
        }
        goto CLEAN;
    } else if (prepareAnchorFrame == NULL) {
        CLOGE("prepareAnchorFrame is NULL!!");
        goto FUNC_EXIT;
    }

    if (prepareAnchorFrame->getMode(FRAME_MODE_DUAL_BOKEH_ANCHOR) == false) {
        CLOGE("[F%d T%d]This frame is not prepareBokehAnchorFrame.",
                prepareAnchorFrame->getFrameCount(), prepareAnchorFrame->getFrameType());
        goto CLEAN;
    }

    if (prepareAnchorFrame->getFrameType() == FRAME_TYPE_INTERNAL) {
        m_prepareBokehAnchorMasterFrames[prepareAnchorFrame->getFrameIndex()] = prepareAnchorFrame;
    } else if (prepareAnchorFrame->getFrameType() == FRAME_TYPE_INTERNAL_SLAVE){
        m_prepareBokehAnchorSlaveFrames[prepareAnchorFrame->getFrameIndex()] = prepareAnchorFrame;
    } else {
        CLOGE("[F%d T%d]This frame is not prepareBokehAnchorFrame.",
                prepareAnchorFrame->getFrameCount(), prepareAnchorFrame->getFrameType());
        goto CLEAN;
    }

    CFLOGD(prepareAnchorFrame, "Done prepareAnchorFrame[%d/%d]",
            prepareAnchorFrame->getFrameIndex(), prepareAnchorFrame->getMaxFrameIndex());

    anchorFrameMaxIndex = prepareAnchorFrame->getMaxFrameIndex();
    if ((checkLastFrameForMultiFrameCapture(prepareAnchorFrame) == true)
        && (m_prepareBokehAnchorMasterFrames.size() == anchorFrameMaxIndex)
        && (m_prepareBokehAnchorSlaveFrames.size() == anchorFrameMaxIndex)) {
        if (prepareAnchorFrame->getBokehAnchorFrameIndex() < 0) {
            prepareAnchorFrame->setBokehAnchorFrameIndex(0);
            CFLOGE(prepareAnchorFrame, "force set AnchorFrameIndex(%d)",
                    prepareAnchorFrame->getBokehAnchorFrameIndex());
        } else {
            CFLOGV(prepareAnchorFrame, "AnchorFrameIndex(%d)",
                    prepareAnchorFrame->getBokehAnchorFrameIndex());
        }

        for (int i = 0; i < anchorFrameMaxIndex; i++) {
            m_prepareBokehAnchorSlaveFrames[i]->setBokehAnchorFrameIndex(prepareAnchorFrame->getBokehAnchorFrameIndex());
            m_prepareBokehAnchorMasterFrames[i]->setBokehAnchorFrameIndex(prepareAnchorFrame->getBokehAnchorFrameIndex());
            m_prepareBokehAnchorSlaveCaptureDoneQ->pushProcessQ(&m_prepareBokehAnchorSlaveFrames[i]);
            m_prepareBokehAnchorMasterCaptureDoneQ->pushProcessQ(&m_prepareBokehAnchorMasterFrames[i]);
        }

        m_prepareBokehAnchorMasterFrames.clear();
        m_prepareBokehAnchorSlaveFrames.clear();
    }

    /* Thread can exit only if timeout or error occured from inputQ (at CLEAN: label) */
    return true;

CLEAN:
    if (prepareAnchorFrame != NULL && m_getState() != EXYNOS_CAMERA_STATE_FLUSH) {
        ret = m_removeFrameFromList(&m_captureProcessList, &m_captureProcessLock, prepareAnchorFrame);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to removeFrameFromList for captureProcessList. ret %d",
                    prepareAnchorFrame->getFrameCount(), ret);
        }

        CFLOGV(prepareAnchorFrame, "Delete frame from captureProcessList", prepareAnchorFrame->getFrameCount());
        prepareAnchorFrame->printEntity();
        prepareAnchorFrame = NULL;
    }

FUNC_EXIT:
    {
        Mutex::Autolock l(m_captureProcessLock);
        if (m_prepareBokehAnchorCaptureQ->getSizeOfProcessQ() > 0 || m_captureProcessList.size() > 0) {
            CLOGD("prepareBokehAnchorCaptureQ(%d) captureProcessSize(%d)",
                    m_prepareBokehAnchorCaptureQ->getSizeOfProcessQ(), m_captureProcessList.size());
            return true;
        } else {
            return false;
        }
    }
}
#endif

void ExynosCamera::m_updateMasterCam(struct camera2_shot_ext *shot_ext, bool isReprocessing)
{
    if (isReprocessing == true) return;

    int masterCamera = m_cameraIds[MAIN_CAM];
    enum aa_cameraMode cameraMode = AA_CAMERAMODE_SINGLE;

#ifdef USE_DUAL_CAMERA
    switch (m_scenario) {
    case SCENARIO_DUAL_REAR_ZOOM:
        {
            float zoomRatio;
            enum DUAL_OPERATION_MODE opMode;
            enum DUAL_OPERATION_SENSORS opSensor;
            {
                Mutex::Autolock lock(m_dualOperationModeLock);

                opMode = m_earlyDualOperationMode;
                masterCamera = m_earlyMasterCameraId;
            }

            if (opMode == DUAL_OPERATION_MODE_SYNC)
                cameraMode = AA_CAMERAMODE_DUAL_SYNC;

            CLOGV("masterCam(%d), sensorIdx(%d, %d, %d) [%d, %d]",
                    masterCamera, m_cameraIds[MAIN_CAM], m_cameraIds[SUB_CAM], m_cameraIds[SUB_CAM2]);
        }
        break;
    case SCENARIO_DUAL_REAR_PORTRAIT:
    case SCENARIO_DUAL_FRONT_PORTRAIT:
        cameraMode = AA_CAMERAMODE_DUAL_SYNC;
        break;
    default:
        break;
    }
#endif

    shot_ext->shot.uctl.masterCamera = (enum aa_sensorPlace)masterCamera;
    shot_ext->shot.uctl.cameraMode = cameraMode;
}

#ifdef USES_SW_VDIS
status_t ExynosCamera::m_handleVdisFrame(ExynosCameraFrameSP_sptr_t frame,
                                              ExynosCameraRequestSP_sprt_t request,
                                              int pipeId,
                                              ExynosCameraFrameFactory *factory)
{
    status_t ret = NO_ERROR;
    ExynosCameraBuffer buffer;
    camera3_buffer_status_t streamBufferState = CAMERA3_BUFFER_STATUS_OK;
    list<int> streamIdList;
    list<int>::iterator iter;

    if (request->hasStream(HAL_STREAM_ID_VIDEO))
        streamIdList.push_back(HAL_STREAM_ID_VIDEO);
    if (request->hasStream(HAL_STREAM_ID_PREVIEW))
        streamIdList.push_back(HAL_STREAM_ID_PREVIEW);

    int streamId = HAL_STREAM_ID_VIDEO;
    int pos = 0;

    if (m_exCameraSolutionSWVdis != NULL) {
        ret = m_exCameraSolutionSWVdis->handleFrame(ExynosCameraSolutionSWVdis::SOLUTION_PROCESS_POST,
                                                    frame, pipeId,
                                                    (-1),
                                                    factory);

        for(iter = streamIdList.begin(); iter != streamIdList.end() ; iter++) {
            bool skipBuffer = false;
            streamId = *iter;
            if (streamId == HAL_STREAM_ID_VIDEO)
                pos = factory->getNodeType(PIPE_VDIS);
            else if (streamId == HAL_STREAM_ID_PREVIEW)
                pos = factory->getNodeType(PIPE_VDIS_PREVIEW);

            ret = frame->getDstBuffer(pipeId, &buffer, pos);
            if (ret != NO_ERROR) {
                CLOGE("[F%d B%d]Failed to getDstBuffer. pipeId %d ret %d",
                            frame->getFrameCount(), buffer.index, pipeId, ret);
                return ret;
            }

            entity_buffer_state_t bufferState = ENTITY_BUFFER_STATE_NOREQ;
            // HACK: video buffer's state is depanding on src buffer's state
            if (streamId == HAL_STREAM_ID_VIDEO)
                ret = frame->getSrcBufferState(pipeId, &bufferState);
            else if (streamId == HAL_STREAM_ID_PREVIEW)
                ret = frame->getDstBufferState(pipeId, &bufferState);
            if (ret != NO_ERROR) {
                CLOGE("Failed to set DST_BUFFER_STATE to replace target buffer(%d) to release pipeId(%d), ret(%d), frame(%d)",
                            buffer.index, pipeId, ret, frame->getFrameCount());
                return ret;
            }

            if (bufferState != ENTITY_BUFFER_STATE_COMPLETE) {
                //streamBufferState = CAMERA3_BUFFER_STATUS_ERROR;
                skipBuffer = true;
            }

            request->setStreamBufferStatus(streamId, streamBufferState);
            ret = m_sendYuvStreamResult(frame, request, &buffer, streamId, skipBuffer,
                                        frame->getStreamTimestamp(), frame->getParameters());
            if (ret != NO_ERROR) {
                CLOGE("[R%d F%d B%d S%d]Failed to sendYuvStreamResult. ret %d",
                            request->getKey(), frame->getFrameCount(), buffer.index, streamId, ret);
                return ret;
            }
        }
    }

    return ret;
}
#endif //USES_SW_VDIS

#ifdef USES_COMBINE_PLUGIN
status_t ExynosCamera::m_handleCombinePreviewFrame(ExynosCameraFrameSP_sptr_t frame,
                                                   ExynosCameraFrameFactory *factory,
                                                   int srcPipeId, NODE_TYPE srcNodeType, int dstPipeId)
{
    ExynosCameraBuffer srcBuffer, dstBuffer;
    entity_buffer_state_t bufferState;
    int ret = NO_ERROR;

    ret = frame->getDstBuffer(srcPipeId, &srcBuffer, srcNodeType);
    if (ret < 0) {
        CLOGE("getDstBuffer fail, pipeId(%d), ret(%d)", srcPipeId, ret);
    }

    ret = frame->getDstBufferState(srcPipeId, &bufferState, srcNodeType);
    if (ret < 0) {
        CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", srcPipeId, ret);
        return ret;
    }

    if (bufferState == ENTITY_BUFFER_STATE_ERROR || srcBuffer.index < 0) {
        CLOGE("[F%d B%d] src buffer is error. srcPipeId(%d)",
                frame->getFrameCount(), srcBuffer.index, srcPipeId);
        ret = frame->setSrcBufferState(dstPipeId, ENTITY_BUFFER_STATE_ERROR);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                    frame->getFrameCount(), dstPipeId, ret);
        }
        return BAD_VALUE;
    }

    ret = frame->getDstBuffer(dstPipeId, &dstBuffer);
    if (ret != NO_ERROR || dstBuffer.index < 0){
        CLOGV("[F%d B%d] dst buffer is error. But intended code. dstPipeId(%d), ret(%d)",
                frame->getFrameCount(), dstBuffer.index, dstPipeId, ret);
        /*
         * The src buffer of the plugin is output based on the preview stream using the internal MCSC buffer.
         * To ensure that the plugin's src buffer and dst buffer have the same attributes,
         * the dst buffer of the pluing must be set to either the internal MCSC buffer or the service preview buffer.
         * If scaling is required according to the service format, the GSC is used in the next step.
         */
        buffer_manager_tag_t bufTag;
        bufTag.pipeId[0] = PIPE_MCSC0;
        bufTag.pipeId[1] = PIPE_MCSC1;
        bufTag.pipeId[2] = PIPE_MCSC2;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->getBuffer(bufTag, &dstBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[B%d]Failed to getBuffer", dstBuffer.index);
            m_bufferSupplier->dump(bufTag);
            frame->setFrameState(FRAME_STATE_SKIPPED);
        }
    }

    camera2_shot_ext *metaData = (camera2_shot_ext *)srcBuffer.addr[srcBuffer.getMetaPlaneIndex()];
    frame->getMetaData(metaData);
    ExynosCameraParameters *params = frame->getParameters();
    params->getFaceDetectMeta(metaData);
    frame->setDynamicMeta(metaData);

    ret = m_setupEntity(dstPipeId, frame, &srcBuffer, &dstBuffer);
    if (ret != NO_ERROR) {
        CLOGE("setupEntity failed, pipeId(%d), ret(%d)",
                dstPipeId, ret);
    }

    ExynosRect srcRect = convertingBufferDst2Rect(&srcBuffer, m_parameters[m_cameraId]->getHwPreviewFormat());
    ExynosRect dstRect = srcRect;
#ifdef USE_DUAL_CAMERA
    if (m_configurations->getDualPreviewMode() == DUAL_PREVIEW_MODE_SW_FUSION) {
        // only if the fusion size and target size are different
        if (m_scenario == SCENARIO_DUAL_REAR_ZOOM) {
            int onePortId = m_streamManager->getOutputPortIdForDualScenario();
            m_configurations->getSize(CONFIGURATION_YUV_SIZE, (uint32_t *)&dstRect.w, (uint32_t *)&dstRect.h, onePortId);
            dstRect.fullW = dstRect.w;
            dstRect.fullH = dstRect.h;
        }
    }
#endif

    ret = frame->setSrcRect(dstPipeId, srcRect);
    if (ret != NO_ERROR) {
        CLOGE("[F%d] Failed to setSrcRect. PiedId(%d), ret(%d)", frame->getFrameCount(), dstPipeId, ret);
    }
    ret = frame->setDstRect(dstPipeId, dstRect);
    if (ret != NO_ERROR) {
        CLOGE("[F%d] Failed to setDstRect. PipeId(%d), ret(%d)",
                frame->getFrameCount(), dstPipeId, ret);
    }

    if (factory->checkPipeThreadRunning(dstPipeId) == false) {
        factory->startThread(dstPipeId);
    }

    factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[dstPipeId], dstPipeId);
    factory->pushFrameToPipe(frame, dstPipeId);

    return ret;
}
#endif

#if defined(USE_SW_MCSC) && (USE_SW_MCSC == true)
status_t ExynosCamera::m_handleSwmcscPreviewFrame(ExynosCameraFrameSP_sptr_t frame,
                                                   ExynosCameraFrameFactory *factory,
                                                   int srcPipeId, NODE_TYPE srcNodeType, int dstPipeId)
{
    ExynosCameraBuffer srcBuffer, dstBuffer;
    entity_buffer_state_t bufferState;
    int ret = NO_ERROR;

    ret = frame->getDstBuffer(srcPipeId, &srcBuffer, srcNodeType);
    if (ret != NO_ERROR || srcBuffer.index < 0){
        buffer_manager_tag_t bufTag;
        bufTag.pipeId[0] = (m_configurations->getOnePortId() % ExynosCameraParameters::YUV_MAX) + PIPE_MCSC0;
        bufTag.pipeId[1] = PIPE_SW_MCSC;
        bufTag.managerType = BUFFER_MANAGER_ION_TYPE;

        ret = m_bufferSupplier->getBuffer(bufTag, &srcBuffer);
        if (ret != NO_ERROR) {
            CLOGE("[B%d]Failed to getBuffer", srcBuffer.index);
            return BAD_VALUE;
        }
    }

    ret = frame->getDstBufferState(srcPipeId, &bufferState, srcNodeType);
    if (ret < 0) {
        CLOGE("getDstBufferState fail, pipeId(%d), ret(%d)", srcPipeId, ret);
        return ret;
    }

    if (bufferState == ENTITY_BUFFER_STATE_ERROR || srcBuffer.index < 0) {
        CLOGE("[F%d B%d] src buffer is error. srcPipeId(%d)",
                frame->getFrameCount(), srcBuffer.index, srcPipeId);
        ret = frame->setSrcBufferState(dstPipeId, ENTITY_BUFFER_STATE_ERROR);
        if (ret != NO_ERROR) {
            CLOGE("[F%d]Failed to setSrcBufferState into ERROR. pipeId %d ret %d",
                    frame->getFrameCount(), dstPipeId, ret);
        }
        return BAD_VALUE;
    }

    ret = frame->setSrcBuffer(dstPipeId, srcBuffer, factory->getNodeType(dstPipeId));
    if (ret != NO_ERROR) {
        CLOGE("[F%d] setSrcBuffer fail, pipeId(%d), ret(%d)",
                frame->getFrameCount(), dstPipeId, ret);
    }

    if (factory->checkPipeThreadRunning(dstPipeId) == false) {
        factory->startThread(dstPipeId);
    }

    factory->setOutputFrameQToPipe(m_pipeFrameDoneQ[dstPipeId], dstPipeId);
    factory->pushFrameToPipe(frame, dstPipeId);

    return ret;
}
#endif

#ifdef SUPPORT_REMOSAIC_CAPTURE
bool ExynosCamera::m_setRemosaicBuffer(void)
{
    status_t ret = NO_ERROR;
    const buffer_manager_tag_t initBufTag;
    const buffer_manager_configuration_t initBufConfig;
    buffer_manager_tag_t bufTag;
    buffer_manager_configuration_t bufConfig;
    int minBufferCount = 0;
    int maxBufferCount = 0;
    int maxSensorW, maxSensorH;
    int maxPictureW, maxPictureH;
    int pictureFormat = m_parameters[m_cameraId]->getHwPictureFormat();
    auto allocMode = m_configurations->getMode(CONFIGURATION_DYNAMIC_REMOSAIC_BUFFER_ALLOC_MODE);

    m_configurations->getSize(CONFIGURATION_MAX_REMOSAIC_SENSOR_SIZE, (uint32_t *)&maxSensorW, (uint32_t *)&maxSensorH);
    m_configurations->getSize(CONFIGURATION_MAX_REMOSAIC_SENSOR_SIZE, (uint32_t *)&maxPictureW, (uint32_t *)&maxPictureH);

#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    // 1. bayer buffer
    ret = m_setFliteBuffers(true, maxSensorW, maxSensorH);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create flite buf. ret %d", ret);
        return ret;
    }

    if (allocMode == DYNAMIC_REMOSAIC_BUFFER_ALLOC_ON_BAYER) {
        CLOGD("allocation done for only remosaic bayer buffers");
        return ret;
    }

    // 2. other reprocessing buffer
    ret = m_setReprocessingBuffer(true);
    if (ret != NO_ERROR) {
        CLOGE("Failed to m_setReprocessingBuffer. ret %d", ret);
        return false;
    }
#endif

#if defined(SUPPORT_REMOSAIC_ROTATION) || defined(SUPPORT_SENSOR_REMOSAIC_SW)
#ifdef SUPPORT_REMOSAIC_ROTATION
    SWAP(int, maxPictureW, maxPictureH);
#endif //SUPPORT_REMOSAIC_ROTATION

    bufTag = initBufTag;
    bufTag.pipeId[0] = PIPE_3AA_REPROCESSING;
#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
    bufTag.managerType = BUFFER_MANAGER_REMOSAIC_ION_TYPE;
#else
    bufTag.managerType = BUFFER_MANAGER_ION_TYPE;
#endif
    ret = m_bufferSupplier->createBufferManager("REMOSAIC_RE_BUF", m_ionAllocator, bufTag);
    if (ret != NO_ERROR) {
        CLOGE("Failed to create REMOSAIC buf. ret %d", ret);
    }

    minBufferCount = 1;
    maxBufferCount = 1;

    bufConfig = initBufConfig;
    bufConfig.planeCount = 2;
#ifdef CAMERA_PACKED_BAYER_ENABLE
    {
        bufConfig.bytesPerLine[0] = getBayerLineSize(maxPictureW, m_parameters[m_cameraId]->getBayerFormat(PIPE_3AA_REPROCESSING));
        // Old: bytesPerLine[0] = ROUND_UP((maxPictureW * 3 / 2), 16);
        bufConfig.size[0] = bufConfig.bytesPerLine[0] * maxPictureH;
    }
#else
    bufConfig.size[0] = maxPictureW * maxPictureH * 2;
#endif
    bufConfig.reqBufCount = minBufferCount;
    bufConfig.allowedMaxBufCount = maxBufferCount;
    bufConfig.batchSize = m_parameters[m_cameraId]->getBatchSize((enum pipeline)bufTag.pipeId[0]);
    bufConfig.type = EXYNOS_CAMERA_BUFFER_ION_CACHED_TYPE; //TODO Check
    bufConfig.allocMode = BUFFER_MANAGER_ALLOCATION_ONDEMAND;
    bufConfig.createMetaPlane = true;
    bufConfig.createDebugInfoPlane = isSupportedDebugInfoPlane((enum pipeline)bufTag.pipeId[0], &(bufConfig.planeCount));
    bufConfig.needMmap = true;
    bufConfig.reservedMemoryCount = 0;
    bufConfig.debugInfo = {maxPictureW, maxPictureH, m_parameters[m_cameraId]->getBayerFormat(PIPE_3AA_REPROCESSING)};

    ret = m_allocBuffers(bufTag, bufConfig);
    if (ret != NO_ERROR) {
        CLOGE("Failed to alloc REMOSAIC. ret %d", ret);
        return false;
    }
#endif //SUPPORT_REMOSAIC_ROTATION || SUPPORT_SENSOR_REMOSAIC_SW

    return false;
}

#ifdef SUPPORT_OPTIMIZED_REMOSAIC_BUFFER_ALLOCATION
bool ExynosCamera::m_releaseRemosaicBuffer(void)
{
    CLOGD("");

    m_bufferSupplier->deinit(BUFFER_MANAGER_REMOSAIC_ION_TYPE);
    m_bufferSupplier->deinit(BUFFER_MANAGER_REMOSAIC_ONLY_HAL_USE_ION_TYPE);

    CLOGD("Done");

    return false;
}
#endif

status_t ExynosCamera::m_handleRemosaicCaptureFrame(ExynosCameraFrameSP_sptr_t frame, int pipeId) {
    status_t ret = NO_ERROR;

    CLOGD("m_handleRemosaicCaptureFrame");

    frame_handle_components_t components;
    m_getFrameHandleComponentsWrapper(frame, &components, m_getCameraSessionId(frame));

    ExynosCameraRequestManager* requestMgr = m_getRequestManager(frame);

    ExynosCameraRequestSP_sprt_t request = requestMgr->getRunningRequest(frame->getFrameCount());

    int pipeId_src = m_getMcscLeaderPipeId(&components);
    int pipeId_jpeg = PIPE_JPEG_REPROCESSING;
    int pipe_mcsc_jpeg = PIPE_MCSC_JPEG_REPROCESSING;

	ExynosCameraFrameFactory* factory = components.reprocessingFactory;

    ExynosCameraBuffer dstBuffer;
    ExynosCameraBuffer gscBuffer;

    ret = frame->getDstBuffer(pipeId_src, &dstBuffer, factory->getNodeType(pipe_mcsc_jpeg));
    if (ret != NO_ERROR) {
        CLOGE("[F%d]Failed to getDstBuffer. pipeId %d ret %d",
                frame->getFrameCount(), pipeId_src, ret);
        return ret;
    }

    m_bufferSupplier->putBuffer(dstBuffer);
    if (ret != NO_ERROR) {
        CLOGE("[F%d B%d]Failed to putBuffer for JPEG_SRC. ret %d",
            frame->getFrameCount(), dstBuffer.index, ret);
    }

    ret = frame->getDstBuffer(pipeId, &gscBuffer);
    if (ret != NO_ERROR) {
        CLOGE("[F%d]Failed to getDstBuffer. pipeId %d ret %d",
            frame->getFrameCount(), pipeId, ret);
        return ret;
    }

    ret = frame->setSrcBuffer(pipeId_jpeg, gscBuffer);
    if (ret != NO_ERROR) {
        if (request == NULL) {
            CLOGE("[F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                    frame->getFrameCount(), pipeId_jpeg, ret);
        } else {
            CLOGE("[F%d]Failed to setSrcBuffer. pipeId %d ret %d",
                    frame->getFrameCount(), pipeId_jpeg, ret);
        }
    }

    factory->setOutputFrameQToPipe(m_yuvCaptureDoneQ, pipeId_jpeg);
    factory->pushFrameToPipe(frame, pipeId_jpeg);

    return ret;
}


#endif //SUPPORT_REMOSAIC_CAPTURE

#ifdef SUPPORT_VENDOR_TAG_FACTORY_LED_CALIBRATION
status_t ExynosCamera::m_setLedCalibration(struct camera2_shot_ext *shot_ext)
{
    if (m_flagOldSetLedCalibration != m_flagSetLedCalibration) {
        CLOGD("[MotFactory] m_setLedCalibration() (m_flagSetLedCalibration : %d) start", m_flagSetLedCalibration);
    }

    status_t ret = NO_ERROR;

    struct camera2_shot *shot = &(shot_ext->shot);

    ////////////////////////////////////////////////
    // set flash
    if (m_flagSetLedCalibration == true) {
        //CLOGI("[MotFactory] set shot->ctl.flash.flashMode(%d -> %d)", shot->ctl.flash.flashMode, CAM2_FLASH_MODE_SINGLE);
        shot->ctl.flash.flashMode = CAM2_FLASH_MODE_SINGLE;

        //CLOGI("[MotFactory] set shot->uctl.flashMode(%d -> %d)", shot->uctl.flashMode, CAMERA_FLASH_MODE_ON);
        shot->uctl.flashMode = CAMERA_FLASH_MODE_ON;
    } else {
        //CLOGI("[MotFactory] set shot->ctl.flash.flashMode(%d -> %d)", shot->ctl.flash.flashMode, CAM2_FLASH_MODE_SINGLE);
        shot->ctl.flash.flashMode = CAM2_FLASH_MODE_NONE;

        //CLOGI("[MotFactory] set shot->uctl.flashMode(%d -> %d)", shot->uctl.flashMode, CAMERA_FLASH_MODE_ON);
        shot->uctl.flashMode = CAMERA_FLASH_MODE_OFF;
    }

#if 0
    ////////////////////////////////////////////////
    // set sensitivity
    //CLOGI("[MotFactory] set shot->ctl.aa.vendor_isoMode(%d -> %d)", shot->ctl.aa.vendor_isoMode, AA_ISOMODE_MANUAL);
    shot->ctl.aa.vendor_isoMode = AA_ISOMODE_MANUAL;

    //CLOGI("[MotFactory] set shot->ctl.aa.vendor_isoValue(%d -> %d)", shot->ctl.aa.vendor_isoValue, 50);
    shot->ctl.aa.vendor_isoValue = 50;

    //CLOGI("[MotFactory] set shot->ctl.sensor.sensitivity(%d -> %d)", shot->ctl.sensor.sensitivity, 50);
    shot->ctl.sensor.sensitivity = 50;

    ////////////////////////////////////////////////
    // set exposure
    int newExposureTime = 25000;
    //CLOGI("[MotFactory] set shot->ctl.sensor.exposureTime(%ju -> %d)", shot->ctl.sensor.exposureTime, newExposureTime);
    setMetaCtlExposureTime(shot_ext, (uint64_t)newExposureTime);
#endif

    ////////////////////////////////////////////////

    if(m_flagOldSetLedCalibration != m_flagSetLedCalibration) {
        m_flagOldSetLedCalibration = m_flagSetLedCalibration;

        CLOGD("[MotFactory] m_setLedCalibration() end");
    }

    return ret;
}

status_t ExynosCamera::m_startLedCalibration(ExynosCameraFrameFactory *factory)
{
    CLOGD("[MotFactory] m_startLedCalibration() start");

    status_t ret = NO_ERROR;

    int pipeId = PIPE_3AA;

    ////////////////////////////////////////////////
    // turn on
    ret = factory->setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_ENABLE, 1, pipeId);
    if (ret != NO_ERROR) {
        CLOGE("[MotFactory] setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_ENABLE, 1, pipeId(%d)) fail", pipeId);
    } else {
        CLOGD("[MotFactory] setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_ENABLE, 1, pipeId(%d))", pipeId);
    }

    ////////////////////////////////////////////////
    // set current
    int cid = 0;
    int current = 0;

    for (int i = 0; i < 2; i++) {
        switch (i) {
        case 0:
            cid = V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_STROBE_CURRENTS_0;
            break;
        case 1:
            cid = V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_STROBE_CURRENTS_1;
            break;
        default:
            CLOGE("[MotFactory] Invalid index(%d) fail", i);
            cid = V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_STROBE_CURRENTS_0;
            break;
        }

        current = m_configurations->getLedCurrent(i);

        ret = factory->setControl(cid, current, pipeId);
        if (ret != NO_ERROR) {
            CLOGE("[MotFactory] setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_STROBE_CURRENTS_%d, %d, pipeId(%d)) fail", i, current, pipeId);
        } else {
            CLOGD("[MotFactory] setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_STROBE_CURRENTS_%d, %d, pipeId(%d))", i, current, pipeId);
        }
    }

    m_flagSetLedCalibration = true;

    ////////////////////////////////////////////////

    CLOGD("[MotFactory] m_startLedCalibration() end");

    return ret;
}

status_t ExynosCamera::m_stopLedCalibration(ExynosCameraFrameFactory *factory)
{
    CLOGD("[MotFactory] m_stopLedCalibration() start");

    status_t ret = NO_ERROR;

    int pipeId = PIPE_3AA;

    ////////////////////////////////////////////////
    // turn off
    ret = factory->setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_ENABLE, 0, pipeId);
    if (ret != NO_ERROR) {
        CLOGE("[MotFactory] setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_ENABLE, 0, pipeId(%d)) fail", pipeId);
    } else {
        CLOGD("[MotFactory] setControl(V4L2_CID_IS_TUNE_FACTORY_LED_CALIBRATION_ENABLE, 0, pipeId(%d))", pipeId);
    }

    m_flagSetLedCalibration = false;

    ////////////////////////////////////////////////

    CLOGD("[MotFactory] m_stopLedCalibration() end");

    return ret;
}

status_t ExynosCamera::m_dumpLedCalibrationFile(ExynosCameraFrameSP_sptr_t frame, ExynosCameraBuffer bayerBuffer)
{
    CLOGD("[MotFactory] m_dumpLedCalibrationFile() start");

    status_t ret = NO_ERROR;
    struct camera2_shot_ext *shot_ext = NULL;
    int hwSensorW = 0;
    int hwSensorH = 0;

    unsigned short AWbCurrentValue[4];
    struct ExynosCameraSensorInfoBase *sensorInfo = m_parameters[m_cameraId]->getSensorStaticInfo();
    int blackLevel = sensorInfo->blackLevel;

    ////////////////////////////////////////////////
    // flash start duration : flash on ~ best frame (bayer)
    m_flagSetLedCalibration = false;

    ////////////////////////////////////////////////
    // check condition
    if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == false) {
        CLOGE("[MotFactory] LED calibration should pure bayer. so, fail.");
        ret = INVALID_OPERATION;
        goto done;
    }

    ////////////////////////////////////////////////
    // get shot_ext
    shot_ext = (struct camera2_shot_ext *) bayerBuffer.addr[bayerBuffer.getMetaPlaneIndex()];
    if (shot_ext == NULL) {
        CLOGE("[MotFactory] [F%d B%d]shot_ext is NULL.", frame->getFrameCount(), bayerBuffer.index);
        ret = INVALID_OPERATION;
        goto done;

    }

    ////////////////////////////////////////////////
    // get argument
    m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&hwSensorW, (uint32_t *)&hwSensorH);

    ////////////////////////////////////////////////
    // get avg value.
    CLOGI("[MotFactory][F%d] ComputeAvgValue(hwSensorW : %d, hwSensorH : %d, bayerBuffer.addr : %p, bayerBuffer.size : %d, blackLevel : %d) start",
        getMetaDmRequestFrameCount(shot_ext),
        hwSensorW, hwSensorH, bayerBuffer.addr[0], bayerBuffer.size[0], blackLevel);

    ret = ComputeAvgValue(hwSensorW, hwSensorH,
#ifdef MOT_9609_SENSORS_TROIKA
                          BAYER_B_FIRST,
#else
                          DEFAULT_BAYER_FIRST,
#endif
                          bayerBuffer.addr[0],
                          hwSensorW / 2, hwSensorH / 2,
                          blackLevel,
                          AWbCurrentValue);
    if (ret != 0) {
        CLOGE("[MotFactory] ComputeAvgValue(%d, %d) fail", hwSensorW, hwSensorH);
        ret = INVALID_OPERATION;
    } else {
        CLOGI("[MotFactory] ComputeAvgValue() success. AWbCurrentValue(%d, %d, %d, %d)",
            AWbCurrentValue[0],
            AWbCurrentValue[1],
            AWbCurrentValue[2],
            AWbCurrentValue[3]);
    }

    ////////////////////////////////////////////////

done:
    if (ret != NO_ERROR) {
        CLOGE("[MotFactory] led calibration fail. please check");
    } else {
        ////////////////////////////////////////////////
        // read latest value
        struct ExynosCameraLEDCalibrationMap ledCalibrationMap;

        char *fileName = (char *)LED_CALIBRATION_FILE_PATH;
        char *bufAddr = (char *)&ledCalibrationMap;
        int   bufSize = sizeof(struct ExynosCameraLEDCalibrationMap);

        ret = readFromFile(fileName, (char*)bufAddr, bufSize);
        if (ret != NO_ERROR) {
            CLOGE("[MotFactory] readFromFile(%s, %p, %d) fail", fileName, (char*)bufAddr, bufSize);
        }

        ////////////////////////////////////////////////
        // calculate value.
        struct ExynosCameraSensorInfoBase *sensorInfo = m_parameters[m_cameraId]->getSensorStaticInfo();

        int count = 0;
        int ledCurrent0 = m_configurations->getLedCurrent(0);
        int ledCurrent1 = m_configurations->getLedCurrent(1);
        int32_t *LedCalibrationMaster = NULL;

        if (ledCurrent0 > ledCurrent1) {
            ////////////////////////////////////////////////
            // 1st led
            count = 1;

            LedCalibrationMaster = sensorInfo->LedCalibrationMasterCool;

            ledCalibrationMap.Cool_LED_Master_R_Avg  = LedCalibrationMaster[0];
            ledCalibrationMap.Cool_LED_Master_Gr_Avg = LedCalibrationMaster[1];
            ledCalibrationMap.Cool_LED_Master_Gb_Avg = LedCalibrationMaster[2];
            ledCalibrationMap.Cool_LED_Master_b_Avg  = LedCalibrationMaster[3];

            ledCalibrationMap.Cool_LED_Current_R_Avg  = AWbCurrentValue[0];
            ledCalibrationMap.Cool_LED_Current_Gr_Avg = AWbCurrentValue[1];
            ledCalibrationMap.Cool_LED_Current_Gb_Avg = AWbCurrentValue[2];
            ledCalibrationMap.Cool_LED_Current_b_Avg  = AWbCurrentValue[3];
        } else if (ledCurrent0 < ledCurrent1) {
            ////////////////////////////////////////////////
            // 2nd led
            count = 2;

            LedCalibrationMaster = sensorInfo->LedCalibrationMasterWarm;

            ledCalibrationMap.Warm_LED_Master_R_Avg  = LedCalibrationMaster[0];
            ledCalibrationMap.Warm_LED_Master_Gr_Avg = LedCalibrationMaster[1];
            ledCalibrationMap.Warm_LED_Master_Gb_Avg = LedCalibrationMaster[2];
            ledCalibrationMap.Warm_LED_Master_b_Avg  = LedCalibrationMaster[3];

            ledCalibrationMap.Warm_LED_Current_R_Avg  = AWbCurrentValue[0];
            ledCalibrationMap.Warm_LED_Current_Gr_Avg = AWbCurrentValue[1];
            ledCalibrationMap.Warm_LED_Current_Gb_Avg = AWbCurrentValue[2];
            ledCalibrationMap.Warm_LED_Current_b_Avg  = AWbCurrentValue[3];
        } else { // (ledCurrent0 == ledCurrent1)
            ////////////////////////////////////////////////
            // 3nd led
            count = 3;

            LedCalibrationMaster = sensorInfo->LedCalibrationMasterCoolWarm;

            ledCalibrationMap.Cool_Warm_LED_Master_R_Avg  = LedCalibrationMaster[0];
            ledCalibrationMap.Cool_Warm_LED_Master_GrAvg  = LedCalibrationMaster[1];
            ledCalibrationMap.Cool_Warm_LED_Master_Gb_Avg = LedCalibrationMaster[2];
            ledCalibrationMap.Cool_Warm_LED_Master_b_Avg  = LedCalibrationMaster[3];

            ledCalibrationMap.Cool_Warm_LED_Current_R_Avg  = AWbCurrentValue[0];
            ledCalibrationMap.Cool_Warm_LED_Current_Gr_Avg = AWbCurrentValue[1];
            ledCalibrationMap.Cool_Warm_LED_Current_Gb_Avg = AWbCurrentValue[2];
            ledCalibrationMap.Cool_Warm_LED_Current_b_Avg  = AWbCurrentValue[3];
        }

        CLOGI("[MotFactory] %d LED ledCurrent0(%d), ledCurrent1(%d), master(%d, %d, %d, %d), current(%d, %d, %d, %d)",
            count,
            ledCurrent0,
            ledCurrent1,
            LedCalibrationMaster[0],
            LedCalibrationMaster[1],
            LedCalibrationMaster[2],
            LedCalibrationMaster[3],
            AWbCurrentValue[0],
            AWbCurrentValue[1],
            AWbCurrentValue[2],
            AWbCurrentValue[3]);

        ////////////////////////////////////////////////
        // write info
        ret = writeToFile(fileName, bufAddr, bufSize);
        if (ret != NO_ERROR) {
            CLOGE("[MotFactory] writeToFile(%s, %p, %d) fail", fileName, bufAddr, bufSize);
        }

        ////////////////////////////////////////////////
    }

    CLOGD("[MotFactory] m_dumpLedCalibrationFile() end");

    return ret;
}
#endif

void ExynosCamera::m_updateTnr(struct camera2_shot_ext *shot_ext, ExynosCameraParameters *parameters)
{
    int tnrMode = parameters->getTnrMode();

    CLOGV("tnrMode : %d", tnrMode);
    setMetaTnrMode(shot_ext, tnrMode);

    return;
}

bool ExynosCamera::isOfflineCaptureRunning(int cameraSessionId)
{
    bool bRunning = false;
    status_t ret = NO_ERROR;

#ifdef USE_DEBUG_PROPERTY
    ExynosCameraProperty property;

    ret = property.get(ExynosCameraProperty::DEBUG_TEST_OFFLINE_CAPTURE, LOG_TAG, bRunning);
    if (ret != NO_ERROR) {
        bRunning = false;
    }
#endif

#ifdef USES_OFFLINE_CAPTURE
    bRunning = m_offlineCapture->isOfflineCaptureRunning(cameraSessionId);
#endif

    CLOGD("[S(%d) [OFFLINE] offline is %s running", cameraSessionId, bRunning?"":"NOT");

    return bRunning;
}

#ifdef DEBUG_RAWDUMP
void ExynosCamera::m_dumpRawBuffer(ExynosCameraBuffer* bayerBuffer, ExynosCameraFrameSP_sptr_t bayerFrame, ExynosCameraFrameSP_sptr_t frame)
{
    status_t ret = NO_ERROR;
    bool bRet = false;
    time_t rawtime;
    struct tm *timeinfo;
    char filePath[100];
    uint32_t width = 0, height = 0;
    enum FRAME_TYPE frameType = frame->getFrameType();

    CLOGD("m_cameraId(%d) getUsePureBayerReprocessing(%d)",
            m_cameraId, m_parameters[m_cameraId]->getUsePureBayerReprocessing());

    if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == true) {
        m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_SIZE, &width, &height);
        memset(filePath, 0, sizeof(filePath));
        time(&rawtime);
        timeinfo = localtime(&rawtime);
        snprintf(filePath, sizeof(filePath), "%sRaw%d_%02d%02d%02d_%02d%02d%02d_%d_%dx%d.raw",
                CAMERA_DATA_PATH, m_cameraId, timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
        timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec, bayerFrame->getFrameCount(), width, height);

        bRet = dumpToFile((char *)filePath,
        bayerBuffer->addr[0],
        bayerBuffer->size[0]);
        if (bRet != true)
            CLOGE("couldn't make a raw file");
    } else if (m_parameters[m_cameraId]->getUsePureBayerReprocessing() == false) {
        if (bayerFrame->getRequest(PIPE_VC0) == true) {
            ExynosCameraBuffer rawDumpBuffer;
            frame_handle_components_t components;

            m_getFrameHandleComponentsWrapper(frame, &components);
            ret = bayerFrame->getDstBuffer(m_getBayerPipeId(), &rawDumpBuffer, components.previewFactory->getNodeType(PIPE_VC0));
            if (ret != NO_ERROR || rawDumpBuffer.index < 0) {
                CLOGE("[F%d B%d]Failed to getDstBuffer for RAW_DUMP. pipeId %d ret %d",
                        bayerFrame->getFrameCount(), rawDumpBuffer.index, m_getBayerPipeId(), ret);
            } else {
                m_parameters[m_cameraId]->getSize(HW_INFO_HW_SENSOR_SIZE, &width, &height);
                time(&rawtime);
                timeinfo = localtime(&rawtime);

#ifdef BUFFER_DUMP
                buffer_dump_info_t bufDumpInfo;
                bufDumpInfo.buffer = rawDumpBuffer;
                bufDumpInfo.format = CAMERA_DUMP_BAYER_FORMAT;
                bufDumpInfo.width = width;
                bufDumpInfo.height = height;
                bufDumpInfo.frameCount = bayerFrame->getFrameCount();

                snprintf(bufDumpInfo.name, sizeof(bufDumpInfo.name), "%02d%02d%02d_%02d%02d%02d",
                        timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
                        timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec);

                m_dumpBufferQ->pushProcessQ(&bufDumpInfo);
#else
                memset(filePath, 0, sizeof(filePath));
                snprintf(filePath, sizeof(filePath), "%sRaw%d_%02d%02d%02d_%02d%02d%02d_%d_%dx%d.raw",
                            CAMERA_DATA_PATH, components.previewFactory->getCameraId(), timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday,
                            timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec, bayerFrame->getFrameCount(), width, height);

                bRet = dumpToFile((char *)filePath,
                            rawDumpBuffer.addr[0],
                            rawDumpBuffer.size[0]);
                if (bRet != true)
                    CLOGE("couldn't make a raw file");

                m_bufferSupplier->putBuffer(rawDumpBuffer);
#endif
            }
        }
    }
    CLOGD("--- OUT ---");
}
#endif /* DEBUG_RAWDUMP */
void ExynosCamera::m_updateCropRegion_vendor(struct camera2_shot_ext *shot_ext,
                                             frame_handle_components_t *components,
                                             frame_type_t frameType,
                                             ExynosRect &targetActiveZoomRect,
                                             int sensorActiveMaxW, int sensorActiveMaxH,
                                             bool isReprocessing)
{

#ifdef USE_DUAL_CAMERA
    float scaleRatioW = 1.0f, scaleRatioH = 1.0f;
    float zoomRatio = shot_ext->shot.uctl.zoomRatio;
    ExynosCameraParameters *parameters = components->parameters;

#ifdef USE_DUAL_VENDOR_LIB_CROP
    // do nothing. just give application info to lib
#else
    int sensorHwMaxW = 0;
    int sensorHwMaxH = 0;
    float scaleRatio = 1.0f;
    int newCropRegion[4] = {0, };

    // should use binning sensor size in case of multiple camera in lib
    parameters->getSize(HW_INFO_HW_SENSOR_SIZE, (uint32_t *)&sensorHwMaxW, (uint32_t *)&sensorHwMaxH);
    scaleRatioW = (float) sensorHwMaxW / (float) sensorActiveMaxW;
    scaleRatioH = (float) sensorHwMaxH / (float) sensorActiveMaxH;
    scaleRatio = getSensorRatio(&m_camIdInfo, components->currentCameraId);

    targetActiveZoomRect.w = newCropRegion[2] = MIN(sensorHwMaxW / (zoomRatio / scaleRatio), sensorHwMaxW);
    targetActiveZoomRect.h = newCropRegion[3] = MIN(sensorHwMaxH / (zoomRatio / scaleRatio), sensorHwMaxH);
    targetActiveZoomRect.x = newCropRegion[0] = (sensorHwMaxW - ALIGN_UP(newCropRegion[2], 2)) / 2;
    targetActiveZoomRect.y = newCropRegion[1] = (sensorHwMaxH - ALIGN_UP(newCropRegion[3], 2)) / 2;
#endif

    parameters->setActiveZoomMargin(0);

    // adjust sensor Hw size to activeArraySize
    targetActiveZoomRect.x = ALIGN_DOWN((int) (((float) targetActiveZoomRect.x) / scaleRatioW), 2);
    targetActiveZoomRect.y = ALIGN_DOWN((int) (((float) targetActiveZoomRect.y) / scaleRatioH), 2);
    targetActiveZoomRect.w = (int) (((float) targetActiveZoomRect.w) / scaleRatioW);
    targetActiveZoomRect.h = (int) (((float) targetActiveZoomRect.h) / scaleRatioH);
#endif
}

bool ExynosCamera::isSupportedDebugInfoPlane(__unused enum pipeline pipeId, int *planeCount)
{
    bool bEnabled = false;

    //Recheck the pipe property, currently only ISP reprocessing enabled the Plane.
    if (getDebugInfoPlanePropertyValue())
        bEnabled = m_parameters[m_cameraId]->isDebugInfoPlane(pipeId, planeCount);

    return bEnabled;
}
}; /* namespace android */
